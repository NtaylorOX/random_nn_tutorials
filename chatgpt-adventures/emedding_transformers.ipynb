{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# from chatgpt\n",
    "def get_sentence_embeddings(model_name_or_path, data_examples):\n",
    "    \n",
    "\n",
    "    # Set the device to use (GPU if available)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Load pre-trained model tokenizer and model weights\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "    model = AutoModel.from_pretrained(model_name_or_path).to(device)\n",
    "\n",
    "    # Tokenize the text samples and convert to tensors\n",
    "    inputs = tokenizer(data_examples, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Pass the inputs through the model and retrieve the embeddings for all tokens\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Retrieve the attention mask from the inputs\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    # Compute the weighted mean of the token embeddings for each sentence\n",
    "    sum_embeddings = torch.sum(outputs.last_hidden_state * attention_mask.unsqueeze(-1), dim=1)\n",
    "    mean_embeddings = sum_embeddings / torch.sum(attention_mask, dim=1, keepdim=True)\n",
    "\n",
    "    # Move embeddings back to the CPU and convert to numpy array\n",
    "    mean_embeddings = mean_embeddings.cpu().detach().numpy()\n",
    "\n",
    "    return mean_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model_name_or_path = \"bert-base-uncased\"\n",
    "data_examples = [\n",
    "    \"This is the first sentence.\",\n",
    "    \"Here is the second sentence.\",\n",
    "    \"And this is the third sentence.\",\n",
    "    \"This is the first sentence.\",\n",
    "    \"Here is the second sentence.\",\n",
    "    \"And this is the third sentence.\",\n",
    "    \"This is the first sentence.\",\n",
    "    \"Here is the second sentence.\",\n",
    "    \"And this is the third sentence.\",\n",
    "    \"This is the first sentence.\",\n",
    "    \"Here is the second sentence.\",\n",
    "    \"And this is the third sentence.\",\n",
    "    \"This is the first sentence.\",\n",
    "    \"Here is the second sentence.\",\n",
    "    \"And this is the third sentence.\",\n",
    "    \"This is the first sentence.\",\n",
    "    \"Here is the second sentence.\",\n",
    "    \"And this is the third sentence.\",\n",
    "    \"This is the first sentence.\",\n",
    "    \"Here is the second sentence.\",\n",
    "    \"And this is the third sentence.\",\n",
    "    \"This is the first sentence.\",\n",
    "    \"Here is the second sentence.\",\n",
    "    \"And this is the third sentence.\"\n",
    "]\n",
    "\n",
    "# Compute sentence embeddings\n",
    "embeddings = get_sentence_embeddings(model_name_or_path, data_examples)\n",
    "\n",
    "# Print the resulting embeddings for each sentence\n",
    "# for i, embedding in enumerate(embeddings):\n",
    "#     # print(f\"Sentence {i+1} embedding:\\n{embedding}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_sentence_embeddings_mine(model_name_or_path, data_examples):\n",
    "    \n",
    "\n",
    "    # Set the device to use (GPU if available)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Load pre-trained model tokenizer and model weights\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "    model = AutoModel.from_pretrained(model_name_or_path).to(device)\n",
    "\n",
    "    # Tokenize the text samples and convert to tensors\n",
    "    inputs = tokenizer(data_examples, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "    # Pass the inputs through the model and retrieve the embeddings for all tokens\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        pooled_output  = torch.sum(\n",
    "            sequence_output * attention_mask.unsqueeze(-1), dim=1\n",
    "        ) / torch.clamp(torch.sum(attention_mask, dim=1, keepdims=True), min=1e-9)\n",
    "\n",
    "\n",
    "\n",
    "    return pooled_output.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embeddings_mine = get_sentence_embeddings_mine(model_name_or_path, data_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def visualize_embeddings(embeddings):\n",
    "#     # Use UMAP to reduce the dimensionality of the embeddings to 2D\n",
    "#     reducer = umap.UMAP(n_components=2, metric = \"cosine\")\n",
    "#     mapper = reducer.fit(embeddings)\n",
    "#     umap_embeddings = mapper.embedding_ \n",
    "\n",
    "#     # Plot the resulting 2D embeddings\n",
    "#     plt.scatter(umap_embeddings[:, 0], umap_embeddings[:, 1])\n",
    "#     plt.show()\n",
    "\n",
    "#     return umap_embeddings\n",
    "\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_embeddings(embeddings):\n",
    "    # Use UMAP to reduce the dimensionality of the embeddings to 2D\n",
    "    reducer = umap.UMAP(n_components=2)\n",
    "    umap_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "    # Plot the resulting 2D embeddings\n",
    "    plt.scatter(umap_embeddings[:, 0], umap_embeddings[:, 1])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_embeddings(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_embeds.embedding_.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "39nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
