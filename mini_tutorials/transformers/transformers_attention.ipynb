{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n",
    "# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"PyTorch BERT model.\"\"\"\n",
    "\n",
    "\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "from transformers.activations import ACT2FN\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    MaskedLMOutput,\n",
    "    MultipleChoiceModelOutput,\n",
    "    NextSentencePredictorOutput,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutput,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "from transformers.utils import (\n",
    "    ModelOutput,\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"bert-base-uncased\"\n",
    "_CONFIG_FOR_DOC = \"BertConfig\"\n",
    "\n",
    "# TokenClassification docstring\n",
    "_CHECKPOINT_FOR_TOKEN_CLASSIFICATION = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "_TOKEN_CLASS_EXPECTED_OUTPUT = (\n",
    "    \"['O', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'I-LOC', 'I-LOC'] \"\n",
    ")\n",
    "_TOKEN_CLASS_EXPECTED_LOSS = 0.01\n",
    "\n",
    "# QuestionAnswering docstring\n",
    "_CHECKPOINT_FOR_QA = \"deepset/bert-base-cased-squad2\"\n",
    "_QA_EXPECTED_OUTPUT = \"'a nice puppet'\"\n",
    "_QA_EXPECTED_LOSS = 7.41\n",
    "_QA_TARGET_START_INDEX = 14\n",
    "_QA_TARGET_END_INDEX = 15\n",
    "\n",
    "# SequenceClassification docstring\n",
    "_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION = \"textattack/bert-base-uncased-yelp-polarity\"\n",
    "_SEQ_CLASS_EXPECTED_OUTPUT = \"'LABEL_1'\"\n",
    "_SEQ_CLASS_EXPECTED_LOSS = 0.01\n",
    "\n",
    "\n",
    "BERT_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"bert-large-uncased\",\n",
    "    \"bert-base-cased\",\n",
    "    \"bert-large-cased\",\n",
    "    \"bert-base-multilingual-uncased\",\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    \"bert-base-chinese\",\n",
    "    \"bert-base-german-cased\",\n",
    "    \"bert-large-uncased-whole-word-masking\",\n",
    "    \"bert-large-cased-whole-word-masking\",\n",
    "    \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
    "    \"bert-large-cased-whole-word-masking-finetuned-squad\",\n",
    "    \"bert-base-cased-finetuned-mrpc\",\n",
    "    \"bert-base-german-dbmdz-cased\",\n",
    "    \"bert-base-german-dbmdz-uncased\",\n",
    "    \"cl-tohoku/bert-base-japanese\",\n",
    "    \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
    "    \"cl-tohoku/bert-base-japanese-char\",\n",
    "    \"cl-tohoku/bert-base-japanese-char-whole-word-masking\",\n",
    "    \"TurkuNLP/bert-base-finnish-cased-v1\",\n",
    "    \"TurkuNLP/bert-base-finnish-uncased-v1\",\n",
    "    \"wietsedv/bert-base-dutch-cased\",\n",
    "    # See all BERT models at https://huggingface.co/models?filter=bert\n",
    "]\n",
    "\n",
    "\n",
    "def load_tf_weights_in_bert(model, config, tf_checkpoint_path):\n",
    "    \"\"\"Load tf checkpoints in a pytorch model.\"\"\"\n",
    "    try:\n",
    "        import re\n",
    "\n",
    "        import numpy as np\n",
    "        import tensorflow as tf\n",
    "    except ImportError:\n",
    "        logger.error(\n",
    "            \"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"\n",
    "            \"https://www.tensorflow.org/install/ for installation instructions.\"\n",
    "        )\n",
    "        raise\n",
    "    tf_path = os.path.abspath(tf_checkpoint_path)\n",
    "    logger.info(f\"Converting TensorFlow checkpoint from {tf_path}\")\n",
    "    # Load weights from TF model\n",
    "    init_vars = tf.train.list_variables(tf_path)\n",
    "    names = []\n",
    "    arrays = []\n",
    "    for name, shape in init_vars:\n",
    "        logger.info(f\"Loading TF weight {name} with shape {shape}\")\n",
    "        array = tf.train.load_variable(tf_path, name)\n",
    "        names.append(name)\n",
    "        arrays.append(array)\n",
    "\n",
    "    for name, array in zip(names, arrays):\n",
    "        name = name.split(\"/\")\n",
    "        # adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v\n",
    "        # which are not required for using pretrained model\n",
    "        if any(\n",
    "            n in [\"adam_v\", \"adam_m\", \"AdamWeightDecayOptimizer\", \"AdamWeightDecayOptimizer_1\", \"global_step\"]\n",
    "            for n in name\n",
    "        ):\n",
    "            logger.info(f\"Skipping {'/'.join(name)}\")\n",
    "            continue\n",
    "        pointer = model\n",
    "        for m_name in name:\n",
    "            if re.fullmatch(r\"[A-Za-z]+_\\d+\", m_name):\n",
    "                scope_names = re.split(r\"_(\\d+)\", m_name)\n",
    "            else:\n",
    "                scope_names = [m_name]\n",
    "            if scope_names[0] == \"kernel\" or scope_names[0] == \"gamma\":\n",
    "                pointer = getattr(pointer, \"weight\")\n",
    "            elif scope_names[0] == \"output_bias\" or scope_names[0] == \"beta\":\n",
    "                pointer = getattr(pointer, \"bias\")\n",
    "            elif scope_names[0] == \"output_weights\":\n",
    "                pointer = getattr(pointer, \"weight\")\n",
    "            elif scope_names[0] == \"squad\":\n",
    "                pointer = getattr(pointer, \"classifier\")\n",
    "            else:\n",
    "                try:\n",
    "                    pointer = getattr(pointer, scope_names[0])\n",
    "                except AttributeError:\n",
    "                    logger.info(f\"Skipping {'/'.join(name)}\")\n",
    "                    continue\n",
    "            if len(scope_names) >= 2:\n",
    "                num = int(scope_names[1])\n",
    "                pointer = pointer[num]\n",
    "        if m_name[-11:] == \"_embeddings\":\n",
    "            pointer = getattr(pointer, \"weight\")\n",
    "        elif m_name == \"kernel\":\n",
    "            array = np.transpose(array)\n",
    "        try:\n",
    "            if pointer.shape != array.shape:\n",
    "                raise ValueError(f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\")\n",
    "        except AssertionError as e:\n",
    "            e.args += (pointer.shape, array.shape)\n",
    "            raise\n",
    "        logger.info(f\"Initialize PyTorch weight {name}\")\n",
    "        pointer.data = torch.from_numpy(array)\n",
    "    return model\n",
    "\n",
    "\n",
    "class BertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        print(f\"position embeddings shape at init: {self.position_embeddings}\")\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
    "        # any TensorFlow checkpoint file\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        # position_ids (1, len position emb) is contiguous in memory and exported when serialized\n",
    "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
    "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n",
    "        self.register_buffer(\n",
    "            \"token_type_ids\", torch.zeros(self.position_ids.size(), dtype=torch.long), persistent=False\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values_length: int = 0,\n",
    "    ) -> torch.Tensor:\n",
    "        if input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        else:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "\n",
    "        seq_length = input_shape[1]\n",
    "\n",
    "        \n",
    "        if position_ids is None:\n",
    "            position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]\n",
    "        print(f\"position ids: {position_ids}\")\n",
    "\n",
    "        # Setting the token_type_ids to the registered buffer in constructor where it is all zeros, which usually occurs\n",
    "        # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves\n",
    "        # issue #5664\n",
    "        if token_type_ids is None:\n",
    "            if hasattr(self, \"token_type_ids\"):\n",
    "                buffered_token_type_ids = self.token_type_ids[:, :seq_length]\n",
    "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(input_shape[0], seq_length)\n",
    "                token_type_ids = buffered_token_type_ids_expanded\n",
    "            else:\n",
    "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.word_embeddings(input_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = inputs_embeds + token_type_embeddings\n",
    "        if self.position_embedding_type == \"absolute\":\n",
    "            position_embeddings = self.position_embeddings(position_ids)\n",
    "            print(f\"position embeddings shape before added to embeddings: {position_embeddings.shape}\")\n",
    "            embeddings += position_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config, position_embedding_type=None):\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
    "                f\"heads ({config.num_attention_heads})\"\n",
    "            )\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "        \n",
    "        print(f\"Number of attention heads is: {self.num_attention_heads}\\n\")\n",
    "        print(f\"attention_head_size is: {self.attention_head_size}\")\n",
    "        print(f\"all_head size is: {self.all_head_size}\")\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        \n",
    "        print(f\"Query is: {self.query}, key is: {self.key}, value is: {self.value}\")\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "        self.position_embedding_type = position_embedding_type or getattr(\n",
    "            config, \"position_embedding_type\", \"absolute\"\n",
    "        )\n",
    "        \n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            self.max_position_embeddings = config.max_position_embeddings\n",
    "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
    "\n",
    "        self.is_decoder = config.is_decoder\n",
    "\n",
    "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        print(f\"inside transpose for scores, shape before new shape:{x.shape}\")\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        print(f\"new x shape is: {new_x_shape}\")\n",
    "        x = x.view(new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        print(f\"hidden states going to mixed query layer: {hidden_states.shape}\")\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "\n",
    "        # If this is instantiated as a cross-attention module, the keys\n",
    "        # and values come from an encoder; the attention mask needs to be\n",
    "        # such that the encoder's padding tokens are not attended to.\n",
    "        is_cross_attention = encoder_hidden_states is not None\n",
    "\n",
    "        if is_cross_attention and past_key_value is not None:\n",
    "            # reuse k,v, cross_attentions\n",
    "            key_layer = past_key_value[0]\n",
    "            value_layer = past_key_value[1]\n",
    "            attention_mask = encoder_attention_mask\n",
    "        elif is_cross_attention:\n",
    "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
    "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
    "            attention_mask = encoder_attention_mask\n",
    "        elif past_key_value is not None:\n",
    "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
    "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
    "        else:\n",
    "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "\n",
    "        use_cache = past_key_value is not None\n",
    "        if self.is_decoder:\n",
    "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
    "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
    "            # key/value_states (first \"if\" case)\n",
    "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
    "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
    "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
    "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
    "            past_key_value = (key_layer, value_layer)\n",
    "        \n",
    "        print(f\"key layer: {key_layer}, query layer: {query_layer}\")\n",
    "\n",
    "        print(f\"after transposing the new key layer shape is: {key_layer.shape}, new value layer is: {value_layer.shape} and query layer is: {query_layer.shape}\")\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        print(f\"attention scores shape is: {attention_scores.shape}\")\n",
    "\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
    "            if use_cache:\n",
    "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
    "                    -1, 1\n",
    "                )\n",
    "            else:\n",
    "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
    "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
    "            distance = position_ids_l - position_ids_r\n",
    "\n",
    "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
    "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
    "\n",
    "            if self.position_embedding_type == \"relative_key\":\n",
    "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "                attention_scores = attention_scores + relative_position_scores\n",
    "            elif self.position_embedding_type == \"relative_key_query\":\n",
    "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
    "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
    "\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "            print(f\"Attention mask is: {attention_mask}\")\n",
    "            print(f\"attention scores before mask is: {attention_scores} of shape: {attention_scores.shape}\")\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "            print(f\"attention scores after mask is: {attention_scores} of shape {attention_scores.shape}\")\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
    "        print(f\"attention probs shape is: {attention_probs}\")\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask\n",
    "        print(f\"before context layer calc, attention_probs shape is:\\n {attention_probs.shape}, and value_layer shape is: \\n{value_layer.shape}\")\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        print(f\"context layer after matmul is:\\n {context_layer} of shape: {context_layer.shape} \")\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(new_context_layer_shape)\n",
    "\n",
    "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "\n",
    "        if self.is_decoder:\n",
    "            outputs = outputs + (past_key_value,)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config, position_embedding_type=None):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(config, position_embedding_type=position_embedding_type)\n",
    "        self.output = BertSelfOutput(config)\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        heads, index = find_pruneable_heads_and_indices(\n",
    "            heads, self.self.num_attention_heads, self.self.attention_head_size, self.pruned_heads\n",
    "        )\n",
    "\n",
    "        # Prune linear layers\n",
    "        self.self.query = prune_linear_layer(self.self.query, index)\n",
    "        self.self.key = prune_linear_layer(self.self.key, index)\n",
    "        self.self.value = prune_linear_layer(self.self.value, index)\n",
    "        self.output.dense = prune_linear_layer(self.output.dense, index, dim=1)\n",
    "\n",
    "        # Update hyper params and store pruned heads\n",
    "        self.self.num_attention_heads = self.self.num_attention_heads - len(heads)\n",
    "        self.self.all_head_size = self.self.attention_head_size * self.self.num_attention_heads\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        self_outputs = self.self(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask,\n",
    "            past_key_value,\n",
    "            output_attentions,\n",
    "        )\n",
    "        attention_output = self.output(self_outputs[0], hidden_states)\n",
    "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        if isinstance(config.hidden_act, str):\n",
    "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.attention = BertAttention(config)\n",
    "        self.is_decoder = config.is_decoder\n",
    "        self.add_cross_attention = config.add_cross_attention\n",
    "        if self.add_cross_attention:\n",
    "            if not self.is_decoder:\n",
    "                raise ValueError(f\"{self} should be used as a decoder model if cross attention is added\")\n",
    "            self.crossattention = BertAttention(config, position_embedding_type=\"absolute\")\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "        \n",
    "        print(f\"got layer\")\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
    "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
    "        self_attention_outputs = self.attention(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            past_key_value=self_attn_past_key_value,\n",
    "        )\n",
    "        attention_output = self_attention_outputs[0]\n",
    "\n",
    "        # if decoder, the last output is tuple of self-attn cache\n",
    "        if self.is_decoder:\n",
    "            outputs = self_attention_outputs[1:-1]\n",
    "            present_key_value = self_attention_outputs[-1]\n",
    "        else:\n",
    "            outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "\n",
    "        cross_attn_present_key_value = None\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            if not hasattr(self, \"crossattention\"):\n",
    "                raise ValueError(\n",
    "                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers\"\n",
    "                    \" by setting `config.add_cross_attention=True`\"\n",
    "                )\n",
    "\n",
    "            # cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple\n",
    "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
    "            cross_attention_outputs = self.crossattention(\n",
    "                attention_output,\n",
    "                attention_mask,\n",
    "                head_mask,\n",
    "                encoder_hidden_states,\n",
    "                encoder_attention_mask,\n",
    "                cross_attn_past_key_value,\n",
    "                output_attentions,\n",
    "            )\n",
    "            attention_output = cross_attention_outputs[0]\n",
    "            outputs = outputs + cross_attention_outputs[1:-1]  # add cross attentions if we output attention weights\n",
    "\n",
    "            # add cross-attn cache to positions 3,4 of present_key_value tuple\n",
    "            cross_attn_present_key_value = cross_attention_outputs[-1]\n",
    "            present_key_value = present_key_value + cross_attn_present_key_value\n",
    "\n",
    "        layer_output = apply_chunking_to_forward(\n",
    "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
    "        )\n",
    "        outputs = (layer_output,) + outputs\n",
    "\n",
    "        # if decoder, return the attn key/values as the last output\n",
    "        if self.is_decoder:\n",
    "            outputs = outputs + (present_key_value,)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def feed_forward_chunk(self, attention_output):\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output\n",
    "\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        output_hidden_states: Optional[bool] = False,\n",
    "        return_dict: Optional[bool] = True,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attentions = () if output_attentions else None\n",
    "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
    "\n",
    "        next_decoder_cache = () if use_cache else None\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
    "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                if use_cache:\n",
    "                    logger.warning(\n",
    "                        \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "                    )\n",
    "                    use_cache = False\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs, past_key_value, output_attentions)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(layer_module),\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                    past_key_value,\n",
    "                    output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "            if use_cache:\n",
    "                next_decoder_cache += (layer_outputs[-1],)\n",
    "            if output_attentions:\n",
    "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
    "                if self.config.add_cross_attention:\n",
    "                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [\n",
    "                    hidden_states,\n",
    "                    next_decoder_cache,\n",
    "                    all_hidden_states,\n",
    "                    all_self_attentions,\n",
    "                    all_cross_attentions,\n",
    "                ]\n",
    "                if v is not None\n",
    "            )\n",
    "        return BaseModelOutputWithPastAndCrossAttentions(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=next_decoder_cache,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attentions,\n",
    "            cross_attentions=all_cross_attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "\n",
    "class BertPredictionHeadTransform(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        if isinstance(config.hidden_act, str):\n",
    "            self.transform_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.transform_act_fn = config.hidden_act\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.transform_act_fn(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class BertLMPredictionHead(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.transform = BertPredictionHeadTransform(config)\n",
    "\n",
    "        # The output weights are the same as the input embeddings, but there is\n",
    "        # an output-only bias for each token.\n",
    "        self.decoder = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.zeros(config.vocab_size))\n",
    "\n",
    "        # Need a link between the two variables so that the bias is correctly resized with `resize_token_embeddings`\n",
    "        self.decoder.bias = self.bias\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.transform(hidden_states)\n",
    "        hidden_states = self.decoder(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class BertOnlyMLMHead(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.predictions = BertLMPredictionHead(config)\n",
    "\n",
    "    def forward(self, sequence_output: torch.Tensor) -> torch.Tensor:\n",
    "        prediction_scores = self.predictions(sequence_output)\n",
    "        return prediction_scores\n",
    "\n",
    "\n",
    "class BertOnlyNSPHead(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, pooled_output):\n",
    "        seq_relationship_score = self.seq_relationship(pooled_output)\n",
    "        return seq_relationship_score\n",
    "\n",
    "\n",
    "class BertPreTrainingHeads(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.predictions = BertLMPredictionHead(config)\n",
    "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, sequence_output, pooled_output):\n",
    "        prediction_scores = self.predictions(sequence_output)\n",
    "        seq_relationship_score = self.seq_relationship(pooled_output)\n",
    "        return prediction_scores, seq_relationship_score\n",
    "\n",
    "\n",
    "class BertPreTrainedModel(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n",
    "    models.\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = BertConfig\n",
    "    load_tf_weights = load_tf_weights_in_bert\n",
    "    base_model_prefix = \"bert\"\n",
    "    supports_gradient_checkpointing = True\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Initialize the weights\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def _set_gradient_checkpointing(self, module, value=False):\n",
    "        if isinstance(module, BertEncoder):\n",
    "            module.gradient_checkpointing = value\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BertForPreTrainingOutput(ModelOutput):\n",
    "    \"\"\"\n",
    "    Output type of [`BertForPreTraining`].\n",
    "    Args:\n",
    "        loss (*optional*, returned when `labels` is provided, `torch.FloatTensor` of shape `(1,)`):\n",
    "            Total loss as the sum of the masked language modeling loss and the next sequence prediction\n",
    "            (classification) loss.\n",
    "        prediction_logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`):\n",
    "            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
    "        seq_relationship_logits (`torch.FloatTensor` of shape `(batch_size, 2)`):\n",
    "            Prediction scores of the next sequence prediction (classification) head (scores of True/False continuation\n",
    "            before SoftMax).\n",
    "        hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n",
    "            Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer) of\n",
    "            shape `(batch_size, sequence_length, hidden_size)`.\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n",
    "            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
    "            sequence_length)`.\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "    \"\"\"\n",
    "\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    prediction_logits: torch.FloatTensor = None\n",
    "    seq_relationship_logits: torch.FloatTensor = None\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "\n",
    "\n",
    "BERT_START_DOCSTRING = r\"\"\"\n",
    "    This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the\n",
    "    library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n",
    "    etc.)\n",
    "    This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.\n",
    "    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\n",
    "    and behavior.\n",
    "    Parameters:\n",
    "        config ([`BertConfig`]): Model configuration class with all the parameters of the model.\n",
    "            Initializing with a config file does not load the weights associated with the model, only the\n",
    "            configuration. Check out the [`~PreTrainedModel.from_pretrained`] method to load the model weights.\n",
    "\"\"\"\n",
    "\n",
    "BERT_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (`torch.LongTensor` of shape `({0})`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        attention_mask (`torch.FloatTensor` of shape `({0})`, *optional*):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "            [What are attention masks?](../glossary#attention-mask)\n",
    "        token_type_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,\n",
    "            1]`:\n",
    "            - 0 corresponds to a *sentence A* token,\n",
    "            - 1 corresponds to a *sentence B* token.\n",
    "            [What are token type IDs?](../glossary#token-type-ids)\n",
    "        position_ids (`torch.LongTensor` of shape `({0})`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
    "            Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
    "            - 1 indicates the head is **not masked**,\n",
    "            - 0 indicates the head is **masked**.\n",
    "        inputs_embeds (`torch.FloatTensor` of shape `({0}, hidden_size)`, *optional*):\n",
    "            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
    "            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
    "            model's internal embedding lookup matrix.\n",
    "        output_attentions (`bool`, *optional*):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (`bool`, *optional*):\n",
    "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (`bool`, *optional*):\n",
    "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"The bare Bert Model transformer outputting raw hidden-states without any specific head on top.\",\n",
    "    BERT_START_DOCSTRING,\n",
    ")\n",
    "class BertModel(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    The model can behave as an encoder (with only self-attention) as well as a decoder, in which case a layer of\n",
    "    cross-attention is added between the self-attention layers, following the architecture described in [Attention is\n",
    "    all you need](https://arxiv.org/abs/1706.03762) by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,\n",
    "    Llion Jones, Aidan N. Gomez, Lukasz Kaiser and Illia Polosukhin.\n",
    "    To behave as an decoder the model needs to be initialized with the `is_decoder` argument of the configuration set\n",
    "    to `True`. To be used in a Seq2Seq model, the model needs to initialized with both `is_decoder` argument and\n",
    "    `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, add_pooling_layer=True):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.encoder = BertEncoder(config)\n",
    "\n",
    "        self.pooler = BertPooler(config) if add_pooling_layer else None\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
    "        r\"\"\"\n",
    "        encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
    "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
    "            the model is configured as a decoder.\n",
    "        encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
    "            the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "        past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
    "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
    "            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
    "            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
    "            `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
    "        use_cache (`bool`, *optional*):\n",
    "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
    "            `past_key_values`).\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if self.config.is_decoder:\n",
    "            use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        else:\n",
    "            use_cache = False\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        # past_key_values_length\n",
    "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            if hasattr(self.embeddings, \"token_type_ids\"):\n",
    "                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
    "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
    "                token_type_ids = buffered_token_type_ids_expanded\n",
    "            else:\n",
    "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape)\n",
    "        print(f\"extended attention mask shape is: {extended_attention_mask}\")\n",
    "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "        print(f\"position ids before embeddings: {position_ids}\")\n",
    "        embedding_output = self.embeddings(\n",
    "            input_ids=input_ids,\n",
    "            position_ids=position_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            past_key_values_length=past_key_values_length,\n",
    "        )\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            attention_mask=extended_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_extended_attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sequence_output, pooled_output) + encoder_outputs[1:]\n",
    "\n",
    "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "            last_hidden_state=sequence_output,\n",
    "            pooler_output=pooled_output,\n",
    "            past_key_values=encoder_outputs.past_key_values,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "            cross_attentions=encoder_outputs.cross_attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"\"\"\n",
    "    Bert Model with two heads on top as done during the pretraining: a `masked language modeling` head and a `next\n",
    "    sentence prediction (classification)` head.\n",
    "    \"\"\",\n",
    "    BERT_START_DOCSTRING,\n",
    ")\n",
    "class BertForPreTraining(BertPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\", r\"predictions.decoder.bias\", r\"cls.predictions.decoder.weight\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.cls = BertPreTrainingHeads(config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.cls.predictions.decoder\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.cls.predictions.decoder = new_embeddings\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @replace_return_docstrings(output_type=BertForPreTrainingOutput, config_class=_CONFIG_FOR_DOC)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        next_sentence_label: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], BertForPreTrainingOutput]:\n",
    "        r\"\"\"\n",
    "            labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "                Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\n",
    "                config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked),\n",
    "                the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\n",
    "            next_sentence_label (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "                Labels for computing the next sequence prediction (classification) loss. Input should be a sequence\n",
    "                pair (see `input_ids` docstring) Indices should be in `[0, 1]`:\n",
    "                - 0 indicates sequence B is a continuation of sequence A,\n",
    "                - 1 indicates sequence B is a random sequence.\n",
    "            kwargs (`Dict[str, any]`, optional, defaults to *{}*):\n",
    "                Used to hide legacy arguments that have been deprecated.\n",
    "        Returns:\n",
    "        Example:\n",
    "        ```python\n",
    "        >>> from transformers import AutoTokenizer, BertForPreTraining\n",
    "        >>> import torch\n",
    "        >>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        >>> model = BertForPreTraining.from_pretrained(\"bert-base-uncased\")\n",
    "        >>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "        >>> outputs = model(**inputs)\n",
    "        >>> prediction_logits = outputs.prediction_logits\n",
    "        >>> seq_relationship_logits = outputs.seq_relationship_logits\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output, pooled_output = outputs[:2]\n",
    "        prediction_scores, seq_relationship_score = self.cls(sequence_output, pooled_output)\n",
    "\n",
    "        total_loss = None\n",
    "        if labels is not None and next_sentence_label is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "            next_sentence_loss = loss_fct(seq_relationship_score.view(-1, 2), next_sentence_label.view(-1))\n",
    "            total_loss = masked_lm_loss + next_sentence_loss\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_scores, seq_relationship_score) + outputs[2:]\n",
    "            return ((total_loss,) + output) if total_loss is not None else output\n",
    "\n",
    "        return BertForPreTrainingOutput(\n",
    "            loss=total_loss,\n",
    "            prediction_logits=prediction_scores,\n",
    "            seq_relationship_logits=seq_relationship_score,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"\"\"Bert Model with a `language modeling` head on top for CLM fine-tuning.\"\"\", BERT_START_DOCSTRING\n",
    ")\n",
    "class BertLMHeadModel(BertPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\", r\"predictions.decoder.bias\", r\"cls.predictions.decoder.weight\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if not config.is_decoder:\n",
    "            logger.warning(\"If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\")\n",
    "\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        self.cls = BertOnlyMLMHead(config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.cls.predictions.decoder\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.cls.predictions.decoder = new_embeddings\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=CausalLMOutputWithCrossAttentions,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        past_key_values: Optional[List[torch.Tensor]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], CausalLMOutputWithCrossAttentions]:\n",
    "        r\"\"\"\n",
    "        encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
    "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
    "            the model is configured as a decoder.\n",
    "        encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
    "            the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the left-to-right language modeling loss (next word prediction). Indices should be in\n",
    "            `[-100, 0, ..., config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are\n",
    "            ignored (masked), the loss is only computed for the tokens with labels n `[0, ..., config.vocab_size]`\n",
    "        past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
    "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
    "            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
    "            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
    "            `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
    "        use_cache (`bool`, *optional*):\n",
    "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
    "            `past_key_values`).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        if labels is not None:\n",
    "            use_cache = False\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        prediction_scores = self.cls(sequence_output)\n",
    "\n",
    "        lm_loss = None\n",
    "        if labels is not None:\n",
    "            # we are doing next-token prediction; shift prediction scores and input ids by one\n",
    "            shifted_prediction_scores = prediction_scores[:, :-1, :].contiguous()\n",
    "            labels = labels[:, 1:].contiguous()\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            lm_loss = loss_fct(shifted_prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_scores,) + outputs[2:]\n",
    "            return ((lm_loss,) + output) if lm_loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithCrossAttentions(\n",
    "            loss=lm_loss,\n",
    "            logits=prediction_scores,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "            cross_attentions=outputs.cross_attentions,\n",
    "        )\n",
    "\n",
    "    def prepare_inputs_for_generation(\n",
    "        self, input_ids, past_key_values=None, attention_mask=None, use_cache=True, **model_kwargs\n",
    "    ):\n",
    "        input_shape = input_ids.shape\n",
    "        # if model is used as a decoder in encoder-decoder model, the decoder attention mask is created on the fly\n",
    "        if attention_mask is None:\n",
    "            attention_mask = input_ids.new_ones(input_shape)\n",
    "\n",
    "        # cut decoder_input_ids if past_key_values is used\n",
    "        if past_key_values is not None:\n",
    "            input_ids = input_ids[:, -1:]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"past_key_values\": past_key_values,\n",
    "            \"use_cache\": use_cache,\n",
    "        }\n",
    "\n",
    "    def _reorder_cache(self, past_key_values, beam_idx):\n",
    "        reordered_past = ()\n",
    "        for layer_past in past_key_values:\n",
    "            reordered_past += (tuple(past_state.index_select(0, beam_idx) for past_state in layer_past),)\n",
    "        return reordered_past\n",
    "\n",
    "\n",
    "@add_start_docstrings(\"\"\"Bert Model with a `language modeling` head on top.\"\"\", BERT_START_DOCSTRING)\n",
    "class BertForMaskedLM(BertPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\", r\"predictions.decoder.bias\", r\"cls.predictions.decoder.weight\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if config.is_decoder:\n",
    "            logger.warning(\n",
    "                \"If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for \"\n",
    "                \"bi-directional self-attention.\"\n",
    "            )\n",
    "\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        self.cls = BertOnlyMLMHead(config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.cls.predictions.decoder\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.cls.predictions.decoder = new_embeddings\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=MaskedLMOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "        expected_output=\"'paris'\",\n",
    "        expected_loss=0.88,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], MaskedLMOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\n",
    "            config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\n",
    "            loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\n",
    "        \"\"\"\n",
    "\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        prediction_scores = self.cls(sequence_output)\n",
    "\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()  # -100 index = padding token\n",
    "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_scores,) + outputs[2:]\n",
    "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "\n",
    "        return MaskedLMOutput(\n",
    "            loss=masked_lm_loss,\n",
    "            logits=prediction_scores,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def prepare_inputs_for_generation(self, input_ids, attention_mask=None, **model_kwargs):\n",
    "        input_shape = input_ids.shape\n",
    "        effective_batch_size = input_shape[0]\n",
    "\n",
    "        #  add a dummy token\n",
    "        if self.config.pad_token_id is None:\n",
    "            raise ValueError(\"The PAD token should be defined for generation\")\n",
    "\n",
    "        attention_mask = torch.cat([attention_mask, attention_mask.new_zeros((attention_mask.shape[0], 1))], dim=-1)\n",
    "        dummy_token = torch.full(\n",
    "            (effective_batch_size, 1), self.config.pad_token_id, dtype=torch.long, device=input_ids.device\n",
    "        )\n",
    "        input_ids = torch.cat([input_ids, dummy_token], dim=1)\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"\"\"Bert Model with a `next sentence prediction (classification)` head on top.\"\"\",\n",
    "    BERT_START_DOCSTRING,\n",
    ")\n",
    "class BertForNextSentencePrediction(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.cls = BertOnlyNSPHead(config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @replace_return_docstrings(output_type=NextSentencePredictorOutput, config_class=_CONFIG_FOR_DOC)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs,\n",
    "    ) -> Union[Tuple[torch.Tensor], NextSentencePredictorOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the next sequence prediction (classification) loss. Input should be a sequence pair\n",
    "            (see `input_ids` docstring). Indices should be in `[0, 1]`:\n",
    "            - 0 indicates sequence B is a continuation of sequence A,\n",
    "            - 1 indicates sequence B is a random sequence.\n",
    "        Returns:\n",
    "        Example:\n",
    "        ```python\n",
    "        >>> from transformers import AutoTokenizer, BertForNextSentencePrediction\n",
    "        >>> import torch\n",
    "        >>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        >>> model = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\")\n",
    "        >>> prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "        >>> next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
    "        >>> encoding = tokenizer(prompt, next_sentence, return_tensors=\"pt\")\n",
    "        >>> outputs = model(**encoding, labels=torch.LongTensor([1]))\n",
    "        >>> logits = outputs.logits\n",
    "        >>> assert logits[0, 0] < logits[0, 1]  # next sentence was random\n",
    "        ```\n",
    "        \"\"\"\n",
    "\n",
    "        if \"next_sentence_label\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"The `next_sentence_label` argument is deprecated and will be removed in a future version, use\"\n",
    "                \" `labels` instead.\",\n",
    "                FutureWarning,\n",
    "            )\n",
    "            labels = kwargs.pop(\"next_sentence_label\")\n",
    "\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        seq_relationship_scores = self.cls(pooled_output)\n",
    "\n",
    "        next_sentence_loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            next_sentence_loss = loss_fct(seq_relationship_scores.view(-1, 2), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (seq_relationship_scores,) + outputs[2:]\n",
    "            return ((next_sentence_loss,) + output) if next_sentence_loss is not None else output\n",
    "\n",
    "        return NextSentencePredictorOutput(\n",
    "            loss=next_sentence_loss,\n",
    "            logits=seq_relationship_scores,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"\"\"\n",
    "    Bert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled\n",
    "    output) e.g. for GLUE tasks.\n",
    "    \"\"\",\n",
    "    BERT_START_DOCSTRING,\n",
    ")\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION,\n",
    "        output_type=SequenceClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "        expected_output=_SEQ_CLASS_EXPECTED_OUTPUT,\n",
    "        expected_loss=_SEQ_CLASS_EXPECTED_LOSS,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"\"\"\n",
    "    Bert Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a\n",
    "    softmax) e.g. for RocStories/SWAG tasks.\n",
    "    \"\"\",\n",
    "    BERT_START_DOCSTRING,\n",
    ")\n",
    "class BertForMultipleChoice(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_size, 1)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, num_choices, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=MultipleChoiceModelOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], MultipleChoiceModelOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the multiple choice classification loss. Indices should be in `[0, ...,\n",
    "            num_choices-1]` where `num_choices` is the size of the second dimension of the input tensors. (See\n",
    "            `input_ids` above)\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        num_choices = input_ids.shape[1] if input_ids is not None else inputs_embeds.shape[1]\n",
    "\n",
    "        input_ids = input_ids.view(-1, input_ids.size(-1)) if input_ids is not None else None\n",
    "        attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None\n",
    "        token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None\n",
    "        position_ids = position_ids.view(-1, position_ids.size(-1)) if position_ids is not None else None\n",
    "        inputs_embeds = (\n",
    "            inputs_embeds.view(-1, inputs_embeds.size(-2), inputs_embeds.size(-1))\n",
    "            if inputs_embeds is not None\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        reshaped_logits = logits.view(-1, num_choices)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(reshaped_logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (reshaped_logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return MultipleChoiceModelOutput(\n",
    "            loss=loss,\n",
    "            logits=reshaped_logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"\"\"\n",
    "    Bert Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for\n",
    "    Named-Entity-Recognition (NER) tasks.\n",
    "    \"\"\",\n",
    "    BERT_START_DOCSTRING,\n",
    ")\n",
    "class BertForTokenClassification(BertPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_TOKEN_CLASSIFICATION,\n",
    "        output_type=TokenClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "        expected_output=_TOKEN_CLASS_EXPECTED_OUTPUT,\n",
    "        expected_loss=_TOKEN_CLASS_EXPECTED_LOSS,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], TokenClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"\"\"\n",
    "    Bert Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear\n",
    "    layers on top of the hidden-states output to compute `span start logits` and `span end logits`).\n",
    "    \"\"\",\n",
    "    BERT_START_DOCSTRING,\n",
    ")\n",
    "class BertForQuestionAnswering(BertPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        checkpoint=_CHECKPOINT_FOR_QA,\n",
    "        output_type=QuestionAnsweringModelOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "        qa_target_start_index=_QA_TARGET_START_INDEX,\n",
    "        qa_target_end_index=_QA_TARGET_END_INDEX,\n",
    "        expected_output=_QA_EXPECTED_OUTPUT,\n",
    "        expected_loss=_QA_EXPECTED_LOSS,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        start_positions: Optional[torch.Tensor] = None,\n",
    "        end_positions: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], QuestionAnsweringModelOutput]:\n",
    "        r\"\"\"\n",
    "        start_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n",
    "            Positions are clamped to the length of the sequence (`sequence_length`). Position outside of the sequence\n",
    "            are not taken into account for computing the loss.\n",
    "        end_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n",
    "            Positions are clamped to the length of the sequence (`sequence_length`). Position outside of the sequence\n",
    "            are not taken into account for computing the loss.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "        total_loss = None\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions = start_positions.clamp(0, ignored_index)\n",
    "            end_positions = end_positions.clamp(0, ignored_index)\n",
    "\n",
    "            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (start_logits, end_logits) + outputs[2:]\n",
    "            return ((total_loss,) + output) if total_loss is not None else output\n",
    "\n",
    "        return QuestionAnsweringModelOutput(\n",
    "            loss=total_loss,\n",
    "            start_logits=start_logits,\n",
    "            end_logits=end_logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we will use the classes defined in this script to allow easier printing etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position embeddings shape at init: Embedding(512, 768)\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "cache_dir = \"/mnt/sdg/niallt/.cache/\"\n",
    "model = BertModel.from_pretrained(model_name, cache_dir) # from this script\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.21.3\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"this is a bit longer\", \"Hello,\"], padding =True,  return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 1010,  102,    0,    0,    0],\n",
       "        [ 101, 2023, 2003, 1037, 2978, 2936,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extended attention mask shape is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "position ids before embeddings: None\n",
      "position ids: tensor([[0, 1, 2, 3, 4, 5, 6]])\n",
      "position embeddings shape before added to embeddings: torch.Size([1, 7, 768])\n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[ 1.2797e+00,  2.2044e-01,  2.4081e-01,  ...,  5.8425e-01,\n",
      "           -4.1908e-01,  9.1936e-01],\n",
      "          [ 3.5969e-01, -4.7975e-01, -9.1391e-02,  ...,  4.3828e-03,\n",
      "            4.6049e-01, -7.1689e-01],\n",
      "          [ 5.3447e-01, -5.9713e-01,  2.5200e-03,  ..., -6.9467e-01,\n",
      "            1.1443e+00,  1.1449e+00],\n",
      "          ...,\n",
      "          [ 5.2574e-01, -1.2158e-01,  6.4653e-01,  ..., -1.4217e+00,\n",
      "           -3.8652e-01, -1.1322e+00],\n",
      "          [-2.4268e-01,  7.6714e-01,  8.6315e-01,  ..., -4.0120e-01,\n",
      "           -2.6315e-01, -1.7730e+00],\n",
      "          [-5.5015e-01,  1.1240e+00,  5.1051e-02,  ..., -4.7778e-01,\n",
      "            5.8507e-02,  5.6054e-01]],\n",
      "\n",
      "         [[ 2.7875e-01, -1.9017e+00,  1.2599e+00,  ...,  1.5024e+00,\n",
      "           -2.2900e+00,  9.9370e-02],\n",
      "          [-1.4215e+00, -1.0942e-01, -2.7454e-01,  ...,  1.3553e+00,\n",
      "           -1.5419e-01, -9.9234e-02],\n",
      "          [-1.1336e+00, -1.0611e+00, -5.4028e-01,  ...,  1.0203e+00,\n",
      "            4.2043e-01,  5.4452e-01],\n",
      "          ...,\n",
      "          [-2.5618e+00, -4.5803e-01, -9.2669e-01,  ...,  2.6585e+00,\n",
      "            1.8013e-01,  3.3563e-01],\n",
      "          [-1.9364e+00, -5.6056e-03, -1.0972e-01,  ...,  2.3126e+00,\n",
      "            8.7547e-01,  1.0199e+00],\n",
      "          [ 8.5220e-02, -1.0133e+00,  8.8411e-01,  ...,  2.0948e+00,\n",
      "           -2.4233e-01,  6.2832e-03]],\n",
      "\n",
      "         [[ 8.1582e-01,  2.8750e+00, -1.7793e+00,  ..., -2.6196e-01,\n",
      "           -1.2568e+00, -7.9839e-01],\n",
      "          [-2.0192e-02,  4.2712e-01,  9.3841e-01,  ..., -1.7483e+00,\n",
      "            3.2634e-01,  1.6566e-01],\n",
      "          [-4.1547e-02, -1.0688e+00, -2.6631e-01,  ..., -8.1191e-01,\n",
      "           -1.3294e+00, -9.2081e-01],\n",
      "          ...,\n",
      "          [-5.2338e-01, -1.5668e+00, -5.5930e-01,  ...,  3.5977e-01,\n",
      "            1.5238e+00, -3.4629e-01],\n",
      "          [-5.7683e-01,  7.4062e-01,  2.4594e-01,  ..., -1.7101e-01,\n",
      "            2.8986e+00, -1.8121e+00],\n",
      "          [-4.2343e-01,  8.7816e-01, -2.8954e-01,  ...,  5.2816e-01,\n",
      "            2.2677e-01, -3.3932e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2373e+00,  3.3905e-01, -1.1571e+00,  ...,  3.6160e-01,\n",
      "           -1.7827e+00, -1.9543e+00],\n",
      "          [ 1.2032e+00, -3.2096e-01, -6.3385e-01,  ...,  2.4859e-01,\n",
      "           -3.4918e-01, -1.2555e+00],\n",
      "          [-2.4711e-01, -2.0068e-02, -5.4984e-01,  ...,  8.3192e-01,\n",
      "           -9.1718e-01, -4.8322e-01],\n",
      "          ...,\n",
      "          [ 3.0402e-01, -6.0456e-01, -3.5607e-01,  ..., -1.4109e+00,\n",
      "            6.8733e-01, -1.0859e-01],\n",
      "          [ 1.4544e-01,  6.6898e-01, -1.4907e+00,  ...,  9.2545e-01,\n",
      "           -6.7808e-01, -2.8507e-01],\n",
      "          [ 8.5744e-01, -4.0792e-02, -1.1372e+00,  ...,  2.9649e-01,\n",
      "           -1.0705e+00, -3.8017e+00]],\n",
      "\n",
      "         [[-1.5103e+00,  1.7913e+00,  6.8068e-01,  ...,  2.3826e+00,\n",
      "           -1.1231e-01,  1.5480e+00],\n",
      "          [-5.2923e-01, -4.0399e-01, -4.7303e-01,  ...,  2.4838e-01,\n",
      "           -7.3193e-01,  1.5160e+00],\n",
      "          [-4.9228e-01, -5.3302e-02, -3.1977e-01,  ..., -2.3726e-01,\n",
      "           -2.8630e-01,  1.0883e+00],\n",
      "          ...,\n",
      "          [ 1.7022e+00, -1.7012e+00,  8.7307e-01,  ...,  1.4955e+00,\n",
      "           -3.3727e-02, -8.2678e-01],\n",
      "          [-4.8272e-01, -8.4763e-01,  1.1743e+00,  ...,  1.9302e+00,\n",
      "           -1.5849e+00,  2.2604e-01],\n",
      "          [ 4.5387e-01,  1.0775e+00,  8.5544e-01,  ...,  1.3073e+00,\n",
      "           -1.6165e+00, -7.6270e-01]],\n",
      "\n",
      "         [[-8.8995e-01,  7.9753e-02, -3.5853e-01,  ..., -1.7204e-02,\n",
      "           -2.6863e-01,  7.2731e-01],\n",
      "          [-1.7715e-01, -2.3939e-01, -2.4951e-01,  ..., -8.5932e-01,\n",
      "            2.7313e-01, -2.7672e+00],\n",
      "          [ 5.1434e-01,  5.1057e-02,  4.9180e-02,  ..., -1.1064e+00,\n",
      "           -3.9094e-01, -3.2550e+00],\n",
      "          ...,\n",
      "          [ 1.3089e+00, -8.2384e-01,  8.0449e-01,  ..., -1.1350e+00,\n",
      "           -2.7915e-01, -3.0665e+00],\n",
      "          [ 1.5488e+00, -8.8447e-01, -4.9683e-01,  ..., -7.5540e-02,\n",
      "            3.3999e-01, -3.3500e+00],\n",
      "          [ 1.0085e+00, -1.5908e+00, -1.0867e+00,  ..., -1.8533e-01,\n",
      "           -1.0654e+00, -2.6340e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2797e+00,  2.2044e-01,  2.4081e-01,  ...,  5.8425e-01,\n",
      "           -4.1908e-01,  9.1936e-01],\n",
      "          [ 9.9487e-01, -1.2641e-01,  8.0097e-01,  ..., -2.7450e-01,\n",
      "           -1.0486e-01, -3.3392e-01],\n",
      "          [-1.6982e+00, -1.1225e+00, -3.4359e-01,  ..., -6.8836e-02,\n",
      "            6.7910e-01, -7.2340e-01],\n",
      "          ...,\n",
      "          [ 5.2282e-01,  1.2019e-01, -5.9244e-01,  ...,  1.8953e-01,\n",
      "            2.9627e-01, -1.9831e-01],\n",
      "          [ 2.7527e-01,  1.4412e-01, -5.8774e-01,  ...,  2.7829e-01,\n",
      "            1.9078e-01, -2.9035e-01],\n",
      "          [ 4.2267e-01,  2.6704e-01, -6.6818e-01,  ...,  2.3221e-01,\n",
      "            1.2242e-01, -4.0821e-01]],\n",
      "\n",
      "         [[ 2.7875e-01, -1.9017e+00,  1.2599e+00,  ...,  1.5024e+00,\n",
      "           -2.2900e+00,  9.9370e-02],\n",
      "          [-2.5936e-01, -1.5111e-01, -1.0154e+00,  ...,  1.8249e+00,\n",
      "           -1.2166e+00, -6.8138e-01],\n",
      "          [ 6.9386e-01, -1.0388e+00,  8.0177e-01,  ...,  8.6270e-01,\n",
      "           -1.8052e-01,  8.7532e-01],\n",
      "          ...,\n",
      "          [ 2.1044e-01, -7.5079e-02,  1.0937e-01,  ...,  2.5142e+00,\n",
      "           -5.5748e-02, -1.8266e-01],\n",
      "          [ 1.3326e-01, -6.7116e-02,  1.6694e-01,  ...,  2.3938e+00,\n",
      "           -2.3870e-01, -1.8668e-01],\n",
      "          [ 1.0991e-01,  7.4387e-02,  1.4667e-01,  ...,  2.4525e+00,\n",
      "           -1.1976e-01, -6.3190e-02]],\n",
      "\n",
      "         [[ 8.1582e-01,  2.8750e+00, -1.7793e+00,  ..., -2.6196e-01,\n",
      "           -1.2568e+00, -7.9839e-01],\n",
      "          [-7.2667e-01,  5.4993e-01,  1.0213e+00,  ..., -1.8438e+00,\n",
      "            7.5130e-01,  6.2234e-01],\n",
      "          [ 2.8287e-01, -1.0677e+00, -4.7919e-01,  ..., -7.3021e-01,\n",
      "           -7.1935e-01, -1.2114e+00],\n",
      "          ...,\n",
      "          [-1.4757e+00, -9.7066e-01,  4.5949e-01,  ...,  9.9505e-01,\n",
      "            1.4185e+00, -8.4103e-01],\n",
      "          [-1.1494e+00, -5.1472e-01, -9.0982e-02,  ...,  2.0716e-01,\n",
      "            1.3778e+00, -5.1569e-01],\n",
      "          [-1.2061e+00, -5.1134e-02,  4.8494e-01,  ...,  1.1508e+00,\n",
      "            1.4965e+00,  3.0558e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2373e+00,  3.3905e-01, -1.1571e+00,  ...,  3.6160e-01,\n",
      "           -1.7827e+00, -1.9543e+00],\n",
      "          [ 1.7042e+00,  1.2819e+00, -1.3960e+00,  ..., -8.8639e-01,\n",
      "           -2.6549e-01, -1.8864e+00],\n",
      "          [-1.4173e+00,  1.0411e+00,  2.6607e-01,  ...,  1.1132e+00,\n",
      "           -4.3696e-01, -1.1782e+00],\n",
      "          ...,\n",
      "          [-1.2767e+00, -8.6148e-01, -5.6654e-01,  ...,  5.9485e-01,\n",
      "           -1.0859e+00, -5.1273e-01],\n",
      "          [-1.3887e+00, -1.1118e+00, -7.8158e-01,  ...,  3.4918e-01,\n",
      "           -1.1341e+00, -1.0511e+00],\n",
      "          [-9.4385e-01, -1.3294e+00, -9.6933e-01,  ...,  4.2655e-01,\n",
      "           -8.3163e-01, -1.1399e+00]],\n",
      "\n",
      "         [[-1.5103e+00,  1.7913e+00,  6.8068e-01,  ...,  2.3826e+00,\n",
      "           -1.1231e-01,  1.5480e+00],\n",
      "          [-9.8903e-01, -2.1113e-01, -8.9029e-01,  ..., -1.9948e-01,\n",
      "           -2.0196e-01, -6.0200e-01],\n",
      "          [-1.6648e-01, -1.3391e-01,  1.7355e-01,  ..., -2.5884e-01,\n",
      "            3.7306e-01,  1.0174e+00],\n",
      "          ...,\n",
      "          [ 1.3215e+00, -5.6827e-01,  1.2785e+00,  ...,  1.0402e+00,\n",
      "           -3.7201e-01, -7.6588e-02],\n",
      "          [ 6.0072e-01,  6.4709e-01,  2.0904e+00,  ...,  3.3483e-01,\n",
      "           -4.6628e-01, -6.4057e-01],\n",
      "          [ 1.4035e+00,  4.4870e-01,  1.0570e+00,  ...,  5.0593e-01,\n",
      "           -8.6316e-01, -1.2040e+00]],\n",
      "\n",
      "         [[-8.8995e-01,  7.9753e-02, -3.5853e-01,  ..., -1.7204e-02,\n",
      "           -2.6863e-01,  7.2731e-01],\n",
      "          [ 5.0887e-01, -1.8836e-01, -1.2346e+00,  ..., -1.0305e+00,\n",
      "           -5.5939e-01, -2.6508e+00],\n",
      "          [ 1.9561e+00,  2.6229e-01,  2.5618e-01,  ...,  9.9989e-01,\n",
      "           -1.0584e+00, -3.1828e+00],\n",
      "          ...,\n",
      "          [ 4.4879e-01, -6.1680e-02, -5.0346e-01,  ..., -8.8064e-01,\n",
      "            1.1040e-01, -2.1284e+00],\n",
      "          [ 2.2888e-01, -8.5572e-01, -3.0823e-01,  ..., -1.3261e+00,\n",
      "           -1.2932e-01, -2.3927e+00],\n",
      "          [ 3.1672e-01, -2.4921e-01, -6.1249e-01,  ..., -5.4122e-01,\n",
      "            1.2256e-01, -2.5527e+00]]]], grad_fn=<PermuteBackward0>), query layer: tensor([[[[ 7.0899e-01, -1.5323e-01, -3.2386e-02,  ..., -1.8608e-01,\n",
      "           -1.1897e+00, -3.9165e-01],\n",
      "          [ 4.4195e-01,  2.4986e-01,  2.8678e-01,  ...,  1.0570e+00,\n",
      "            1.2258e-01,  6.9003e-01],\n",
      "          [ 4.2882e-02,  3.0820e-01,  4.6835e-01,  ...,  1.3721e+00,\n",
      "            8.8151e-01, -1.6187e-01],\n",
      "          ...,\n",
      "          [ 6.3557e-01,  8.2579e-01, -3.9441e-01,  ...,  5.9049e-02,\n",
      "           -1.4229e-01,  8.7461e-01],\n",
      "          [ 1.0502e+00, -1.0273e+00, -5.7713e-01,  ...,  3.6916e-01,\n",
      "            6.0468e-01,  2.8997e-02],\n",
      "          [ 3.7913e-01, -5.0651e-01, -2.1010e-01,  ...,  3.4291e-01,\n",
      "           -4.3606e-01,  6.2793e-01]],\n",
      "\n",
      "         [[ 2.2178e-01, -1.2996e+00,  7.4310e-01,  ...,  1.1388e-03,\n",
      "           -3.0399e-01,  2.5811e-01],\n",
      "          [-2.3224e-01,  6.7403e-01, -7.9037e-01,  ...,  1.4293e+00,\n",
      "            5.7001e-01,  2.2323e-03],\n",
      "          [-1.3663e-01,  6.4388e-01, -1.1401e+00,  ...,  1.0289e+00,\n",
      "            1.5844e-01,  2.2275e-01],\n",
      "          ...,\n",
      "          [ 1.1046e+00, -8.3536e-01, -2.6248e-01,  ...,  2.2137e+00,\n",
      "           -8.6140e-01,  1.9780e-01],\n",
      "          [ 1.9724e-01, -5.4693e-01, -7.7687e-01,  ...,  1.7315e+00,\n",
      "            5.6765e-01, -4.3915e-01],\n",
      "          [ 7.8351e-01, -1.4089e+00, -3.8284e-01,  ...,  1.0961e+00,\n",
      "           -7.2075e-01,  1.0589e+00]],\n",
      "\n",
      "         [[ 8.4190e-01,  1.0626e+00, -6.4894e-01,  ...,  3.1729e-01,\n",
      "           -1.0299e+00, -1.2475e-01],\n",
      "          [-3.6010e-01,  1.1312e+00, -1.2789e+00,  ..., -1.6476e+00,\n",
      "           -1.5534e+00, -2.9347e-01],\n",
      "          [-3.5807e-01,  8.9579e-01, -1.4265e-01,  ..., -4.5545e-01,\n",
      "           -4.2700e-01, -1.0067e+00],\n",
      "          ...,\n",
      "          [ 1.5577e+00,  1.0024e+00,  1.5224e-01,  ..., -2.6070e-01,\n",
      "           -1.2861e+00, -4.1231e-01],\n",
      "          [-7.5480e-01,  8.9911e-02, -1.2190e+00,  ...,  1.0541e+00,\n",
      "            1.1105e-01,  2.5598e-01],\n",
      "          [-1.6990e-01,  6.9290e-01, -9.8187e-01,  ..., -6.3776e-01,\n",
      "           -4.5053e-01, -5.3445e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3174e+00, -1.2112e+00, -3.8361e-01,  ...,  1.4632e+00,\n",
      "            2.0169e-01, -1.5972e+00],\n",
      "          [-9.3396e-02, -5.6823e-02, -1.7524e-01,  ...,  9.4676e-01,\n",
      "           -2.4404e-01, -4.6771e-01],\n",
      "          [-5.2293e-01,  3.6857e-01, -4.4115e-01,  ...,  3.3819e-01,\n",
      "           -4.3081e-01, -3.3848e-01],\n",
      "          ...,\n",
      "          [-3.2248e-01,  7.0711e-02,  9.5530e-01,  ..., -9.0036e-01,\n",
      "            6.1407e-01, -1.2747e+00],\n",
      "          [-8.4694e-01,  8.2673e-01,  1.2788e+00,  ...,  3.1558e-01,\n",
      "           -1.8535e-02, -8.0018e-01],\n",
      "          [-1.5627e+00,  9.1643e-01, -3.5871e-01,  ...,  9.0050e-01,\n",
      "           -6.3146e-01, -1.8863e+00]],\n",
      "\n",
      "         [[-1.8782e-01,  1.6068e-01,  8.0058e-01,  ..., -9.6358e-02,\n",
      "           -7.4036e-01,  3.0357e-01],\n",
      "          [-2.6636e-01,  1.0459e-02,  6.5199e-01,  ..., -2.9859e-01,\n",
      "            2.8462e-01,  6.5719e-01],\n",
      "          [ 1.9794e+00, -1.4046e-01,  2.7209e-01,  ...,  8.4643e-01,\n",
      "            8.5145e-01,  8.1414e-02],\n",
      "          ...,\n",
      "          [-1.0918e-02,  2.5586e+00,  3.3753e+00,  ...,  7.6766e-01,\n",
      "           -4.7852e-01,  3.3856e-01],\n",
      "          [ 1.3154e+00,  1.2031e+00,  3.9036e-01,  ..., -4.3631e-01,\n",
      "           -7.8188e-01, -1.3307e+00],\n",
      "          [ 5.8900e-01,  1.5898e-01,  9.5581e-01,  ...,  7.8550e-01,\n",
      "            5.5107e-01,  9.3399e-01]],\n",
      "\n",
      "         [[-1.7337e+00, -2.3543e+00, -1.0601e+00,  ..., -3.0180e+00,\n",
      "            9.9064e-01, -1.5274e+00],\n",
      "          [-2.9005e-01, -2.6243e-01, -4.9785e-01,  ..., -5.1015e-01,\n",
      "            1.0248e+00, -1.8391e+00],\n",
      "          [-3.1711e-01, -1.0115e+00, -7.1680e-01,  ..., -4.9208e-01,\n",
      "            1.1658e+00, -2.3855e+00],\n",
      "          ...,\n",
      "          [-1.2355e+00, -1.5534e+00, -9.5431e-01,  ..., -6.0996e-01,\n",
      "           -8.4257e-01, -2.8127e+00],\n",
      "          [-1.8087e-01,  3.0866e-01, -4.8699e-01,  ..., -2.7678e-01,\n",
      "           -5.8817e-01, -2.9453e+00],\n",
      "          [-2.8106e-01, -8.3973e-01, -1.0037e-02,  ..., -1.8529e+00,\n",
      "            3.2766e-02, -2.5814e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0899e-01, -1.5323e-01, -3.2386e-02,  ..., -1.8608e-01,\n",
      "           -1.1897e+00, -3.9165e-01],\n",
      "          [ 1.0491e+00,  5.9209e-02,  2.1953e-01,  ...,  6.7519e-01,\n",
      "           -2.6321e-01, -5.5709e-01],\n",
      "          [ 6.8951e-01, -4.8035e-01,  3.2689e-01,  ...,  3.5725e-01,\n",
      "           -2.2126e-01, -3.0940e-01],\n",
      "          ...,\n",
      "          [ 2.4636e-01, -1.0988e-01,  3.0585e-01,  ...,  1.1207e-01,\n",
      "           -4.2760e-01, -8.5899e-02],\n",
      "          [ 3.0484e-01, -5.9807e-02,  1.6047e-01,  ...,  1.8013e-01,\n",
      "           -4.0364e-01, -3.0590e-02],\n",
      "          [ 3.1150e-01, -7.4933e-02,  2.3635e-01,  ...,  1.7531e-01,\n",
      "           -3.0238e-01, -8.1137e-02]],\n",
      "\n",
      "         [[ 2.2178e-01, -1.2996e+00,  7.4310e-01,  ...,  1.1387e-03,\n",
      "           -3.0399e-01,  2.5811e-01],\n",
      "          [-4.2200e-01,  6.6089e-01, -4.5647e-03,  ...,  3.0422e+00,\n",
      "           -2.2383e-01, -2.7399e-01],\n",
      "          [-8.2661e-02, -8.1587e-02, -1.0151e+00,  ...,  6.3337e-01,\n",
      "            6.4736e-02,  6.8108e-01],\n",
      "          ...,\n",
      "          [ 7.6690e-01, -2.7024e-01,  4.0624e-01,  ...,  1.3795e+00,\n",
      "           -5.7309e-01,  2.8688e-01],\n",
      "          [ 9.0741e-01, -2.4498e-01,  4.0569e-01,  ...,  1.3977e+00,\n",
      "           -4.9436e-01,  2.7154e-01],\n",
      "          [ 6.5106e-01, -1.8203e-01,  4.7132e-01,  ...,  1.4251e+00,\n",
      "           -6.3918e-01,  2.5278e-01]],\n",
      "\n",
      "         [[ 8.4190e-01,  1.0626e+00, -6.4894e-01,  ...,  3.1729e-01,\n",
      "           -1.0299e+00, -1.2475e-01],\n",
      "          [-1.4467e+00,  6.0614e-01, -2.6008e+00,  ..., -1.0549e+00,\n",
      "           -1.6483e+00, -5.0472e-01],\n",
      "          [-9.4913e-01,  8.6875e-01,  1.6316e-02,  ..., -1.2859e+00,\n",
      "           -8.9309e-01, -4.1209e-01],\n",
      "          ...,\n",
      "          [ 1.4329e+00,  4.9917e-01, -9.2428e-01,  ...,  4.3130e-01,\n",
      "           -1.3778e-01, -1.7683e+00],\n",
      "          [ 2.7952e-01,  2.4366e-01, -1.2727e+00,  ...,  7.3040e-01,\n",
      "            1.3380e+00, -2.3964e+00],\n",
      "          [ 6.3761e-01,  7.9396e-01, -1.6529e+00,  ..., -2.4295e-01,\n",
      "            1.1392e+00, -2.1234e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3174e+00, -1.2112e+00, -3.8361e-01,  ...,  1.4632e+00,\n",
      "            2.0169e-01, -1.5972e+00],\n",
      "          [ 6.4756e-01,  8.6221e-01,  5.5771e-01,  ...,  9.8644e-01,\n",
      "            1.7644e-01, -1.2958e+00],\n",
      "          [-7.7313e-01,  1.7723e-01, -6.6108e-01,  ...,  4.3990e-01,\n",
      "           -5.1610e-01, -9.0461e-01],\n",
      "          ...,\n",
      "          [-5.8110e-01,  3.3440e-01, -5.6471e-01,  ...,  3.4395e-01,\n",
      "           -3.9034e-01, -6.3649e-01],\n",
      "          [-5.2726e-01,  5.5746e-01, -2.4922e-01,  ...,  5.8665e-01,\n",
      "           -3.2795e-01, -1.4624e-01],\n",
      "          [-8.2116e-01,  9.4262e-01, -3.3472e-01,  ...,  5.0171e-01,\n",
      "           -6.1436e-01, -1.4807e-01]],\n",
      "\n",
      "         [[-1.8782e-01,  1.6068e-01,  8.0058e-01,  ..., -9.6358e-02,\n",
      "           -7.4036e-01,  3.0357e-01],\n",
      "          [-1.4139e+00,  6.9559e-01,  4.9726e-01,  ...,  7.2405e-01,\n",
      "            1.7043e-02,  1.8149e+00],\n",
      "          [-1.2151e-01,  4.0215e-04,  4.5194e-01,  ...,  9.1718e-01,\n",
      "            7.6879e-02,  3.1026e-01],\n",
      "          ...,\n",
      "          [-1.0729e+00,  1.3199e+00,  3.2535e+00,  ...,  1.1306e+00,\n",
      "           -8.6351e-01, -2.0404e-01],\n",
      "          [-6.1738e-02,  8.4443e-01,  2.1679e+00,  ...,  1.4714e+00,\n",
      "           -1.2206e+00, -8.2261e-01],\n",
      "          [ 6.3849e-01, -9.1835e-03,  1.6686e+00,  ...,  9.3719e-01,\n",
      "           -5.3801e-01,  5.5430e-01]],\n",
      "\n",
      "         [[-1.7337e+00, -2.3543e+00, -1.0601e+00,  ..., -3.0180e+00,\n",
      "            9.9064e-01, -1.5274e+00],\n",
      "          [ 6.4991e-01, -2.2632e+00,  6.0212e-01,  ...,  3.5757e-01,\n",
      "            2.5095e-01, -2.5490e+00],\n",
      "          [-8.5721e-01, -2.4455e-01, -5.7554e-01,  ..., -1.0999e+00,\n",
      "            9.3067e-02, -2.1309e+00],\n",
      "          ...,\n",
      "          [-9.4496e-01, -2.1994e+00, -8.3453e-01,  ..., -2.3473e+00,\n",
      "           -2.4351e-01, -3.2427e+00],\n",
      "          [-2.9371e-01, -1.3249e+00, -8.5003e-01,  ..., -1.6836e+00,\n",
      "            8.8920e-02, -3.0091e+00],\n",
      "          [-2.2848e-01, -1.7638e+00, -5.4090e-01,  ..., -1.8633e+00,\n",
      "           -2.0235e-01, -3.3263e+00]]]], grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[ 0.0356,  0.6047, -0.3017,  ...,  0.3985,  0.6789,  1.6870],\n",
      "          [ 2.4510,  0.8613,  2.1837,  ...,  1.9036,  1.2658,  1.5385],\n",
      "          [ 1.9659,  1.0713,  1.8547,  ...,  1.8345,  1.3004,  0.9263],\n",
      "          ...,\n",
      "          [ 1.1575,  1.2044,  2.0412,  ...,  1.5656,  1.1211,  2.4241],\n",
      "          [ 1.8780,  1.6463,  2.5539,  ...,  1.6977,  1.2033,  2.0420],\n",
      "          [ 1.9648,  2.1093,  1.5732,  ...,  1.6148,  1.6654,  2.3384]],\n",
      "\n",
      "         [[ 3.6259, -0.8658, -0.6675,  ..., -1.8552, -2.2300, -0.9666],\n",
      "          [-0.8917, -0.3589,  1.7556,  ...,  2.8481,  2.8124,  0.6205],\n",
      "          [-0.8596,  0.1460,  0.3501,  ...,  2.0507,  2.1834,  0.1340],\n",
      "          ...,\n",
      "          [ 0.2347, -0.1619, -0.8699,  ...,  1.1579,  1.1067,  1.6994],\n",
      "          [-0.0185,  1.4098,  1.3434,  ...,  2.3924,  1.3649,  1.6882],\n",
      "          [ 1.0561,  2.6675,  2.2702,  ...,  1.4026,  0.9690,  1.0266]],\n",
      "\n",
      "         [[ 3.8793,  0.7152,  0.6985,  ..., -0.4770, -1.0755,  1.1280],\n",
      "          [ 5.5047,  3.6681,  3.1273,  ...,  1.7515,  1.9586,  2.6338],\n",
      "          [ 5.6804,  6.5215,  3.4987,  ...,  2.4289,  1.2589,  3.7334],\n",
      "          ...,\n",
      "          [ 4.3884,  3.3591,  4.1101,  ...,  3.1338,  0.7881,  3.1157],\n",
      "          [ 4.1999,  2.7742,  2.4280,  ...,  5.1560,  2.2434,  4.2329],\n",
      "          [ 5.5802,  2.3792,  2.6936,  ...,  2.6531,  4.3610,  4.7999]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0714,  0.2244, -0.6436,  ...,  0.6691,  1.2094, -1.5693],\n",
      "          [ 1.7797, -0.4507,  0.1190,  ..., -0.4461,  0.6187,  0.8662],\n",
      "          [ 2.5386, -1.0778, -0.3508,  ..., -0.1303,  0.2634,  1.0598],\n",
      "          ...,\n",
      "          [ 1.8330, -0.0324, -0.4874,  ...,  3.2481,  0.2974,  0.9184],\n",
      "          [ 2.6901, -0.8247, -0.4197,  ...,  1.0951,  1.2668,  0.7493],\n",
      "          [ 2.5530, -0.0445,  0.8374,  ...,  0.2828,  0.8605, -0.4638]],\n",
      "\n",
      "         [[ 3.5762,  0.2029, -0.3849,  ...,  0.0896, -0.6107,  0.1661],\n",
      "          [ 1.7938,  4.6560,  6.5898,  ...,  4.5318,  3.4384,  3.5023],\n",
      "          [ 0.3933,  4.4492,  4.4469,  ...,  7.1634,  4.0517,  4.4901],\n",
      "          ...,\n",
      "          [ 2.3595,  3.8708,  4.1164,  ...,  4.3909,  6.2833,  6.5738],\n",
      "          [ 2.9827,  2.7683,  2.1183,  ...,  5.8746,  2.9432,  7.8597],\n",
      "          [ 4.6607,  0.3491,  2.3970,  ...,  3.0648,  2.6707,  5.0597]],\n",
      "\n",
      "         [[ 5.5482,  2.8198, -0.2082,  ...,  0.6926, -0.4960,  2.2453],\n",
      "          [ 3.1770,  2.3198,  2.4842,  ...,  2.2307,  2.4522,  1.4928],\n",
      "          [ 2.2482,  2.5341,  0.8112,  ...,  3.4152,  3.7034,  0.8392],\n",
      "          ...,\n",
      "          [ 4.3192,  2.7567,  1.3717,  ...,  0.5083,  1.5737,  3.9959],\n",
      "          [ 3.0381,  3.2674,  2.7399,  ...,  2.5011,  1.2996,  3.4591],\n",
      "          [ 5.1169,  2.8734,  1.4250,  ...,  1.9756,  2.1808,  3.5726]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0356, -0.2298, -0.1717,  ..., -0.7057, -0.6712, -0.5883],\n",
      "          [ 1.0727,  1.2793,  0.4459,  ...,  2.5086,  2.4197,  2.4304],\n",
      "          [ 1.5328,  1.6410,  1.3810,  ...,  1.9416,  1.8258,  1.8956],\n",
      "          ...,\n",
      "          [ 0.9400,  2.7176,  1.0907,  ...,  3.5680,  3.5161,  3.5374],\n",
      "          [ 0.9316,  2.5137,  0.8927,  ...,  3.4811,  3.3922,  3.4178],\n",
      "          [ 0.9484,  2.6502,  0.9754,  ...,  3.5152,  3.4276,  3.4330]],\n",
      "\n",
      "         [[ 3.6259, -2.2888,  3.8499,  ..., -2.4247, -2.2836, -2.1448],\n",
      "          [ 0.8946,  2.1824,  0.2733,  ...,  3.4956,  3.3768,  3.4778],\n",
      "          [-1.1585,  2.8192,  1.7923,  ...,  1.4869,  1.2871,  1.4446],\n",
      "          ...,\n",
      "          [ 1.9047,  0.9088,  1.5647,  ...,  2.7525,  2.7769,  2.8574],\n",
      "          [ 2.0568,  0.7963,  1.5833,  ...,  2.7285,  2.7157,  2.8110],\n",
      "          [ 1.9274,  0.9417,  1.6098,  ...,  2.8014,  2.7913,  2.8655]],\n",
      "\n",
      "         [[ 3.8793,  0.0697,  0.4982,  ..., -1.0428, -1.1658, -1.0783],\n",
      "          [ 6.6016,  0.3798,  2.4950,  ...,  0.5690,  0.6467, -0.5420],\n",
      "          [ 5.3102,  5.3989,  4.1844,  ...,  1.3780, -0.0510,  0.8045],\n",
      "          ...,\n",
      "          [ 6.6824,  1.8732,  3.8767,  ...,  3.3596,  1.6853,  2.0706],\n",
      "          [ 6.7351,  1.9706,  2.6834,  ...,  6.1176,  3.3013,  2.0960],\n",
      "          [ 6.6366,  1.3648,  2.5842,  ...,  3.8714,  5.9840,  3.7671]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0714, -0.5129,  1.8277,  ..., -1.6871, -1.5031, -1.5805],\n",
      "          [ 1.7745,  1.6850, -0.4962,  ...,  0.6170,  0.5275,  1.0261],\n",
      "          [ 2.2506,  0.0109,  0.5587,  ..., -0.1917, -0.2503, -0.1573],\n",
      "          ...,\n",
      "          [ 1.7336,  0.7429,  0.1068,  ...,  1.5469,  1.9999,  2.3424],\n",
      "          [ 1.8778,  0.9680,  0.1393,  ...,  2.0013,  1.5394,  1.9305],\n",
      "          [ 2.0915,  0.9760,  0.4602,  ...,  2.4076,  1.9742,  1.4435]],\n",
      "\n",
      "         [[ 3.5762, -0.5180, -0.2663,  ..., -0.2507, -0.3440, -0.3035],\n",
      "          [ 4.8796,  3.9181,  6.2075,  ...,  3.7618,  3.1152,  1.8127],\n",
      "          [ 1.8645,  4.5326,  4.9513,  ...,  5.8024,  3.8148,  3.6265],\n",
      "          ...,\n",
      "          [ 8.2461,  2.8735,  3.8746,  ...,  6.1231,  8.0910,  6.2053],\n",
      "          [ 8.1366,  2.9517,  2.1908,  ...,  4.9444,  5.7726,  8.2253],\n",
      "          [ 8.2193,  1.3367,  2.7044,  ...,  4.2772,  4.6340,  6.0354]],\n",
      "\n",
      "         [[ 5.5482,  0.3607, -7.5716,  ..., -0.1640, -0.0830, -0.3246],\n",
      "          [ 3.6210, -0.2708,  1.3797,  ...,  2.4289,  2.5426,  2.0560],\n",
      "          [ 4.2810,  3.4908, -1.8430,  ...,  3.1892,  2.6320,  2.6154],\n",
      "          ...,\n",
      "          [ 5.2436,  2.6187, -2.9572,  ...,  3.4407,  3.6617,  3.4155],\n",
      "          [ 5.3243,  2.8792, -3.1702,  ...,  3.8960,  3.4306,  3.7409],\n",
      "          [ 5.2690,  2.1821, -3.1700,  ...,  3.5692,  3.9795,  3.6071]]]],\n",
      "       grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[ 3.5620e-02,  6.0469e-01, -3.0173e-01,  ...,  3.9845e-01,\n",
      "            6.7895e-01,  1.6870e+00],\n",
      "          [ 2.4510e+00,  8.6129e-01,  2.1837e+00,  ...,  1.9036e+00,\n",
      "            1.2658e+00,  1.5385e+00],\n",
      "          [ 1.9659e+00,  1.0713e+00,  1.8547e+00,  ...,  1.8345e+00,\n",
      "            1.3004e+00,  9.2631e-01],\n",
      "          ...,\n",
      "          [ 1.1575e+00,  1.2044e+00,  2.0412e+00,  ...,  1.5656e+00,\n",
      "            1.1211e+00,  2.4241e+00],\n",
      "          [ 1.8780e+00,  1.6463e+00,  2.5539e+00,  ...,  1.6977e+00,\n",
      "            1.2033e+00,  2.0420e+00],\n",
      "          [ 1.9648e+00,  2.1093e+00,  1.5732e+00,  ...,  1.6148e+00,\n",
      "            1.6654e+00,  2.3384e+00]],\n",
      "\n",
      "         [[ 3.6259e+00, -8.6580e-01, -6.6750e-01,  ..., -1.8552e+00,\n",
      "           -2.2300e+00, -9.6657e-01],\n",
      "          [-8.9165e-01, -3.5889e-01,  1.7556e+00,  ...,  2.8481e+00,\n",
      "            2.8124e+00,  6.2045e-01],\n",
      "          [-8.5963e-01,  1.4601e-01,  3.5006e-01,  ...,  2.0507e+00,\n",
      "            2.1834e+00,  1.3403e-01],\n",
      "          ...,\n",
      "          [ 2.3466e-01, -1.6192e-01, -8.6992e-01,  ...,  1.1579e+00,\n",
      "            1.1067e+00,  1.6994e+00],\n",
      "          [-1.8496e-02,  1.4098e+00,  1.3434e+00,  ...,  2.3924e+00,\n",
      "            1.3649e+00,  1.6882e+00],\n",
      "          [ 1.0561e+00,  2.6675e+00,  2.2702e+00,  ...,  1.4026e+00,\n",
      "            9.6898e-01,  1.0266e+00]],\n",
      "\n",
      "         [[ 3.8793e+00,  7.1524e-01,  6.9850e-01,  ..., -4.7703e-01,\n",
      "           -1.0755e+00,  1.1280e+00],\n",
      "          [ 5.5047e+00,  3.6681e+00,  3.1273e+00,  ...,  1.7515e+00,\n",
      "            1.9586e+00,  2.6338e+00],\n",
      "          [ 5.6804e+00,  6.5215e+00,  3.4987e+00,  ...,  2.4289e+00,\n",
      "            1.2589e+00,  3.7334e+00],\n",
      "          ...,\n",
      "          [ 4.3884e+00,  3.3591e+00,  4.1101e+00,  ...,  3.1338e+00,\n",
      "            7.8814e-01,  3.1157e+00],\n",
      "          [ 4.1999e+00,  2.7742e+00,  2.4280e+00,  ...,  5.1560e+00,\n",
      "            2.2434e+00,  4.2329e+00],\n",
      "          [ 5.5802e+00,  2.3792e+00,  2.6936e+00,  ...,  2.6531e+00,\n",
      "            4.3610e+00,  4.7999e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.1410e-02,  2.2438e-01, -6.4357e-01,  ...,  6.6908e-01,\n",
      "            1.2094e+00, -1.5693e+00],\n",
      "          [ 1.7797e+00, -4.5069e-01,  1.1896e-01,  ..., -4.4615e-01,\n",
      "            6.1872e-01,  8.6621e-01],\n",
      "          [ 2.5386e+00, -1.0778e+00, -3.5079e-01,  ..., -1.3029e-01,\n",
      "            2.6338e-01,  1.0598e+00],\n",
      "          ...,\n",
      "          [ 1.8330e+00, -3.2371e-02, -4.8741e-01,  ...,  3.2481e+00,\n",
      "            2.9737e-01,  9.1837e-01],\n",
      "          [ 2.6901e+00, -8.2470e-01, -4.1974e-01,  ...,  1.0951e+00,\n",
      "            1.2668e+00,  7.4927e-01],\n",
      "          [ 2.5530e+00, -4.4489e-02,  8.3740e-01,  ...,  2.8284e-01,\n",
      "            8.6047e-01, -4.6381e-01]],\n",
      "\n",
      "         [[ 3.5762e+00,  2.0288e-01, -3.8491e-01,  ...,  8.9602e-02,\n",
      "           -6.1067e-01,  1.6610e-01],\n",
      "          [ 1.7938e+00,  4.6560e+00,  6.5898e+00,  ...,  4.5318e+00,\n",
      "            3.4384e+00,  3.5023e+00],\n",
      "          [ 3.9330e-01,  4.4492e+00,  4.4469e+00,  ...,  7.1634e+00,\n",
      "            4.0517e+00,  4.4901e+00],\n",
      "          ...,\n",
      "          [ 2.3595e+00,  3.8708e+00,  4.1164e+00,  ...,  4.3909e+00,\n",
      "            6.2833e+00,  6.5738e+00],\n",
      "          [ 2.9827e+00,  2.7683e+00,  2.1183e+00,  ...,  5.8746e+00,\n",
      "            2.9432e+00,  7.8597e+00],\n",
      "          [ 4.6607e+00,  3.4908e-01,  2.3970e+00,  ...,  3.0648e+00,\n",
      "            2.6707e+00,  5.0597e+00]],\n",
      "\n",
      "         [[ 5.5482e+00,  2.8198e+00, -2.0818e-01,  ...,  6.9259e-01,\n",
      "           -4.9596e-01,  2.2453e+00],\n",
      "          [ 3.1770e+00,  2.3198e+00,  2.4842e+00,  ...,  2.2307e+00,\n",
      "            2.4522e+00,  1.4928e+00],\n",
      "          [ 2.2482e+00,  2.5341e+00,  8.1118e-01,  ...,  3.4152e+00,\n",
      "            3.7034e+00,  8.3920e-01],\n",
      "          ...,\n",
      "          [ 4.3192e+00,  2.7567e+00,  1.3717e+00,  ...,  5.0830e-01,\n",
      "            1.5737e+00,  3.9959e+00],\n",
      "          [ 3.0381e+00,  3.2674e+00,  2.7399e+00,  ...,  2.5011e+00,\n",
      "            1.2996e+00,  3.4591e+00],\n",
      "          [ 5.1169e+00,  2.8734e+00,  1.4250e+00,  ...,  1.9756e+00,\n",
      "            2.1808e+00,  3.5726e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5620e-02, -2.2984e-01, -1.7166e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0727e+00,  1.2793e+00,  4.4593e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.5328e+00,  1.6410e+00,  1.3810e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 9.4001e-01,  2.7176e+00,  1.0907e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 9.3164e-01,  2.5137e+00,  8.9265e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 9.4843e-01,  2.6502e+00,  9.7545e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.6259e+00, -2.2888e+00,  3.8499e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 8.9456e-01,  2.1824e+00,  2.7332e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1585e+00,  2.8192e+00,  1.7923e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.9047e+00,  9.0882e-01,  1.5647e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.0568e+00,  7.9631e-01,  1.5833e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.9274e+00,  9.4166e-01,  1.6098e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.8793e+00,  6.9666e-02,  4.9824e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.6016e+00,  3.7978e-01,  2.4950e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.3102e+00,  5.3989e+00,  4.1844e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 6.6824e+00,  1.8732e+00,  3.8767e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.7351e+00,  1.9706e+00,  2.6834e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.6366e+00,  1.3648e+00,  2.5842e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.1409e-02, -5.1290e-01,  1.8277e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.7745e+00,  1.6850e+00, -4.9621e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.2506e+00,  1.0940e-02,  5.5872e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.7336e+00,  7.4290e-01,  1.0677e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.8778e+00,  9.6798e-01,  1.3929e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.0915e+00,  9.7598e-01,  4.6017e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.5762e+00, -5.1801e-01, -2.6630e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.8796e+00,  3.9181e+00,  6.2075e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.8645e+00,  4.5326e+00,  4.9513e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 8.2461e+00,  2.8735e+00,  3.8746e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 8.1366e+00,  2.9517e+00,  2.1908e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 8.2193e+00,  1.3367e+00,  2.7044e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 5.5482e+00,  3.6070e-01, -7.5716e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.6210e+00, -2.7076e-01,  1.3797e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.2810e+00,  3.4908e+00, -1.8430e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 5.2436e+00,  2.6187e+00, -2.9572e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.3243e+00,  2.8792e+00, -3.1702e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.2690e+00,  2.1821e+00, -3.1700e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[6.8721e-02, 1.2140e-01, 4.9043e-02,  ..., 9.8779e-02,\n",
      "           1.3076e-01, 3.5832e-01],\n",
      "          [2.9334e-01, 5.9837e-02, 2.2454e-01,  ..., 1.6968e-01,\n",
      "           8.9667e-02, 1.1778e-01],\n",
      "          [2.2737e-01, 9.2939e-02, 2.0344e-01,  ..., 1.9936e-01,\n",
      "           1.1687e-01, 8.0393e-02],\n",
      "          ...,\n",
      "          [9.0881e-02, 9.5250e-02, 2.1992e-01,  ..., 1.3668e-01,\n",
      "           8.7636e-02, 3.2253e-01],\n",
      "          [1.4780e-01, 1.1723e-01, 2.9052e-01,  ..., 1.2341e-01,\n",
      "           7.5273e-02, 1.7413e-01],\n",
      "          [1.4254e-01, 1.6470e-01, 9.6356e-02,  ..., 1.0044e-01,\n",
      "           1.0566e-01, 2.0711e-01]],\n",
      "\n",
      "         [[9.4372e-01, 1.0571e-02, 1.2889e-02,  ..., 3.9301e-03,\n",
      "           2.7017e-03, 9.5576e-03],\n",
      "          [9.2191e-03, 1.5706e-02, 1.3013e-01,  ..., 3.8803e-01,\n",
      "           3.7440e-01, 4.1820e-02],\n",
      "          [1.8888e-02, 5.1634e-02, 6.3322e-02,  ..., 3.4683e-01,\n",
      "           3.9608e-01, 5.1020e-02],\n",
      "          ...,\n",
      "          [8.0830e-02, 5.4367e-02, 2.6783e-02,  ..., 2.0349e-01,\n",
      "           1.9332e-01, 3.4971e-01],\n",
      "          [3.0793e-02, 1.2846e-01, 1.2020e-01,  ..., 3.4316e-01,\n",
      "           1.2282e-01, 1.6969e-01],\n",
      "          [6.4105e-02, 3.2116e-01, 2.1586e-01,  ..., 9.0648e-02,\n",
      "           5.8756e-02, 6.2241e-02]],\n",
      "\n",
      "         [[8.3407e-01, 3.5241e-02, 3.4656e-02,  ..., 1.0697e-02,\n",
      "           5.8793e-03, 5.3247e-02],\n",
      "          [6.7038e-01, 1.0683e-01, 6.2202e-02,  ..., 1.5715e-02,\n",
      "           1.9332e-02, 3.7974e-02],\n",
      "          [2.6540e-01, 6.1543e-01, 2.9950e-02,  ..., 1.0275e-02,\n",
      "           3.1892e-03, 3.7872e-02],\n",
      "          ...,\n",
      "          [4.7586e-02, 1.6999e-02, 3.6024e-02,  ..., 1.3570e-02,\n",
      "           1.2998e-03, 1.3327e-02],\n",
      "          [1.0499e-01, 2.5234e-02, 1.7849e-02,  ..., 2.7313e-01,\n",
      "           1.4840e-02, 1.0852e-01],\n",
      "          [5.1531e-01, 2.0983e-02, 2.8737e-02,  ..., 2.7594e-02,\n",
      "           1.5226e-01, 2.3614e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.1194e-01, 1.3044e-01, 5.4760e-02,  ..., 2.0349e-01,\n",
      "           3.4931e-01, 2.1697e-02],\n",
      "          [4.4167e-01, 4.7472e-02, 8.3915e-02,  ..., 4.7689e-02,\n",
      "           1.3832e-01, 1.7716e-01],\n",
      "          [6.5721e-01, 1.7666e-02, 3.6546e-02,  ..., 4.5562e-02,\n",
      "           6.7542e-02, 1.4978e-01],\n",
      "          ...,\n",
      "          [1.6497e-01, 2.5544e-02, 1.6206e-02,  ..., 6.7917e-01,\n",
      "           3.5522e-02, 6.6098e-02],\n",
      "          [5.9170e-01, 1.7606e-02, 2.6396e-02,  ..., 1.2006e-01,\n",
      "           1.4256e-01, 8.4962e-02],\n",
      "          [6.0035e-01, 4.4704e-02, 1.0798e-01,  ..., 6.2016e-02,\n",
      "           1.1050e-01, 2.9392e-02]],\n",
      "\n",
      "         [[8.6370e-01, 2.9604e-02, 1.6447e-02,  ..., 2.6433e-02,\n",
      "           1.3123e-02, 2.8535e-02],\n",
      "          [4.8854e-03, 8.5496e-02, 5.9126e-01,  ..., 7.5510e-02,\n",
      "           2.5301e-02, 2.6973e-02],\n",
      "          [6.4301e-04, 3.7126e-02, 3.7040e-02,  ..., 5.6032e-01,\n",
      "           2.4948e-02, 3.8677e-02],\n",
      "          ...,\n",
      "          [6.9536e-03, 3.1515e-02, 4.0288e-02,  ..., 5.3019e-02,\n",
      "           3.5178e-01, 4.7037e-01],\n",
      "          [6.5173e-03, 5.2599e-03, 2.7458e-03,  ..., 1.1749e-01,\n",
      "           6.2653e-03, 8.5533e-01],\n",
      "          [3.3261e-01, 4.4608e-03, 3.4578e-02,  ..., 6.7427e-02,\n",
      "           4.5463e-02, 4.9567e-01]],\n",
      "\n",
      "         [[8.5820e-01, 5.6059e-02, 2.7141e-03,  ..., 6.6808e-03,\n",
      "           2.0354e-03, 3.1561e-02],\n",
      "          [3.2023e-01, 1.3590e-01, 1.6018e-01,  ..., 1.2430e-01,\n",
      "           1.5513e-01, 5.9433e-02],\n",
      "          [9.4701e-02, 1.2604e-01, 2.2503e-02,  ..., 3.0418e-01,\n",
      "           4.0580e-01, 2.3143e-02],\n",
      "          ...,\n",
      "          [4.6238e-01, 9.6922e-02, 2.4261e-02,  ..., 1.0232e-02,\n",
      "           2.9691e-02, 3.3464e-01],\n",
      "          [1.6366e-01, 2.0584e-01, 1.2146e-01,  ..., 9.5659e-02,\n",
      "           2.8769e-02, 2.4932e-01],\n",
      "          [6.5232e-01, 6.9204e-02, 1.6259e-02,  ..., 2.8197e-02,\n",
      "           3.4619e-02, 1.3925e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.4510e-01, 1.1127e-01, 1.1794e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.3926e-01, 2.9416e-01, 1.2784e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.3844e-01, 2.6569e-01, 2.0485e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [9.2100e-02, 5.4480e-01, 1.0708e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0894e-01, 5.2998e-01, 1.0478e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0248e-01, 5.6194e-01, 1.0528e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[4.4216e-01, 1.1935e-03, 5.5313e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4923e-01, 5.4095e-01, 8.0180e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2583e-02, 6.7187e-01, 2.4059e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [3.3526e-01, 1.2385e-01, 2.3864e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.7813e-01, 1.0721e-01, 2.3552e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.3745e-01, 1.2592e-01, 2.4562e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[8.9057e-01, 1.9731e-02, 3.0289e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.2759e-01, 1.8419e-03, 1.5273e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.6854e-01, 4.0274e-01, 1.1955e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.2045e-01, 3.4284e-03, 2.5423e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.7963e-01, 7.5010e-03, 1.5299e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.4359e-01, 4.8445e-03, 1.6400e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.3270e-01, 7.3979e-02, 7.6847e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.9640e-01, 3.6247e-01, 4.0925e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.6964e-01, 7.1315e-02, 1.2333e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.7404e-01, 2.1315e-01, 1.1283e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.5326e-01, 2.2273e-01, 9.7249e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.7652e-01, 1.8895e-01, 1.1281e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[9.3629e-01, 1.5607e-02, 2.0074e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.1387e-01, 4.3535e-02, 4.2964e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.6656e-03, 2.4005e-02, 3.6489e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [9.1388e-01, 4.2421e-03, 1.1544e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.5886e-01, 5.3704e-03, 2.5092e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.8652e-01, 1.0117e-03, 3.9721e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[9.4920e-01, 5.3023e-03, 1.9034e-06,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.4056e-01, 1.1033e-02, 5.7476e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.2785e-01, 2.3951e-01, 1.1558e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.1194e-01, 3.7090e-02, 1.4050e-04,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.9445e-01, 5.1546e-02, 1.2162e-04,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.2175e-01, 3.2944e-02, 1.5610e-04,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[ 2.4562e-01,  1.2968e-01,  5.0245e-02,  ...,  4.0555e-01,\n",
      "           -1.6753e-01,  1.3090e-01],\n",
      "          [ 5.0284e-01,  1.9850e-01, -3.3358e-02,  ...,  1.8338e-01,\n",
      "           -8.9166e-04,  2.2963e-01],\n",
      "          [ 3.2402e-01,  2.2213e-01, -3.6334e-02,  ...,  1.9114e-01,\n",
      "           -3.1235e-02,  1.8849e-01],\n",
      "          ...,\n",
      "          [ 1.5596e-01,  2.1334e-01,  6.5794e-02,  ...,  2.9860e-01,\n",
      "           -1.4132e-02,  2.3740e-01],\n",
      "          [ 1.3024e-01,  2.3042e-01,  8.8541e-03,  ...,  1.7832e-01,\n",
      "           -3.1213e-04,  2.8443e-01],\n",
      "          [ 2.9589e-01,  1.4554e-01, -2.7651e-02,  ...,  2.9023e-01,\n",
      "           -1.7223e-01,  1.5974e-01]],\n",
      "\n",
      "         [[ 2.3919e-01,  1.0628e-02, -1.1477e-01,  ...,  1.1878e-01,\n",
      "            1.8280e-01,  2.2040e-01],\n",
      "          [ 2.4021e-01,  3.1966e-01, -4.7226e-01,  ..., -6.2116e-02,\n",
      "            5.6883e-01, -1.7677e-01],\n",
      "          [ 1.9679e-01,  3.2804e-01, -4.2406e-01,  ..., -6.3908e-02,\n",
      "            5.1999e-01, -1.4205e-01],\n",
      "          ...,\n",
      "          [ 1.9742e-01,  3.3950e-01, -3.0263e-01,  ...,  3.8051e-02,\n",
      "            1.6413e-01,  4.0977e-02],\n",
      "          [ 2.4015e-01,  3.3774e-01, -3.1432e-01,  ...,  1.1359e-01,\n",
      "            2.9148e-01, -1.5834e-01],\n",
      "          [ 8.9904e-02,  1.4989e-01,  2.8327e-02,  ..., -8.6996e-02,\n",
      "            2.9074e-01,  9.2019e-03]],\n",
      "\n",
      "         [[ 4.9885e-02, -1.3087e-01, -5.6803e-02,  ...,  1.2540e-02,\n",
      "           -1.1839e-01, -5.5320e-02],\n",
      "          [ 2.1244e-02, -2.0190e-01, -6.0960e-02,  ..., -1.1926e-01,\n",
      "           -2.4726e-01,  3.7097e-02],\n",
      "          [-2.7299e-01, -5.9027e-01, -8.5493e-02,  ..., -7.9288e-01,\n",
      "           -1.0722e+00, -1.0620e-01],\n",
      "          ...,\n",
      "          [ 3.8990e-01, -5.0776e-01,  1.1469e-01,  ..., -4.9615e-01,\n",
      "           -3.0321e-01,  1.1065e+00],\n",
      "          [ 2.7739e-02, -1.4143e-01, -1.4731e-01,  ...,  4.3158e-02,\n",
      "           -1.5996e-01,  7.3976e-01],\n",
      "          [-7.8060e-02, -1.3621e-01, -1.4138e-01,  ...,  1.9618e-01,\n",
      "           -1.4318e-01,  5.7760e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5905e-01, -1.8358e-01,  5.6286e-01,  ..., -2.4749e-01,\n",
      "            1.0465e-01,  1.8550e-01],\n",
      "          [ 2.5838e-01, -1.3333e-01,  2.0613e-01,  ..., -2.3065e-01,\n",
      "            1.1588e-01,  1.0657e-01],\n",
      "          [ 3.2469e-01, -1.1630e-01,  1.4034e-01,  ..., -2.1879e-01,\n",
      "            2.5513e-02, -6.7380e-02],\n",
      "          ...,\n",
      "          [ 5.0960e-01, -5.9145e-01,  8.5598e-01,  ..., -4.2729e-01,\n",
      "            2.0162e-01, -5.6396e-01],\n",
      "          [ 3.0689e-01, -1.7596e-01,  2.6678e-01,  ..., -2.4116e-01,\n",
      "           -5.5942e-03, -1.6196e-01],\n",
      "          [ 3.0149e-01, -1.6531e-01,  1.7130e-01,  ..., -1.8186e-01,\n",
      "            1.9723e-03, -9.5908e-03]],\n",
      "\n",
      "         [[-1.1392e-01, -2.3395e-01, -8.8770e-03,  ..., -3.8448e-02,\n",
      "           -6.1845e-02,  1.9629e-01],\n",
      "          [ 1.5037e-01, -6.6688e-02, -3.7184e-01,  ...,  2.4498e-01,\n",
      "            3.1962e-01, -1.7469e-02],\n",
      "          [-6.7953e-02,  3.8159e-02, -1.1922e+00,  ..., -3.2700e-01,\n",
      "            2.4186e-02,  1.9074e-01],\n",
      "          ...,\n",
      "          [-8.4124e-01, -1.0109e-01, -2.5698e-01,  ...,  7.7899e-02,\n",
      "           -2.4325e-01,  1.1792e-01],\n",
      "          [-6.3558e-01, -9.1527e-01,  6.0955e-02,  ..., -7.5397e-02,\n",
      "           -7.0487e-01, -3.2710e-01],\n",
      "          [-4.5301e-01, -5.7016e-01,  1.0560e-02,  ..., -3.3838e-02,\n",
      "           -4.0964e-01, -7.6137e-02]],\n",
      "\n",
      "         [[-1.1978e-02, -9.6900e-02, -2.3497e-02,  ..., -1.8513e-02,\n",
      "            1.3241e-01,  8.4275e-02],\n",
      "          [-2.5198e-01, -2.2933e-01, -5.7986e-02,  ...,  1.4181e-03,\n",
      "            2.2634e-01, -2.5134e-02],\n",
      "          [-7.2560e-02, -2.9360e-01, -8.9488e-02,  ...,  6.1552e-02,\n",
      "            3.3794e-01, -4.6107e-02],\n",
      "          ...,\n",
      "          [-1.1179e-01, -1.4934e-01, -6.3281e-02,  ...,  1.8716e-02,\n",
      "            1.8341e-01,  6.9881e-02],\n",
      "          [-3.1374e-01, -1.6643e-01, -1.2493e-01,  ..., -2.0125e-02,\n",
      "            2.5257e-01, -1.7115e-02],\n",
      "          [-6.4079e-02, -1.1875e-01, -4.4016e-02,  ..., -2.9857e-03,\n",
      "            1.6374e-01,  7.2941e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.5758e-01,  2.2885e-01,  1.3461e-01,  ...,  4.5271e-01,\n",
      "           -1.2385e-02,  1.0453e-01],\n",
      "          [ 8.9187e-01,  3.8608e-01,  2.5489e-01,  ...,  8.3502e-02,\n",
      "           -7.7269e-02, -5.6630e-02],\n",
      "          [ 8.3571e-01,  4.3973e-01,  2.1767e-01,  ...,  1.3283e-01,\n",
      "           -5.8382e-02, -3.6390e-02],\n",
      "          ...,\n",
      "          [ 5.3506e-01,  6.0215e-01,  5.3570e-01,  ..., -2.4731e-01,\n",
      "           -1.1207e-01, -2.7591e-01],\n",
      "          [ 5.7226e-01,  5.8473e-01,  5.1643e-01,  ..., -2.3295e-01,\n",
      "           -1.1228e-01, -2.6270e-01],\n",
      "          [ 5.4324e-01,  6.1392e-01,  5.4680e-01,  ..., -2.8292e-01,\n",
      "           -1.1889e-01, -2.9084e-01]],\n",
      "\n",
      "         [[-2.6011e-02,  1.5515e-01, -2.9486e-02,  ...,  6.2686e-02,\n",
      "            3.3391e-01, -4.5894e-03],\n",
      "          [ 8.7444e-01,  8.0068e-02, -5.7479e-01,  ...,  3.8062e-01,\n",
      "            2.4166e-01,  3.4476e-01],\n",
      "          [ 9.9480e-01,  7.6113e-02, -6.0934e-01,  ...,  4.5057e-01,\n",
      "            3.8747e-01,  2.7929e-01],\n",
      "          ...,\n",
      "          [ 2.3573e-01,  1.5472e-01, -2.4823e-01,  ...,  1.2874e-01,\n",
      "            1.4854e-01,  2.0279e-01],\n",
      "          [ 2.1979e-01,  1.4708e-01, -2.3067e-01,  ...,  1.2323e-01,\n",
      "            1.5307e-01,  1.9674e-01],\n",
      "          [ 2.3707e-01,  1.5323e-01, -2.4592e-01,  ...,  1.3044e-01,\n",
      "            1.5585e-01,  1.9843e-01]],\n",
      "\n",
      "         [[ 7.5099e-02, -6.9021e-02, -4.9893e-02,  ...,  4.7990e-02,\n",
      "           -3.8591e-02, -8.3049e-02],\n",
      "          [ 7.1423e-02, -1.0688e-01, -4.1239e-02,  ...,  6.8331e-02,\n",
      "           -5.1568e-02, -1.0209e-01],\n",
      "          [ 2.4256e-01,  6.6124e-01, -1.7635e-01,  ..., -2.4482e-01,\n",
      "            2.0817e-01,  1.5362e-01],\n",
      "          ...,\n",
      "          [-3.3177e-02, -1.5160e-01, -2.5126e-01,  ...,  2.2641e-02,\n",
      "           -1.6617e-01,  9.8561e-02],\n",
      "          [ 6.5802e-02, -1.0086e-01, -6.0290e-02,  ...,  6.1545e-02,\n",
      "           -5.7985e-02, -8.3266e-02],\n",
      "          [ 7.6809e-02, -9.8876e-02, -3.3703e-02,  ...,  6.7378e-02,\n",
      "           -4.4698e-02, -1.0795e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.4787e-02, -3.8852e-01,  4.0761e-01,  ..., -1.2965e-01,\n",
      "           -1.3438e-01, -6.7822e-01],\n",
      "          [ 5.4001e-01, -2.7877e-01,  2.2083e-01,  ..., -4.7034e-01,\n",
      "           -3.8971e-03,  2.2057e-02],\n",
      "          [ 3.5883e-01, -1.2233e-01,  1.3744e-01,  ..., -2.1812e-01,\n",
      "           -4.7175e-02, -1.9837e-01],\n",
      "          ...,\n",
      "          [ 4.3442e-01, -2.2598e-01,  1.7283e-01,  ..., -3.2222e-01,\n",
      "           -8.4711e-02, -1.4957e-01],\n",
      "          [ 4.4601e-01, -2.2033e-01,  1.7657e-01,  ..., -3.3761e-01,\n",
      "           -6.1801e-02, -1.1953e-01],\n",
      "          [ 4.2196e-01, -2.0378e-01,  1.7038e-01,  ..., -3.0832e-01,\n",
      "           -6.4580e-02, -1.4754e-01]],\n",
      "\n",
      "         [[-1.3788e-01, -2.6545e-01,  6.2003e-02,  ..., -4.1493e-02,\n",
      "           -1.1487e-01,  2.1437e-01],\n",
      "          [-5.7804e-01, -4.5694e-01,  1.6346e-01,  ..., -1.1650e-01,\n",
      "           -4.4836e-01, -1.7234e-01],\n",
      "          [-6.9704e-01, -1.0145e+00,  2.9437e-01,  ..., -3.8591e-02,\n",
      "           -7.2882e-01, -4.2805e-01],\n",
      "          ...,\n",
      "          [-1.5656e-01, -3.1216e-01,  8.2308e-02,  ..., -4.1627e-02,\n",
      "           -1.3918e-01,  1.8540e-01],\n",
      "          [-1.3001e-01, -2.8265e-01,  7.1082e-02,  ..., -3.9803e-02,\n",
      "           -1.1307e-01,  2.1428e-01],\n",
      "          [-1.1476e-01, -2.6507e-01,  6.8403e-02,  ..., -4.1012e-02,\n",
      "           -9.5750e-02,  2.3055e-01]],\n",
      "\n",
      "         [[ 6.1398e-02, -8.4292e-02,  1.3235e-02,  ..., -1.1561e-02,\n",
      "            1.0924e-01,  9.8038e-02],\n",
      "          [ 1.2858e-02, -1.0894e-01,  3.2036e-02,  ...,  1.6082e-02,\n",
      "            1.4042e-01,  9.2244e-02],\n",
      "          [ 4.3539e-01,  2.8666e-03, -1.1742e-02,  ...,  1.4281e-01,\n",
      "            2.1685e-02, -4.7198e-02],\n",
      "          ...,\n",
      "          [ 4.5734e-02, -9.0225e-02,  3.3423e-03,  ...,  5.6851e-02,\n",
      "            1.7479e-01,  7.2246e-02],\n",
      "          [ 8.7762e-02, -7.9760e-02,  3.6137e-03,  ...,  5.2872e-02,\n",
      "            1.4736e-01,  6.5010e-02],\n",
      "          [ 7.4483e-02, -8.2315e-02,  7.2584e-03,  ...,  2.8839e-02,\n",
      "            1.3509e-01,  7.8056e-02]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[-2.8722e-01,  3.5436e-02, -6.2860e-01,  ..., -1.2443e+00,\n",
      "            1.5450e+00,  4.0176e-01],\n",
      "          [-2.2408e-01,  1.0068e+00,  2.3384e-01,  ...,  3.9829e-01,\n",
      "           -3.6335e-01, -7.3362e-01],\n",
      "          [ 8.5771e-01, -1.8368e-01,  3.1129e-01,  ..., -3.2103e-01,\n",
      "           -5.7111e-01,  8.3294e-01],\n",
      "          ...,\n",
      "          [ 1.9907e+00,  1.2489e+00, -3.6346e-01,  ..., -1.1305e+00,\n",
      "           -4.1583e-01,  1.2125e+00],\n",
      "          [ 1.5287e-01,  1.3523e+00, -8.2789e-01,  ..., -1.3101e-01,\n",
      "           -5.8557e-01,  2.3376e-01],\n",
      "          [ 4.4039e-01,  1.0463e+00,  7.8658e-01,  ...,  3.8341e-01,\n",
      "            3.4994e-01,  2.9193e-01]],\n",
      "\n",
      "         [[ 1.3331e+00,  2.4396e-01,  7.9607e-01,  ..., -1.0397e+00,\n",
      "            4.1660e-01, -7.3553e-01],\n",
      "          [-6.1258e-01,  8.1758e-01, -5.2903e-01,  ...,  7.2046e-01,\n",
      "            1.2612e+00,  8.2847e-01],\n",
      "          [-1.2161e-02, -1.1807e+00, -4.6351e-01,  ...,  1.3871e+00,\n",
      "            3.0272e-01,  2.2238e+00],\n",
      "          ...,\n",
      "          [ 2.2198e-02,  1.3261e+00, -2.4014e+00,  ..., -1.0409e+00,\n",
      "            2.1650e-01,  1.1419e+00],\n",
      "          [ 6.7164e-01, -9.8017e-01, -9.8098e-01,  ...,  1.4820e+00,\n",
      "            1.3351e+00,  2.4348e+00],\n",
      "          [-1.6230e+00, -4.4919e-01,  6.0520e-02,  ..., -1.0604e+00,\n",
      "           -4.1670e-01,  2.6692e-01]],\n",
      "\n",
      "         [[-7.2964e-01, -2.5385e-01,  3.1411e-01,  ..., -5.4323e-01,\n",
      "            4.8988e-02, -9.5717e-01],\n",
      "          [-3.2320e-01, -6.7744e-01, -1.2444e-02,  ..., -5.5322e-01,\n",
      "           -4.9145e-01, -3.7705e-01],\n",
      "          [-4.0658e-01, -1.0349e+00, -2.1874e-01,  ...,  4.3836e-02,\n",
      "            3.4347e-02, -3.3133e-01],\n",
      "          ...,\n",
      "          [ 3.9026e-01,  4.2137e-01, -6.9322e-01,  ...,  2.1663e+00,\n",
      "            1.3391e+00,  1.6269e+00],\n",
      "          [-1.1380e+00,  1.0470e-01, -4.7403e-02,  ...,  2.1750e-03,\n",
      "           -3.0777e-01,  7.3382e-01],\n",
      "          [-2.6154e-01,  7.3518e-01, -6.6738e-01,  ..., -2.2772e-01,\n",
      "           -1.4785e-01, -3.9513e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1522e-01, -4.2171e-02,  2.4223e-01,  ..., -4.8121e-02,\n",
      "           -9.4148e-02, -1.2625e-01],\n",
      "          [-1.6576e-01,  1.6386e-01,  3.4295e-01,  ...,  1.6257e-01,\n",
      "           -1.7173e+00,  1.5560e-01],\n",
      "          [ 9.4130e-02,  7.1269e-01,  1.0148e+00,  ...,  9.5740e-02,\n",
      "           -1.2631e+00,  4.6800e-01],\n",
      "          ...,\n",
      "          [-3.3711e-01,  9.7080e-01,  3.6030e-01,  ..., -2.3169e-01,\n",
      "           -1.8321e+00,  8.2249e-01],\n",
      "          [ 1.4164e+00,  3.5030e-01, -8.3376e-01,  ..., -8.6850e-01,\n",
      "           -1.4705e+00,  2.8342e-01],\n",
      "          [ 5.7199e-03,  2.0547e-01,  4.0775e-01,  ..., -3.8085e-01,\n",
      "            4.7841e-01,  1.0221e+00]],\n",
      "\n",
      "         [[-6.5437e-01, -3.6524e-01,  2.1436e-01,  ...,  8.7677e-01,\n",
      "           -1.1515e-01,  3.6432e-01],\n",
      "          [-1.4617e+00, -8.8367e-01, -5.7093e-01,  ..., -1.0861e-01,\n",
      "           -5.7207e-01,  1.0936e+00],\n",
      "          [ 1.0104e+00, -8.5642e-01,  2.3751e-01,  ..., -1.0053e-01,\n",
      "            5.2364e-01,  6.6156e-01],\n",
      "          ...,\n",
      "          [-1.0016e+00,  5.5560e-01, -4.6305e-01,  ...,  6.8923e-01,\n",
      "            5.2106e-01,  6.1680e-01],\n",
      "          [ 6.5867e-01,  1.0148e+00,  6.7141e-02,  ..., -1.0634e+00,\n",
      "            1.4196e+00, -6.1956e-01],\n",
      "          [-3.1510e-01,  6.4381e-01,  1.1050e+00,  ...,  4.7875e-01,\n",
      "            2.9437e-01, -4.3246e-01]],\n",
      "\n",
      "         [[-1.5409e-01,  6.3230e-01, -4.4500e-02,  ..., -8.1770e-01,\n",
      "            1.4287e+00, -3.1958e-01],\n",
      "          [-4.5571e-01, -3.3532e-01, -4.2698e-02,  ...,  4.3432e-01,\n",
      "            1.8975e+00, -1.9951e+00],\n",
      "          [-1.7145e+00, -6.4254e-01,  1.9135e-01,  ..., -5.8893e-01,\n",
      "            8.6847e-01,  1.1910e-01],\n",
      "          ...,\n",
      "          [-8.8701e-01,  2.3995e-01,  7.2287e-01,  ..., -9.2441e-01,\n",
      "           -2.2467e-01, -7.3387e-01],\n",
      "          [ 1.9215e-01, -7.2799e-01,  6.0379e-01,  ..., -7.2514e-01,\n",
      "           -8.9736e-01,  2.7874e-01],\n",
      "          [-2.6982e-01,  4.2863e-01, -2.4082e-01,  ..., -2.2053e+00,\n",
      "            1.1020e+00,  3.1743e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2470e-01,  7.6431e-02, -6.7195e-01,  ..., -9.7634e-01,\n",
      "            1.0152e+00, -8.5631e-02],\n",
      "          [ 1.2962e+00,  4.8192e-01,  1.1067e+00,  ..., -1.0556e+00,\n",
      "            6.6727e-01, -2.5417e-01],\n",
      "          [ 8.5035e-01,  1.3604e+00, -5.4519e-01,  ..., -1.9491e+00,\n",
      "            6.3530e-01,  4.7139e-01],\n",
      "          ...,\n",
      "          [ 1.5250e-01, -4.7287e-01, -1.2802e+00,  ...,  1.3248e-01,\n",
      "           -6.5627e-01, -4.6560e-01],\n",
      "          [ 1.9954e-01, -4.3914e-01, -1.2996e+00,  ...,  1.7712e-01,\n",
      "           -7.4748e-01, -4.3091e-01],\n",
      "          [ 2.3761e-01, -3.7000e-01, -1.1703e+00,  ...,  2.5659e-01,\n",
      "           -7.4090e-01, -4.6363e-01]],\n",
      "\n",
      "         [[ 1.3222e+00,  5.4836e-01,  1.1693e+00,  ..., -1.2358e+00,\n",
      "            2.0292e-01, -1.2493e+00],\n",
      "          [-5.1038e-01,  7.9664e-01,  5.6452e-01,  ...,  1.5926e+00,\n",
      "            1.6529e+00, -8.6499e-01],\n",
      "          [ 6.2524e-01, -9.0691e-01, -1.3328e+00,  ...,  1.2870e+00,\n",
      "            1.7489e-01,  1.7338e+00],\n",
      "          ...,\n",
      "          [-1.8589e-02,  1.9637e+00, -4.9506e-01,  ..., -1.4518e-01,\n",
      "            1.4331e-01, -1.8152e-01],\n",
      "          [-7.9235e-01,  9.8799e-02,  4.7945e-01,  ...,  4.5923e-01,\n",
      "            5.8505e-01,  2.0113e-01],\n",
      "          [-2.4539e+00,  1.0323e+00,  8.1896e-01,  ..., -8.8505e-01,\n",
      "            2.8304e-01, -7.3693e-02]],\n",
      "\n",
      "         [[-6.2539e-01, -2.6297e-01, -2.4721e-01,  ..., -2.5537e-01,\n",
      "            2.1288e-01, -1.1281e+00],\n",
      "          [ 2.6459e-01,  1.4913e-01, -5.3517e-01,  ...,  1.2748e+00,\n",
      "           -6.6494e-02,  4.8593e-01],\n",
      "          [ 2.5518e-01,  8.0180e-04,  1.6590e-01,  ..., -1.0368e-01,\n",
      "            8.9183e-01,  6.8216e-01],\n",
      "          ...,\n",
      "          [ 8.9193e-02, -6.2348e-01, -2.3016e-01,  ...,  4.2416e-01,\n",
      "           -1.4533e-01,  5.0994e-01],\n",
      "          [ 8.7094e-02, -5.1319e-01, -3.7523e-01,  ...,  6.0331e-01,\n",
      "            1.7126e-02,  6.1692e-01],\n",
      "          [ 7.9417e-02, -4.4653e-01, -4.0049e-01,  ...,  5.9538e-01,\n",
      "            8.0230e-02,  6.1399e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5380e-01, -6.2804e-02,  4.0024e-02,  ...,  1.1662e-01,\n",
      "            1.1221e-01, -3.6827e-01],\n",
      "          [-7.9421e-01,  1.7582e+00, -2.1665e-01,  ...,  3.3210e-01,\n",
      "           -1.9617e+00,  8.3617e-01],\n",
      "          [-5.2930e-01,  1.7859e-01,  1.2395e-02,  ..., -2.9668e-01,\n",
      "           -5.2521e-01,  1.5684e+00],\n",
      "          ...,\n",
      "          [-4.4407e-01,  5.3262e-01, -6.1144e-01,  ..., -3.3801e-01,\n",
      "           -8.1723e-01, -9.4055e-02],\n",
      "          [-3.2046e-01,  5.5733e-01, -8.0128e-01,  ..., -3.2522e-01,\n",
      "           -7.3155e-01, -1.4169e-01],\n",
      "          [-2.6263e-01,  5.5638e-01, -7.1880e-01,  ..., -3.1301e-01,\n",
      "           -7.2643e-01, -1.1043e-01]],\n",
      "\n",
      "         [[-5.7756e-01, -2.4008e-01,  7.4234e-02,  ...,  9.4574e-01,\n",
      "            2.3708e-01,  1.5758e-01],\n",
      "          [-1.1527e+00, -2.1252e-01, -2.8660e-01,  ...,  3.6317e-01,\n",
      "            1.8788e-01,  1.7612e+00],\n",
      "          [ 4.5146e-01,  2.9985e-01,  1.2898e-02,  ...,  7.9703e-01,\n",
      "           -7.0317e-01,  6.8784e-01],\n",
      "          ...,\n",
      "          [ 6.2798e-01,  1.2068e+00, -2.3393e-02,  ...,  4.3931e-01,\n",
      "           -2.0683e-01, -1.2725e-01],\n",
      "          [ 6.3322e-01,  1.4089e+00,  3.1459e-01,  ...,  7.5428e-01,\n",
      "           -1.5781e-01, -2.6456e-02],\n",
      "          [ 5.0294e-01,  1.5175e+00,  6.6711e-01,  ...,  1.0103e+00,\n",
      "           -2.9930e-01,  4.2584e-01]],\n",
      "\n",
      "         [[-3.8553e-01,  5.8233e-01,  2.8014e-01,  ..., -6.7450e-01,\n",
      "            9.6497e-01, -2.3521e-01],\n",
      "          [-2.4775e+00,  6.6627e-01,  9.9411e-01,  ..., -6.0695e-01,\n",
      "           -8.3399e-01,  1.0663e+00],\n",
      "          [-1.1332e+00,  2.7688e-01, -4.0998e-01,  ..., -4.9245e-01,\n",
      "           -3.6391e-02, -6.1100e-02],\n",
      "          ...,\n",
      "          [ 3.6867e-01, -8.0955e-02, -9.8783e-02,  ..., -8.2257e-01,\n",
      "            2.2893e-01, -1.2374e-02],\n",
      "          [ 3.3200e-01, -2.5781e-01, -7.5111e-02,  ..., -1.4192e+00,\n",
      "            5.9928e-02,  7.0009e-01],\n",
      "          [ 4.0917e-01, -1.0834e-01, -3.4532e-01,  ..., -1.6918e+00,\n",
      "           -4.3243e-02,  1.1006e+00]]]], grad_fn=<PermuteBackward0>), query layer: tensor([[[[-4.0908e-01, -6.4207e-01, -8.0802e-01,  ..., -8.9070e-01,\n",
      "            2.8651e-01,  7.3422e-02],\n",
      "          [ 1.2550e+00,  6.3318e-01, -2.9885e-01,  ..., -8.1572e-01,\n",
      "            1.5764e-01, -1.6071e-01],\n",
      "          [-1.6554e-01,  1.3441e+00,  5.5826e-01,  ...,  2.4316e-01,\n",
      "           -1.9106e-01, -3.3460e-01],\n",
      "          ...,\n",
      "          [ 4.9242e-01,  2.5190e+00, -3.0285e-01,  ..., -1.0719e-01,\n",
      "            7.1688e-01, -4.5399e-02],\n",
      "          [ 7.1271e-01,  2.4053e+00, -8.7175e-01,  ..., -1.4523e-01,\n",
      "            8.0040e-01, -1.0102e+00],\n",
      "          [-9.8246e-01, -5.3590e-01, -7.1530e-01,  ..., -8.0713e-01,\n",
      "           -5.1645e-02,  4.8913e-01]],\n",
      "\n",
      "         [[ 3.0600e-01,  6.6801e-01,  3.9754e-01,  ..., -7.3293e-01,\n",
      "            1.9332e-01, -5.4118e-01],\n",
      "          [ 2.4654e-01, -1.8644e+00, -5.7859e-01,  ...,  1.3368e+00,\n",
      "            7.9702e-01,  7.4977e-01],\n",
      "          [ 1.6582e+00, -4.3958e-01, -4.4185e-01,  ..., -3.2160e-01,\n",
      "            1.8212e-01,  7.3188e-01],\n",
      "          ...,\n",
      "          [ 2.0267e-01,  4.4092e-01,  5.2487e-01,  ..., -4.9345e-01,\n",
      "            1.2583e-01,  2.3948e+00],\n",
      "          [-3.4456e+00,  1.6487e-01,  2.1285e+00,  ...,  1.0968e+00,\n",
      "           -1.3794e-02,  4.6493e-01],\n",
      "          [ 1.3872e-01,  2.1682e-02, -3.0357e-01,  ..., -7.2233e-01,\n",
      "            5.5333e-01, -6.4454e-01]],\n",
      "\n",
      "         [[-7.0993e-01,  5.7869e-01, -2.9320e-01,  ..., -2.0569e-02,\n",
      "            7.0427e-01, -6.6151e-01],\n",
      "          [-2.8205e-01,  3.2590e-01,  1.0362e+00,  ..., -8.0357e-01,\n",
      "            9.8756e-01, -9.6427e-01],\n",
      "          [-2.2236e-01,  1.2986e+00,  8.9262e-01,  ..., -8.1281e-01,\n",
      "            8.6119e-01, -1.0970e-01],\n",
      "          ...,\n",
      "          [-2.1029e+00,  3.9663e-01,  6.7368e-01,  ..., -5.5783e-01,\n",
      "            1.5500e+00, -4.8602e-01],\n",
      "          [-8.5770e-02,  3.0353e-01,  6.5123e-01,  ..., -1.1632e+00,\n",
      "           -3.7671e-01, -3.1423e-01],\n",
      "          [ 4.6418e-01,  1.2989e+00, -1.3650e+00,  ..., -4.5104e-01,\n",
      "            4.4323e-01, -2.0064e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3711e-01,  4.5352e-01, -1.3141e-01,  ..., -4.0640e-01,\n",
      "           -7.0537e-01,  6.4338e-01],\n",
      "          [-5.0365e-01,  1.0807e+00,  1.0215e+00,  ...,  7.2566e-01,\n",
      "            3.8075e-01,  2.0196e-01],\n",
      "          [ 1.4622e+00,  5.9929e-01,  1.1026e+00,  ..., -8.6723e-02,\n",
      "            2.0099e-01, -3.6962e-02],\n",
      "          ...,\n",
      "          [ 5.2479e-02, -1.1469e+00, -9.8817e-01,  ..., -9.4907e-01,\n",
      "            7.7414e-01,  4.2301e-02],\n",
      "          [-1.3947e+00, -5.9921e-01, -3.2431e-01,  ...,  2.7230e-01,\n",
      "           -7.7484e-01, -6.9063e-02],\n",
      "          [-5.2740e-01, -2.4304e-01,  3.9443e-01,  ..., -5.3624e-01,\n",
      "            1.3937e-01,  1.3625e-01]],\n",
      "\n",
      "         [[-3.9843e-01,  6.3211e-01, -9.7775e-01,  ...,  6.0892e-01,\n",
      "           -1.7456e-01,  2.6349e-01],\n",
      "          [ 5.6321e-01,  1.1434e+00, -2.1331e-01,  ...,  1.5558e+00,\n",
      "           -3.9885e-01,  1.1637e+00],\n",
      "          [ 1.3375e-01,  9.8239e-01,  9.2568e-02,  ...,  8.6176e-01,\n",
      "           -5.3828e-01,  8.4993e-01],\n",
      "          ...,\n",
      "          [ 1.3567e+00, -4.8246e-02,  4.5617e-01,  ..., -6.6348e-02,\n",
      "           -2.0271e-01,  1.6179e-01],\n",
      "          [ 7.2350e-01, -1.5899e-01,  1.3070e+00,  ...,  1.3177e+00,\n",
      "            1.3893e+00,  2.0472e+00],\n",
      "          [-5.9632e-01,  1.1649e+00, -2.7093e-01,  ...,  1.0644e+00,\n",
      "            2.3672e-01,  8.3651e-01]],\n",
      "\n",
      "         [[ 7.2886e-02, -2.2686e-01, -7.2329e-01,  ..., -2.9127e-01,\n",
      "            9.0018e-01,  4.5523e-01],\n",
      "          [ 1.7534e+00, -9.4953e-01, -4.1824e-01,  ..., -9.4124e-01,\n",
      "            3.4280e+00, -9.6111e-01],\n",
      "          [ 6.2346e-01, -1.3796e+00, -5.3462e-01,  ..., -1.4001e+00,\n",
      "            2.8368e+00,  1.6968e-01],\n",
      "          ...,\n",
      "          [-7.6139e-01, -1.4863e-01,  1.2610e-01,  ..., -1.3417e+00,\n",
      "            2.1909e-01,  4.3643e-01],\n",
      "          [-2.5398e-01, -3.8029e-01,  2.8538e-02,  ...,  8.8217e-01,\n",
      "           -4.4804e-01, -5.4387e-01],\n",
      "          [-6.4044e-01,  1.9996e-01, -4.9275e-01,  ...,  8.4787e-01,\n",
      "            6.6840e-01, -7.5246e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.5537e-01, -5.7901e-01, -6.9481e-01,  ..., -9.9316e-01,\n",
      "            4.7262e-01,  4.4034e-01],\n",
      "          [ 1.9523e+00, -2.9793e-02,  4.9409e-01,  ..., -4.0152e-01,\n",
      "           -1.9992e+00, -5.6263e-01],\n",
      "          [ 3.0501e-01, -5.5209e-01, -5.8748e-01,  ..., -6.8417e-01,\n",
      "           -2.9413e-01, -7.4177e-01],\n",
      "          ...,\n",
      "          [ 8.5040e-01, -1.8708e-02, -2.5931e-01,  ..., -1.5125e+00,\n",
      "            6.7907e-01,  1.3402e+00],\n",
      "          [ 8.4839e-01, -1.4983e-02, -3.7531e-01,  ..., -1.4946e+00,\n",
      "            6.3823e-01,  1.2548e+00],\n",
      "          [ 9.1187e-01, -2.7854e-03, -3.8434e-01,  ..., -1.4748e+00,\n",
      "            5.5714e-01,  1.3542e+00]],\n",
      "\n",
      "         [[ 4.7905e-01,  7.8566e-01, -2.6177e-02,  ..., -6.7058e-01,\n",
      "           -1.2633e-01, -1.8851e-01],\n",
      "          [-1.1675e-01,  9.9160e-01, -4.8479e-01,  ...,  1.9209e+00,\n",
      "            1.6353e+00,  9.0730e-01],\n",
      "          [ 8.5715e-01,  4.0931e-01, -3.7654e-02,  ..., -4.7769e-01,\n",
      "            7.5482e-01,  2.3032e+00],\n",
      "          ...,\n",
      "          [ 4.2272e-01, -3.0896e-01, -4.1956e-01,  ...,  7.2010e-01,\n",
      "            1.4065e-01,  6.9392e-01],\n",
      "          [-1.3291e+00,  4.2994e-01,  1.3275e-01,  ..., -8.1414e-01,\n",
      "           -2.1858e-01,  6.5171e-01],\n",
      "          [-9.4610e-02,  1.2864e-01, -1.1885e+00,  ..., -3.0729e-01,\n",
      "            1.1826e-01, -6.1512e-02]],\n",
      "\n",
      "         [[-6.3165e-01,  3.9365e-01,  4.6363e-02,  ...,  7.2068e-02,\n",
      "            6.4156e-01, -4.5271e-01],\n",
      "          [-1.5698e-01,  1.6702e+00,  2.0170e+00,  ..., -1.0026e+00,\n",
      "            1.1015e+00, -1.3706e+00],\n",
      "          [-3.2070e-02,  6.0082e-01,  6.0924e-01,  ...,  2.0146e-01,\n",
      "            3.9251e-01, -7.4630e-01],\n",
      "          ...,\n",
      "          [-3.9213e-01, -1.2948e-01,  2.2320e-01,  ...,  7.3326e-02,\n",
      "            5.8349e-01, -7.3311e-01],\n",
      "          [-4.1332e-01, -7.1272e-02,  2.6819e-01,  ...,  1.4593e-01,\n",
      "            4.8509e-01, -8.2000e-01],\n",
      "          [-4.6827e-01, -9.9348e-02,  2.4438e-01,  ...,  4.9907e-02,\n",
      "            4.9484e-01, -7.9381e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0053e-01,  3.2943e-01, -1.0292e-01,  ..., -1.7462e-01,\n",
      "           -5.9694e-01,  9.0948e-01],\n",
      "          [ 2.0178e+00, -1.5311e+00,  7.5510e-01,  ..., -8.8646e-01,\n",
      "            1.1394e+00, -1.0089e+00],\n",
      "          [ 9.2277e-01,  7.3671e-01,  7.7601e-02,  ...,  3.1655e-02,\n",
      "            2.2266e-01, -6.6975e-01],\n",
      "          ...,\n",
      "          [ 6.0015e-01, -4.3889e-01, -1.9027e-01,  ...,  1.4573e-01,\n",
      "           -7.1917e-01,  6.5389e-02],\n",
      "          [ 5.7408e-01, -4.2962e-01, -1.1380e-01,  ..., -8.3499e-05,\n",
      "           -5.7321e-01,  2.8738e-02],\n",
      "          [ 5.9307e-01, -4.4707e-01, -1.4760e-01,  ..., -1.5696e-02,\n",
      "           -5.5012e-01,  1.3396e-02]],\n",
      "\n",
      "         [[-4.7617e-01,  8.0463e-01, -1.1379e+00,  ...,  6.4153e-01,\n",
      "            4.9107e-02,  3.7201e-01],\n",
      "          [-6.1731e-01, -5.8705e-01,  8.5723e-02,  ..., -1.1773e+00,\n",
      "           -1.1779e+00, -7.7641e-01],\n",
      "          [ 5.2139e-01,  2.1125e-01,  4.4466e-01,  ..., -5.7029e-01,\n",
      "           -2.4473e-01,  4.4563e-01],\n",
      "          ...,\n",
      "          [ 1.7194e-01,  1.0372e-01, -5.6654e-01,  ...,  5.9164e-01,\n",
      "           -1.9047e-01,  3.4877e-01],\n",
      "          [ 4.6270e-01,  8.9632e-02, -6.9618e-01,  ...,  3.1437e-01,\n",
      "           -6.5901e-02,  2.8486e-01],\n",
      "          [ 6.4984e-01,  1.9777e-01, -7.1013e-01,  ...,  2.7123e-01,\n",
      "            3.1991e-01, -8.2974e-02]],\n",
      "\n",
      "         [[ 2.3845e-01, -4.2463e-01, -5.8154e-01,  ..., -1.5958e-01,\n",
      "            7.8874e-01,  4.9004e-01],\n",
      "          [ 3.3592e-01,  1.4497e-01,  5.9008e-01,  ..., -2.1933e+00,\n",
      "            1.0216e+00,  1.8603e+00],\n",
      "          [ 9.2006e-01, -5.4057e-01, -7.2267e-01,  ..., -1.2052e+00,\n",
      "            2.7081e+00,  9.0072e-02],\n",
      "          ...,\n",
      "          [-5.1164e-01, -3.3091e-01, -2.5671e-01,  ..., -2.6091e-02,\n",
      "           -5.2845e-02,  5.1231e-01],\n",
      "          [-2.6968e-01, -1.9798e-01, -3.9121e-01,  ...,  6.0513e-01,\n",
      "            5.2612e-03, -1.8875e-01],\n",
      "          [-3.9252e-01, -3.2578e-01, -3.3083e-02,  ...,  1.0319e+00,\n",
      "            2.5445e-01, -4.9304e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[ 2.3612e+00, -4.9916e-01, -7.7391e-01,  ..., -1.4665e-01,\n",
      "            7.4640e-01,  6.3562e-01],\n",
      "          [ 2.3779e+00, -1.0897e+00,  8.0376e-01,  ..., -3.3603e-02,\n",
      "           -7.4233e-01,  2.2577e+00],\n",
      "          [ 6.7425e-01,  9.8939e-01,  1.6093e+00,  ..., -1.6932e-01,\n",
      "           -6.2982e-03,  1.5486e+00],\n",
      "          ...,\n",
      "          [ 2.5878e+00,  5.8651e-01, -1.6279e+00,  ..., -1.7993e-01,\n",
      "            1.5427e-01,  3.2658e+00],\n",
      "          [ 2.3830e+00, -1.7340e-01, -3.3697e-02,  ...,  1.1616e-01,\n",
      "           -2.7527e-01,  2.9183e+00],\n",
      "          [ 2.2362e+00, -2.9120e-01, -5.8637e-01,  ..., -5.8503e-02,\n",
      "            1.0083e+00,  1.4683e-01]],\n",
      "\n",
      "         [[ 3.6665e+00,  6.7673e-01,  1.0757e+00,  ..., -6.6007e-01,\n",
      "           -8.1469e-01,  1.6867e+00],\n",
      "          [ 7.2206e+00,  4.3475e+00,  7.6241e+00,  ...,  1.9250e+00,\n",
      "            1.7264e+00,  3.8859e+00],\n",
      "          [ 6.0776e+00,  3.3460e+00,  5.0236e+00,  ...,  2.8928e+00,\n",
      "            2.4337e+00,  4.5749e+00],\n",
      "          ...,\n",
      "          [ 5.4243e+00,  2.5521e+00,  2.8334e+00,  ...,  3.2762e+00,\n",
      "            6.9374e+00,  5.7307e+00],\n",
      "          [ 6.3782e+00,  2.3961e+00,  2.3203e+00,  ...,  1.9477e+00,\n",
      "            2.8737e+00,  7.6728e+00],\n",
      "          [ 8.4789e+00,  1.6186e+00,  2.8456e+00,  ...,  3.4206e-01,\n",
      "            2.1018e+00,  5.4380e+00]],\n",
      "\n",
      "         [[ 3.7739e+00, -1.4559e-01, -1.0336e+00,  ...,  7.6979e-02,\n",
      "           -1.4874e-01,  6.5983e-01],\n",
      "          [ 1.3597e+00,  2.6759e+00,  3.1013e+00,  ...,  6.7372e-01,\n",
      "            1.6496e+00,  1.8307e+00],\n",
      "          [ 2.2318e+00,  3.0741e+00,  2.8686e+00,  ...,  1.5194e+00,\n",
      "            1.2381e+00,  1.7731e+00],\n",
      "          ...,\n",
      "          [ 2.3391e+00,  2.3301e+00,  1.8793e+00,  ...,  1.4799e+00,\n",
      "            1.8155e+00,  1.6213e+00],\n",
      "          [ 2.8117e+00,  1.5533e+00,  1.0199e+00,  ...,  1.5999e+00,\n",
      "            1.3500e-01,  1.6395e+00],\n",
      "          [ 3.3504e+00,  1.2564e+00,  4.3466e-01,  ...,  1.7253e+00,\n",
      "            3.6413e-01,  2.2439e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9676e+00,  7.6074e-01,  2.5173e-01,  ...,  2.3682e-01,\n",
      "            5.6769e-01,  1.1741e+00],\n",
      "          [ 2.0564e+00, -6.4242e-01, -9.5478e-02,  ..., -7.0711e-03,\n",
      "           -1.4291e+00,  1.1865e+00],\n",
      "          [ 1.8795e+00,  8.3496e-02, -7.8849e-01,  ...,  1.8637e-01,\n",
      "           -1.3232e+00,  8.4485e-01],\n",
      "          ...,\n",
      "          [ 1.4599e+00, -6.3175e-02, -4.5919e-01,  ..., -4.6354e+00,\n",
      "           -1.4347e+00,  5.1845e-01],\n",
      "          [ 1.9171e+00,  1.7766e-01, -5.6359e-01,  ..., -1.4307e+00,\n",
      "           -2.7647e+00,  1.0412e-01],\n",
      "          [ 3.6121e-01, -1.5472e-01, -1.8475e-01,  ..., -4.1163e-01,\n",
      "           -3.0604e-01,  5.3667e-01]],\n",
      "\n",
      "         [[ 3.9347e+00,  3.5327e-01,  3.3045e-01,  ..., -6.4364e-01,\n",
      "           -1.9096e-01,  1.6890e+00],\n",
      "          [ 6.5847e+00,  1.4712e+00,  3.6711e+00,  ...,  2.3541e+00,\n",
      "            2.0976e+00,  2.8560e+00],\n",
      "          [ 5.7212e+00,  2.9654e+00,  2.1908e+00,  ...,  1.2700e+00,\n",
      "            1.8341e+00,  2.7078e+00],\n",
      "          ...,\n",
      "          [ 3.9826e+00,  2.8413e+00,  2.7632e+00,  ...,  3.5478e-01,\n",
      "            2.8745e+00,  2.6107e+00],\n",
      "          [ 3.5117e+00,  2.4413e+00,  3.0632e+00,  ...,  3.0935e+00,\n",
      "            2.6680e+00,  2.9163e+00],\n",
      "          [ 6.6138e+00,  2.1463e+00,  2.2778e+00,  ...,  1.1236e+00,\n",
      "            1.3995e+00,  3.6320e+00]],\n",
      "\n",
      "         [[ 3.2096e+00,  1.4154e+00,  1.3946e+00,  ...,  2.4533e-01,\n",
      "            2.3241e-01,  2.3357e+00],\n",
      "          [ 4.5205e+00,  4.8111e+00,  1.9591e+00,  ..., -1.3105e+00,\n",
      "            1.4697e+00,  3.9041e+00],\n",
      "          [ 4.4884e+00,  2.3959e+00,  3.9387e+00,  ..., -5.1879e-02,\n",
      "            2.0364e-01,  3.9079e+00],\n",
      "          ...,\n",
      "          [ 4.0822e+00,  4.7912e-01,  2.5244e-01,  ...,  5.5277e+00,\n",
      "            8.1167e-01,  3.7665e+00],\n",
      "          [ 3.7127e+00,  2.4647e+00,  2.2241e+00,  ...,  5.4845e-01,\n",
      "            4.9294e+00,  2.4163e+00],\n",
      "          [ 2.3890e+00,  1.1067e+00,  7.5433e-01,  ..., -3.4596e-01,\n",
      "           -1.0715e+00,  5.7978e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3842e+00,  1.3120e-01,  2.2891e+00,  ..., -7.6819e-01,\n",
      "           -8.2231e-01, -8.8752e-01],\n",
      "          [ 2.9165e+00,  1.1659e-01,  2.3039e+00,  ...,  1.6410e+00,\n",
      "            1.6088e+00,  1.5481e+00],\n",
      "          [ 2.9597e+00, -6.2633e-01,  4.8541e-01,  ...,  5.9909e-01,\n",
      "            4.2807e-01,  4.3475e-01],\n",
      "          ...,\n",
      "          [ 4.2446e+00,  1.7044e+00,  4.0382e+00,  ..., -2.5112e+00,\n",
      "           -2.6869e+00, -2.7885e+00],\n",
      "          [ 4.1052e+00,  1.7291e+00,  3.9277e+00,  ..., -2.4102e+00,\n",
      "           -2.5917e+00, -2.6873e+00],\n",
      "          [ 4.1813e+00,  1.6615e+00,  3.9290e+00,  ..., -2.2771e+00,\n",
      "           -2.4522e+00, -2.5559e+00]],\n",
      "\n",
      "         [[ 1.9672e+00,  4.0939e-01,  6.5423e-01,  ...,  1.7634e+00,\n",
      "            1.6074e+00,  1.4203e+00],\n",
      "          [ 6.1898e+00,  3.0344e+00,  6.0241e+00,  ..., -2.0964e-01,\n",
      "            4.5586e-01, -1.1946e+00],\n",
      "          [ 4.9604e+00,  3.2581e+00,  4.3801e+00,  ...,  2.5519e-01,\n",
      "           -6.9141e-01, -5.9856e-01],\n",
      "          ...,\n",
      "          [ 1.3822e+00,  6.0352e-01,  1.3397e+00,  ...,  1.9578e+00,\n",
      "            4.0481e+00,  1.9004e+00],\n",
      "          [ 1.2632e+00,  1.5701e+00,  2.2744e-01,  ...,  1.3210e+00,\n",
      "            2.4455e+00,  4.5573e+00],\n",
      "          [ 1.5640e+00,  9.1038e-01,  1.5997e+00,  ...,  1.5867e+00,\n",
      "            1.6677e+00,  2.9833e+00]],\n",
      "\n",
      "         [[ 3.3025e+00,  2.4157e-01,  3.6281e-02,  ...,  6.8341e-02,\n",
      "           -1.2285e-02,  6.0063e-02],\n",
      "          [ 1.8223e+00, -1.2318e+00,  4.0240e-01,  ..., -2.1802e+00,\n",
      "           -2.4562e+00, -2.4696e+00],\n",
      "          [ 1.6410e+00,  2.1469e+00,  2.7859e-01,  ..., -1.7065e+00,\n",
      "           -1.8341e+00, -1.8519e+00],\n",
      "          ...,\n",
      "          [ 1.4840e+00,  5.9440e-01, -1.4649e-01,  ..., -1.0591e+00,\n",
      "           -1.1213e+00, -1.0948e+00],\n",
      "          [ 1.3916e+00,  5.1493e-01, -1.4589e-01,  ..., -1.0793e+00,\n",
      "           -1.1467e+00, -1.1188e+00],\n",
      "          [ 1.4290e+00,  5.6594e-01, -9.5553e-02,  ..., -1.0200e+00,\n",
      "           -1.0883e+00, -1.0639e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.5808e-01, -3.2474e-01,  1.0466e+00,  ...,  1.8598e-01,\n",
      "            2.0289e-01,  2.5144e-01],\n",
      "          [ 1.5912e+00, -3.9866e+00, -9.0951e-01,  ..., -8.2024e-01,\n",
      "           -7.1440e-01, -6.6660e-01],\n",
      "          [ 1.1744e+00, -2.5922e-01, -7.9539e-01,  ...,  8.9116e-02,\n",
      "            7.9980e-02,  1.3538e-01],\n",
      "          ...,\n",
      "          [-1.2999e-01, -1.2254e+00,  2.2729e-01,  ..., -2.4601e-01,\n",
      "           -1.9002e-01, -1.7774e-01],\n",
      "          [-2.4731e-01, -1.2521e+00,  2.4664e-01,  ..., -2.0468e-01,\n",
      "           -1.4364e-01, -1.3224e-01],\n",
      "          [-1.1279e-01, -1.1472e+00,  2.0306e-01,  ..., -1.7441e-01,\n",
      "           -1.2757e-01, -1.3268e-01]],\n",
      "\n",
      "         [[ 3.0882e+00, -2.3257e-02,  9.2360e-01,  ...,  7.2468e-01,\n",
      "            7.2187e-01,  7.5211e-01],\n",
      "          [ 6.0641e+00,  5.4659e-01,  2.6616e+00,  ...,  1.7684e+00,\n",
      "            1.7203e+00,  1.3522e+00],\n",
      "          [ 4.6222e+00,  2.6541e+00,  2.8650e+00,  ...,  1.5332e+00,\n",
      "            1.5161e+00,  1.1607e+00],\n",
      "          ...,\n",
      "          [ 3.2668e+00,  1.9583e+00,  2.5442e+00,  ...,  1.8567e+00,\n",
      "            1.9986e+00,  2.0600e+00],\n",
      "          [ 2.5544e+00,  1.9222e+00,  2.5133e+00,  ...,  2.0372e+00,\n",
      "            1.9687e+00,  1.9691e+00],\n",
      "          [ 2.6682e+00,  1.7234e+00,  2.4119e+00,  ...,  2.1765e+00,\n",
      "            2.0831e+00,  1.7621e+00]],\n",
      "\n",
      "         [[ 1.7887e+00,  9.8561e-01,  5.9897e-01,  ..., -1.0964e+00,\n",
      "           -1.3264e+00, -1.1717e+00],\n",
      "          [ 3.6008e+00,  5.2681e+00,  1.4387e+00,  ...,  5.3391e-01,\n",
      "            1.0676e+00,  9.8372e-01],\n",
      "          [ 2.8587e+00,  3.6883e-01,  7.2559e-01,  ..., -1.2942e-01,\n",
      "           -3.4891e-01,  6.7379e-02],\n",
      "          ...,\n",
      "          [ 2.7132e-01,  1.2841e+00,  4.8905e-01,  ..., -2.8205e-01,\n",
      "           -8.8378e-02, -2.5894e-02],\n",
      "          [ 2.8132e-01,  1.2505e+00,  3.4136e-01,  ..., -4.2159e-02,\n",
      "           -6.2904e-01, -3.3551e-01],\n",
      "          [ 2.6806e-01,  1.1058e+00,  5.4405e-01,  ...,  2.6788e-01,\n",
      "           -9.0434e-02, -6.9710e-01]]]], grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[ 2.3612e+00, -4.9916e-01, -7.7391e-01,  ..., -1.4665e-01,\n",
      "            7.4640e-01,  6.3562e-01],\n",
      "          [ 2.3779e+00, -1.0897e+00,  8.0376e-01,  ..., -3.3603e-02,\n",
      "           -7.4233e-01,  2.2577e+00],\n",
      "          [ 6.7425e-01,  9.8939e-01,  1.6093e+00,  ..., -1.6932e-01,\n",
      "           -6.2982e-03,  1.5486e+00],\n",
      "          ...,\n",
      "          [ 2.5878e+00,  5.8651e-01, -1.6279e+00,  ..., -1.7993e-01,\n",
      "            1.5427e-01,  3.2658e+00],\n",
      "          [ 2.3830e+00, -1.7340e-01, -3.3697e-02,  ...,  1.1616e-01,\n",
      "           -2.7527e-01,  2.9183e+00],\n",
      "          [ 2.2362e+00, -2.9120e-01, -5.8637e-01,  ..., -5.8503e-02,\n",
      "            1.0083e+00,  1.4683e-01]],\n",
      "\n",
      "         [[ 3.6665e+00,  6.7673e-01,  1.0757e+00,  ..., -6.6007e-01,\n",
      "           -8.1469e-01,  1.6867e+00],\n",
      "          [ 7.2206e+00,  4.3475e+00,  7.6241e+00,  ...,  1.9250e+00,\n",
      "            1.7264e+00,  3.8859e+00],\n",
      "          [ 6.0776e+00,  3.3460e+00,  5.0236e+00,  ...,  2.8928e+00,\n",
      "            2.4337e+00,  4.5749e+00],\n",
      "          ...,\n",
      "          [ 5.4243e+00,  2.5521e+00,  2.8334e+00,  ...,  3.2762e+00,\n",
      "            6.9374e+00,  5.7307e+00],\n",
      "          [ 6.3782e+00,  2.3961e+00,  2.3203e+00,  ...,  1.9477e+00,\n",
      "            2.8737e+00,  7.6728e+00],\n",
      "          [ 8.4789e+00,  1.6186e+00,  2.8456e+00,  ...,  3.4206e-01,\n",
      "            2.1018e+00,  5.4380e+00]],\n",
      "\n",
      "         [[ 3.7739e+00, -1.4559e-01, -1.0336e+00,  ...,  7.6979e-02,\n",
      "           -1.4874e-01,  6.5983e-01],\n",
      "          [ 1.3597e+00,  2.6759e+00,  3.1013e+00,  ...,  6.7372e-01,\n",
      "            1.6496e+00,  1.8307e+00],\n",
      "          [ 2.2318e+00,  3.0741e+00,  2.8686e+00,  ...,  1.5194e+00,\n",
      "            1.2381e+00,  1.7731e+00],\n",
      "          ...,\n",
      "          [ 2.3391e+00,  2.3301e+00,  1.8793e+00,  ...,  1.4799e+00,\n",
      "            1.8155e+00,  1.6213e+00],\n",
      "          [ 2.8117e+00,  1.5533e+00,  1.0199e+00,  ...,  1.5999e+00,\n",
      "            1.3500e-01,  1.6395e+00],\n",
      "          [ 3.3504e+00,  1.2564e+00,  4.3466e-01,  ...,  1.7253e+00,\n",
      "            3.6413e-01,  2.2439e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9676e+00,  7.6074e-01,  2.5173e-01,  ...,  2.3682e-01,\n",
      "            5.6769e-01,  1.1741e+00],\n",
      "          [ 2.0564e+00, -6.4242e-01, -9.5478e-02,  ..., -7.0711e-03,\n",
      "           -1.4291e+00,  1.1865e+00],\n",
      "          [ 1.8795e+00,  8.3496e-02, -7.8849e-01,  ...,  1.8637e-01,\n",
      "           -1.3232e+00,  8.4485e-01],\n",
      "          ...,\n",
      "          [ 1.4599e+00, -6.3175e-02, -4.5919e-01,  ..., -4.6354e+00,\n",
      "           -1.4347e+00,  5.1845e-01],\n",
      "          [ 1.9171e+00,  1.7766e-01, -5.6359e-01,  ..., -1.4307e+00,\n",
      "           -2.7647e+00,  1.0412e-01],\n",
      "          [ 3.6121e-01, -1.5472e-01, -1.8475e-01,  ..., -4.1163e-01,\n",
      "           -3.0604e-01,  5.3667e-01]],\n",
      "\n",
      "         [[ 3.9347e+00,  3.5327e-01,  3.3045e-01,  ..., -6.4364e-01,\n",
      "           -1.9096e-01,  1.6890e+00],\n",
      "          [ 6.5847e+00,  1.4712e+00,  3.6711e+00,  ...,  2.3541e+00,\n",
      "            2.0976e+00,  2.8560e+00],\n",
      "          [ 5.7212e+00,  2.9654e+00,  2.1908e+00,  ...,  1.2700e+00,\n",
      "            1.8341e+00,  2.7078e+00],\n",
      "          ...,\n",
      "          [ 3.9826e+00,  2.8413e+00,  2.7632e+00,  ...,  3.5478e-01,\n",
      "            2.8745e+00,  2.6107e+00],\n",
      "          [ 3.5117e+00,  2.4413e+00,  3.0632e+00,  ...,  3.0935e+00,\n",
      "            2.6680e+00,  2.9163e+00],\n",
      "          [ 6.6138e+00,  2.1463e+00,  2.2778e+00,  ...,  1.1236e+00,\n",
      "            1.3995e+00,  3.6320e+00]],\n",
      "\n",
      "         [[ 3.2096e+00,  1.4154e+00,  1.3946e+00,  ...,  2.4533e-01,\n",
      "            2.3241e-01,  2.3357e+00],\n",
      "          [ 4.5205e+00,  4.8111e+00,  1.9591e+00,  ..., -1.3105e+00,\n",
      "            1.4697e+00,  3.9041e+00],\n",
      "          [ 4.4884e+00,  2.3959e+00,  3.9387e+00,  ..., -5.1879e-02,\n",
      "            2.0364e-01,  3.9079e+00],\n",
      "          ...,\n",
      "          [ 4.0822e+00,  4.7912e-01,  2.5244e-01,  ...,  5.5277e+00,\n",
      "            8.1167e-01,  3.7665e+00],\n",
      "          [ 3.7127e+00,  2.4647e+00,  2.2241e+00,  ...,  5.4845e-01,\n",
      "            4.9294e+00,  2.4163e+00],\n",
      "          [ 2.3890e+00,  1.1067e+00,  7.5433e-01,  ..., -3.4596e-01,\n",
      "           -1.0715e+00,  5.7978e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3842e+00,  1.3120e-01,  2.2891e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.9165e+00,  1.1659e-01,  2.3039e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.9597e+00, -6.2633e-01,  4.8541e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 4.2446e+00,  1.7044e+00,  4.0382e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.1052e+00,  1.7291e+00,  3.9277e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.1813e+00,  1.6615e+00,  3.9290e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.9672e+00,  4.0939e-01,  6.5423e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.1898e+00,  3.0344e+00,  6.0241e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.9604e+00,  3.2581e+00,  4.3801e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.3822e+00,  6.0352e-01,  1.3397e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.2632e+00,  1.5701e+00,  2.2744e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.5640e+00,  9.1038e-01,  1.5997e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.3025e+00,  2.4157e-01,  3.6281e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.8223e+00, -1.2318e+00,  4.0240e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.6410e+00,  2.1469e+00,  2.7859e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.4840e+00,  5.9440e-01, -1.4649e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.3916e+00,  5.1493e-01, -1.4589e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.4290e+00,  5.6594e-01, -9.5553e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.5808e-01, -3.2474e-01,  1.0466e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.5912e+00, -3.9866e+00, -9.0951e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.1744e+00, -2.5922e-01, -7.9539e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-1.2999e-01, -1.2254e+00,  2.2729e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-2.4731e-01, -1.2521e+00,  2.4664e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1279e-01, -1.1472e+00,  2.0306e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.0882e+00, -2.3257e-02,  9.2360e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.0641e+00,  5.4659e-01,  2.6616e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.6222e+00,  2.6541e+00,  2.8650e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 3.2668e+00,  1.9583e+00,  2.5442e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.5544e+00,  1.9222e+00,  2.5133e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.6682e+00,  1.7234e+00,  2.4119e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.7887e+00,  9.8561e-01,  5.9897e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.6008e+00,  5.2681e+00,  1.4387e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.8587e+00,  3.6883e-01,  7.2559e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.7132e-01,  1.2841e+00,  4.8905e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.8132e-01,  1.2505e+00,  3.4136e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.6806e-01,  1.1058e+00,  5.4405e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[5.5774e-01, 3.1928e-02, 2.4258e-02,  ..., 4.5422e-02,\n",
      "           1.1095e-01, 9.9312e-02],\n",
      "          [4.3742e-01, 1.3644e-02, 9.0626e-02,  ..., 3.9228e-02,\n",
      "           1.9311e-02, 3.8787e-01],\n",
      "          [1.1977e-01, 1.6413e-01, 3.0509e-01,  ..., 5.1519e-02,\n",
      "           6.0642e-02, 2.8711e-01],\n",
      "          ...,\n",
      "          [2.9120e-01, 3.9358e-02, 4.2987e-03,  ..., 1.8288e-02,\n",
      "           2.5545e-02, 5.7365e-01],\n",
      "          [3.1200e-01, 2.4206e-02, 2.7836e-02,  ..., 3.2336e-02,\n",
      "           2.1862e-02, 5.3288e-01],\n",
      "          [5.3701e-01, 4.2890e-02, 3.1927e-02,  ..., 5.4127e-02,\n",
      "           1.5730e-01, 6.6464e-02]],\n",
      "\n",
      "         [[7.4646e-01, 3.7545e-02, 5.5955e-02,  ..., 9.8624e-03,\n",
      "           8.4495e-03, 1.0308e-01],\n",
      "          [3.7561e-01, 2.1230e-02, 5.6232e-01,  ..., 1.8832e-03,\n",
      "           1.5439e-03, 1.3381e-02],\n",
      "          [9.7215e-02, 6.3303e-03, 3.3885e-02,  ..., 4.0235e-03,\n",
      "           2.5423e-03, 2.1633e-02],\n",
      "          ...,\n",
      "          [1.3256e-01, 7.4995e-03, 9.9356e-03,  ..., 1.5471e-02,\n",
      "           6.0191e-01, 1.8008e-01],\n",
      "          [2.0991e-01, 3.9140e-03, 3.6283e-03,  ..., 2.4997e-03,\n",
      "           6.3104e-03, 7.6604e-01],\n",
      "          [9.4788e-01, 9.9387e-04, 3.3901e-03,  ..., 2.7730e-04,\n",
      "           1.6114e-03, 4.5299e-02]],\n",
      "\n",
      "         [[8.8161e-01, 1.7502e-02, 7.2017e-03,  ..., 2.1864e-02,\n",
      "           1.7447e-02, 3.9162e-02],\n",
      "          [7.0792e-02, 2.6401e-01, 4.0398e-01,  ..., 3.5651e-02,\n",
      "           9.4603e-02, 1.1338e-01],\n",
      "          [1.4637e-01, 3.3982e-01, 2.7669e-01,  ..., 7.1785e-02,\n",
      "           5.4187e-02, 9.2523e-02],\n",
      "          ...,\n",
      "          [2.3561e-01, 2.3349e-01, 1.4876e-01,  ..., 9.9779e-02,\n",
      "           1.3956e-01, 1.1494e-01],\n",
      "          [4.5668e-01, 1.2975e-01, 7.6114e-02,  ..., 1.3594e-01,\n",
      "           3.1416e-02, 1.4143e-01],\n",
      "          [5.5897e-01, 6.8866e-02, 3.0277e-02,  ..., 1.1006e-01,\n",
      "           2.8215e-02, 1.8487e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.8317e-01, 1.1462e-01, 6.8898e-02,  ..., 6.7878e-02,\n",
      "           9.4499e-02, 1.7329e-01],\n",
      "          [5.4387e-01, 3.6593e-02, 6.3232e-02,  ..., 6.9076e-02,\n",
      "           1.6664e-02, 2.2788e-01],\n",
      "          [5.3729e-01, 8.9172e-02, 3.7285e-02,  ..., 9.8834e-02,\n",
      "           2.1842e-02, 1.9093e-01],\n",
      "          ...,\n",
      "          [4.9739e-01, 1.0845e-01, 7.2987e-02,  ..., 1.1209e-03,\n",
      "           2.7517e-02, 1.9401e-01],\n",
      "          [6.5973e-01, 1.1586e-01, 5.5210e-02,  ..., 2.3198e-02,\n",
      "           6.1108e-03, 1.0765e-01],\n",
      "          [1.9421e-01, 1.1594e-01, 1.1250e-01,  ..., 8.9668e-02,\n",
      "           9.9655e-02, 2.3146e-01]],\n",
      "\n",
      "         [[8.1965e-01, 2.2815e-02, 2.2300e-02,  ..., 8.4191e-03,\n",
      "           1.3239e-02, 8.6758e-02],\n",
      "          [8.6739e-01, 5.2175e-03, 4.7081e-02,  ..., 1.2615e-02,\n",
      "           9.7615e-03, 2.0839e-02],\n",
      "          [8.0738e-01, 5.1318e-02, 2.3652e-02,  ..., 9.4181e-03,\n",
      "           1.6556e-02, 3.9664e-02],\n",
      "          ...,\n",
      "          [4.1244e-01, 1.3174e-01, 1.2184e-01,  ..., 1.0960e-02,\n",
      "           1.3617e-01, 1.0460e-01],\n",
      "          [2.3442e-01, 8.0382e-02, 1.4970e-01,  ..., 1.5430e-01,\n",
      "           1.0084e-01, 1.2925e-01],\n",
      "          [9.0643e-01, 1.0403e-02, 1.1864e-02,  ..., 3.7410e-03,\n",
      "           4.9296e-03, 4.5957e-02]],\n",
      "\n",
      "         [[5.1403e-01, 8.5461e-02, 8.3708e-02,  ..., 2.6523e-02,\n",
      "           2.6183e-02, 2.1453e-01],\n",
      "          [3.2730e-01, 4.3769e-01, 2.5268e-02,  ..., 9.6065e-04,\n",
      "           1.5489e-02, 1.7670e-01],\n",
      "          [4.3272e-01, 5.3391e-02, 2.4975e-01,  ..., 4.6174e-03,\n",
      "           5.9617e-03, 2.4218e-01],\n",
      "          ...,\n",
      "          [1.6425e-01, 4.4745e-03, 3.5669e-03,  ..., 6.9715e-01,\n",
      "           6.2397e-03, 1.1979e-01],\n",
      "          [1.8505e-01, 5.3122e-02, 4.1765e-02,  ..., 7.8177e-03,\n",
      "           6.2472e-01, 5.0614e-02],\n",
      "          [5.5217e-01, 1.5316e-01, 1.0768e-01,  ..., 3.5833e-02,\n",
      "           1.7345e-02, 9.0432e-02]]],\n",
      "\n",
      "\n",
      "        [[[2.5289e-01, 7.2236e-02, 6.2504e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.6055e-01, 2.1927e-02, 1.9539e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.7260e-01, 2.1407e-02, 6.5068e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.1919e-01, 4.0938e-02, 4.2239e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0902e-01, 4.7292e-02, 4.2622e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.2921e-01, 4.2588e-02, 4.1120e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[5.3479e-01, 1.1262e-01, 1.4386e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.7420e-01, 2.0211e-02, 4.0179e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.3977e-01, 2.5475e-02, 7.8233e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [3.3447e-01, 1.5352e-01, 3.2054e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.5093e-01, 3.4106e-01, 8.9069e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.2543e-01, 1.6928e-01, 3.3728e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[8.7131e-01, 4.0818e-02, 3.3242e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.2386e-01, 1.9991e-02, 1.0246e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1361e-01, 3.5429e-01, 5.4694e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.3876e-01, 1.8025e-01, 8.5924e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.2956e-01, 1.7877e-01, 9.2324e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.4368e-01, 1.8718e-01, 9.6598e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.8122e-01, 9.5233e-02, 3.7529e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.0841e-01, 2.3004e-03, 4.9907e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.3151e-01, 1.2673e-01, 7.4137e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [2.6963e-01, 9.0164e-02, 3.8542e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.5174e-01, 9.2168e-02, 4.1254e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.7652e-01, 9.8287e-02, 3.7923e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[7.5203e-01, 3.3492e-02, 8.6330e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.0553e-01, 3.6364e-03, 3.0144e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.8322e-01, 9.5460e-02, 1.1787e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.2528e-01, 1.1492e-01, 2.0646e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.5212e-01, 1.3398e-01, 2.4198e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.4757e-01, 9.6238e-02, 1.9159e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[3.5903e-01, 1.6082e-01, 1.0925e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4096e-01, 7.4678e-01, 1.6222e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.3497e-01, 4.4359e-02, 6.3375e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.7472e-01, 4.8102e-01, 2.1722e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.8154e-01, 4.7849e-01, 1.9277e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.8215e-01, 4.2097e-01, 2.4004e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[ 4.6406e-02,  2.2994e-01,  2.5332e-01,  ...,  2.0214e-01,\n",
      "           -2.5666e-01,  8.6166e-02],\n",
      "          [-7.6566e-02,  1.4423e-01, -4.5326e-02,  ...,  2.1349e-01,\n",
      "           -1.6405e-01, -2.0350e-01],\n",
      "          [ 8.0514e-02,  1.4225e-01, -2.5414e-02,  ...,  3.1859e-02,\n",
      "           -2.7236e-01, -2.5693e-01],\n",
      "          ...,\n",
      "          [-1.9222e-01,  1.5992e-02, -2.9376e-02,  ...,  3.1532e-02,\n",
      "           -7.7281e-02, -1.7615e-01],\n",
      "          [-1.6801e-01,  3.3828e-02, -4.0065e-02,  ...,  7.3010e-02,\n",
      "           -1.0060e-01, -1.7450e-01],\n",
      "          [ 5.4414e-02,  2.2257e-01,  2.8874e-01,  ...,  2.0524e-01,\n",
      "           -2.5961e-01,  1.4651e-01]],\n",
      "\n",
      "         [[-1.7785e-02,  6.9091e-02,  1.4158e-01,  ...,  8.4300e-02,\n",
      "           -9.1707e-02, -1.3000e-01],\n",
      "          [-6.0019e-02, -1.0724e-01,  5.8424e-01,  ..., -7.3976e-03,\n",
      "           -5.7074e-01, -5.2379e-01],\n",
      "          [-2.5191e-01, -6.3696e-01,  5.0772e-01,  ...,  9.9878e-03,\n",
      "            5.6813e-02,  6.5941e-01],\n",
      "          ...,\n",
      "          [ 5.9797e-01,  6.9086e-01,  2.2418e-01,  ..., -3.9993e-01,\n",
      "            7.1684e-02,  3.4034e-01],\n",
      "          [-8.2357e-02,  6.4391e-01,  4.4588e-01,  ...,  4.7240e-01,\n",
      "           -6.1885e-01, -1.3699e-01],\n",
      "          [-8.7000e-03,  7.7501e-02,  5.1466e-02,  ...,  2.8027e-02,\n",
      "            8.7588e-03, -1.9859e-01]],\n",
      "\n",
      "         [[ 4.3280e-02, -9.7132e-02, -1.7102e-01,  ...,  5.6128e-02,\n",
      "            2.0335e-01, -8.4245e-02],\n",
      "          [-8.0346e-02, -1.2351e-01,  1.0333e-01,  ..., -1.7338e-01,\n",
      "            4.1875e-02, -2.9156e-01],\n",
      "          [-4.4322e-02, -1.3979e-01,  1.0195e-01,  ..., -1.9481e-01,\n",
      "            1.5422e-01, -2.0427e-01],\n",
      "          ...,\n",
      "          [-5.0132e-02, -9.3628e-02,  1.0430e-01,  ..., -1.0844e-01,\n",
      "            2.1922e-01, -2.3145e-01],\n",
      "          [ 8.1990e-02, -1.4171e-01,  1.9509e-02,  ..., -2.1198e-02,\n",
      "            2.7186e-01, -1.5158e-01],\n",
      "          [ 1.1377e-01, -1.3067e-01, -5.4628e-02,  ...,  7.0346e-02,\n",
      "            2.8025e-01, -1.3685e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5698e-02, -5.3636e-01,  4.6935e-02,  ..., -1.7209e-02,\n",
      "           -1.7422e-01, -1.0086e-02],\n",
      "          [-2.5166e-02, -5.2117e-01, -7.2167e-02,  ..., -2.2234e-02,\n",
      "           -5.9358e-02, -7.5041e-02],\n",
      "          [-3.6159e-02, -5.4003e-01, -3.1014e-02,  ..., -2.4563e-02,\n",
      "           -7.7878e-02, -9.7356e-02],\n",
      "          ...,\n",
      "          [-1.3438e-02, -4.6135e-01,  1.9861e-02,  ...,  1.8941e-02,\n",
      "           -1.6257e-01, -8.3926e-02],\n",
      "          [-8.8419e-02, -4.8040e-01,  2.9320e-02,  ..., -2.5153e-02,\n",
      "           -1.5384e-01, -1.0629e-01],\n",
      "          [ 7.4530e-02, -5.7085e-01,  4.8201e-02,  ...,  1.6036e-02,\n",
      "           -1.6845e-01, -9.9541e-03]],\n",
      "\n",
      "         [[ 6.1937e-02,  5.6960e-02, -7.4935e-02,  ...,  2.3940e-02,\n",
      "            8.1196e-02, -8.5090e-02],\n",
      "          [ 7.0992e-02,  6.2011e-02, -5.5700e-02,  ..., -2.1997e-02,\n",
      "            3.1245e-02, -8.9506e-02],\n",
      "          [ 3.6587e-02,  6.5156e-02, -7.0683e-02,  ...,  2.1585e-02,\n",
      "            7.7083e-02, -9.8223e-02],\n",
      "          ...,\n",
      "          [-1.9841e-01,  1.2444e-01, -5.4738e-02,  ...,  1.8045e-01,\n",
      "            1.2964e-01,  6.7287e-02],\n",
      "          [-4.5147e-01,  2.5128e-01, -2.9291e-01,  ...,  2.4998e-01,\n",
      "            1.6630e-01,  6.5981e-02],\n",
      "          [ 1.1217e-01,  3.2459e-02, -6.1551e-02,  ..., -2.7221e-02,\n",
      "            4.3357e-02, -1.0482e-01]],\n",
      "\n",
      "         [[-3.9488e-02,  3.4600e-02,  1.1573e-01,  ..., -1.4267e-01,\n",
      "           -2.4818e-01, -7.7574e-02],\n",
      "          [-2.1655e-01, -5.2782e-02, -1.2977e-01,  ..., -2.7073e-01,\n",
      "           -1.2892e-01, -1.8470e-01],\n",
      "          [-2.7459e-02, -1.3024e-03,  7.3407e-03,  ..., -2.0109e-01,\n",
      "           -2.2154e-01, -1.3398e-01],\n",
      "          ...,\n",
      "          [-7.2191e-02, -1.3756e-01, -1.3301e-01,  ..., -1.1413e-02,\n",
      "           -7.4040e-02,  6.3783e-02],\n",
      "          [ 3.0733e-01,  4.0763e-02, -1.6834e-01,  ...,  2.7866e-02,\n",
      "            5.7395e-02,  4.0705e-01],\n",
      "          [-9.8746e-02,  1.7394e-02,  3.0846e-02,  ..., -1.8268e-01,\n",
      "           -1.3986e-01, -1.2898e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0754e-01, -2.5088e-01,  1.1871e-01,  ..., -6.8870e-02,\n",
      "           -3.5877e-02,  2.6947e-01],\n",
      "          [-1.6287e-01, -9.4841e-02,  5.6044e-02,  ..., -8.1129e-02,\n",
      "           -1.4261e-01,  2.7820e-02],\n",
      "          [-1.2208e-01,  1.7299e-01,  2.0214e-01,  ...,  4.1199e-02,\n",
      "           -2.8804e-01,  1.8056e-01],\n",
      "          ...,\n",
      "          [ 2.3619e-01, -3.9068e-02,  1.8038e-01,  ..., -6.0256e-03,\n",
      "           -1.6789e-01,  2.6607e-01],\n",
      "          [ 2.4543e-01, -5.0902e-02,  1.7794e-01,  ..., -7.8065e-03,\n",
      "           -1.5734e-01,  2.6975e-01],\n",
      "          [ 2.2941e-01, -3.2988e-02,  1.8232e-01,  ..., -3.4456e-03,\n",
      "           -1.6989e-01,  2.6708e-01]],\n",
      "\n",
      "         [[ 9.9139e-02,  4.6721e-02,  2.1242e-01,  ...,  9.5502e-02,\n",
      "           -1.2219e-01, -9.6215e-02],\n",
      "          [ 2.4257e-02,  1.9606e-02,  1.0060e-01,  ...,  7.4376e-02,\n",
      "           -1.9249e-01, -1.2907e-01],\n",
      "          [-6.9709e-02,  5.6308e-01,  3.9973e-01,  ...,  4.0343e-01,\n",
      "           -5.0301e-01, -1.4906e-01],\n",
      "          ...,\n",
      "          [ 8.8293e-02, -3.9461e-02,  1.8120e-01,  ...,  1.1481e-01,\n",
      "           -1.9014e-01, -1.1577e-01],\n",
      "          [ 2.0148e-01, -9.9266e-02,  3.1939e-01,  ...,  1.5510e-01,\n",
      "           -1.3133e-01, -8.1168e-02],\n",
      "          [ 9.8898e-02, -7.6532e-02,  1.7339e-01,  ...,  1.0410e-01,\n",
      "           -1.7851e-01, -1.1448e-01]],\n",
      "\n",
      "         [[-2.2305e-02, -1.6669e-01, -1.8583e-01,  ..., -1.2824e-01,\n",
      "            2.5400e-01, -1.2817e-02],\n",
      "          [ 1.4734e-01, -9.5453e-02, -1.9770e-01,  ...,  2.3114e-01,\n",
      "            2.5883e-01, -9.0095e-02],\n",
      "          [ 6.0482e-02, -2.7944e-01,  2.8303e-02,  ...,  1.3081e-01,\n",
      "           -1.8469e-01, -2.3259e-01],\n",
      "          ...,\n",
      "          [ 5.3678e-02, -1.9264e-01, -8.5575e-02,  ...,  8.5869e-02,\n",
      "            2.6765e-02, -1.3285e-01],\n",
      "          [ 5.5456e-02, -1.8928e-01, -8.5633e-02,  ...,  9.2332e-02,\n",
      "            2.3045e-02, -1.3331e-01],\n",
      "          [ 4.2487e-02, -1.9425e-01, -7.8487e-02,  ...,  7.1895e-02,\n",
      "            3.8114e-03, -1.3186e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2432e-02,  7.1216e-03, -5.0796e-03,  ..., -1.3771e-02,\n",
      "            1.4252e-01, -3.1993e-01],\n",
      "          [-1.5702e-01, -2.7421e-01,  1.9287e-02,  ..., -2.9345e-02,\n",
      "            6.3492e-02, -1.9607e-01],\n",
      "          [-1.8702e-01, -3.0439e-01,  5.8810e-02,  ..., -1.4100e-01,\n",
      "            1.0313e-01, -2.1267e-01],\n",
      "          ...,\n",
      "          [-3.2022e-03,  1.6514e-02, -1.0316e-02,  ..., -3.8877e-03,\n",
      "            1.4404e-01, -3.2444e-01],\n",
      "          [ 8.1413e-03,  4.6352e-02, -1.2064e-02,  ...,  5.1453e-04,\n",
      "            1.4713e-01, -3.3282e-01],\n",
      "          [-1.1400e-02,  9.7572e-03, -4.6547e-03,  ..., -1.5477e-02,\n",
      "            1.4400e-01, -3.2152e-01]],\n",
      "\n",
      "         [[ 1.6440e-01,  7.0544e-02, -1.0586e-01,  ...,  4.5534e-02,\n",
      "            8.7224e-02, -8.0266e-02],\n",
      "          [ 2.2033e-01,  3.5995e-02, -5.6097e-02,  ..., -1.6697e-02,\n",
      "            1.5788e-01, -1.0478e-01],\n",
      "          [ 1.4262e-01,  5.6316e-02, -1.6405e-01,  ...,  5.9825e-02,\n",
      "            6.8414e-03, -7.8245e-02],\n",
      "          ...,\n",
      "          [ 4.6125e-02,  1.3286e-01, -2.2381e-01,  ...,  1.7265e-01,\n",
      "           -7.8563e-02, -3.2633e-02],\n",
      "          [-2.3964e-02,  1.7658e-01, -2.5229e-01,  ...,  2.4200e-01,\n",
      "           -1.0706e-01, -2.0084e-02],\n",
      "          [-3.9108e-02,  1.9362e-01, -1.9471e-01,  ...,  2.4570e-01,\n",
      "           -4.2387e-03, -4.4465e-02]],\n",
      "\n",
      "         [[-7.4849e-02,  2.0633e-01,  2.7052e-01,  ..., -2.2179e-01,\n",
      "           -3.1083e-01, -4.0386e-01],\n",
      "          [-4.7723e-02,  1.4793e-01, -1.0507e-01,  ...,  9.3825e-02,\n",
      "            2.1092e-01, -7.7970e-01],\n",
      "          [-1.0239e-01,  2.9362e-01,  4.4201e-01,  ..., -2.8212e-01,\n",
      "           -4.2850e-01, -2.9055e-01],\n",
      "          ...,\n",
      "          [-7.4826e-02,  1.0391e-01, -6.2665e-02,  ..., -3.7891e-02,\n",
      "            6.6393e-02, -6.0491e-01],\n",
      "          [-7.1482e-02,  1.1328e-01, -4.2848e-02,  ..., -4.1331e-02,\n",
      "            4.8772e-02, -6.0561e-01],\n",
      "          [-7.6334e-02,  9.9793e-02, -3.8886e-02,  ..., -6.9909e-02,\n",
      "            1.8540e-02, -5.6963e-01]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[ 0.6729,  2.0791,  1.9365,  ..., -0.8837, -0.1236,  3.3075],\n",
      "          [-0.0527,  1.7603, -0.0119,  ...,  0.4724, -1.7560,  0.5274],\n",
      "          [-0.8989,  1.6074, -0.7301,  ..., -0.9426,  0.6843,  1.1197],\n",
      "          ...,\n",
      "          [-1.9568, -3.3126, -1.5511,  ..., -2.1693,  0.2926, -0.5439],\n",
      "          [ 1.3103, -3.5113,  2.0905,  ..., -0.4831, -0.1271,  1.1902],\n",
      "          [ 1.3286, -0.1524,  2.0625,  ...,  0.3667, -0.0628,  0.7514]],\n",
      "\n",
      "         [[ 0.2298,  2.1121,  1.4364,  ...,  1.8714,  0.0532,  0.5751],\n",
      "          [-0.1432,  1.7316,  1.1451,  ...,  2.7174, -1.0367, -1.2149],\n",
      "          [-0.8720,  1.7682,  2.5500,  ...,  1.5278, -1.2109, -2.9984],\n",
      "          ...,\n",
      "          [-0.1384,  0.8259,  3.3277,  ...,  0.8771, -0.1107, -2.1473],\n",
      "          [-1.3635, -0.0994,  1.9554,  ...,  2.2394,  1.3745, -0.2256],\n",
      "          [ 0.1111,  1.1642,  1.3966,  ...,  1.7225, -0.0391,  1.0191]],\n",
      "\n",
      "         [[ 0.4424, -0.7821,  0.6568,  ...,  0.7317, -0.0220,  0.9813],\n",
      "          [ 0.0089, -0.8898, -0.5328,  ...,  1.5058, -1.1720,  0.0432],\n",
      "          [-0.6742, -0.3593, -0.1600,  ..., -0.0273, -0.6119,  0.0987],\n",
      "          ...,\n",
      "          [-0.6118,  0.9155, -0.9838,  ..., -0.0096, -0.2287, -0.3127],\n",
      "          [-0.3109, -0.3717,  0.4818,  ..., -0.5768, -0.5997,  0.3820],\n",
      "          [-0.2389, -0.8934,  0.6944,  ...,  0.6331, -0.1619, -0.0562]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4916, -1.1138, -0.4035,  ...,  1.6370, -0.3900, -1.6524],\n",
      "          [-0.1230,  3.2421, -0.2310,  ..., -0.6626, -0.1086,  1.4337],\n",
      "          [-1.6066,  2.4913,  1.1693,  ...,  0.4055, -2.0801, -0.1759],\n",
      "          ...,\n",
      "          [-0.2797,  2.7367, -1.2394,  ...,  2.1403,  0.5529, -2.1806],\n",
      "          [-2.4224,  2.3128, -0.5841,  ...,  3.0757, -1.2542, -0.1114],\n",
      "          [ 0.1095, -0.1890, -2.5142,  ...,  0.7414,  0.2991,  1.2157]],\n",
      "\n",
      "         [[-3.7137,  0.9496,  1.6282,  ..., -2.2084, -0.0154,  1.3669],\n",
      "          [-1.1401,  0.6290,  0.1163,  ...,  0.2312, -0.5999,  0.7254],\n",
      "          [-1.4929,  0.3814,  0.2173,  ...,  0.8596, -0.1626,  1.0475],\n",
      "          ...,\n",
      "          [-0.3520,  0.7836, -1.2675,  ..., -0.4535, -1.5618,  1.8756],\n",
      "          [-1.2348,  0.8121, -0.5889,  ..., -1.8224,  0.1833,  1.6831],\n",
      "          [-1.9316, -0.6040,  1.7267,  ..., -0.7044, -1.1737, -0.0330]],\n",
      "\n",
      "         [[-0.4666, -0.5926,  0.6861,  ..., -1.1129,  1.6199,  0.0431],\n",
      "          [-0.3014, -1.4554, -0.5446,  ...,  0.6054, -0.4827,  0.8488],\n",
      "          [-0.2095, -0.7380, -1.0196,  ...,  0.9107, -0.8053,  0.1905],\n",
      "          ...,\n",
      "          [ 0.2015, -0.9448, -2.0536,  ..., -0.3724, -1.0899, -0.4399],\n",
      "          [-0.2525, -1.3977, -2.4135,  ..., -0.4385, -1.4929, -0.3272],\n",
      "          [-0.1456, -1.2524, -0.5183,  ...,  0.0269, -0.4975,  0.3940]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1594,  1.8467,  1.7236,  ..., -0.7641,  0.0229,  3.0880],\n",
      "          [ 0.9910,  0.7637,  0.2315,  ..., -0.0818, -0.5350, -0.7229],\n",
      "          [-0.7784,  2.0370,  0.7990,  ..., -0.2707, -0.8956,  2.0353],\n",
      "          ...,\n",
      "          [-1.3966,  0.0141, -2.3482,  ..., -0.5120, -1.2280,  0.3805],\n",
      "          [ 0.5602, -0.3773,  0.5449,  ...,  1.1138, -1.6919,  2.7352],\n",
      "          [ 0.5321, -1.5624,  0.1461,  ...,  3.0338,  1.3844,  0.9823]],\n",
      "\n",
      "         [[ 0.3996,  1.9436,  1.4249,  ...,  1.9433,  0.1775,  0.5681],\n",
      "          [ 1.2733,  3.3905,  3.4224,  ...,  1.4199,  2.1322, -0.8634],\n",
      "          [-0.5317,  0.9902,  1.4766,  ...,  1.4437, -0.3292,  0.1110],\n",
      "          ...,\n",
      "          [ 0.2268,  0.3688,  1.1521,  ...,  0.3737,  0.2633,  0.0350],\n",
      "          [ 0.4494,  0.0395,  0.9943,  ..., -0.2951,  0.2989,  0.3836],\n",
      "          [ 0.5311,  0.1874,  0.8531,  ..., -0.2569,  0.3176,  0.6772]],\n",
      "\n",
      "         [[ 0.3489, -0.4516,  0.7012,  ...,  0.6779, -0.2374,  0.7512],\n",
      "          [-1.8443, -0.7713,  0.3409,  ...,  1.7892,  1.3278,  2.1463],\n",
      "          [-0.3637, -1.0876,  0.5044,  ...,  0.6576,  0.0150, -0.0131],\n",
      "          ...,\n",
      "          [-0.1540, -0.1766,  0.3248,  ...,  0.6423, -0.4130, -0.6276],\n",
      "          [-0.1462,  0.2088,  0.1424,  ...,  0.5617, -0.1527, -0.6169],\n",
      "          [-0.1089,  0.1501,  0.0851,  ...,  0.1936, -0.2629, -0.5577]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4325, -0.7641,  0.0964,  ...,  1.5420, -0.2020, -1.7775],\n",
      "          [ 0.0174,  2.7626, -1.8596,  ..., -0.3926,  0.1906,  0.3724],\n",
      "          [ 0.1339,  1.6763,  0.9675,  ...,  0.7980, -1.8828, -0.2144],\n",
      "          ...,\n",
      "          [ 0.6037,  3.2220, -0.1428,  ..., -0.7798, -0.8874, -3.1217],\n",
      "          [-1.6291,  1.8482,  1.8547,  ..., -0.4822, -1.4315, -0.9618],\n",
      "          [-0.9779,  1.7375, -0.4876,  ..., -2.5641,  2.9578,  1.3715]],\n",
      "\n",
      "         [[-4.5219,  0.8414,  1.7866,  ..., -2.0360,  0.0211,  1.3560],\n",
      "          [-0.0382,  0.9872, -0.3806,  ..., -1.1721, -1.5237, -2.0455],\n",
      "          [-3.4867, -1.0409,  0.5446,  ..., -0.2135, -0.1156, -0.3277],\n",
      "          ...,\n",
      "          [-4.4992, -0.6909, -0.1763,  ...,  0.9306,  0.2383,  0.0832],\n",
      "          [-4.4285, -0.9031, -0.1267,  ...,  1.4920, -0.0936, -0.0264],\n",
      "          [-4.5657, -0.6420, -0.0671,  ...,  1.3394,  0.2030,  0.0080]],\n",
      "\n",
      "         [[-0.2880, -0.7474,  0.6884,  ..., -1.2636,  1.5161, -0.0512],\n",
      "          [-0.2595, -1.1439, -0.1033,  ...,  0.4820, -1.2243, -0.8217],\n",
      "          [ 0.1769, -0.1598,  0.1435,  ..., -0.2836,  0.3324,  0.9084],\n",
      "          ...,\n",
      "          [ 1.1032, -0.0308,  0.8511,  ..., -0.9285,  0.0959, -0.9181],\n",
      "          [ 1.5087,  0.1281,  0.6553,  ..., -0.7701, -0.0482, -0.7210],\n",
      "          [ 1.2841,  0.0751,  0.5813,  ..., -1.1823,  0.4516, -0.6559]]]],\n",
      "       grad_fn=<PermuteBackward0>), query layer: tensor([[[[ 3.9448e-01,  1.1521e+00,  4.8280e-02,  ..., -5.5572e-01,\n",
      "            1.0509e-01,  1.5584e+00],\n",
      "          [-4.1117e-01,  2.0463e-01,  1.3741e+00,  ..., -4.6658e-01,\n",
      "            8.4144e-01,  1.4724e+00],\n",
      "          [-3.3535e+00, -1.3840e+00, -1.5493e+00,  ..., -7.6332e-01,\n",
      "            5.7379e-01,  2.2206e+00],\n",
      "          ...,\n",
      "          [ 4.8686e-01, -1.6139e+00,  2.0461e+00,  ..., -5.1545e-01,\n",
      "            2.7766e-01,  2.4790e+00],\n",
      "          [ 5.2103e-01, -2.0473e+00,  2.1526e+00,  ...,  1.8867e+00,\n",
      "            1.3383e+00,  2.9370e+00],\n",
      "          [ 1.9323e+00,  8.5621e-01,  1.4787e+00,  ..., -3.2390e+00,\n",
      "            1.3910e+00,  1.1890e+00]],\n",
      "\n",
      "         [[ 1.2142e-01,  1.1159e+00, -1.6529e-01,  ...,  7.3358e-01,\n",
      "           -5.5318e-01,  4.5513e-01],\n",
      "          [ 4.0813e-01,  1.5386e+00,  6.8421e-01,  ...,  2.0588e+00,\n",
      "           -6.7632e-01, -1.4084e+00],\n",
      "          [-2.1177e-01,  8.8118e-01, -2.2519e-01,  ...,  1.8804e+00,\n",
      "            2.5114e-01,  6.7535e-01],\n",
      "          ...,\n",
      "          [-1.5880e+00, -2.0986e-01,  1.8072e+00,  ...,  2.9602e+00,\n",
      "            2.2801e-01,  1.1641e+00],\n",
      "          [-1.2031e+00,  3.4704e-01,  2.5261e+00,  ...,  5.2354e+00,\n",
      "           -1.4343e+00, -2.7400e+00],\n",
      "          [ 6.1327e-01,  1.1891e+00,  1.8232e+00,  ...,  5.6078e-01,\n",
      "            4.1721e-01,  1.5745e-01]],\n",
      "\n",
      "         [[ 3.1180e-01,  3.9758e-01,  7.5450e-01,  ..., -3.1224e-01,\n",
      "           -3.9596e-01,  2.8001e-01],\n",
      "          [-3.8958e-01, -7.5006e-01,  6.2369e-01,  ..., -3.7681e-01,\n",
      "            1.1763e+00, -7.5100e-01],\n",
      "          [ 9.2829e-01, -6.7172e-01,  7.8499e-01,  ...,  2.0990e-01,\n",
      "            4.2599e-01, -1.7568e-01],\n",
      "          ...,\n",
      "          [ 1.5655e+00,  5.8998e-02,  7.4512e-01,  ..., -2.5000e+00,\n",
      "            6.4275e-01, -1.1510e+00],\n",
      "          [-9.6171e-01, -7.4297e-01, -3.2390e-01,  ...,  2.1218e-01,\n",
      "            1.5128e+00, -2.3263e+00],\n",
      "          [-7.6818e-01,  3.8917e-02,  5.2120e-01,  ..., -4.5026e-01,\n",
      "           -4.7149e-01, -4.5118e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.6588e-02, -7.2991e-02, -7.9725e-01,  ...,  3.4698e-01,\n",
      "           -8.2821e-01, -3.3850e-01],\n",
      "          [-2.5515e-01,  1.1774e+00,  1.6698e+00,  ...,  1.5305e+00,\n",
      "           -3.1790e+00,  1.7786e-01],\n",
      "          [ 9.4671e-01,  2.6772e+00,  1.0578e+00,  ...,  9.6166e-01,\n",
      "           -5.8569e-01,  1.4383e+00],\n",
      "          ...,\n",
      "          [-1.1233e+00,  1.2632e+00,  1.1757e+00,  ...,  3.3396e+00,\n",
      "           -2.9897e+00, -1.3261e+00],\n",
      "          [-3.7639e-01,  4.1808e-01,  5.0604e-01,  ...,  2.4816e-02,\n",
      "            3.6318e-01,  2.1076e+00],\n",
      "          [ 1.4249e+00,  8.1500e-01, -1.0467e+00,  ...,  2.0637e+00,\n",
      "            1.2608e+00, -1.9041e+00]],\n",
      "\n",
      "         [[-3.2381e-01,  5.0412e-01,  7.1363e-01,  ..., -1.3672e+00,\n",
      "            3.5507e-02,  7.1016e-01],\n",
      "          [-1.1019e+00,  1.7036e+00,  6.4172e-01,  ...,  1.6913e-01,\n",
      "            2.7605e-02,  1.6185e+00],\n",
      "          [-1.3496e+00,  1.6474e+00,  5.4247e-01,  ..., -3.0035e-01,\n",
      "           -6.7102e-01,  8.3696e-02],\n",
      "          ...,\n",
      "          [-3.1790e+00,  1.1285e+00,  1.0113e+00,  ..., -1.3997e-02,\n",
      "            1.1046e+00,  1.1890e+00],\n",
      "          [-2.1558e+00,  1.9449e+00, -1.5550e-01,  ..., -8.4403e-01,\n",
      "           -7.3708e-01,  1.6857e-01],\n",
      "          [-1.0311e+00,  2.4707e-01,  4.7556e-01,  ..., -1.1770e+00,\n",
      "            6.3912e-01,  9.9482e-02]],\n",
      "\n",
      "         [[ 2.8017e-01, -1.4374e-01,  2.8049e-01,  ..., -1.0257e+00,\n",
      "            1.2201e+00, -1.0533e-01],\n",
      "          [-3.4376e-01, -1.2042e+00, -1.6383e+00,  ...,  7.8017e-01,\n",
      "           -3.1807e-01, -5.1489e-01],\n",
      "          [-1.1983e+00, -1.1204e+00, -1.1036e+00,  ...,  5.1116e-01,\n",
      "           -1.2260e+00,  1.0355e-01],\n",
      "          ...,\n",
      "          [-1.6111e+00,  6.5048e-02, -1.9150e-01,  ..., -7.6759e-01,\n",
      "            5.5862e-01,  4.8334e-01],\n",
      "          [ 7.0697e-01,  1.0268e-02, -9.3538e-01,  ...,  1.3996e-01,\n",
      "            6.1310e-01, -1.1673e-01],\n",
      "          [ 9.5144e-02,  4.6758e-02,  5.7318e-01,  ..., -8.7340e-01,\n",
      "            1.7138e+00,  7.2553e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7075e-01,  1.0564e+00,  7.3396e-02,  ..., -8.3445e-01,\n",
      "            7.1840e-03,  1.1419e+00],\n",
      "          [-1.2097e+00,  2.4369e+00,  2.4555e+00,  ..., -5.3835e-01,\n",
      "           -8.2930e-01,  2.2727e+00],\n",
      "          [-1.9988e+00, -6.8788e-01, -1.8048e+00,  ..., -4.3661e-01,\n",
      "            5.9852e-01,  1.9423e+00],\n",
      "          ...,\n",
      "          [ 1.8623e+00, -9.3717e-01,  2.7544e+00,  ..., -1.3129e+00,\n",
      "           -1.6089e+00,  2.0696e+00],\n",
      "          [ 1.7821e+00, -2.9601e+00,  2.6049e+00,  ...,  1.0756e+00,\n",
      "            1.2987e+00,  8.0197e-01],\n",
      "          [ 3.3822e+00, -9.3251e-01,  2.4614e+00,  ..., -6.8689e-01,\n",
      "            1.4295e+00, -2.5871e+00]],\n",
      "\n",
      "         [[ 6.3784e-01,  1.1805e+00, -4.8031e-01,  ...,  5.5637e-01,\n",
      "           -7.5144e-01,  5.8058e-01],\n",
      "          [ 1.0102e+00,  1.2698e+00,  8.9313e-01,  ...,  1.2578e+00,\n",
      "           -2.7097e+00, -3.4348e-03],\n",
      "          [ 6.5555e-01,  8.6506e-01,  3.3491e-01,  ...,  6.3059e-01,\n",
      "            4.9760e-01, -2.5044e-01],\n",
      "          ...,\n",
      "          [ 3.5155e-01,  1.4530e+00,  7.1276e-01,  ...,  1.8153e+00,\n",
      "           -3.8370e-01, -2.9048e-01],\n",
      "          [ 2.5895e-02,  1.3850e+00,  3.1704e-02,  ...,  1.5074e+00,\n",
      "           -1.4862e-01, -1.8766e-01],\n",
      "          [-2.0707e-02,  1.4404e+00,  1.3313e-01,  ...,  1.0536e+00,\n",
      "           -8.7122e-02,  1.5904e-01]],\n",
      "\n",
      "         [[ 5.1685e-01,  3.3690e-01,  7.5847e-01,  ..., -2.5601e-01,\n",
      "           -1.8159e-01,  1.4619e-01],\n",
      "          [-1.5483e+00, -6.9249e-01,  1.2896e-01,  ...,  2.8090e-01,\n",
      "           -6.0909e-02, -1.1247e+00],\n",
      "          [-1.9767e-01, -1.9367e-01,  8.4390e-02,  ...,  6.2254e-02,\n",
      "           -3.9453e-01,  4.1138e-02],\n",
      "          ...,\n",
      "          [-4.4078e-01, -7.8083e-01,  7.8321e-01,  ...,  2.1649e-01,\n",
      "            8.5865e-01, -8.2256e-02],\n",
      "          [-3.7082e-01, -4.5887e-01,  9.8524e-01,  ..., -7.8317e-02,\n",
      "            7.7534e-01, -5.0316e-01],\n",
      "          [-2.2140e-01, -7.5459e-01,  7.6679e-01,  ...,  1.4896e-01,\n",
      "            6.1891e-01, -2.9693e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.5800e-01, -1.6317e-01, -9.1273e-01,  ...,  8.6192e-01,\n",
      "           -8.2053e-01, -6.2151e-01],\n",
      "          [-4.1830e-02,  7.1310e-01,  2.1108e+00,  ...,  1.3925e+00,\n",
      "           -2.9932e+00, -9.1499e-02],\n",
      "          [-2.6321e-01,  9.3952e-01,  1.9465e-01,  ...,  3.4890e-01,\n",
      "           -1.7045e+00,  7.8731e-01],\n",
      "          ...,\n",
      "          [ 1.6383e-01, -1.0006e-01,  1.9292e+00,  ...,  4.5447e+00,\n",
      "           -6.5726e-01, -1.0694e+00],\n",
      "          [ 3.7217e-01, -3.6084e-01, -4.9414e-01,  ...,  1.4318e+00,\n",
      "            4.3429e+00,  2.5656e+00],\n",
      "          [ 4.3520e+00, -5.3369e-01, -1.4065e+00,  ...,  4.1740e+00,\n",
      "            2.6037e+00, -1.5136e+00]],\n",
      "\n",
      "         [[-4.1003e-01,  2.3620e-01,  9.6592e-01,  ..., -1.2506e+00,\n",
      "           -3.0808e-01,  9.5117e-01],\n",
      "          [-2.4418e+00,  3.6651e-01, -1.0316e+00,  ..., -3.7456e-01,\n",
      "            2.1815e+00, -1.8080e-01],\n",
      "          [-6.5556e-01,  1.2074e+00,  7.3075e-01,  ..., -9.3392e-01,\n",
      "            5.3327e-01,  4.5909e-01],\n",
      "          ...,\n",
      "          [-1.8896e-01, -1.3530e-01,  1.2644e+00,  ..., -5.4536e-01,\n",
      "           -4.1509e-01,  1.4181e+00],\n",
      "          [-1.9894e-01,  2.0609e-01,  1.1553e+00,  ..., -1.1359e+00,\n",
      "           -1.0501e-01,  1.3872e+00],\n",
      "          [-8.6519e-02, -1.8587e-01,  1.3316e+00,  ..., -9.1500e-01,\n",
      "           -2.7560e-01,  1.2841e+00]],\n",
      "\n",
      "         [[ 4.0488e-01, -2.8419e-01,  3.3366e-01,  ..., -1.0098e+00,\n",
      "            1.2387e+00,  1.1283e-01],\n",
      "          [-3.0636e-01, -1.0349e+00, -2.6849e+00,  ...,  7.5188e-01,\n",
      "            7.5607e-01, -2.4522e-01],\n",
      "          [-3.1130e-01,  2.3675e-01, -6.4745e-01,  ...,  1.1535e+00,\n",
      "            1.3291e-01, -7.5547e-01],\n",
      "          ...,\n",
      "          [-3.8343e-01, -9.3799e-01, -3.8436e-01,  ..., -3.7737e-01,\n",
      "            1.4646e+00,  2.5958e-01],\n",
      "          [-2.7274e-01, -5.9583e-01, -1.2837e-01,  ..., -7.6992e-01,\n",
      "            1.4701e+00,  5.2470e-01],\n",
      "          [-3.8176e-01, -4.9872e-01, -4.6858e-01,  ..., -7.0205e-01,\n",
      "            1.6384e+00,  4.5115e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[ 5.9763e+00, -1.6967e+00, -1.4461e-01,  ..., -1.8607e+00,\n",
      "           -1.9648e+00,  1.5484e+00],\n",
      "          [ 5.7822e+00,  5.3978e+00,  1.4062e+01,  ...,  1.7915e+00,\n",
      "            3.0190e+00,  1.1469e+00],\n",
      "          [ 4.9852e+00,  3.0995e+00,  6.3891e+00,  ...,  7.4937e+00,\n",
      "            1.2002e+00,  2.6793e+00],\n",
      "          ...,\n",
      "          [ 4.7418e+00,  1.3871e+00,  1.8532e+00,  ...,  4.6682e+00,\n",
      "            1.5524e+01,  3.9911e+00],\n",
      "          [ 8.5243e+00,  3.7246e+00,  2.2260e+00,  ...,  2.9756e-01,\n",
      "            7.6525e+00,  1.4087e+01],\n",
      "          [ 9.2504e+00, -2.3589e+00,  2.1318e+00,  ..., -6.3445e-01,\n",
      "           -7.7890e-02,  4.1678e+00]],\n",
      "\n",
      "         [[ 4.2764e+00,  1.4152e+00,  1.1832e+00,  ...,  5.4225e-01,\n",
      "            3.2112e-01,  2.8834e+00],\n",
      "          [ 8.0424e+00,  4.7365e+00,  5.3032e+00,  ...,  1.3064e+00,\n",
      "            1.1960e+00,  5.2564e+00],\n",
      "          [ 6.8632e+00,  5.7038e+00,  3.4494e+00,  ...,  4.8008e-01,\n",
      "            2.2551e+00,  5.1365e+00],\n",
      "          ...,\n",
      "          [ 5.2689e+00,  4.7033e+00,  4.0666e+00,  ...,  1.9104e+00,\n",
      "            5.2964e+00,  4.9789e+00],\n",
      "          [ 6.7600e+00,  5.7776e+00,  7.4414e+00,  ...,  5.2443e+00,\n",
      "            5.1558e+00,  6.5439e+00],\n",
      "          [ 7.1534e+00,  1.9812e+00,  2.4105e+00,  ...,  1.7239e+00,\n",
      "            1.8422e+00,  5.4917e+00]],\n",
      "\n",
      "         [[ 3.6031e+00, -1.3075e-02,  3.4085e-01,  ...,  1.1217e+00,\n",
      "            8.2171e-01,  1.7991e+00],\n",
      "          [ 5.2238e+00,  1.3693e-01,  7.9774e-01,  ...,  2.3842e-01,\n",
      "           -6.5951e-01,  3.5538e+00],\n",
      "          [ 5.8454e+00,  7.7836e-01,  4.2458e-01,  ..., -2.0332e-01,\n",
      "           -3.3301e-01,  2.4170e+00],\n",
      "          ...,\n",
      "          [ 4.0294e+00,  4.1130e-01,  5.0445e-01,  ..., -2.5084e+00,\n",
      "           -1.6752e-01,  3.0703e+00],\n",
      "          [ 4.7065e+00,  3.1392e-01, -1.6115e-01,  ...,  9.0757e-01,\n",
      "           -4.0900e-01,  2.3707e+00],\n",
      "          [ 2.8472e+00, -6.8161e-02,  6.9453e-01,  ...,  1.3818e+00,\n",
      "            5.0918e-01,  1.7995e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6391e+00,  1.8727e+00,  2.2468e+00,  ...,  3.9550e-01,\n",
      "            8.1597e-01,  4.1344e+00],\n",
      "          [ 6.0394e+00,  6.5688e+00,  1.4624e+01,  ...,  5.2168e-01,\n",
      "            2.6340e+00,  2.1783e+00],\n",
      "          [ 4.4434e+00,  3.5435e+00,  6.1909e+00,  ...,  7.0440e+00,\n",
      "           -4.8477e-01,  3.9077e+00],\n",
      "          ...,\n",
      "          [ 6.1352e+00,  1.3097e+00,  1.6812e+00,  ...,  4.9295e+00,\n",
      "            1.6654e+01,  5.1451e+00],\n",
      "          [ 1.0101e+01,  3.8757e+00,  1.9283e+00,  ..., -4.8106e-02,\n",
      "            7.2959e+00,  1.5714e+01],\n",
      "          [ 1.1162e+01, -1.2911e+00,  3.5068e+00,  ...,  4.1845e-01,\n",
      "            1.0428e+00,  5.1742e+00]],\n",
      "\n",
      "         [[ 3.8052e+00,  6.6278e-01,  8.1064e-01,  ..., -6.2711e-02,\n",
      "            8.2617e-02,  2.3539e+00],\n",
      "          [ 3.5589e+00,  1.0495e+00,  2.1127e+00,  ...,  9.3736e-01,\n",
      "            1.0862e+00,  1.8777e+00],\n",
      "          [ 4.2362e+00,  1.5496e+00,  1.7344e+00,  ...,  1.0478e-01,\n",
      "            6.1975e-01,  2.5199e+00],\n",
      "          ...,\n",
      "          [ 3.7544e+00,  1.3269e+00,  1.7604e+00,  ...,  3.4138e-01,\n",
      "            2.1174e+00,  1.6243e+00],\n",
      "          [ 3.9492e+00,  1.6413e+00,  1.9758e+00,  ...,  4.8006e-01,\n",
      "           -1.8751e-01,  1.7156e+00],\n",
      "          [ 5.0665e+00,  1.0300e+00,  1.4639e+00,  ..., -4.3529e-01,\n",
      "            2.7836e-01,  2.5776e+00]],\n",
      "\n",
      "         [[ 6.5896e+00,  9.5085e-01,  1.1008e+00,  ...,  4.3411e-01,\n",
      "            7.6696e-01,  3.1487e+00],\n",
      "          [ 1.9515e+00,  1.1214e+00,  2.8348e+00,  ...,  1.6514e+00,\n",
      "            1.8344e+00,  1.8873e+00],\n",
      "          [ 8.6248e-01,  9.5245e-01,  4.5471e-01,  ...,  1.5828e+00,\n",
      "            2.4671e+00,  1.7415e+00],\n",
      "          ...,\n",
      "          [ 2.4782e+00,  1.0712e+00,  1.6616e+00,  ...,  5.1237e-01,\n",
      "            1.7253e+00,  1.5611e+00],\n",
      "          [ 2.6112e+00,  1.4097e+00,  2.2456e+00,  ...,  2.1019e+00,\n",
      "            7.6972e-01,  1.7086e+00],\n",
      "          [ 8.2835e+00,  1.1211e+00,  1.3390e+00,  ...,  7.2413e-01,\n",
      "            1.3922e+00,  3.4249e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6306e+00, -8.0920e-01,  1.0003e+00,  ..., -6.8388e-01,\n",
      "           -1.1958e+00, -1.7643e+00],\n",
      "          [ 6.3651e+00, -3.3007e-01,  1.4637e+01,  ..., -2.5114e+00,\n",
      "            3.2584e+00, -5.5191e+00],\n",
      "          [ 5.4970e+00,  2.5884e+00,  3.3214e+00,  ...,  3.1233e+00,\n",
      "           -1.9929e+00, -6.1723e-01],\n",
      "          ...,\n",
      "          [ 8.9819e+00, -2.3895e+00,  4.2958e+00,  ...,  1.0560e+00,\n",
      "            1.0897e+01, -4.9987e-01],\n",
      "          [ 9.8989e+00,  2.9272e+00, -3.4151e-01,  ..., -4.2673e+00,\n",
      "            2.4373e-01,  1.2910e+01],\n",
      "          [ 8.2851e+00, -5.3580e-01,  3.6867e+00,  ..., -2.2287e+00,\n",
      "           -4.0618e+00,  4.3862e+00]],\n",
      "\n",
      "         [[ 3.9625e+00,  1.1991e+00,  1.7526e+00,  ...,  6.9197e-01,\n",
      "            2.6941e-01,  5.8615e-01],\n",
      "          [ 7.7092e+00,  1.5744e+00,  4.8473e+00,  ...,  2.7592e+00,\n",
      "            1.4365e+00,  1.5981e+00],\n",
      "          [ 4.1137e+00,  3.6940e+00,  1.5412e+00,  ...,  1.6844e+00,\n",
      "            3.5787e-01,  3.4421e-01],\n",
      "          ...,\n",
      "          [ 6.3725e+00,  3.1424e+00,  2.8189e+00,  ...,  1.9766e+00,\n",
      "            9.1321e-01,  8.5162e-01],\n",
      "          [ 5.4173e+00,  2.4516e+00,  2.1214e+00,  ...,  2.0328e+00,\n",
      "            1.1059e+00,  1.1734e+00],\n",
      "          [ 4.7103e+00,  1.7789e+00,  1.4926e+00,  ...,  1.6920e+00,\n",
      "            1.1478e+00,  1.5407e+00]],\n",
      "\n",
      "         [[ 3.4464e+00,  9.9190e-01,  6.8075e-01,  ...,  9.1643e-01,\n",
      "            5.0046e-01,  9.4706e-01],\n",
      "          [ 2.5659e+00,  1.2304e-01,  3.2176e+00,  ...,  9.6165e-02,\n",
      "            4.0009e-01,  1.7505e-01],\n",
      "          [ 3.1108e+00,  9.0213e-01,  5.0369e-01,  ...,  1.7511e+00,\n",
      "            1.2959e+00,  1.7079e+00],\n",
      "          ...,\n",
      "          [ 3.6333e+00,  1.3411e+00,  2.0144e+00,  ...,  9.3117e-01,\n",
      "            6.8805e-01,  8.5954e-01],\n",
      "          [ 3.5907e+00,  1.3438e+00,  1.4985e+00,  ...,  1.3062e+00,\n",
      "            9.5464e-01,  1.2520e+00],\n",
      "          [ 3.3193e+00,  1.0818e+00,  1.9950e+00,  ...,  4.9377e-01,\n",
      "            3.0428e-01,  4.3216e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2376e+00,  1.6545e+00,  2.7448e+00,  ...,  5.6481e-01,\n",
      "           -6.9508e-01, -1.8132e+00],\n",
      "          [ 6.5131e+00,  7.4057e-01,  1.4996e+01,  ..., -3.4738e+00,\n",
      "            1.4893e+00, -7.3375e+00],\n",
      "          [ 5.6167e+00,  2.6103e+00,  3.6461e+00,  ...,  3.9890e+00,\n",
      "           -1.7489e+00, -7.3116e-01],\n",
      "          ...,\n",
      "          [ 9.9723e+00, -2.9009e+00,  4.4426e+00,  ..., -2.8958e-01,\n",
      "            9.4248e+00, -2.0750e+00],\n",
      "          [ 1.1146e+01,  1.2957e+00, -1.3835e-02,  ..., -5.9028e+00,\n",
      "           -1.6802e+00,  1.1015e+01],\n",
      "          [ 1.0250e+01, -7.2483e-01,  4.1761e+00,  ..., -3.6996e+00,\n",
      "           -5.7480e+00,  2.6602e+00]],\n",
      "\n",
      "         [[ 3.2661e+00,  1.1441e+00,  1.0260e+00,  ...,  3.0829e-01,\n",
      "           -1.1883e-01,  5.1167e-02],\n",
      "          [ 1.5963e+00,  3.3276e+00,  1.7296e+00,  ...,  2.5903e+00,\n",
      "            2.0107e+00,  2.3346e+00],\n",
      "          [ 3.6083e+00,  1.6019e+00,  7.1106e-01,  ...,  1.2457e+00,\n",
      "            5.7415e-01,  8.0493e-01],\n",
      "          ...,\n",
      "          [ 2.1124e+00,  7.6040e-01,  5.3304e-01,  ...,  1.6497e-01,\n",
      "           -1.5802e-01, -5.6039e-02],\n",
      "          [ 2.4815e+00,  1.1113e+00,  4.3638e-01,  ..., -3.0249e-02,\n",
      "           -4.9017e-01, -3.3596e-01],\n",
      "          [ 1.9759e+00,  1.0126e+00,  3.9253e-01,  ..., -1.5772e-01,\n",
      "           -5.3741e-01, -4.5770e-01]],\n",
      "\n",
      "         [[ 6.0818e+00,  4.7647e-01,  1.4666e+00,  ...,  2.4377e+00,\n",
      "            1.7805e+00,  2.6537e+00],\n",
      "          [ 3.8888e+00, -2.6919e-01,  1.6818e+00,  ...,  1.9762e+00,\n",
      "            1.2350e+00,  1.7666e+00],\n",
      "          [ 2.8819e+00,  1.0145e+00,  1.3367e+00,  ...,  1.2271e+00,\n",
      "            1.5017e+00,  1.7212e+00],\n",
      "          ...,\n",
      "          [ 3.4899e+00, -2.4478e-01,  1.1750e+00,  ...,  1.3435e+00,\n",
      "            1.3704e+00,  1.8496e+00],\n",
      "          [ 4.0037e+00, -4.4533e-02,  1.0942e+00,  ...,  1.7612e+00,\n",
      "            1.6811e+00,  2.3404e+00],\n",
      "          [ 3.3176e+00, -1.9725e-01,  5.1426e-01,  ...,  1.0702e+00,\n",
      "            9.2657e-01,  1.5668e+00]]]], grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[ 5.9763e+00, -1.6967e+00, -1.4461e-01,  ..., -1.8607e+00,\n",
      "           -1.9648e+00,  1.5484e+00],\n",
      "          [ 5.7822e+00,  5.3978e+00,  1.4062e+01,  ...,  1.7915e+00,\n",
      "            3.0190e+00,  1.1469e+00],\n",
      "          [ 4.9852e+00,  3.0995e+00,  6.3891e+00,  ...,  7.4937e+00,\n",
      "            1.2002e+00,  2.6793e+00],\n",
      "          ...,\n",
      "          [ 4.7418e+00,  1.3871e+00,  1.8532e+00,  ...,  4.6682e+00,\n",
      "            1.5524e+01,  3.9911e+00],\n",
      "          [ 8.5243e+00,  3.7246e+00,  2.2260e+00,  ...,  2.9756e-01,\n",
      "            7.6525e+00,  1.4087e+01],\n",
      "          [ 9.2504e+00, -2.3589e+00,  2.1318e+00,  ..., -6.3445e-01,\n",
      "           -7.7890e-02,  4.1678e+00]],\n",
      "\n",
      "         [[ 4.2764e+00,  1.4152e+00,  1.1832e+00,  ...,  5.4225e-01,\n",
      "            3.2112e-01,  2.8834e+00],\n",
      "          [ 8.0424e+00,  4.7365e+00,  5.3032e+00,  ...,  1.3064e+00,\n",
      "            1.1960e+00,  5.2564e+00],\n",
      "          [ 6.8632e+00,  5.7038e+00,  3.4494e+00,  ...,  4.8008e-01,\n",
      "            2.2551e+00,  5.1365e+00],\n",
      "          ...,\n",
      "          [ 5.2689e+00,  4.7033e+00,  4.0666e+00,  ...,  1.9104e+00,\n",
      "            5.2964e+00,  4.9789e+00],\n",
      "          [ 6.7600e+00,  5.7776e+00,  7.4414e+00,  ...,  5.2443e+00,\n",
      "            5.1558e+00,  6.5439e+00],\n",
      "          [ 7.1534e+00,  1.9812e+00,  2.4105e+00,  ...,  1.7239e+00,\n",
      "            1.8422e+00,  5.4917e+00]],\n",
      "\n",
      "         [[ 3.6031e+00, -1.3075e-02,  3.4085e-01,  ...,  1.1217e+00,\n",
      "            8.2171e-01,  1.7991e+00],\n",
      "          [ 5.2238e+00,  1.3693e-01,  7.9774e-01,  ...,  2.3842e-01,\n",
      "           -6.5951e-01,  3.5538e+00],\n",
      "          [ 5.8454e+00,  7.7836e-01,  4.2458e-01,  ..., -2.0332e-01,\n",
      "           -3.3301e-01,  2.4170e+00],\n",
      "          ...,\n",
      "          [ 4.0294e+00,  4.1130e-01,  5.0445e-01,  ..., -2.5084e+00,\n",
      "           -1.6752e-01,  3.0703e+00],\n",
      "          [ 4.7065e+00,  3.1392e-01, -1.6115e-01,  ...,  9.0757e-01,\n",
      "           -4.0900e-01,  2.3707e+00],\n",
      "          [ 2.8472e+00, -6.8161e-02,  6.9453e-01,  ...,  1.3818e+00,\n",
      "            5.0918e-01,  1.7995e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6391e+00,  1.8727e+00,  2.2468e+00,  ...,  3.9550e-01,\n",
      "            8.1597e-01,  4.1344e+00],\n",
      "          [ 6.0394e+00,  6.5688e+00,  1.4624e+01,  ...,  5.2168e-01,\n",
      "            2.6340e+00,  2.1783e+00],\n",
      "          [ 4.4434e+00,  3.5435e+00,  6.1909e+00,  ...,  7.0440e+00,\n",
      "           -4.8477e-01,  3.9077e+00],\n",
      "          ...,\n",
      "          [ 6.1352e+00,  1.3097e+00,  1.6812e+00,  ...,  4.9295e+00,\n",
      "            1.6654e+01,  5.1451e+00],\n",
      "          [ 1.0101e+01,  3.8757e+00,  1.9283e+00,  ..., -4.8106e-02,\n",
      "            7.2959e+00,  1.5714e+01],\n",
      "          [ 1.1162e+01, -1.2911e+00,  3.5068e+00,  ...,  4.1845e-01,\n",
      "            1.0428e+00,  5.1742e+00]],\n",
      "\n",
      "         [[ 3.8052e+00,  6.6278e-01,  8.1064e-01,  ..., -6.2711e-02,\n",
      "            8.2617e-02,  2.3539e+00],\n",
      "          [ 3.5589e+00,  1.0495e+00,  2.1127e+00,  ...,  9.3736e-01,\n",
      "            1.0862e+00,  1.8777e+00],\n",
      "          [ 4.2362e+00,  1.5496e+00,  1.7344e+00,  ...,  1.0478e-01,\n",
      "            6.1975e-01,  2.5199e+00],\n",
      "          ...,\n",
      "          [ 3.7544e+00,  1.3269e+00,  1.7604e+00,  ...,  3.4138e-01,\n",
      "            2.1174e+00,  1.6243e+00],\n",
      "          [ 3.9492e+00,  1.6413e+00,  1.9758e+00,  ...,  4.8006e-01,\n",
      "           -1.8751e-01,  1.7156e+00],\n",
      "          [ 5.0665e+00,  1.0300e+00,  1.4639e+00,  ..., -4.3529e-01,\n",
      "            2.7836e-01,  2.5776e+00]],\n",
      "\n",
      "         [[ 6.5896e+00,  9.5085e-01,  1.1008e+00,  ...,  4.3411e-01,\n",
      "            7.6696e-01,  3.1487e+00],\n",
      "          [ 1.9515e+00,  1.1214e+00,  2.8348e+00,  ...,  1.6514e+00,\n",
      "            1.8344e+00,  1.8873e+00],\n",
      "          [ 8.6248e-01,  9.5245e-01,  4.5471e-01,  ...,  1.5828e+00,\n",
      "            2.4671e+00,  1.7415e+00],\n",
      "          ...,\n",
      "          [ 2.4782e+00,  1.0712e+00,  1.6616e+00,  ...,  5.1237e-01,\n",
      "            1.7253e+00,  1.5611e+00],\n",
      "          [ 2.6112e+00,  1.4097e+00,  2.2456e+00,  ...,  2.1019e+00,\n",
      "            7.6972e-01,  1.7086e+00],\n",
      "          [ 8.2835e+00,  1.1211e+00,  1.3390e+00,  ...,  7.2413e-01,\n",
      "            1.3922e+00,  3.4249e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6306e+00, -8.0920e-01,  1.0003e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.3651e+00, -3.3007e-01,  1.4637e+01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.4970e+00,  2.5884e+00,  3.3214e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 8.9819e+00, -2.3895e+00,  4.2958e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 9.8989e+00,  2.9272e+00, -3.4151e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 8.2851e+00, -5.3580e-01,  3.6867e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.9625e+00,  1.1991e+00,  1.7526e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.7092e+00,  1.5744e+00,  4.8473e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.1137e+00,  3.6940e+00,  1.5412e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 6.3725e+00,  3.1424e+00,  2.8189e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.4173e+00,  2.4516e+00,  2.1214e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.7103e+00,  1.7789e+00,  1.4926e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.4464e+00,  9.9190e-01,  6.8075e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.5659e+00,  1.2304e-01,  3.2176e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.1108e+00,  9.0213e-01,  5.0369e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 3.6333e+00,  1.3411e+00,  2.0144e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.5907e+00,  1.3438e+00,  1.4985e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.3193e+00,  1.0818e+00,  1.9950e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2376e+00,  1.6545e+00,  2.7448e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.5131e+00,  7.4057e-01,  1.4996e+01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.6167e+00,  2.6103e+00,  3.6461e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 9.9723e+00, -2.9009e+00,  4.4426e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.1146e+01,  1.2957e+00, -1.3835e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0250e+01, -7.2483e-01,  4.1761e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.2661e+00,  1.1441e+00,  1.0260e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.5963e+00,  3.3276e+00,  1.7296e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.6083e+00,  1.6019e+00,  7.1106e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.1124e+00,  7.6040e-01,  5.3304e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.4815e+00,  1.1113e+00,  4.3638e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.9759e+00,  1.0126e+00,  3.9253e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 6.0818e+00,  4.7647e-01,  1.4666e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.8888e+00, -2.6919e-01,  1.6818e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.8819e+00,  1.0145e+00,  1.3367e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 3.4899e+00, -2.4478e-01,  1.1750e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.0037e+00, -4.4533e-02,  1.0942e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.3176e+00, -1.9725e-01,  5.1426e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[9.8364e-01, 4.5762e-04, 2.1606e-03,  ..., 3.8842e-04,\n",
      "           3.5002e-04, 1.1744e-02],\n",
      "          [2.5353e-04, 1.7263e-04, 9.9948e-01,  ..., 4.6871e-06,\n",
      "           1.5995e-05, 2.4601e-06],\n",
      "          [4.2997e-05, 6.5232e-06, 1.7503e-04,  ..., 5.2828e-04,\n",
      "           9.7640e-07, 4.2852e-06],\n",
      "          ...,\n",
      "          [2.0757e-05, 7.2481e-07, 1.1551e-06,  ..., 1.9283e-05,\n",
      "           9.9995e-01, 9.7977e-06],\n",
      "          [3.8158e-03, 3.1411e-05, 7.0189e-06,  ..., 1.0203e-06,\n",
      "           1.5957e-03, 9.9440e-01],\n",
      "          [9.9286e-01, 9.0168e-06, 8.0416e-04,  ..., 5.0578e-05,\n",
      "           8.8242e-05, 6.1595e-03]],\n",
      "\n",
      "         [[6.9500e-01, 3.9757e-02, 3.1525e-02,  ..., 1.6607e-02,\n",
      "           1.3312e-02, 1.7260e-01],\n",
      "          [8.4523e-01, 3.0992e-02, 5.4622e-02,  ..., 1.0036e-03,\n",
      "           8.9878e-04, 5.2126e-02],\n",
      "          [6.3717e-01, 1.9986e-01, 2.0973e-02,  ..., 1.0767e-03,\n",
      "           6.3530e-03, 1.1333e-01],\n",
      "          ...,\n",
      "          [2.1638e-01, 1.2291e-01, 6.5025e-02,  ..., 7.5279e-03,\n",
      "           2.2241e-01, 1.6191e-01],\n",
      "          [1.2537e-01, 4.6936e-02, 2.4781e-01,  ..., 2.7537e-02,\n",
      "           2.5205e-02, 1.0100e-01],\n",
      "          [8.1955e-01, 4.6482e-03, 7.1408e-03,  ..., 3.5939e-03,\n",
      "           4.0450e-03, 1.5555e-01]],\n",
      "\n",
      "         [[7.1214e-01, 1.9147e-02, 2.7277e-02,  ..., 5.9558e-02,\n",
      "           4.4120e-02, 1.1725e-01],\n",
      "          [8.1566e-01, 5.0384e-03, 9.7562e-03,  ..., 5.5766e-03,\n",
      "           2.2720e-03, 1.5354e-01],\n",
      "          [9.5144e-01, 5.9954e-03, 4.2089e-03,  ..., 2.2463e-03,\n",
      "           1.9731e-03, 3.0864e-02],\n",
      "          ...,\n",
      "          [6.6003e-01, 1.7711e-02, 1.9440e-02,  ..., 9.5549e-04,\n",
      "           9.9282e-03, 2.5296e-01],\n",
      "          [8.5699e-01, 1.0600e-02, 6.5918e-03,  ..., 1.9193e-02,\n",
      "           5.1447e-03, 8.2902e-02],\n",
      "          [5.2720e-01, 2.8566e-02, 6.1247e-02,  ..., 1.2177e-01,\n",
      "           5.0885e-02, 1.8491e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[7.6727e-01, 1.7751e-02, 2.5804e-02,  ..., 4.0522e-03,\n",
      "           6.1702e-03, 1.7040e-01],\n",
      "          [1.8694e-04, 3.1742e-04, 9.9944e-01,  ..., 7.5055e-07,\n",
      "           6.2052e-06, 3.9341e-06],\n",
      "          [3.6403e-05, 1.4803e-05, 2.0897e-04,  ..., 4.9043e-04,\n",
      "           2.6356e-07, 2.1305e-05],\n",
      "          ...,\n",
      "          [2.7013e-05, 2.1671e-07, 3.1419e-07,  ..., 8.0899e-06,\n",
      "           9.9995e-01, 1.0036e-05],\n",
      "          [3.6360e-03, 7.1977e-06, 1.0267e-06,  ..., 1.4227e-07,\n",
      "           2.2008e-04, 9.9612e-01],\n",
      "          [9.9695e-01, 3.8942e-06, 4.7221e-04,  ..., 2.1522e-05,\n",
      "           4.0184e-05, 2.5020e-03]],\n",
      "\n",
      "         [[7.1129e-01, 3.0713e-02, 3.5607e-02,  ..., 1.4868e-02,\n",
      "           1.7193e-02, 1.6664e-01],\n",
      "          [5.8850e-01, 4.7856e-02, 1.3857e-01,  ..., 4.2777e-02,\n",
      "           4.9640e-02, 1.0955e-01],\n",
      "          [7.1572e-01, 4.8747e-02, 5.8643e-02,  ..., 1.1494e-02,\n",
      "           1.9237e-02, 1.2863e-01],\n",
      "          ...,\n",
      "          [6.1980e-01, 5.4700e-02, 8.4386e-02,  ..., 2.0417e-02,\n",
      "           1.2059e-01, 7.3647e-02],\n",
      "          [7.0542e-01, 7.0172e-02, 9.8046e-02,  ..., 2.1970e-02,\n",
      "           1.1270e-02, 7.5585e-02],\n",
      "          [8.6413e-01, 1.5259e-02, 2.3548e-02,  ..., 3.5250e-03,\n",
      "           7.1960e-03, 7.1722e-02]],\n",
      "\n",
      "         [[9.5330e-01, 3.3912e-03, 3.9396e-03,  ..., 2.0227e-03,\n",
      "           2.8215e-03, 3.0541e-02],\n",
      "          [1.3582e-01, 5.9217e-02, 3.2852e-01,  ..., 1.0061e-01,\n",
      "           1.2081e-01, 1.2737e-01],\n",
      "          [7.5939e-02, 8.3088e-02, 5.0509e-02,  ..., 1.5606e-01,\n",
      "           3.7786e-01, 1.8290e-01],\n",
      "          ...,\n",
      "          [3.4320e-01, 8.4047e-02, 1.5168e-01,  ..., 4.8064e-02,\n",
      "           1.6166e-01, 1.3718e-01],\n",
      "          [2.7923e-01, 8.3974e-02, 1.9372e-01,  ..., 1.6779e-01,\n",
      "           4.4281e-02, 1.1323e-01],\n",
      "          [9.8777e-01, 7.6571e-04, 9.5213e-04,  ..., 5.1481e-04,\n",
      "           1.0041e-03, 7.6665e-03]]],\n",
      "\n",
      "\n",
      "        [[[9.4781e-01, 1.5134e-03, 9.2425e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.5558e-04, 3.1611e-07, 9.9973e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1872e-02, 1.1931e-03, 2.4834e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [9.5676e-01, 1.1022e-05, 8.8236e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.0505e-01, 5.6757e-04, 2.1600e-05,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.5924e-01, 1.4159e-04, 9.6572e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[7.1066e-01, 4.4824e-02, 7.7965e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.8228e-01, 1.6945e-03, 4.4716e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0819e-01, 3.3402e-01, 3.8798e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [8.6986e-01, 3.4405e-02, 2.4896e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.3149e-01, 4.2842e-02, 3.0793e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.1398e-01, 4.3404e-02, 3.2599e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[7.4277e-01, 6.3807e-02, 4.6745e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9857e-01, 1.7258e-02, 3.8101e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.5057e-01, 8.2450e-02, 5.5354e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.2873e-01, 5.3424e-02, 1.0474e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.1877e-01, 6.5420e-02, 7.6369e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.6492e-01, 4.9623e-02, 1.2367e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.3550e-01, 1.7659e-02, 5.2541e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0697e-04, 6.4406e-07, 9.9974e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.8890e-03, 2.9133e-04, 8.2076e-04,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [9.8520e-01, 2.5278e-06, 3.9084e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.4077e-01, 4.4352e-05, 1.1973e-05,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.8934e-01, 1.6937e-05, 2.2765e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[6.2803e-01, 7.5235e-02, 6.6851e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2628e-01, 7.1324e-01, 1.4430e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.3415e-01, 9.8721e-02, 4.0507e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.1655e-01, 1.3364e-01, 1.0646e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.9082e-01, 1.5010e-01, 7.6431e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.7496e-01, 1.8127e-01, 9.7503e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[9.6428e-01, 3.5469e-03, 9.5468e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.2091e-01, 1.1274e-02, 7.9325e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.7104e-01, 8.8240e-02, 1.2179e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [7.4356e-01, 1.7756e-02, 7.3440e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.3447e-01, 1.4565e-02, 4.5483e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.0759e-01, 2.4029e-02, 4.8948e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[-1.2521e-01, -1.1175e-01,  1.6697e-01,  ..., -2.5807e-02,\n",
      "            1.0705e-03, -8.3380e-02],\n",
      "          [ 9.0581e-02,  2.6120e-01,  2.1880e-01,  ..., -1.8500e-01,\n",
      "            4.1507e-01,  3.2035e-01],\n",
      "          [-6.0888e-01,  3.9067e-01,  9.7331e-02,  ...,  3.8211e-01,\n",
      "            5.5689e-01, -5.2555e-01],\n",
      "          ...,\n",
      "          [ 4.4046e-02, -6.7933e-01, -3.3404e-02,  ...,  8.8591e-02,\n",
      "            1.7464e-01, -1.1278e+00],\n",
      "          [ 1.8404e-01, -1.2761e-01,  2.4970e-01,  ...,  3.4108e-01,\n",
      "           -9.9244e-02, -8.8210e-01],\n",
      "          [-1.2639e-01, -1.1267e-01,  1.6629e-01,  ..., -2.7784e-02,\n",
      "            5.0329e-04, -7.8790e-02]],\n",
      "\n",
      "         [[ 4.8232e-02, -2.0694e-01,  5.3086e-02,  ..., -1.9813e-02,\n",
      "            9.4198e-04,  2.4144e-01],\n",
      "          [ 2.1931e-02, -1.8832e-01,  6.5891e-02,  ..., -4.6532e-02,\n",
      "            8.1979e-02,  1.9665e-01],\n",
      "          [ 4.9720e-02, -3.0868e-01, -2.7290e-03,  ..., -9.9001e-02,\n",
      "            3.8457e-02,  3.6222e-01],\n",
      "          ...,\n",
      "          [ 1.4849e-01, -6.0432e-01, -3.3616e-01,  ...,  5.4816e-03,\n",
      "           -1.5952e-01,  5.3005e-01],\n",
      "          [ 2.6234e-01, -3.9185e-01, -1.4715e-01,  ...,  9.2454e-02,\n",
      "           -1.4565e-01,  6.4536e-01],\n",
      "          [ 2.3665e-02, -1.4236e-01,  9.2400e-02,  ..., -1.6321e-02,\n",
      "            4.8208e-02,  1.5501e-01]],\n",
      "\n",
      "         [[-5.1521e-02,  2.2889e-01,  7.7794e-02,  ...,  3.2434e-02,\n",
      "            8.5649e-03, -1.7165e-01],\n",
      "          [-7.2219e-02,  1.5084e-01,  5.6936e-02,  ...,  5.0784e-02,\n",
      "            2.3781e-02, -1.0647e-01],\n",
      "          [-9.2736e-02,  1.7729e-01,  6.2076e-02,  ...,  6.9706e-02,\n",
      "            6.3039e-02,  1.0507e-01],\n",
      "          ...,\n",
      "          [-6.0613e-02,  1.3892e-01,  5.5838e-02,  ...,  5.4547e-02,\n",
      "           -3.2848e-02, -2.9400e-01],\n",
      "          [-8.3508e-02,  1.7709e-01,  6.6977e-02,  ...,  6.2104e-02,\n",
      "            4.2503e-02, -1.9072e-02],\n",
      "          [-3.2395e-02,  2.5843e-01,  1.2729e-01,  ..., -1.5716e-02,\n",
      "           -2.2190e-02, -3.9313e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1594e-01,  1.3704e-01, -1.7595e-01,  ..., -2.2180e-01,\n",
      "            2.8135e-01,  9.5459e-02],\n",
      "          [ 4.7380e-02,  1.6617e-01, -3.0923e-01,  ..., -1.3635e-01,\n",
      "            5.3975e-01, -2.2706e-01],\n",
      "          [-1.1174e-01,  8.7197e-01,  3.4744e-01,  ...,  4.7036e-01,\n",
      "            1.7434e-01,  6.0471e-01],\n",
      "          ...,\n",
      "          [ 3.0050e-01,  6.1263e-01,  2.6870e-01,  ..., -3.1453e-01,\n",
      "           -7.5272e-01, -8.0174e-01],\n",
      "          [ 2.3457e-01,  1.0630e+00, -3.6390e-01,  ...,  2.9885e-02,\n",
      "            4.8116e-01,  8.9950e-02],\n",
      "          [ 9.3273e-02, -8.1651e-02, -1.3436e-01,  ..., -2.9037e-01,\n",
      "            2.4293e-01,  1.1921e-01]],\n",
      "\n",
      "         [[ 2.5687e-02,  4.5191e-02, -9.0174e-03,  ...,  2.4292e-01,\n",
      "            1.0895e-01, -1.1468e-01],\n",
      "          [-1.9774e-02,  1.1504e-01, -7.0683e-02,  ...,  2.2234e-01,\n",
      "            2.1770e-02, -6.7473e-02],\n",
      "          [ 8.4739e-03,  6.2674e-02, -3.6270e-02,  ...,  2.2907e-01,\n",
      "            8.8182e-02, -1.0721e-01],\n",
      "          ...,\n",
      "          [-3.8269e-02,  1.0170e-01, -1.0494e-01,  ...,  2.1102e-01,\n",
      "            8.1960e-02, -1.6861e-02],\n",
      "          [-1.8743e-03,  8.5086e-02, -6.2084e-02,  ...,  2.2329e-01,\n",
      "            5.2870e-02, -9.8145e-02],\n",
      "          [ 4.5984e-02,  1.9333e-02, -1.6741e-03,  ...,  2.3500e-01,\n",
      "            1.6611e-01, -1.3114e-01]],\n",
      "\n",
      "         [[-5.1477e-02, -9.7137e-02, -3.3546e-01,  ...,  7.0795e-04,\n",
      "            1.7783e-02,  1.4191e-01],\n",
      "          [-6.1691e-02, -8.2033e-02, -5.9583e-02,  ..., -1.1068e-02,\n",
      "           -5.8688e-01,  3.6947e-01],\n",
      "          [-3.0457e-02, -5.7758e-01, -2.3870e-01,  ..., -4.7606e-01,\n",
      "           -5.4028e-01,  4.8928e-01],\n",
      "          ...,\n",
      "          [-4.2060e-02, -1.6991e-01, -1.4433e-01,  ..., -1.2825e-01,\n",
      "           -3.7614e-01,  3.1850e-01],\n",
      "          [-9.3851e-02, -1.9914e-01, -1.6539e-01,  ...,  1.8448e-03,\n",
      "           -5.2289e-01,  4.1619e-01],\n",
      "          [-4.7086e-02, -9.5064e-02, -3.4418e-01,  ..., -1.7548e-03,\n",
      "            4.4905e-02,  1.3510e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6814e-01, -1.2182e-01,  2.4614e-01,  ..., -1.6750e-01,\n",
      "           -1.2778e-01, -1.0293e-01],\n",
      "          [-2.8332e-02, -4.0284e-01, -1.0218e-01,  ..., -1.4187e-01,\n",
      "            2.4793e-01, -1.6281e-01],\n",
      "          [ 2.8813e-01, -8.9335e-02,  4.7115e-01,  ...,  2.6178e-01,\n",
      "           -5.7086e-02, -8.3017e-01],\n",
      "          ...,\n",
      "          [-1.7039e-01, -1.2181e-01,  2.4374e-01,  ..., -1.7094e-01,\n",
      "           -1.2755e-01, -9.8566e-02],\n",
      "          [ 4.0767e-03, -1.0758e-01,  3.3305e-01,  ..., -5.5204e-03,\n",
      "           -1.0306e-01, -3.7804e-01],\n",
      "          [-1.7205e-01, -1.2217e-01,  2.4271e-01,  ..., -1.7247e-01,\n",
      "           -1.2758e-01, -9.5855e-02]],\n",
      "\n",
      "         [[ 2.0528e-01, -1.8443e-01,  9.1065e-02,  ..., -1.8790e-01,\n",
      "            2.6531e-02,  2.3010e-01],\n",
      "          [ 1.3047e-01, -2.3369e-01,  1.0277e-01,  ..., -1.3591e-01,\n",
      "            4.0184e-02,  2.2265e-01],\n",
      "          [ 5.7119e-01, -3.7164e-02,  3.1238e-02,  ..., -6.1791e-01,\n",
      "            1.2067e-01,  2.4422e-01],\n",
      "          ...,\n",
      "          [ 1.3595e-01, -2.4539e-01,  8.3289e-02,  ..., -2.3294e-01,\n",
      "            1.2668e-01,  2.0405e-01],\n",
      "          [ 1.5769e-01, -2.3150e-01,  8.4710e-02,  ..., -2.3172e-01,\n",
      "            1.0719e-01,  2.1023e-01],\n",
      "          [ 1.6386e-01, -2.2707e-01,  8.6677e-02,  ..., -2.2496e-01,\n",
      "            9.5615e-02,  2.1342e-01]],\n",
      "\n",
      "         [[-1.8930e-01,  5.2180e-02,  9.0241e-02,  ...,  2.0842e-01,\n",
      "            8.0760e-02, -4.7510e-02],\n",
      "          [-1.1024e-01,  1.5179e-01,  3.0164e-01,  ..., -2.8248e-02,\n",
      "           -1.1425e-01, -1.0390e+00],\n",
      "          [-1.9838e-01,  3.7487e-02,  8.4938e-02,  ...,  2.1631e-01,\n",
      "            7.8170e-02, -1.2560e-02],\n",
      "          ...,\n",
      "          [-1.3128e-01,  6.1913e-02,  1.4498e-01,  ...,  1.3080e-01,\n",
      "            1.6933e-03, -4.7056e-01],\n",
      "          [-1.5536e-01,  4.9317e-02,  1.1765e-01,  ...,  1.6700e-01,\n",
      "            3.2668e-02, -2.8895e-01],\n",
      "          [-1.1450e-01,  6.5977e-02,  1.6213e-01,  ...,  1.0712e-01,\n",
      "           -2.1667e-02, -5.9635e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.2822e-02,  1.3964e-01, -1.2226e-01,  ..., -2.9078e-01,\n",
      "            9.5261e-02,  1.1212e-01],\n",
      "          [-5.6838e-02, -6.1318e-01,  1.1692e-01,  ..., -7.9132e-01,\n",
      "           -3.0214e-01,  4.3585e-01],\n",
      "          [ 1.0064e-01,  1.0221e+00, -2.1450e-01,  ..., -2.5711e-02,\n",
      "            3.8520e-01,  1.4203e-01],\n",
      "          ...,\n",
      "          [ 5.6399e-02, -2.0765e-01, -9.1939e-02,  ..., -3.7601e-01,\n",
      "            1.1560e-03,  8.3850e-02],\n",
      "          [ 6.3467e-02, -2.0617e-02, -1.1116e-01,  ..., -3.2170e-01,\n",
      "            6.0172e-02,  9.1420e-02],\n",
      "          [ 5.6479e-02, -2.1016e-01, -9.1970e-02,  ..., -3.7623e-01,\n",
      "            6.5928e-04,  8.3115e-02]],\n",
      "\n",
      "         [[-3.3049e-02, -5.8625e-02,  7.4965e-02,  ...,  4.8542e-01,\n",
      "            1.5145e-01, -2.6120e-01],\n",
      "          [ 3.5238e-01, -3.6258e-03, -4.7686e-01,  ...,  1.6300e+00,\n",
      "            2.5491e-01, -3.7607e-01],\n",
      "          [ 3.1108e-03, -7.6771e-02,  7.3506e-02,  ...,  5.5675e-01,\n",
      "            1.6683e-01, -2.6967e-01],\n",
      "          ...,\n",
      "          [-8.5223e-03, -4.5549e-02,  3.4737e-03,  ...,  5.7087e-01,\n",
      "            1.7265e-01, -2.6071e-01],\n",
      "          [ 1.6259e-02, -5.6512e-02,  9.9028e-03,  ...,  6.2352e-01,\n",
      "            1.7138e-01, -2.7257e-01],\n",
      "          [ 1.8788e-02, -3.8421e-02, -2.8229e-02,  ...,  6.5898e-01,\n",
      "            1.6368e-01, -2.7717e-01]],\n",
      "\n",
      "         [[-1.4605e-01, -4.6447e-02, -5.0082e-01,  ...,  1.7642e-01,\n",
      "           -7.2691e-02,  7.7626e-03],\n",
      "          [-1.7221e-01, -4.2800e-02, -3.4556e-01,  ...,  1.5256e-01,\n",
      "           -2.9090e-01,  1.1000e-01],\n",
      "          [-2.3432e-01,  7.7220e-02, -2.2006e-01,  ...,  7.9908e-02,\n",
      "           -3.9101e-01,  1.8529e-01],\n",
      "          ...,\n",
      "          [-1.7439e-01, -3.1458e-02, -3.5650e-01,  ...,  1.4898e-01,\n",
      "           -2.6673e-01,  1.0180e-01],\n",
      "          [-1.6434e-01, -3.3134e-02, -4.1615e-01,  ...,  1.5818e-01,\n",
      "           -1.8663e-01,  6.3309e-02],\n",
      "          [-1.7255e-01, -1.8282e-02, -3.9879e-01,  ...,  1.4874e-01,\n",
      "           -2.0946e-01,  7.5517e-02]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[ 7.2465e-01, -9.5440e-01, -3.4669e-02,  ...,  1.2059e+00,\n",
      "            5.2924e-01, -1.1034e+00],\n",
      "          [ 4.4444e-01, -6.5271e-01, -9.5328e-01,  ...,  2.6483e+00,\n",
      "           -2.1352e+00, -1.0045e+00],\n",
      "          [-3.6455e-01, -2.0604e-02,  1.5155e-01,  ...,  6.1464e-01,\n",
      "           -5.2155e-01, -8.0773e-01],\n",
      "          ...,\n",
      "          [-5.8548e-01, -6.4429e-01, -6.9979e-02,  ..., -1.2342e+00,\n",
      "           -7.1929e-01, -1.5868e+00],\n",
      "          [-2.1957e+00, -1.3697e+00, -1.5159e+00,  ...,  9.9649e-01,\n",
      "            1.6332e-01,  8.0114e-01],\n",
      "          [ 3.7825e-01, -1.2207e+00, -1.6255e-01,  ...,  1.2107e+00,\n",
      "            1.9138e-01, -4.8317e-01]],\n",
      "\n",
      "         [[-5.5437e-01, -1.3443e-01,  6.7922e-02,  ...,  8.2242e-02,\n",
      "           -3.3853e-01,  1.0055e-01],\n",
      "          [-3.8476e-01, -1.8508e-01,  1.2672e+00,  ...,  2.4658e-01,\n",
      "           -3.7010e-01, -1.9515e+00],\n",
      "          [-1.0289e+00, -7.2903e-01,  8.0018e-01,  ..., -1.3018e-02,\n",
      "            2.6470e-01, -4.7911e-01],\n",
      "          ...,\n",
      "          [ 5.9993e-01,  1.0957e+00,  5.3439e-01,  ...,  1.1825e+00,\n",
      "           -6.6183e-01, -8.3410e-01],\n",
      "          [ 1.4675e+00, -2.4217e-01,  1.0441e+00,  ..., -6.6486e-01,\n",
      "            5.2764e-02, -5.0099e-02],\n",
      "          [-2.4247e-01, -7.6407e-02, -3.5256e-01,  ..., -2.3569e-01,\n",
      "           -1.5785e+00, -2.0684e-01]],\n",
      "\n",
      "         [[-2.4358e-01,  1.4411e+00,  1.4519e-01,  ...,  2.1225e-01,\n",
      "           -1.8716e-01, -2.5245e-02],\n",
      "          [ 1.0739e+00,  9.5517e-01, -3.0691e-01,  ...,  1.4171e-01,\n",
      "           -1.1291e+00, -1.8632e+00],\n",
      "          [-3.0862e-01,  5.7114e-01,  6.3129e-01,  ...,  1.3470e+00,\n",
      "           -6.7442e-01,  7.6176e-01],\n",
      "          ...,\n",
      "          [-6.4094e-01, -5.5118e-02, -5.1396e-01,  ...,  9.1477e-01,\n",
      "           -7.0508e-01,  2.6487e-01],\n",
      "          [-5.7967e-01,  9.3545e-01, -6.5406e-01,  ...,  9.7092e-01,\n",
      "           -4.9848e-01, -1.1121e+00],\n",
      "          [ 4.9160e-02,  9.7374e-01,  3.1689e-02,  ...,  2.4251e-01,\n",
      "           -1.5596e-01,  3.4997e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1530e+00, -2.4596e+00, -9.1647e-01,  ...,  1.0083e+00,\n",
      "            5.1948e-01, -3.5559e-01],\n",
      "          [ 4.9021e-02,  1.9794e+00, -1.0369e+00,  ..., -6.4703e-01,\n",
      "            1.8014e+00, -2.4633e-01],\n",
      "          [-5.3854e-01,  2.9919e-01, -1.3453e+00,  ..., -3.7275e-01,\n",
      "            2.1547e+00,  9.2553e-01],\n",
      "          ...,\n",
      "          [-2.8505e+00, -3.6593e-01, -1.0763e+00,  ..., -7.9808e-01,\n",
      "            7.2910e-01, -5.4092e-01],\n",
      "          [-3.1212e-01, -1.9666e+00, -5.3164e-01,  ..., -1.6808e+00,\n",
      "            1.5752e+00, -2.4580e+00],\n",
      "          [-1.2823e-03, -2.2595e+00, -3.9801e-01,  ..., -5.0321e-01,\n",
      "            5.9717e-01, -2.8490e-02]],\n",
      "\n",
      "         [[ 6.3418e-01,  6.9561e-01,  5.9219e-01,  ...,  1.4298e+00,\n",
      "            7.8342e-01,  7.4195e-01],\n",
      "          [ 2.9060e-01,  8.2109e-02, -8.7230e-02,  ...,  9.2516e-01,\n",
      "            1.3256e+00,  6.2855e-01],\n",
      "          [ 1.5322e+00,  1.8345e-01, -6.6553e-01,  ...,  3.4545e-01,\n",
      "            1.6596e+00,  6.3224e-01],\n",
      "          ...,\n",
      "          [ 1.6277e+00, -1.9420e+00, -4.7649e-01,  ...,  9.6201e-01,\n",
      "            1.2093e+00,  6.9013e-01],\n",
      "          [-8.3130e-02,  1.3781e-01,  1.1943e+00,  ...,  6.3532e-02,\n",
      "            2.1349e+00,  6.7279e-01],\n",
      "          [ 7.7525e-01,  1.4577e+00,  3.7761e-01,  ...,  1.3227e+00,\n",
      "            1.2655e+00,  5.8426e-01]],\n",
      "\n",
      "         [[ 1.1181e+00,  1.1852e+00, -5.2413e-01,  ..., -1.2276e+00,\n",
      "            2.7594e-01,  8.0019e-01],\n",
      "          [ 5.2827e-01, -1.0055e+00, -1.8384e+00,  ..., -1.1469e-01,\n",
      "            2.0319e-01,  5.4725e-01],\n",
      "          [ 1.2829e+00, -8.4993e-01, -1.3780e+00,  ...,  5.8332e-01,\n",
      "            2.2049e-01,  1.8714e-01],\n",
      "          ...,\n",
      "          [-5.0165e-02, -1.2670e+00, -2.2881e+00,  ..., -7.5493e-02,\n",
      "           -1.5851e-01, -1.0114e+00],\n",
      "          [-1.0976e-01, -4.5952e-01, -8.1958e-01,  ..., -8.3387e-01,\n",
      "            4.7060e-01,  1.2155e-03],\n",
      "          [ 8.0655e-01,  2.1051e+00, -3.0583e-01,  ..., -4.3759e-02,\n",
      "           -6.8611e-02,  2.9917e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2807e+00, -1.1345e+00,  2.9488e-01,  ...,  9.5664e-01,\n",
      "            9.5980e-01, -1.3662e+00],\n",
      "          [-9.9619e-01,  8.1967e-01, -2.3348e+00,  ..., -1.5615e+00,\n",
      "           -2.3828e+00, -4.3559e-01],\n",
      "          [-8.5307e-02, -7.1718e-01,  1.0215e+00,  ...,  2.4922e+00,\n",
      "           -1.5288e+00, -9.5451e-01],\n",
      "          ...,\n",
      "          [ 1.3146e+00, -8.2055e-01, -2.0935e-01,  ...,  5.8616e-01,\n",
      "            4.1345e-01, -1.5524e+00],\n",
      "          [ 9.9691e-01, -5.7669e-01, -4.4348e-01,  ...,  1.2788e+00,\n",
      "            6.8755e-01, -1.5601e+00],\n",
      "          [ 1.2164e+00, -5.0648e-01, -5.3825e-01,  ...,  1.0050e+00,\n",
      "            6.2204e-01, -1.4575e+00]],\n",
      "\n",
      "         [[-6.4911e-01, -7.8406e-02,  4.6270e-01,  ..., -3.2802e-01,\n",
      "           -6.0306e-01,  5.2313e-01],\n",
      "          [-4.8459e-01, -6.3254e-01, -4.5351e-01,  ..., -1.0509e+00,\n",
      "            4.9723e-01, -2.1538e+00],\n",
      "          [-3.4353e-01, -7.0192e-01,  1.2834e+00,  ..., -7.9954e-01,\n",
      "           -1.4218e+00,  9.2841e-01],\n",
      "          ...,\n",
      "          [-1.6505e+00, -3.8815e-01,  2.0528e+00,  ..., -6.9643e-01,\n",
      "           -6.9438e-01,  3.8193e-01],\n",
      "          [-1.2212e+00, -6.6519e-01,  1.8871e+00,  ..., -8.2594e-01,\n",
      "           -9.2003e-01,  1.0049e+00],\n",
      "          [-1.3695e+00, -4.6986e-01,  1.9444e+00,  ..., -8.3551e-01,\n",
      "           -7.4158e-01,  7.4563e-01]],\n",
      "\n",
      "         [[-2.2000e-01,  9.3904e-01, -1.5068e-01,  ...,  5.3504e-01,\n",
      "           -3.2377e-01, -5.6987e-02],\n",
      "          [ 1.5830e+00,  1.0731e+00, -1.2129e+00,  ...,  7.8350e-01,\n",
      "           -7.1569e-01,  1.4275e+00],\n",
      "          [-1.5684e+00,  1.2516e+00,  2.2410e-01,  ...,  3.1320e-01,\n",
      "           -1.3053e-01,  6.4029e-01],\n",
      "          ...,\n",
      "          [ 1.0555e+00, -4.4770e-02, -1.1622e+00,  ...,  8.8149e-01,\n",
      "           -7.0923e-01,  4.7601e-01],\n",
      "          [ 4.9100e-01, -6.6748e-03, -1.0488e+00,  ...,  7.8016e-01,\n",
      "           -3.9710e-01,  4.8801e-01],\n",
      "          [ 5.7016e-01, -1.2515e-03, -9.3368e-01,  ...,  9.6492e-01,\n",
      "           -2.7238e-01,  5.4004e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2907e+00, -2.5373e+00, -9.3115e-01,  ...,  6.3715e-01,\n",
      "            3.0617e-01, -6.2730e-01],\n",
      "          [ 7.0456e-01,  2.7303e+00, -4.4986e-01,  ..., -1.0133e+00,\n",
      "            2.5750e+00, -2.7027e-01],\n",
      "          [ 1.4955e-01, -1.3050e+00, -8.0247e-01,  ..., -2.4577e-01,\n",
      "            1.9971e+00, -1.3201e-01],\n",
      "          ...,\n",
      "          [ 2.8525e-01, -1.2396e+00, -2.6945e+00,  ..., -1.1232e+00,\n",
      "            4.2093e-01, -1.6249e-01],\n",
      "          [ 1.2745e+00, -3.2801e+00, -2.9523e+00,  ..., -5.3415e-01,\n",
      "            7.9368e-01, -1.1194e+00],\n",
      "          [ 7.5422e-01, -2.8643e+00, -2.0432e+00,  ...,  1.4685e-01,\n",
      "            1.0742e+00, -1.9490e-01]],\n",
      "\n",
      "         [[ 3.6190e-01,  9.1142e-01,  4.8178e-01,  ...,  1.3867e+00,\n",
      "            2.7747e-01,  3.1331e-01],\n",
      "          [ 8.9460e-02,  6.5560e-01,  2.2494e-01,  ..., -1.4696e+00,\n",
      "            3.1012e-01, -3.8440e-02],\n",
      "          [ 9.9007e-02, -3.5965e-01, -4.9837e-02,  ...,  1.4518e+00,\n",
      "            3.1028e-02,  4.0470e-01],\n",
      "          ...,\n",
      "          [ 1.7827e-01, -2.9738e-01, -2.1154e-01,  ...,  5.6178e-01,\n",
      "           -3.5473e-02, -9.3251e-02],\n",
      "          [-3.5220e-01, -2.4331e-01,  1.0943e-01,  ...,  5.5002e-01,\n",
      "           -1.0254e-01, -7.4815e-02],\n",
      "          [ 8.7307e-02, -4.1281e-01, -3.1905e-02,  ...,  6.1255e-01,\n",
      "           -3.4241e-01,  4.0482e-01]],\n",
      "\n",
      "         [[ 1.2410e+00,  1.4115e+00, -4.9484e-01,  ..., -1.1161e+00,\n",
      "            1.3316e-01,  2.1048e-01],\n",
      "          [ 1.3834e+00, -4.1746e-01, -3.0590e-01,  ..., -1.1778e-02,\n",
      "            7.6075e-01,  3.3029e-01],\n",
      "          [ 1.6724e+00, -5.2039e-01, -9.6324e-01,  ..., -4.1533e-01,\n",
      "           -6.7228e-01, -3.7461e-01],\n",
      "          ...,\n",
      "          [ 6.6364e-01,  8.5071e-01, -1.1393e+00,  ..., -1.3866e+00,\n",
      "            1.4184e+00, -3.0733e-01],\n",
      "          [-2.5911e-01,  4.6372e-01, -7.6307e-01,  ..., -1.0548e+00,\n",
      "            3.0747e-01,  1.1998e-01],\n",
      "          [-2.1699e-01,  1.4416e+00, -1.3027e-01,  ..., -1.1196e+00,\n",
      "            2.2983e-01,  4.1635e-02]]]], grad_fn=<PermuteBackward0>), query layer: tensor([[[[ 0.8123, -0.4551, -0.3853,  ...,  0.2759,  0.3194, -0.2693],\n",
      "          [ 0.1079,  0.9500, -1.0950,  ...,  1.6172, -0.6824,  0.7462],\n",
      "          [-0.0500,  0.9619, -0.0796,  ...,  0.0190,  0.5264,  0.0300],\n",
      "          ...,\n",
      "          [ 0.3237, -0.6943,  0.0377,  ..., -1.0352,  0.0912, -1.8452],\n",
      "          [-0.9881, -1.2651, -0.6563,  ...,  0.6138,  1.3922, -0.5449],\n",
      "          [-0.3645,  0.0834, -0.9458,  ..., -0.2168, -0.0550,  0.4709]],\n",
      "\n",
      "         [[ 0.0884, -0.3628, -0.6406,  ..., -0.9009, -0.4733, -0.2113],\n",
      "          [-0.1725, -0.1750, -0.2955,  ...,  0.1803,  0.1747,  0.7098],\n",
      "          [-0.2308, -0.7423, -0.9715,  ...,  1.5487,  0.3243, -0.1387],\n",
      "          ...,\n",
      "          [-0.4317, -1.2483, -0.5551,  ..., -1.4432, -0.1049,  0.0938],\n",
      "          [ 0.0446,  0.1165, -1.0388,  ..., -0.3318, -1.6226, -1.3765],\n",
      "          [-1.3376, -0.2138,  0.2500,  ..., -0.8716, -2.6667, -0.4309]],\n",
      "\n",
      "         [[ 0.3234, -0.0051, -0.5767,  ...,  0.4818,  0.4611, -0.7232],\n",
      "          [-0.3784,  2.2377,  1.0775,  ...,  0.1778,  1.0329,  0.5767],\n",
      "          [-0.3057,  1.3029,  0.6055,  ...,  0.4636,  1.1618,  1.0342],\n",
      "          ...,\n",
      "          [-0.2998,  0.9372,  1.4454,  ...,  1.6613,  0.9162,  1.0468],\n",
      "          [ 0.5619,  0.5455,  0.3148,  ...,  0.1429,  1.7081, -0.1933],\n",
      "          [ 0.0107, -0.8692,  0.0679,  ..., -0.2115,  0.2260, -0.4784]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2042, -0.4959, -0.4669,  ...,  0.3474, -0.0056, -0.1988],\n",
      "          [-2.0059, -0.3602, -1.5664,  ...,  1.7743,  1.4046,  0.7902],\n",
      "          [-1.9029, -1.5794, -0.9084,  ..., -0.3206,  1.9420, -0.4733],\n",
      "          ...,\n",
      "          [ 0.1505, -1.8715, -0.3917,  ..., -1.4243,  1.7273, -1.2988],\n",
      "          [-0.4577, -2.8259, -0.0060,  ...,  1.1609,  1.4617, -0.4042],\n",
      "          [ 0.6097, -1.0864, -1.1631,  ...,  1.5626,  0.9152,  0.1634]],\n",
      "\n",
      "         [[ 0.2044,  0.8157, -0.0688,  ..., -0.0604,  0.7659,  0.1309],\n",
      "          [-0.8992,  0.6357,  0.3248,  ..., -0.3738,  1.6161, -0.5978],\n",
      "          [-1.9392, -0.3136, -0.3942,  ..., -0.6604,  0.3952,  0.5516],\n",
      "          ...,\n",
      "          [ 0.7543, -0.9288,  0.1377,  ..., -2.1185,  0.1415,  1.9213],\n",
      "          [ 1.1403, -0.7431,  0.7983,  ...,  0.2417,  2.7924, -0.0150],\n",
      "          [ 0.8933,  1.1822,  0.0425,  ...,  3.0156,  0.3740,  1.3191]],\n",
      "\n",
      "         [[ 0.4788,  0.4651, -0.2572,  ..., -0.3401,  0.6764,  0.3979],\n",
      "          [ 0.9539,  0.3600, -0.3139,  ..., -0.9557,  1.2511,  1.4314],\n",
      "          [-0.4216, -1.3259, -0.3094,  ..., -1.4647, -0.2044,  0.3154],\n",
      "          ...,\n",
      "          [-0.0782, -0.0066, -1.5669,  ..., -1.5782, -0.6893, -0.9920],\n",
      "          [-0.5246, -0.5139, -0.5977,  ..., -0.9417,  1.0437, -1.8971],\n",
      "          [ 1.0754,  1.3790, -0.0430,  ..., -0.3964,  0.9501,  1.3563]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0009,  0.1161, -0.4192,  ..., -0.1727,  0.4150, -0.4819],\n",
      "          [-0.7718,  1.2772, -1.2563,  ..., -1.1432, -0.9411,  1.4558],\n",
      "          [ 1.1369,  0.1861, -0.2099,  ...,  1.0530, -0.6036, -0.3961],\n",
      "          ...,\n",
      "          [ 1.3558,  0.4511, -0.9860,  ...,  0.5209, -0.1668, -1.0152],\n",
      "          [ 1.8689,  0.1572, -0.8707,  ...,  0.4934, -0.2511, -1.6281],\n",
      "          [ 1.2474, -0.0453, -0.9499,  ...,  0.4991, -0.7235, -0.9233]],\n",
      "\n",
      "         [[-0.1501, -0.3731, -0.6162,  ..., -1.2276, -0.8804, -0.4620],\n",
      "          [ 0.9778, -0.8550, -1.0186,  ..., -0.2857,  0.3687,  1.3326],\n",
      "          [ 0.8741, -0.9554, -0.8280,  ..., -0.9989, -2.2187, -0.5542],\n",
      "          ...,\n",
      "          [-0.0699,  0.1737,  0.0199,  ..., -1.5885, -0.8954,  0.3496],\n",
      "          [ 0.3027, -0.2840,  0.4111,  ..., -1.7196, -1.6783, -0.4667],\n",
      "          [ 0.0369, -0.0377,  0.4064,  ..., -1.3926, -0.9301, -0.2690]],\n",
      "\n",
      "         [[ 0.3684, -0.0051, -1.1261,  ...,  0.5663,  1.0170, -1.0178],\n",
      "          [ 0.4776,  1.9734, -0.0982,  ...,  0.9700,  0.1446,  0.5603],\n",
      "          [ 0.6930,  0.2728, -0.8885,  ..., -0.5387,  1.3666,  0.4295],\n",
      "          ...,\n",
      "          [-1.1280,  1.9137, -1.4721,  ...,  0.0995,  0.7130, -0.4319],\n",
      "          [-0.7354,  1.7120, -1.2935,  ..., -0.1023,  0.3686, -0.4831],\n",
      "          [-0.7970,  1.5992, -1.3829,  ..., -0.2440,  0.3407, -0.4988]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2511, -0.8138,  0.0693,  ...,  0.0863, -0.1994, -0.4966],\n",
      "          [-0.9806, -1.8300, -0.4919,  ...,  0.4181,  0.1302, -0.1141],\n",
      "          [-0.1275, -1.2897, -0.3815,  ..., -0.6850,  0.6692,  0.2673],\n",
      "          ...,\n",
      "          [ 0.3105, -1.2220, -1.2359,  ...,  0.0330,  1.3265, -1.0200],\n",
      "          [ 0.1352, -1.5117,  0.1518,  ...,  0.3694,  2.5743,  0.9741],\n",
      "          [ 0.1766, -1.5811,  0.0206,  ...,  0.4340,  1.5250, -0.2256]],\n",
      "\n",
      "         [[ 0.1960,  1.1011,  0.0808,  ..., -0.1115,  0.9006,  0.2115],\n",
      "          [ 1.5050, -0.0177, -0.8011,  ...,  0.3228, -0.2061,  0.3533],\n",
      "          [ 0.7614,  1.0156, -0.6887,  ..., -1.3904,  1.9852, -0.3057],\n",
      "          ...,\n",
      "          [ 0.8479,  1.2178,  0.1653,  ..., -1.2134,  1.9025,  0.5120],\n",
      "          [ 1.0239,  1.5809, -0.1302,  ..., -1.0974,  2.3849,  0.4802],\n",
      "          [ 0.8445,  1.2187,  0.0477,  ..., -0.8304,  2.0098,  0.3045]],\n",
      "\n",
      "         [[ 0.2060,  0.5040, -0.4844,  ..., -0.7582,  0.0221,  0.3289],\n",
      "          [-0.1818,  0.5566, -1.5841,  ..., -0.8309,  1.1544,  0.5173],\n",
      "          [-1.4958, -1.4250,  0.4024,  ..., -0.9279, -0.7330, -0.0320],\n",
      "          ...,\n",
      "          [-0.0590,  1.1497, -1.5404,  ..., -1.7116,  0.1048,  0.8752],\n",
      "          [ 0.2646,  1.0465, -1.4680,  ..., -1.2266, -0.4364,  0.1360],\n",
      "          [-0.1990,  1.0077, -1.7052,  ..., -1.4822, -0.6371,  0.7902]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[ 7.4078e+00,  3.1377e+00,  2.8319e+00,  ...,  1.6084e-01,\n",
      "            1.4761e+00,  8.1249e+00],\n",
      "          [ 7.9883e+00,  8.8011e+00,  4.0078e+00,  ...,  8.4036e-01,\n",
      "            4.2123e+00,  8.8895e+00],\n",
      "          [ 8.6066e+00,  5.0546e+00,  7.1361e+00,  ..., -1.6028e-01,\n",
      "            2.5221e+00,  9.4961e+00],\n",
      "          ...,\n",
      "          [ 8.7802e+00,  2.8551e+00,  1.6173e+00,  ...,  8.9033e+00,\n",
      "            2.3262e+00,  8.7745e+00],\n",
      "          [ 9.4073e+00,  4.2432e+00,  2.1782e+00,  ...,  2.0559e-01,\n",
      "            8.6962e+00,  9.8189e+00],\n",
      "          [ 6.1651e+00,  1.5608e+00,  1.6636e+00,  ...,  7.4550e-01,\n",
      "            1.7832e+00,  7.0572e+00]],\n",
      "\n",
      "         [[ 2.3296e+00, -2.1403e-01, -8.7366e-02,  ..., -1.0687e+00,\n",
      "           -2.0890e-02,  2.7406e+00],\n",
      "          [ 1.3359e+00,  6.1095e-01, -1.2305e-01,  ..., -4.5391e-01,\n",
      "            2.7628e-01,  2.0039e+00],\n",
      "          [ 1.1419e+00,  2.2256e-01,  5.5117e-01,  ..., -5.1956e-01,\n",
      "            9.1794e-02,  1.9835e+00],\n",
      "          ...,\n",
      "          [ 1.3934e+00,  2.0181e-01,  8.1542e-01,  ..., -1.4990e+00,\n",
      "           -5.4854e-02,  1.5800e+00],\n",
      "          [ 1.0981e+00,  5.6224e-01, -5.5067e-01,  ..., -2.7314e-01,\n",
      "           -6.9382e-01,  3.4016e+00],\n",
      "          [ 6.0024e+00,  1.5979e+00,  1.2372e+00,  ...,  4.8712e-01,\n",
      "            1.6826e+00,  5.9026e+00]],\n",
      "\n",
      "         [[ 1.0235e+00,  1.8044e+00,  1.6005e+00,  ...,  1.3262e+00,\n",
      "            1.5034e+00,  1.5035e+00],\n",
      "          [ 5.6031e+00,  1.3737e-01,  2.5253e-01,  ..., -1.0200e+00,\n",
      "           -2.7072e+00,  5.0219e+00],\n",
      "          [ 4.6643e+00, -4.1694e-01,  1.1149e-01,  ..., -1.1327e+00,\n",
      "           -2.7942e+00,  4.4867e+00],\n",
      "          ...,\n",
      "          [ 4.8029e+00, -5.9809e-01,  4.2846e-01,  ..., -1.1208e+00,\n",
      "           -1.5811e+00,  4.7763e+00],\n",
      "          [ 3.3672e+00, -1.4969e-01,  3.2740e-01,  ...,  2.5071e-02,\n",
      "           -1.6166e+00,  4.0067e+00],\n",
      "          [ 2.3046e+00, -3.4188e-01,  7.4827e-01,  ..., -7.4366e-01,\n",
      "           -2.3488e-01,  4.0698e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6244e+00,  1.7480e-01,  9.6297e-01,  ..., -5.7200e-01,\n",
      "            6.0379e-01,  2.9267e+00],\n",
      "          [ 4.2739e+00,  3.2138e+00,  4.9085e+00,  ...,  2.9439e+00,\n",
      "            8.6640e-01,  4.5477e+00],\n",
      "          [ 3.0255e+00,  1.3705e+00,  1.0292e+00,  ...,  5.3137e+00,\n",
      "            3.9793e+00,  3.7081e+00],\n",
      "          ...,\n",
      "          [ 4.2606e+00,  2.4290e+00,  1.7142e+00,  ...,  2.3616e+00,\n",
      "            7.5420e+00,  5.4621e+00],\n",
      "          [ 9.5124e+00,  1.3170e+00,  2.5632e+00,  ...,  8.8542e-01,\n",
      "            4.0353e+00,  7.6685e+00],\n",
      "          [ 7.0775e+00,  1.3479e+00,  1.9531e+00,  ..., -7.8957e-02,\n",
      "           -1.4715e-02,  4.2457e+00]],\n",
      "\n",
      "         [[ 3.0253e+00,  2.9248e-01,  2.7192e-01,  ..., -5.0744e-01,\n",
      "            6.0253e-01,  3.8610e+00],\n",
      "          [ 1.8055e+00,  5.4250e-01,  8.3552e-01,  ...,  6.1543e-01,\n",
      "            1.1030e+00,  2.1962e+00],\n",
      "          [ 1.8468e+00,  2.4509e+00, -3.4077e-01,  ...,  4.4671e-01,\n",
      "            2.0800e+00,  1.5211e+00],\n",
      "          ...,\n",
      "          [ 2.0939e+00,  2.4835e+00,  1.5275e+00,  ...,  4.2072e-01,\n",
      "            2.7754e+00,  1.9465e+00],\n",
      "          [ 2.5033e+00,  1.8875e+00,  1.6071e+00,  ...,  2.0328e+00,\n",
      "            1.2744e+00,  2.1134e+00],\n",
      "          [ 6.4755e+00,  1.9324e+00,  2.7024e+00,  ...,  1.5671e+00,\n",
      "            8.3142e-01,  7.4071e+00]],\n",
      "\n",
      "         [[ 3.5072e+00,  3.2459e-01,  4.0308e-01,  ..., -3.0978e-01,\n",
      "            8.1199e-01,  2.6226e+00],\n",
      "          [ 7.0273e+00,  3.5714e+00,  1.9729e+00,  ...,  1.1283e+00,\n",
      "            2.5047e+00,  5.8279e+00],\n",
      "          [ 4.8580e+00,  3.3390e+00,  2.0648e+00,  ...,  8.3365e-01,\n",
      "            2.2782e+00,  3.7944e+00],\n",
      "          ...,\n",
      "          [ 3.1978e+00,  3.5359e+00,  4.0594e+00,  ...,  2.1613e+00,\n",
      "            2.8373e+00,  3.4422e+00],\n",
      "          [ 3.0082e+00,  1.9155e+00,  3.6817e+00,  ...,  3.1329e+00,\n",
      "            2.8445e+00,  3.6723e+00],\n",
      "          [ 6.9148e+00,  1.8100e+00,  1.2055e+00,  ...,  6.8949e-01,\n",
      "            2.3515e+00,  5.4961e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5926e+00,  7.9714e-01,  2.2996e+00,  ...,  2.4163e+00,\n",
      "            2.4165e+00,  2.1558e+00],\n",
      "          [ 7.1507e+00,  8.5711e+00,  3.7515e+00,  ...,  4.6123e+00,\n",
      "            4.7456e+00,  4.8765e+00],\n",
      "          [ 7.4299e+00,  7.5714e-01,  6.8562e+00,  ...,  3.1881e+00,\n",
      "            3.9641e+00,  3.6876e+00],\n",
      "          ...,\n",
      "          [ 7.3783e+00,  1.6487e+00,  2.4613e+00,  ...,  2.0075e+00,\n",
      "            2.0334e+00,  1.8323e+00],\n",
      "          [ 7.3481e+00,  1.4077e+00,  2.6252e+00,  ...,  1.8874e+00,\n",
      "            1.7044e+00,  1.4367e+00],\n",
      "          [ 7.0655e+00,  1.6921e+00,  2.9645e+00,  ...,  1.6807e+00,\n",
      "            1.3398e+00,  9.2307e-01]],\n",
      "\n",
      "         [[ 3.5780e+00, -4.0776e-01,  6.7308e-01,  ...,  1.8525e+00,\n",
      "            1.8184e+00,  1.9085e+00],\n",
      "          [ 1.0450e+00, -1.8525e+00, -5.2777e-02,  ..., -1.6582e+00,\n",
      "           -1.7543e+00, -1.8194e+00],\n",
      "          [ 1.0314e+00, -9.7753e-02,  1.4043e+00,  ..., -1.1668e-01,\n",
      "            7.8642e-02, -2.3121e-01],\n",
      "          ...,\n",
      "          [ 2.7946e+00,  6.4661e-01,  4.1123e-01,  ...,  2.3068e+00,\n",
      "            1.7854e+00,  2.0635e+00],\n",
      "          [ 2.7260e+00,  4.0609e-01,  1.0811e+00,  ...,  2.0054e+00,\n",
      "            1.5579e+00,  1.6916e+00],\n",
      "          [ 2.7672e+00,  5.0022e-01,  4.0392e-01,  ...,  2.1836e+00,\n",
      "            1.6179e+00,  1.9060e+00]],\n",
      "\n",
      "         [[ 1.6407e+00,  5.3306e-01,  1.4277e+00,  ...,  1.8204e+00,\n",
      "            1.5435e+00,  1.7393e+00],\n",
      "          [ 2.9855e+00, -2.5188e-01,  2.8173e+00,  ...,  1.4297e+00,\n",
      "            1.8544e+00,  1.6715e+00],\n",
      "          [ 2.6678e+00,  7.4035e-02,  2.1802e+00,  ...,  6.1231e-01,\n",
      "            1.1095e+00,  1.0969e+00],\n",
      "          ...,\n",
      "          [ 4.9849e+00, -2.2293e+00,  3.5842e+00,  ...,  2.5708e+00,\n",
      "            3.1967e+00,  3.2879e+00],\n",
      "          [ 4.9114e+00, -1.9740e+00,  3.2817e+00,  ...,  2.2407e+00,\n",
      "            2.9183e+00,  2.9983e+00],\n",
      "          [ 5.0967e+00, -1.9433e+00,  3.3380e+00,  ...,  2.6512e+00,\n",
      "            3.2424e+00,  3.4070e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2907e+00,  1.3166e-01,  1.7798e+00,  ...,  8.1313e-01,\n",
      "            7.8016e-01,  7.1170e-01],\n",
      "          [ 4.6434e+00,  6.5042e-01,  4.9926e+00,  ...,  6.4241e-01,\n",
      "            5.2972e-01, -2.1017e-01],\n",
      "          [ 5.3246e+00,  1.8128e+00,  1.4533e+00,  ...,  3.5194e+00,\n",
      "            8.9748e-01,  8.7222e-01],\n",
      "          ...,\n",
      "          [ 5.1333e+00,  1.1631e+00,  3.1031e+00,  ...,  1.6771e+00,\n",
      "            3.8862e+00,  2.4985e+00],\n",
      "          [ 6.4138e+00,  2.0391e+00,  2.2473e+00,  ...,  4.7590e-01,\n",
      "            1.7374e+00,  4.5919e+00],\n",
      "          [ 5.2781e+00,  5.4770e-01,  2.8163e+00,  ..., -7.1619e-02,\n",
      "            2.0976e-01,  2.6423e+00]],\n",
      "\n",
      "         [[ 3.6089e+00,  9.1406e-01,  7.9309e-02,  ...,  9.2953e-01,\n",
      "            6.0878e-01,  8.6867e-01],\n",
      "          [ 4.8854e+00,  2.8020e-01,  2.3211e+00,  ...,  1.4335e+00,\n",
      "            8.5620e-01,  1.0078e+00],\n",
      "          [ 9.3570e-01,  2.7203e+00, -4.5993e-01,  ...,  2.6276e-01,\n",
      "           -2.3920e-01, -2.0216e-01],\n",
      "          ...,\n",
      "          [ 2.3120e+00,  1.0908e+00, -5.8728e-01,  ...,  4.1453e-02,\n",
      "           -2.8546e-01, -3.8770e-02],\n",
      "          [ 1.9594e+00,  1.4411e+00, -7.6961e-01,  ..., -3.0594e-03,\n",
      "           -4.3899e-01, -1.6360e-01],\n",
      "          [ 2.0363e+00,  7.9764e-01, -7.6389e-01,  ..., -1.8203e-02,\n",
      "           -4.2423e-01, -1.1061e-01]],\n",
      "\n",
      "         [[ 3.7753e+00,  9.9711e-01,  8.9206e-01,  ...,  1.4426e+00,\n",
      "            1.2108e+00,  1.3151e+00],\n",
      "          [ 4.7739e+00,  5.4336e-01,  2.2611e+00,  ...,  3.4537e+00,\n",
      "            3.4816e+00,  2.0018e+00],\n",
      "          [ 3.3157e+00,  2.2754e+00,  1.3282e+00,  ...,  1.8188e+00,\n",
      "            1.5892e+00,  3.3424e-01],\n",
      "          ...,\n",
      "          [ 5.7321e+00,  4.0884e+00,  3.5237e+00,  ...,  3.2154e+00,\n",
      "            1.6431e+00,  1.9596e+00],\n",
      "          [ 5.0017e+00,  2.7285e+00,  2.8360e+00,  ...,  3.6364e+00,\n",
      "            1.3979e+00,  9.8345e-01],\n",
      "          [ 4.3837e+00,  2.1525e+00,  1.6623e+00,  ...,  3.5479e+00,\n",
      "            2.2803e+00,  1.6416e+00]]]], grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[ 7.4078e+00,  3.1377e+00,  2.8319e+00,  ...,  1.6084e-01,\n",
      "            1.4761e+00,  8.1249e+00],\n",
      "          [ 7.9883e+00,  8.8011e+00,  4.0078e+00,  ...,  8.4036e-01,\n",
      "            4.2123e+00,  8.8895e+00],\n",
      "          [ 8.6066e+00,  5.0546e+00,  7.1361e+00,  ..., -1.6028e-01,\n",
      "            2.5221e+00,  9.4961e+00],\n",
      "          ...,\n",
      "          [ 8.7802e+00,  2.8551e+00,  1.6173e+00,  ...,  8.9033e+00,\n",
      "            2.3262e+00,  8.7745e+00],\n",
      "          [ 9.4073e+00,  4.2432e+00,  2.1782e+00,  ...,  2.0559e-01,\n",
      "            8.6962e+00,  9.8189e+00],\n",
      "          [ 6.1651e+00,  1.5608e+00,  1.6636e+00,  ...,  7.4550e-01,\n",
      "            1.7832e+00,  7.0572e+00]],\n",
      "\n",
      "         [[ 2.3296e+00, -2.1403e-01, -8.7366e-02,  ..., -1.0687e+00,\n",
      "           -2.0890e-02,  2.7406e+00],\n",
      "          [ 1.3359e+00,  6.1095e-01, -1.2305e-01,  ..., -4.5391e-01,\n",
      "            2.7628e-01,  2.0039e+00],\n",
      "          [ 1.1419e+00,  2.2256e-01,  5.5117e-01,  ..., -5.1956e-01,\n",
      "            9.1794e-02,  1.9835e+00],\n",
      "          ...,\n",
      "          [ 1.3934e+00,  2.0181e-01,  8.1542e-01,  ..., -1.4990e+00,\n",
      "           -5.4854e-02,  1.5800e+00],\n",
      "          [ 1.0981e+00,  5.6224e-01, -5.5067e-01,  ..., -2.7314e-01,\n",
      "           -6.9382e-01,  3.4016e+00],\n",
      "          [ 6.0024e+00,  1.5979e+00,  1.2372e+00,  ...,  4.8712e-01,\n",
      "            1.6826e+00,  5.9026e+00]],\n",
      "\n",
      "         [[ 1.0235e+00,  1.8044e+00,  1.6005e+00,  ...,  1.3262e+00,\n",
      "            1.5034e+00,  1.5035e+00],\n",
      "          [ 5.6031e+00,  1.3737e-01,  2.5253e-01,  ..., -1.0200e+00,\n",
      "           -2.7072e+00,  5.0219e+00],\n",
      "          [ 4.6643e+00, -4.1694e-01,  1.1149e-01,  ..., -1.1327e+00,\n",
      "           -2.7942e+00,  4.4867e+00],\n",
      "          ...,\n",
      "          [ 4.8029e+00, -5.9809e-01,  4.2846e-01,  ..., -1.1208e+00,\n",
      "           -1.5811e+00,  4.7763e+00],\n",
      "          [ 3.3672e+00, -1.4969e-01,  3.2740e-01,  ...,  2.5071e-02,\n",
      "           -1.6166e+00,  4.0067e+00],\n",
      "          [ 2.3046e+00, -3.4188e-01,  7.4827e-01,  ..., -7.4366e-01,\n",
      "           -2.3488e-01,  4.0698e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6244e+00,  1.7480e-01,  9.6297e-01,  ..., -5.7200e-01,\n",
      "            6.0379e-01,  2.9267e+00],\n",
      "          [ 4.2739e+00,  3.2138e+00,  4.9085e+00,  ...,  2.9439e+00,\n",
      "            8.6640e-01,  4.5477e+00],\n",
      "          [ 3.0255e+00,  1.3705e+00,  1.0292e+00,  ...,  5.3137e+00,\n",
      "            3.9793e+00,  3.7081e+00],\n",
      "          ...,\n",
      "          [ 4.2606e+00,  2.4290e+00,  1.7142e+00,  ...,  2.3616e+00,\n",
      "            7.5420e+00,  5.4621e+00],\n",
      "          [ 9.5124e+00,  1.3170e+00,  2.5632e+00,  ...,  8.8542e-01,\n",
      "            4.0353e+00,  7.6685e+00],\n",
      "          [ 7.0775e+00,  1.3479e+00,  1.9531e+00,  ..., -7.8957e-02,\n",
      "           -1.4715e-02,  4.2457e+00]],\n",
      "\n",
      "         [[ 3.0253e+00,  2.9248e-01,  2.7192e-01,  ..., -5.0744e-01,\n",
      "            6.0253e-01,  3.8610e+00],\n",
      "          [ 1.8055e+00,  5.4250e-01,  8.3552e-01,  ...,  6.1543e-01,\n",
      "            1.1030e+00,  2.1962e+00],\n",
      "          [ 1.8468e+00,  2.4509e+00, -3.4077e-01,  ...,  4.4671e-01,\n",
      "            2.0800e+00,  1.5211e+00],\n",
      "          ...,\n",
      "          [ 2.0939e+00,  2.4835e+00,  1.5275e+00,  ...,  4.2072e-01,\n",
      "            2.7754e+00,  1.9465e+00],\n",
      "          [ 2.5033e+00,  1.8875e+00,  1.6071e+00,  ...,  2.0328e+00,\n",
      "            1.2744e+00,  2.1134e+00],\n",
      "          [ 6.4755e+00,  1.9324e+00,  2.7024e+00,  ...,  1.5671e+00,\n",
      "            8.3142e-01,  7.4071e+00]],\n",
      "\n",
      "         [[ 3.5072e+00,  3.2459e-01,  4.0308e-01,  ..., -3.0978e-01,\n",
      "            8.1199e-01,  2.6226e+00],\n",
      "          [ 7.0273e+00,  3.5714e+00,  1.9729e+00,  ...,  1.1283e+00,\n",
      "            2.5047e+00,  5.8279e+00],\n",
      "          [ 4.8580e+00,  3.3390e+00,  2.0648e+00,  ...,  8.3365e-01,\n",
      "            2.2782e+00,  3.7944e+00],\n",
      "          ...,\n",
      "          [ 3.1978e+00,  3.5359e+00,  4.0594e+00,  ...,  2.1613e+00,\n",
      "            2.8373e+00,  3.4422e+00],\n",
      "          [ 3.0082e+00,  1.9155e+00,  3.6817e+00,  ...,  3.1329e+00,\n",
      "            2.8445e+00,  3.6723e+00],\n",
      "          [ 6.9148e+00,  1.8100e+00,  1.2055e+00,  ...,  6.8949e-01,\n",
      "            2.3515e+00,  5.4961e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5926e+00,  7.9714e-01,  2.2996e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.1507e+00,  8.5711e+00,  3.7515e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.4299e+00,  7.5714e-01,  6.8562e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 7.3783e+00,  1.6487e+00,  2.4613e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.3481e+00,  1.4077e+00,  2.6252e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.0655e+00,  1.6921e+00,  2.9645e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.5780e+00, -4.0776e-01,  6.7308e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0450e+00, -1.8525e+00, -5.2777e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0314e+00, -9.7753e-02,  1.4043e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.7946e+00,  6.4661e-01,  4.1123e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.7260e+00,  4.0609e-01,  1.0811e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.7672e+00,  5.0022e-01,  4.0392e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.6407e+00,  5.3306e-01,  1.4277e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.9855e+00, -2.5188e-01,  2.8173e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.6678e+00,  7.4035e-02,  2.1802e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 4.9849e+00, -2.2293e+00,  3.5842e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.9114e+00, -1.9740e+00,  3.2817e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.0967e+00, -1.9433e+00,  3.3380e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2907e+00,  1.3166e-01,  1.7798e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.6434e+00,  6.5042e-01,  4.9926e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.3246e+00,  1.8128e+00,  1.4533e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 5.1333e+00,  1.1631e+00,  3.1031e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.4138e+00,  2.0391e+00,  2.2473e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.2781e+00,  5.4770e-01,  2.8163e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.6089e+00,  9.1406e-01,  7.9309e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.8854e+00,  2.8020e-01,  2.3211e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 9.3570e-01,  2.7203e+00, -4.5993e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.3120e+00,  1.0908e+00, -5.8728e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.9594e+00,  1.4411e+00, -7.6961e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.0363e+00,  7.9764e-01, -7.6389e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.7753e+00,  9.9711e-01,  8.9206e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.7739e+00,  5.4336e-01,  2.2611e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.3157e+00,  2.2754e+00,  1.3282e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 5.7321e+00,  4.0884e+00,  3.5237e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.0017e+00,  2.7285e+00,  2.8360e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.3837e+00,  2.1525e+00,  1.6623e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[3.2450e-01, 4.5367e-03, 3.3414e-03,  ..., 2.3116e-04,\n",
      "           8.6127e-04, 6.6476e-01],\n",
      "          [1.7351e-01, 3.9113e-01, 3.2406e-03,  ..., 1.3646e-04,\n",
      "           3.9760e-03, 4.2727e-01],\n",
      "          [2.7038e-01, 7.7514e-03, 6.2139e-02,  ..., 4.2129e-05,\n",
      "           6.1592e-04, 6.5813e-01],\n",
      "          ...,\n",
      "          [3.1935e-01, 8.5309e-04, 2.4741e-04,  ..., 3.6119e-01,\n",
      "           5.0271e-04, 3.1753e-01],\n",
      "          [3.3246e-01, 1.9011e-03, 2.4108e-04,  ..., 3.3535e-05,\n",
      "           1.6328e-01, 5.0178e-01],\n",
      "          [2.8629e-01, 2.8655e-03, 3.1756e-03,  ..., 1.2680e-03,\n",
      "           3.5790e-03, 6.9861e-01]],\n",
      "\n",
      "         [[3.5330e-01, 2.7761e-02, 3.1510e-02,  ..., 1.1810e-02,\n",
      "           3.3676e-02, 5.3288e-01],\n",
      "          [2.2419e-01, 1.0859e-01, 5.2121e-02,  ..., 3.7439e-02,\n",
      "           7.7703e-02, 4.3723e-01],\n",
      "          [1.9569e-01, 7.8038e-02, 1.0840e-01,  ..., 3.7154e-02,\n",
      "           6.8472e-02, 4.5403e-01],\n",
      "          ...,\n",
      "          [2.7379e-01, 8.3156e-02, 1.5360e-01,  ..., 1.5180e-02,\n",
      "           6.4332e-02, 3.2993e-01],\n",
      "          [7.9017e-02, 4.6237e-02, 1.5194e-02,  ..., 2.0054e-02,\n",
      "           1.3167e-02, 7.9084e-01],\n",
      "          [5.1295e-01, 6.2696e-03, 4.3710e-03,  ..., 2.0646e-03,\n",
      "           6.8240e-03, 4.6425e-01]],\n",
      "\n",
      "         [[9.8464e-02, 2.1499e-01, 1.7533e-01,  ..., 1.3328e-01,\n",
      "           1.5911e-01, 1.5913e-01],\n",
      "          [6.2768e-01, 2.6546e-03, 2.9786e-03,  ..., 8.3434e-04,\n",
      "           1.5439e-04, 3.5102e-01],\n",
      "          [4.7622e-01, 2.9582e-03, 5.0179e-03,  ..., 1.4461e-03,\n",
      "           2.7455e-04, 3.9871e-01],\n",
      "          ...,\n",
      "          [1.5826e-01, 7.1410e-04, 1.9934e-03,  ..., 4.2340e-04,\n",
      "           2.6719e-04, 1.5411e-01],\n",
      "          [3.1252e-01, 9.2794e-03, 1.4953e-02,  ..., 1.1051e-02,\n",
      "           2.1402e-03, 5.9238e-01],\n",
      "          [1.3558e-01, 9.6128e-03, 2.8595e-02,  ..., 6.4322e-03,\n",
      "           1.0698e-02, 7.9216e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[7.9804e-01, 9.3237e-03, 2.0506e-02,  ..., 4.4183e-03,\n",
      "           1.4318e-02, 1.4613e-01],\n",
      "          [1.4074e-01, 4.8754e-02, 2.6546e-01,  ..., 3.7222e-02,\n",
      "           4.6618e-03, 1.8506e-01],\n",
      "          [5.2157e-02, 9.9671e-03, 7.0854e-03,  ..., 5.1415e-01,\n",
      "           1.3538e-01, 1.0322e-01],\n",
      "          ...,\n",
      "          [3.1764e-02, 5.0869e-03, 2.4891e-03,  ..., 4.7557e-03,\n",
      "           8.4528e-01, 1.0562e-01],\n",
      "          [8.5903e-01, 2.3701e-04, 8.2413e-04,  ..., 1.5394e-04,\n",
      "           3.5921e-03, 1.3589e-01],\n",
      "          [9.3154e-01, 3.0260e-03, 5.5426e-03,  ..., 7.2641e-04,\n",
      "           7.7461e-04, 5.4873e-02]],\n",
      "\n",
      "         [[2.7960e-01, 1.8184e-02, 1.7813e-02,  ..., 8.1710e-03,\n",
      "           2.4793e-02, 6.4489e-01],\n",
      "          [2.4857e-01, 7.0295e-02, 9.4229e-02,  ..., 7.5613e-02,\n",
      "           1.2312e-01, 3.6739e-01],\n",
      "          [1.8948e-01, 3.4668e-01, 2.1258e-02,  ..., 4.6721e-02,\n",
      "           2.3923e-01, 1.3680e-01],\n",
      "          ...,\n",
      "          [1.5162e-01, 2.2385e-01, 8.6056e-02,  ..., 2.8451e-02,\n",
      "           2.9972e-01, 1.3084e-01],\n",
      "          [2.6082e-01, 1.4090e-01, 1.0644e-01,  ..., 1.6294e-01,\n",
      "           7.6317e-02, 1.7660e-01],\n",
      "          [2.7884e-01, 2.9669e-03, 6.4079e-03,  ..., 2.0590e-03,\n",
      "           9.8661e-04, 7.0782e-01]],\n",
      "\n",
      "         [[6.1939e-01, 2.5690e-02, 2.7787e-02,  ..., 1.3623e-02,\n",
      "           4.1825e-02, 2.5572e-01],\n",
      "          [7.3700e-01, 2.3258e-02, 4.7030e-03,  ..., 2.0211e-03,\n",
      "           8.0041e-03, 2.2211e-01],\n",
      "          [5.7650e-01, 1.2621e-01, 3.5297e-02,  ..., 1.0305e-02,\n",
      "           4.3693e-02, 1.9901e-01],\n",
      "          ...,\n",
      "          [1.2518e-01, 1.7554e-01, 2.9631e-01,  ..., 4.4401e-02,\n",
      "           8.7296e-02, 1.5985e-01],\n",
      "          [1.2096e-01, 4.0559e-02, 2.3721e-01,  ..., 1.3703e-01,\n",
      "           1.0270e-01, 2.3499e-01],\n",
      "          [7.8917e-01, 4.7882e-03, 2.6160e-03,  ..., 1.5615e-03,\n",
      "           8.2291e-03, 1.9099e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.2099e-01, 3.6797e-04, 1.6531e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.5673e-02, 3.9596e-01, 3.1956e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.1282e-01, 1.4271e-04, 6.3567e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.5452e-01, 5.0195e-04, 1.1313e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9472e-01, 5.1232e-04, 1.7311e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4296e-01, 6.6309e-04, 2.3669e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[4.2858e-01, 7.9621e-03, 2.3465e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9958e-01, 1.1010e-02, 6.6585e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.7208e-02, 1.2029e-02, 5.4025e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [2.4106e-01, 2.8137e-02, 2.2236e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2199e-01, 1.1990e-02, 2.3549e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.7879e-01, 2.8891e-02, 2.6239e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[2.3086e-01, 7.6260e-02, 1.8657e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.7390e-01, 1.0755e-02, 2.3149e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.2996e-01, 2.4660e-02, 2.0263e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.4956e-01, 3.3090e-04, 1.1078e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.6275e-01, 4.7321e-04, 9.0688e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.6390e-01, 4.0645e-04, 7.9916e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[7.5458e-01, 1.1788e-02, 6.1271e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.3748e-01, 6.2245e-03, 4.7851e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.9270e-01, 1.4705e-02, 1.0264e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [6.9614e-01, 1.3136e-02, 9.1409e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.4389e-01, 9.3671e-03, 1.1535e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.2043e-01, 6.3565e-03, 6.1444e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.9364e-01, 1.3081e-02, 5.6771e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2028e-01, 1.2028e-03, 9.2586e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.8822e-02, 5.2915e-01, 2.1999e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.2394e-01, 3.6546e-02, 6.8246e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0144e-01, 6.0411e-02, 6.6221e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2128e-01, 3.5144e-02, 7.3737e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[6.7687e-01, 4.2067e-02, 3.7872e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.4417e-01, 7.9146e-03, 4.4100e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.8299e-01, 1.3533e-01, 5.2485e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [6.6428e-01, 1.2839e-01, 7.2991e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.0724e-01, 6.2533e-02, 6.9628e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.3987e-01, 6.8719e-02, 4.2094e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[-4.9013e-02, -1.5223e-01, -6.3873e-02,  ..., -6.9878e-03,\n",
      "            2.1823e-02, -1.4926e-01],\n",
      "          [-7.2116e-02, -1.6106e-01,  1.4289e-01,  ..., -4.2132e-02,\n",
      "            1.5708e-01, -5.4494e-02],\n",
      "          [-4.6691e-02, -1.4502e-01, -7.5698e-02,  ..., -8.1977e-03,\n",
      "            2.3542e-02, -1.0209e-01],\n",
      "          ...,\n",
      "          [ 2.4288e-01, -1.2567e-01, -1.7035e-01,  ..., -7.8955e-02,\n",
      "            3.1062e-02, -3.6622e-01],\n",
      "          [-1.3525e-02, -6.7019e-02, -1.7609e-02,  ...,  3.4823e-02,\n",
      "            1.4496e-01, -2.8407e-01],\n",
      "          [-4.8974e-02, -1.4071e-01, -5.9073e-02,  ..., -1.0578e-02,\n",
      "            2.2034e-02, -1.3747e-01]],\n",
      "\n",
      "         [[-7.4729e-03, -7.6781e-03,  5.3317e-02,  ..., -5.8919e-02,\n",
      "           -1.0864e-01, -8.3502e-02],\n",
      "          [-1.4584e-01, -1.0287e-01, -1.5696e-02,  ...,  2.3275e-02,\n",
      "           -1.2704e-01, -4.6355e-02],\n",
      "          [-2.2943e-01, -3.1849e-02,  1.2200e-02,  ...,  6.3006e-02,\n",
      "           -9.6360e-02, -3.3382e-03],\n",
      "          ...,\n",
      "          [-3.2434e-01, -2.3541e-02,  1.1941e-02,  ...,  8.9683e-02,\n",
      "           -7.0643e-02,  2.9879e-02],\n",
      "          [-2.9624e-02,  6.3604e-02,  2.2632e-02,  ..., -3.2784e-02,\n",
      "            6.5668e-03, -7.0421e-02],\n",
      "          [ 5.4527e-02, -1.0807e-02,  5.9808e-02,  ..., -1.2093e-01,\n",
      "           -1.1732e-01, -1.2129e-01]],\n",
      "\n",
      "         [[-1.0046e+00,  6.9424e-01,  1.4005e-01,  ...,  3.1884e-01,\n",
      "           -6.8010e-02, -3.5599e-01],\n",
      "          [-3.8265e-02,  3.6681e-01,  8.5670e-02,  ..., -8.7083e-02,\n",
      "           -1.7108e-01,  9.2595e-02],\n",
      "          [-5.4784e-02,  4.1409e-01,  9.3145e-02,  ..., -8.5106e-02,\n",
      "           -1.5238e-01,  1.6257e-01],\n",
      "          ...,\n",
      "          [-1.4364e-01,  8.6765e-01,  1.7034e-01,  ..., -1.1281e-01,\n",
      "           -1.4380e-01,  5.8045e-01],\n",
      "          [-7.7297e-02,  3.1155e-01,  7.4083e-02,  ..., -6.1324e-02,\n",
      "           -1.1843e-01,  8.7214e-02],\n",
      "          [-7.8321e-02,  2.2070e-01,  5.5659e-02,  ..., -2.7668e-02,\n",
      "           -8.7896e-02,  6.6565e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.9700e-03,  9.3327e-02, -9.6762e-02,  ...,  3.4276e-02,\n",
      "            2.5458e-01, -7.6658e-02],\n",
      "          [-2.2003e-01,  4.7478e-01,  5.6190e-02,  ...,  3.1135e-01,\n",
      "            8.9932e-02, -6.8588e-01],\n",
      "          [-5.1904e-02,  1.0344e-01, -7.3172e-01,  ...,  4.2079e-01,\n",
      "           -9.9945e-03,  1.7413e-01],\n",
      "          ...,\n",
      "          [-1.4756e-01, -1.4688e-01, -1.6418e-01,  ..., -1.6243e-01,\n",
      "            4.0126e-01,  2.5656e-01],\n",
      "          [ 8.7113e-03,  7.8923e-02, -1.0332e-01,  ...,  2.0807e-02,\n",
      "            2.5817e-01, -4.9452e-02],\n",
      "          [ 5.7595e-03,  9.8676e-02, -1.3459e-01,  ..., -7.3181e-03,\n",
      "            2.7760e-01, -4.5752e-02]],\n",
      "\n",
      "         [[-7.5105e-02, -9.4605e-02, -1.0335e-01,  ...,  1.3425e-02,\n",
      "            6.5769e-02, -9.7946e-02],\n",
      "          [-5.0107e-02, -1.2362e-03, -9.1437e-02,  ..., -6.8722e-02,\n",
      "            9.0191e-02, -6.2002e-02],\n",
      "          [-9.8863e-02,  1.4969e-01, -2.0747e-01,  ..., -9.3512e-02,\n",
      "            2.5836e-01, -1.9587e-01],\n",
      "          ...,\n",
      "          [-8.8496e-02,  9.4932e-02, -2.4544e-01,  ..., -1.5694e-01,\n",
      "            2.4885e-01, -1.5164e-01],\n",
      "          [ 1.4936e-02,  1.4724e-02, -6.3014e-03,  ..., -8.0977e-02,\n",
      "            7.4901e-02, -1.2924e-02],\n",
      "          [-7.4657e-02, -1.1091e-01, -9.3271e-02,  ...,  2.9133e-02,\n",
      "            5.2208e-02, -9.8371e-02]],\n",
      "\n",
      "         [[ 2.1690e-01, -1.4880e-01,  1.1284e-01,  ..., -8.5140e-03,\n",
      "           -5.1619e-03,  8.2409e-02],\n",
      "          [ 1.9577e-01, -1.5291e-01,  6.6227e-02,  ..., -5.1475e-02,\n",
      "           -3.2886e-02,  9.5103e-02],\n",
      "          [ 1.8336e-01, -2.1486e-02,  1.1586e-01,  ...,  1.9861e-02,\n",
      "           -8.5919e-03,  7.0742e-02],\n",
      "          ...,\n",
      "          [ 4.4076e-02, -8.1870e-02,  2.7174e-01,  ...,  2.6480e-01,\n",
      "            1.4104e-01,  8.6411e-02],\n",
      "          [ 1.4274e-01, -1.7964e-01,  3.5657e-01,  ...,  2.0856e-01,\n",
      "            1.5738e-01,  2.9511e-02],\n",
      "          [ 2.0607e-01, -1.7345e-01,  6.5097e-02,  ..., -6.1837e-02,\n",
      "           -3.8665e-02,  1.0483e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8606e-02, -1.1905e-01, -8.3612e-02,  ..., -8.8050e-02,\n",
      "            4.2993e-03, -4.1137e-02],\n",
      "          [ 1.6020e-01,  1.7231e-01,  2.9020e-01,  ..., -1.3901e-01,\n",
      "           -4.8438e-01, -8.9368e-02],\n",
      "          [-1.2182e-02, -1.0337e-01, -8.5221e-02,  ..., -1.0405e-01,\n",
      "            3.6070e-02, -6.0701e-02],\n",
      "          ...,\n",
      "          [-3.0026e-02, -1.3777e-01, -9.0143e-02,  ..., -9.7688e-02,\n",
      "           -2.1874e-03, -5.0994e-02],\n",
      "          [-3.1479e-02, -1.6010e-01, -9.8173e-02,  ..., -1.0959e-01,\n",
      "           -9.1834e-03, -6.3229e-02],\n",
      "          [-2.9162e-02, -1.3098e-01, -8.7751e-02,  ..., -9.4711e-02,\n",
      "            3.0102e-04, -4.8002e-02]],\n",
      "\n",
      "         [[-9.1810e-02, -1.3148e-01,  6.4433e-02,  ...,  3.7985e-02,\n",
      "           -9.1601e-02, -1.2668e-01],\n",
      "          [-4.5069e-02, -7.0354e-02,  7.8278e-02,  ...,  1.6823e-02,\n",
      "           -2.9908e-02, -5.9563e-03],\n",
      "          [-9.7764e-04,  3.8970e-02,  9.2873e-02,  ...,  7.4958e-04,\n",
      "            3.5556e-02,  1.7793e-02],\n",
      "          ...,\n",
      "          [-5.7943e-02, -1.8578e-02,  8.8904e-02,  ...,  2.7411e-02,\n",
      "           -7.1436e-03, -5.8251e-02],\n",
      "          [-1.5680e-02,  3.9086e-02,  9.0071e-02,  ...,  8.8300e-03,\n",
      "            2.1250e-02, -4.5975e-02],\n",
      "          [-6.9171e-02, -4.5284e-02,  8.5861e-02,  ...,  3.1569e-02,\n",
      "           -2.2101e-02, -6.1081e-02]],\n",
      "\n",
      "         [[-8.8774e-03,  5.6755e-01,  6.8174e-02,  ..., -1.9011e-01,\n",
      "           -3.3580e-01, -5.7819e-02],\n",
      "          [ 2.7572e-02,  5.5982e-01,  1.2777e-01,  ..., -1.4151e-01,\n",
      "           -1.5402e-01, -4.2747e-02],\n",
      "          [ 2.4749e-02,  6.0511e-01,  9.7712e-02,  ..., -1.6327e-01,\n",
      "           -2.3019e-01, -4.7014e-02],\n",
      "          ...,\n",
      "          [ 5.2479e-02,  6.0536e-01,  4.3120e-02,  ..., -1.5017e-01,\n",
      "           -2.5290e-01, -1.8054e-02],\n",
      "          [ 5.4718e-02,  6.0059e-01,  2.9319e-02,  ..., -1.4987e-01,\n",
      "           -2.6724e-01, -1.3133e-02],\n",
      "          [ 5.5699e-02,  5.9239e-01,  2.2470e-02,  ..., -1.4824e-01,\n",
      "           -2.7180e-01, -9.7575e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3087e-02,  1.7382e-01, -5.1473e-02,  ...,  7.9118e-02,\n",
      "            2.8373e-01, -1.9866e-01],\n",
      "          [-1.4191e-01, -9.1749e-02, -7.3879e-02,  ..., -2.7765e-01,\n",
      "           -5.6865e-02, -2.2990e-01],\n",
      "          [ 2.4976e-02,  1.1080e-01,  7.8763e-02,  ...,  2.0077e-01,\n",
      "            2.3060e-01, -2.0261e-01],\n",
      "          ...,\n",
      "          [ 1.7705e-02,  1.4734e-01, -4.0901e-02,  ...,  6.0091e-02,\n",
      "            2.5154e-01, -2.0158e-01],\n",
      "          [ 4.8414e-02,  1.8398e-01, -2.5672e-02,  ...,  1.3744e-01,\n",
      "            3.0379e-01, -1.9652e-01],\n",
      "          [ 3.0074e-02,  1.5840e-01, -4.0034e-02,  ...,  8.8613e-02,\n",
      "            2.6968e-01, -1.9966e-01]],\n",
      "\n",
      "         [[-7.3810e-02, -1.4609e-01, -1.4605e-01,  ..., -5.0691e-02,\n",
      "            1.5974e-01, -1.5560e-01],\n",
      "          [-6.3399e-02, -1.2608e-01, -1.1100e-01,  ..., -3.1965e-02,\n",
      "            1.3132e-01, -1.2756e-01],\n",
      "          [ 2.8634e-01, -1.7199e-02, -2.8812e-01,  ..., -4.3077e-01,\n",
      "            1.6600e-01, -8.7313e-01],\n",
      "          ...,\n",
      "          [-4.1321e-02, -1.1563e-01, -1.2370e-01,  ..., -5.7844e-02,\n",
      "            1.3471e-01, -1.8071e-01],\n",
      "          [-2.0252e-02, -1.0122e-01, -1.2187e-01,  ..., -7.2101e-02,\n",
      "            1.2773e-01, -2.1270e-01],\n",
      "          [-4.1584e-02, -1.1580e-01, -1.2231e-01,  ..., -5.6655e-02,\n",
      "            1.3375e-01, -1.7797e-01]],\n",
      "\n",
      "         [[ 3.0843e-01, -2.4202e-01, -5.6323e-02,  ..., -2.0276e-01,\n",
      "            1.1378e-02,  3.4546e-02],\n",
      "          [ 3.1732e-01, -2.1786e-01, -5.3027e-02,  ..., -1.5928e-01,\n",
      "           -1.2461e-02,  2.3794e-02],\n",
      "          [ 1.8920e-01, -2.9744e-01, -2.7266e-02,  ..., -1.6591e-01,\n",
      "            1.2395e-01,  1.2742e-04],\n",
      "          ...,\n",
      "          [ 2.4380e-01, -3.0328e-01, -6.1972e-02,  ..., -2.3965e-01,\n",
      "            7.9399e-02,  2.9738e-02],\n",
      "          [ 2.8833e-01, -2.5891e-01, -6.4175e-02,  ..., -2.0133e-01,\n",
      "            2.2000e-02,  2.8018e-02],\n",
      "          [ 2.8171e-01, -2.5901e-01, -5.1930e-02,  ..., -2.0402e-01,\n",
      "            3.8968e-02,  2.9402e-02]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[-7.4438e-02, -2.4888e-01, -5.3375e-01,  ..., -4.4670e-01,\n",
      "            3.2203e-01,  1.4242e-01],\n",
      "          [-1.1160e+00, -3.7191e-02,  3.5918e-01,  ..., -9.3683e-01,\n",
      "           -2.9294e-01,  7.2335e-01],\n",
      "          [ 2.6367e-01, -2.2038e-01,  1.2034e+00,  ...,  1.3046e+00,\n",
      "           -9.2394e-02,  1.1496e+00],\n",
      "          ...,\n",
      "          [-2.1979e-01, -7.2132e-01, -3.9634e-01,  ..., -1.1003e+00,\n",
      "           -8.9476e-02, -4.2254e-01],\n",
      "          [-7.7873e-01, -2.9796e-01,  1.8263e-01,  ...,  6.7917e-01,\n",
      "           -9.3128e-02,  2.8522e-02],\n",
      "          [ 1.8713e-01,  3.2159e-01,  3.2325e-02,  ...,  5.1302e-02,\n",
      "            3.7460e-01,  6.4253e-01]],\n",
      "\n",
      "         [[ 8.1811e-01,  4.5637e-01,  1.0160e-01,  ...,  3.3673e-01,\n",
      "            1.2248e+00, -1.4456e+00],\n",
      "          [-4.8930e-01, -9.6026e-01, -4.3051e-01,  ..., -8.8427e-01,\n",
      "           -5.0791e-01,  3.5836e-01],\n",
      "          [-4.6052e-01, -1.1889e+00,  2.2410e-01,  ..., -2.3155e-01,\n",
      "           -3.5944e-01,  9.6748e-02],\n",
      "          ...,\n",
      "          [-4.3303e-01, -1.5130e-01, -5.1761e-01,  ..., -8.8365e-01,\n",
      "            7.5425e-01,  7.4769e-01],\n",
      "          [-1.1258e+00, -4.6694e-01, -1.0756e+00,  ..., -1.4342e-01,\n",
      "           -2.6307e-01,  5.1691e-01],\n",
      "          [-1.2964e+00, -2.1366e-01,  6.5724e-01,  ...,  4.6601e-01,\n",
      "           -8.2310e-01, -2.2314e-01]],\n",
      "\n",
      "         [[-2.0894e-01, -7.8712e-01,  1.4718e-01,  ...,  4.4054e-01,\n",
      "            3.8496e-01,  2.3198e+00],\n",
      "          [-2.1127e-01,  9.8997e-02, -3.5457e-01,  ...,  3.2071e-01,\n",
      "           -7.8855e-01,  2.0756e+00],\n",
      "          [ 3.5777e-01, -1.5612e-01,  4.3555e-01,  ..., -2.6370e-01,\n",
      "            1.2518e-01,  8.4511e-01],\n",
      "          ...,\n",
      "          [-5.2276e-01, -3.6902e-01, -1.0923e-01,  ...,  7.5914e-01,\n",
      "           -1.0137e+00,  2.6338e-01],\n",
      "          [-4.9005e-01,  3.7317e-01,  1.3114e+00,  ...,  3.8838e-01,\n",
      "           -6.5925e-01,  8.4564e-01],\n",
      "          [ 3.3255e-01, -4.5350e-01,  5.2782e-02,  ...,  1.1081e+00,\n",
      "           -6.2007e-01,  9.2394e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5848e-01,  3.4291e-01,  1.9251e-01,  ..., -6.2281e-01,\n",
      "           -4.1701e-01, -9.9189e-03],\n",
      "          [ 5.7601e-02,  3.5870e-01, -1.5064e+00,  ...,  5.8769e-01,\n",
      "            8.2531e-01,  1.0037e+00],\n",
      "          [-9.9631e-01, -9.5914e-01,  4.6315e-01,  ..., -3.0469e-01,\n",
      "            8.3105e-01, -5.0506e-01],\n",
      "          ...,\n",
      "          [-1.0600e+00, -8.6732e-01, -1.3311e+00,  ..., -4.0658e-02,\n",
      "            4.2412e-01,  2.1106e+00],\n",
      "          [ 1.0929e+00, -1.8228e-01, -1.6261e+00,  ..., -7.9484e-01,\n",
      "           -1.2528e+00,  4.9446e-02],\n",
      "          [ 2.6435e-01,  4.0109e-01,  2.2848e-01,  ..., -2.1771e-01,\n",
      "           -1.1566e+00, -7.1907e-02]],\n",
      "\n",
      "         [[-6.4518e-01, -6.3276e-01, -1.9917e+00,  ...,  5.1903e-01,\n",
      "           -8.7346e-01,  7.4246e-01],\n",
      "          [-1.7804e-01,  1.1274e+00, -1.0606e-01,  ...,  7.9921e-02,\n",
      "            8.4801e-02,  8.6463e-01],\n",
      "          [ 6.3539e-02,  6.3684e-01, -5.4615e-01,  ...,  2.9516e-01,\n",
      "            1.2179e+00, -2.1725e-01],\n",
      "          ...,\n",
      "          [ 1.9404e-01, -3.1284e-01,  2.4712e-01,  ...,  4.6753e-01,\n",
      "            2.6874e+00, -5.4087e-01],\n",
      "          [ 2.4578e-01,  1.1489e+00,  5.4569e-01,  ...,  1.0032e+00,\n",
      "            3.5170e-01,  1.1957e-01],\n",
      "          [-2.8050e-01, -1.2813e+00, -2.1644e+00,  ...,  7.2442e-01,\n",
      "            8.0840e-01,  9.0858e-01]],\n",
      "\n",
      "         [[ 8.6109e-01, -5.8963e-01,  7.8989e-01,  ...,  4.0133e-01,\n",
      "           -2.7427e-02,  1.8010e-01],\n",
      "          [-1.6456e+00, -7.6674e-01, -1.2989e+00,  ...,  1.9007e+00,\n",
      "           -1.0521e-01,  1.2810e+00],\n",
      "          [-1.0330e+00, -6.0046e-01,  2.1821e-01,  ...,  3.2783e-01,\n",
      "            5.9339e-01,  8.1423e-01],\n",
      "          ...,\n",
      "          [ 4.0178e-01, -3.6227e-02, -8.8482e-01,  ...,  1.3842e-01,\n",
      "           -1.8956e+00,  1.6528e+00],\n",
      "          [ 1.9884e+00,  2.7356e-02, -1.6469e+00,  ...,  1.0647e+00,\n",
      "           -8.7219e-01,  9.9805e-01],\n",
      "          [-1.9484e-01,  6.9681e-01,  7.4131e-01,  ...,  4.2071e-01,\n",
      "           -3.4180e-01,  1.6152e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1847e-01, -1.8288e-03, -2.6974e-01,  ..., -2.7772e-01,\n",
      "            6.4282e-01, -2.3655e-01],\n",
      "          [ 7.9604e-02,  7.5325e-01, -5.5093e-01,  ...,  4.0880e-01,\n",
      "            1.7564e+00,  1.3399e+00],\n",
      "          [-7.9221e-01, -7.6736e-01, -1.3883e+00,  ...,  7.0261e-02,\n",
      "           -7.9918e-02,  1.9109e-01],\n",
      "          ...,\n",
      "          [-5.1686e-01, -5.3501e-01,  2.6388e-01,  ..., -8.5553e-02,\n",
      "            9.1549e-01, -5.3568e-01],\n",
      "          [-7.7869e-01, -3.8075e-01,  2.4644e-01,  ...,  1.1531e-01,\n",
      "            1.0480e+00, -3.0740e-01],\n",
      "          [-7.4215e-01, -3.8462e-01,  3.8642e-01,  ..., -1.1678e-01,\n",
      "            1.1105e+00, -1.2701e-02]],\n",
      "\n",
      "         [[ 6.2094e-01,  5.5913e-01,  3.8838e-01,  ...,  9.2969e-01,\n",
      "            7.9547e-01, -1.2200e+00],\n",
      "          [-4.0653e-01, -1.9763e-01,  5.2753e-01,  ..., -7.2476e-01,\n",
      "           -2.0779e-01,  5.6905e-02],\n",
      "          [-3.7123e-01, -4.6692e-01,  4.0071e-01,  ...,  9.8220e-01,\n",
      "           -9.7894e-01, -1.3269e+00],\n",
      "          ...,\n",
      "          [ 8.8891e-01, -3.0231e-01, -3.7469e-01,  ...,  1.3418e+00,\n",
      "           -6.6458e-01,  1.3040e-01],\n",
      "          [ 3.9556e-01, -4.2726e-01, -4.8126e-01,  ...,  1.4521e+00,\n",
      "           -1.0181e+00,  5.7439e-01],\n",
      "          [ 8.3271e-01, -5.8237e-01, -5.8625e-01,  ...,  1.2287e+00,\n",
      "           -1.0479e+00,  4.6653e-01]],\n",
      "\n",
      "         [[-3.1981e-01, -2.8463e-01,  6.9444e-01,  ...,  2.3669e-01,\n",
      "            1.3760e-01,  2.1183e+00],\n",
      "          [ 1.8395e+00, -2.5686e-01,  6.7750e-01,  ...,  3.0770e-02,\n",
      "            2.0920e-01,  1.8820e+00],\n",
      "          [-1.0060e+00,  2.8459e-01,  1.2914e+00,  ...,  1.8469e+00,\n",
      "           -1.6973e-01,  2.0294e+00],\n",
      "          ...,\n",
      "          [-2.0944e-01,  8.0160e-01,  1.0090e+00,  ..., -5.3872e-01,\n",
      "            1.7344e-01,  2.1289e-01],\n",
      "          [ 8.3838e-02,  1.3227e+00,  9.3791e-01,  ...,  1.9044e-01,\n",
      "            7.3271e-02,  7.8980e-01],\n",
      "          [ 1.5699e-01,  9.3486e-01,  1.0617e+00,  ...,  4.2682e-02,\n",
      "            2.0297e-01,  3.1155e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.7983e-01,  4.1966e-01,  1.4537e-01,  ..., -5.3409e-01,\n",
      "           -4.5540e-01, -2.6417e-01],\n",
      "          [-4.0566e-01,  1.3720e+00, -6.3012e-01,  ..., -1.7080e-01,\n",
      "           -9.0243e-02,  2.1647e-02],\n",
      "          [-1.0433e+00,  1.1960e+00, -1.0462e-01,  ..., -8.4759e-01,\n",
      "            1.7020e-01,  1.6964e-01],\n",
      "          ...,\n",
      "          [-1.0964e-01,  3.4763e-01,  7.3233e-01,  ...,  3.4533e-01,\n",
      "            3.5201e-02, -8.4869e-01],\n",
      "          [-1.1168e-01, -1.3484e-01,  1.2054e+00,  ..., -1.9506e-01,\n",
      "           -2.0360e-01, -3.8049e-01],\n",
      "          [-7.4140e-03,  6.3867e-03,  1.1582e+00,  ...,  1.8990e-01,\n",
      "           -9.6543e-02, -5.1191e-01]],\n",
      "\n",
      "         [[-6.9335e-01, -7.1620e-01, -1.9657e+00,  ...,  4.2428e-01,\n",
      "           -3.8298e-01,  8.0216e-01],\n",
      "          [ 3.8000e-01, -3.2235e-01, -1.8516e+00,  ..., -1.4251e+00,\n",
      "           -3.3952e-02,  4.8119e-01],\n",
      "          [-4.8700e-01,  9.4670e-02, -5.7896e-01,  ...,  1.5034e+00,\n",
      "           -5.3062e-01,  5.1738e-01],\n",
      "          ...,\n",
      "          [ 6.7535e-01, -5.8034e-01, -1.3996e+00,  ...,  6.3515e-01,\n",
      "            1.1388e+00, -9.8034e-01],\n",
      "          [ 8.4554e-01, -4.7057e-03, -1.4059e+00,  ...,  1.0406e+00,\n",
      "            4.6918e-01, -8.2453e-01],\n",
      "          [ 1.3063e+00, -1.2298e-01, -1.5481e+00,  ...,  7.0833e-01,\n",
      "            5.6952e-02, -6.7388e-01]],\n",
      "\n",
      "         [[ 1.1405e+00, -1.2867e-01,  7.7542e-01,  ...,  5.9671e-01,\n",
      "           -1.6048e-01,  3.2016e-01],\n",
      "          [ 1.5142e-02, -3.0336e-01, -1.1882e+00,  ...,  9.1315e-01,\n",
      "           -1.0989e+00,  8.0145e-01],\n",
      "          [ 1.5271e-01, -3.2342e-01,  2.8520e-01,  ...,  7.5915e-01,\n",
      "           -6.8934e-01, -6.7803e-02],\n",
      "          ...,\n",
      "          [ 5.0227e-01,  4.6446e-01,  1.7302e-01,  ...,  2.5120e+00,\n",
      "           -1.6992e+00,  2.6511e-01],\n",
      "          [ 1.0116e+00,  5.4656e-01, -6.2214e-01,  ...,  1.6298e+00,\n",
      "           -9.4967e-01,  1.8210e-01],\n",
      "          [ 6.6645e-01,  6.8427e-01, -8.1082e-01,  ...,  4.9890e-01,\n",
      "           -1.1435e-01, -5.6105e-01]]]], grad_fn=<PermuteBackward0>), query layer: tensor([[[[-3.6870e-01, -4.8902e-01, -1.8359e-01,  ...,  1.6977e-01,\n",
      "            1.2731e+00,  7.0098e-02],\n",
      "          [ 4.6391e-01, -2.2282e-01,  3.8246e-01,  ..., -1.4770e-01,\n",
      "            9.4510e-01,  1.1717e-01],\n",
      "          [-8.2993e-01, -4.8324e-01, -5.1492e-01,  ..., -8.1354e-02,\n",
      "            5.8876e-01,  4.6608e-01],\n",
      "          ...,\n",
      "          [-8.8785e-01, -3.4940e-03,  3.2860e-01,  ..., -1.1080e-01,\n",
      "           -8.0472e-02, -1.1159e+00],\n",
      "          [ 2.3198e+00, -9.2004e-01,  3.6452e-01,  ..., -2.1662e+00,\n",
      "           -7.7597e-02, -6.9373e-01],\n",
      "          [ 8.9667e-01, -7.9449e-01, -9.7361e-01,  ..., -8.4410e-01,\n",
      "            1.5923e+00,  5.6179e-01]],\n",
      "\n",
      "         [[ 4.3642e-01, -3.3698e-01,  7.8904e-01,  ..., -1.0527e+00,\n",
      "            1.3438e-01, -1.3565e-01],\n",
      "          [-3.8541e-01, -8.0041e-01, -1.5363e-01,  ..., -7.3848e-01,\n",
      "           -6.0065e-01,  1.5982e-01],\n",
      "          [ 1.1539e-01, -1.6908e-01,  6.7411e-01,  ...,  1.3221e-01,\n",
      "           -2.0197e-01,  8.2899e-01],\n",
      "          ...,\n",
      "          [-1.4638e+00,  1.5183e-01,  1.5248e+00,  ...,  1.3259e-01,\n",
      "           -2.6982e-01, -2.8988e-01],\n",
      "          [-2.1753e-01,  1.6879e-01,  2.2802e+00,  ..., -1.6508e+00,\n",
      "           -3.0080e-01, -3.4733e-01],\n",
      "          [-2.7940e-01, -3.6697e-01,  2.7681e-01,  ..., -6.7427e-01,\n",
      "            4.8920e-01, -1.0322e+00]],\n",
      "\n",
      "         [[-5.9419e-02, -4.1602e-02, -2.4548e-01,  ..., -2.3683e-01,\n",
      "           -1.4939e-01,  1.3383e-01],\n",
      "          [ 1.5093e-01, -2.6864e-02, -3.0713e-01,  ..., -2.7950e-01,\n",
      "            4.7611e-01,  1.1183e-01],\n",
      "          [ 8.9678e-01,  6.5377e-01, -1.3886e+00,  ..., -3.9820e-01,\n",
      "            2.1417e-01, -3.8509e-01],\n",
      "          ...,\n",
      "          [-3.1160e-01, -6.3024e-01, -8.3449e-01,  ...,  3.5037e-02,\n",
      "            9.4751e-01,  2.2467e+00],\n",
      "          [-2.8517e-01, -4.7487e-01, -1.9961e+00,  ...,  8.7412e-01,\n",
      "            8.8763e-02,  6.1792e-01],\n",
      "          [-5.1902e-01,  9.9979e-02,  9.4078e-01,  ...,  1.3212e+00,\n",
      "           -1.7572e+00,  4.1181e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.4194e-01, -1.4426e+00, -9.2148e-01,  ...,  7.5832e-01,\n",
      "           -4.9951e-01, -2.8248e-01],\n",
      "          [ 8.4011e-01,  1.4749e-01, -9.9936e-02,  ..., -1.0372e+00,\n",
      "           -6.4073e-01,  7.1947e-01],\n",
      "          [-1.4901e+00, -8.5977e-01,  3.6215e-01,  ..., -1.1084e+00,\n",
      "           -9.6002e-01,  7.3086e-01],\n",
      "          ...,\n",
      "          [ 1.8887e+00, -4.5044e-01,  1.1202e+00,  ..., -6.1646e-01,\n",
      "           -1.5406e+00, -1.8590e+00],\n",
      "          [-4.2215e-01, -5.1413e-01,  7.8924e-01,  ..., -1.7241e+00,\n",
      "           -4.5137e-01,  7.9258e-01],\n",
      "          [ 6.2334e-01, -4.1659e-01,  8.2871e-01,  ..., -5.5395e-01,\n",
      "           -1.5421e+00, -2.1294e-01]],\n",
      "\n",
      "         [[-4.8624e-01, -4.3153e-01, -1.0327e+00,  ...,  3.2545e-01,\n",
      "            1.3439e+00,  6.6865e-01],\n",
      "          [-5.1961e-01, -4.5858e-02, -6.2618e-01,  ...,  1.1490e+00,\n",
      "            2.7310e-01,  8.3753e-01],\n",
      "          [-1.3538e+00, -5.0539e-02,  2.9775e-01,  ...,  1.0108e+00,\n",
      "           -3.5192e-01,  1.0660e+00],\n",
      "          ...,\n",
      "          [-5.2035e-01,  9.4594e-01, -4.0681e-01,  ...,  4.8748e-01,\n",
      "           -2.6187e-01,  1.0810e+00],\n",
      "          [ 8.6018e-01,  5.4007e-01, -4.1243e-02,  ..., -1.6923e+00,\n",
      "            1.3272e+00,  2.4071e-01],\n",
      "          [-6.2831e-02, -9.5324e-01, -1.1032e+00,  ...,  1.2093e+00,\n",
      "            2.2450e+00,  1.0677e+00]],\n",
      "\n",
      "         [[-5.6086e-01,  8.0616e-01, -3.9903e-01,  ...,  4.6547e-01,\n",
      "            8.0546e-02,  1.1419e+00],\n",
      "          [ 1.2807e+00, -1.5281e+00,  3.9072e-02,  ...,  1.7721e-01,\n",
      "            1.6989e+00,  1.5461e+00],\n",
      "          [ 2.4501e+00,  4.5303e-01,  1.5814e-01,  ...,  8.5264e-01,\n",
      "            5.3428e-01,  1.5230e+00],\n",
      "          ...,\n",
      "          [-3.6445e-01, -2.2478e-01, -1.0593e+00,  ...,  1.1585e+00,\n",
      "            9.5635e-01,  1.3819e+00],\n",
      "          [-1.7341e+00, -4.4403e-01, -1.2439e+00,  ...,  1.1990e+00,\n",
      "            1.0236e-01,  2.2164e+00],\n",
      "          [-1.9166e-01,  9.5916e-01,  4.4154e-01,  ...,  2.2460e-01,\n",
      "           -1.5232e-01,  1.7653e+00]]],\n",
      "\n",
      "\n",
      "        [[[-6.4551e-02, -7.8685e-01, -2.0422e-01,  ...,  3.2528e-01,\n",
      "            1.4952e+00,  5.0351e-01],\n",
      "          [-3.8537e-04,  4.0664e-01,  2.7642e-01,  ..., -3.6636e-01,\n",
      "            1.6543e+00,  8.6876e-02],\n",
      "          [ 4.3098e-01, -7.1865e-01,  1.1868e-01,  ..., -6.9062e-01,\n",
      "            8.8401e-01,  3.1343e-01],\n",
      "          ...,\n",
      "          [ 2.7707e-01, -9.4533e-01, -6.7371e-01,  ...,  1.0292e+00,\n",
      "            1.9401e+00,  7.3050e-01],\n",
      "          [ 4.9710e-01, -1.2920e+00, -4.3266e-01,  ...,  5.9789e-01,\n",
      "            1.5234e+00,  7.5328e-01],\n",
      "          [ 4.3876e-01, -8.7128e-01, -3.0421e-01,  ...,  8.1898e-01,\n",
      "            1.6319e+00,  8.6762e-01]],\n",
      "\n",
      "         [[ 2.2271e-01, -3.2209e-01,  5.4677e-01,  ..., -1.8172e+00,\n",
      "            5.5947e-01,  1.8365e-01],\n",
      "          [-4.0049e-01, -5.8307e-01,  3.7893e-01,  ..., -1.0149e+00,\n",
      "           -5.6356e-01,  3.9009e-01],\n",
      "          [-2.3899e-01,  1.5016e+00,  1.3247e+00,  ..., -1.2019e+00,\n",
      "            7.7722e-01,  9.8692e-03],\n",
      "          ...,\n",
      "          [ 5.0990e-01, -6.4403e-01, -3.6710e-01,  ..., -1.4260e+00,\n",
      "            8.0041e-01,  1.1792e+00],\n",
      "          [ 9.6886e-02, -3.5211e-01,  4.0205e-01,  ..., -2.3692e+00,\n",
      "            1.2540e+00,  1.2734e+00],\n",
      "          [ 1.8144e-01, -6.8276e-01,  5.3722e-01,  ..., -2.2618e+00,\n",
      "            1.5538e+00,  1.1990e+00]],\n",
      "\n",
      "         [[ 7.4492e-02,  2.9271e-01, -5.3010e-01,  ...,  2.1204e-01,\n",
      "           -6.6050e-01, -3.2614e-02],\n",
      "          [-6.7332e-01,  3.9665e-02, -1.5898e+00,  ...,  2.7292e-01,\n",
      "           -1.0395e+00, -7.7588e-01],\n",
      "          [-1.4021e+00, -7.3739e-01, -8.8567e-01,  ...,  7.1207e-01,\n",
      "           -8.8696e-01, -6.6474e-01],\n",
      "          ...,\n",
      "          [ 8.9592e-01,  2.5454e-02, -9.0216e-01,  ...,  7.5147e-01,\n",
      "           -3.1636e-01, -5.4192e-01],\n",
      "          [ 2.0854e-01, -2.0421e-01, -1.1249e+00,  ...,  9.1198e-01,\n",
      "            4.2468e-01, -5.2443e-01],\n",
      "          [ 8.0571e-01, -1.4171e-01, -1.1779e+00,  ...,  1.2636e+00,\n",
      "            2.7604e-01, -2.2613e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.5837e-01, -1.1905e+00, -1.5771e-01,  ...,  6.1344e-01,\n",
      "           -5.0697e-01, -2.8897e-01],\n",
      "          [ 1.1821e+00, -1.7398e+00, -7.5040e-01,  ..., -1.9071e-01,\n",
      "           -6.1773e-01, -5.8454e-01],\n",
      "          [-1.3420e-01, -5.5975e-01,  7.0988e-01,  ...,  3.6752e-01,\n",
      "           -3.9252e-01, -5.2914e-01],\n",
      "          ...,\n",
      "          [ 8.9367e-01, -8.2712e-01,  7.2901e-01,  ...,  7.0668e-01,\n",
      "            1.0487e-01, -1.5350e-02],\n",
      "          [ 2.2489e-01, -5.1811e-01,  5.4926e-01,  ...,  6.5922e-01,\n",
      "           -1.3846e-01, -3.2228e-01],\n",
      "          [ 4.1099e-01, -6.3569e-01,  4.9656e-01,  ...,  6.6940e-01,\n",
      "           -7.4671e-03, -1.1099e-01]],\n",
      "\n",
      "         [[-9.4856e-01, -4.7135e-01, -1.1993e+00,  ...,  5.0744e-01,\n",
      "            1.5058e+00,  8.9076e-01],\n",
      "          [ 1.0611e+00, -1.9397e-02, -4.7674e-01,  ...,  1.3091e+00,\n",
      "            1.7749e+00,  1.3303e+00],\n",
      "          [ 1.2696e+00, -1.4419e-01, -3.2636e-01,  ..., -4.6030e-01,\n",
      "            1.7999e+00,  7.7857e-01],\n",
      "          ...,\n",
      "          [-3.7685e-01, -8.1496e-01, -2.0652e+00,  ...,  2.6997e-01,\n",
      "            9.2919e-01,  2.4048e-01],\n",
      "          [-2.8413e-01, -3.5570e-01, -1.5582e+00,  ..., -3.0253e-01,\n",
      "            1.5606e+00, -2.3008e-01],\n",
      "          [ 7.2022e-02, -7.9538e-02, -1.8947e+00,  ..., -1.3032e-01,\n",
      "            1.4278e+00, -1.6122e-01]],\n",
      "\n",
      "         [[-6.5344e-01,  1.0084e+00, -6.4095e-01,  ...,  9.3023e-01,\n",
      "            3.7140e-02,  9.7466e-01],\n",
      "          [-1.1049e+00,  7.0584e-01, -4.1274e-01,  ...,  6.3152e-01,\n",
      "            9.1173e-01,  9.8992e-01],\n",
      "          [-7.9910e-01,  1.9385e+00,  3.8178e-01,  ...,  9.1628e-01,\n",
      "           -6.7656e-01,  3.2909e+00],\n",
      "          ...,\n",
      "          [ 3.5525e-01,  5.0134e-01, -1.7377e-01,  ...,  1.1671e+00,\n",
      "           -3.2557e-02,  8.3503e-01],\n",
      "          [-4.2022e-01,  1.0662e+00, -7.1923e-01,  ...,  1.9798e-01,\n",
      "            8.9253e-01,  4.4126e-01],\n",
      "          [ 8.8890e-01,  9.2577e-01, -5.4993e-01,  ..., -4.4245e-01,\n",
      "            6.5338e-01, -3.7393e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[ 1.7937e+00, -8.4064e-01, -1.4199e+00,  ..., -5.8516e-01,\n",
      "           -1.7783e-01,  3.5469e+00],\n",
      "          [-1.7374e+00, -1.3940e+00, -6.5210e-01,  ...,  1.8573e-01,\n",
      "            4.8854e-01,  1.1897e+00],\n",
      "          [-1.1615e+00, -1.3435e-01, -5.8340e-01,  ...,  1.1945e+00,\n",
      "            1.0867e+00,  2.4352e+00],\n",
      "          ...,\n",
      "          [-4.4276e-01, -2.3291e-01, -7.5739e-01,  ...,  1.9843e-01,\n",
      "            9.0555e-01,  2.0329e+00],\n",
      "          [-1.0135e+00,  5.0783e-01,  2.0994e-02,  ...,  1.0231e+00,\n",
      "            2.4113e-01,  1.6467e+00],\n",
      "          [ 5.3897e+00,  1.1248e+00,  1.6349e+00,  ...,  2.2995e+00,\n",
      "            2.2401e+00,  7.4834e+00]],\n",
      "\n",
      "         [[ 2.5706e+00, -8.7843e-01, -5.2389e-01,  ..., -5.2266e-01,\n",
      "            9.1699e-01, -2.5404e+00],\n",
      "          [-2.2191e+00,  2.5819e+00,  2.8834e+00,  ...,  2.1181e+00,\n",
      "            2.9331e+00,  1.9984e+00],\n",
      "          [-2.2441e+00,  1.9006e+00,  1.7901e+00,  ...,  1.7962e+00,\n",
      "            1.9378e+00,  1.6897e+00],\n",
      "          ...,\n",
      "          [-1.4873e+00,  2.0493e+00,  2.4735e+00,  ...,  3.1347e+00,\n",
      "            1.5971e+00,  3.1766e+00],\n",
      "          [-1.9097e+00,  1.6928e+00,  2.0905e+00,  ...,  1.0273e+00,\n",
      "            3.3707e-02,  1.8879e+00],\n",
      "          [ 4.0064e-01,  1.5017e-01,  3.8771e-01,  ...,  1.4210e-01,\n",
      "            4.3190e-01,  2.8644e+00]],\n",
      "\n",
      "         [[ 4.3980e-01,  2.2593e+00,  2.2761e+00,  ...,  3.1911e-01,\n",
      "            9.6720e-01,  6.1515e-01],\n",
      "          [ 1.7817e+00,  9.1283e-02, -1.9809e+00,  ..., -2.7797e+00,\n",
      "           -2.3641e+00,  2.5571e+00],\n",
      "          [ 1.4935e+00,  8.9635e-02, -7.2876e-01,  ..., -2.8260e+00,\n",
      "           -1.9659e+00,  2.1144e+00],\n",
      "          ...,\n",
      "          [ 3.0278e+00, -2.7266e-01, -1.5365e+00,  ..., -4.0833e+00,\n",
      "           -1.7495e+00,  3.5699e+00],\n",
      "          [ 1.7480e+00, -3.2568e-01, -1.8036e+00,  ..., -2.3274e+00,\n",
      "           -2.1051e+00,  2.6969e+00],\n",
      "          [ 2.1054e+00, -1.1105e+00, -8.6387e-01,  ..., -1.1039e+00,\n",
      "           -3.9569e-01,  4.0170e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1541e-01,  5.0022e-01,  1.0297e+00,  ...,  1.5152e+00,\n",
      "            2.0409e-01,  3.1484e+00],\n",
      "          [ 1.7186e+00,  1.1672e+00,  5.3680e-01,  ..., -4.0641e-01,\n",
      "            8.8351e-01,  2.4266e+00],\n",
      "          [ 1.1601e+00,  1.0601e+00,  2.0027e+00,  ..., -4.5888e-04,\n",
      "            3.8784e-01,  2.7197e+00],\n",
      "          ...,\n",
      "          [ 1.4729e+00,  1.5166e-02,  2.4598e-01,  ..., -2.1078e+00,\n",
      "            1.1014e+00,  3.1336e+00],\n",
      "          [ 1.2127e-01,  1.5415e-01, -6.0644e-01,  ..., -6.2308e-01,\n",
      "           -1.5982e+00,  1.7808e+00],\n",
      "          [ 1.6672e+00, -1.0282e+00, -2.1481e-01,  ..., -5.1547e-02,\n",
      "            9.4623e-01,  4.9368e+00]],\n",
      "\n",
      "         [[ 6.9294e-01,  4.5013e-01,  8.9739e-02,  ..., -6.3238e-01,\n",
      "            1.8682e-01,  4.1676e+00],\n",
      "          [ 1.8087e+00,  1.2190e+00,  2.0633e-01,  ..., -2.6731e-02,\n",
      "            4.2201e-01,  4.4483e+00],\n",
      "          [ 2.2517e+00,  4.1975e+00,  1.1979e+00,  ...,  2.0830e-01,\n",
      "            1.0776e+00,  3.5014e+00],\n",
      "          ...,\n",
      "          [ 7.7902e-01,  3.7191e+00,  3.5238e+00,  ..., -8.0138e-02,\n",
      "            1.1564e+00,  2.8922e+00],\n",
      "          [-1.6753e-01,  3.9899e+00,  2.7492e+00,  ...,  8.8668e-01,\n",
      "            1.8523e-01,  1.8575e+00],\n",
      "          [ 9.2305e-01, -5.8787e-01, -3.3600e-01,  ..., -1.5793e-01,\n",
      "           -1.0728e-02,  5.4536e+00]],\n",
      "\n",
      "         [[ 9.5839e-01,  9.8235e-03, -7.6429e-01,  ..., -1.6211e+00,\n",
      "            1.4836e-01,  1.9968e+00],\n",
      "          [ 2.0555e+00,  1.5657e+00,  4.0374e+00,  ...,  8.3315e-01,\n",
      "           -6.4450e-01,  4.0457e+00],\n",
      "          [ 2.2923e+00,  1.0799e+00,  8.2937e-01,  ...,  3.0261e+00,\n",
      "            2.7396e+00,  3.9566e+00],\n",
      "          ...,\n",
      "          [ 2.9332e+00,  8.0359e-01, -9.7714e-02,  ...,  1.2469e+00,\n",
      "            6.3146e+00,  4.2047e+00],\n",
      "          [ 1.5031e+00,  1.6219e+00, -5.7516e-02,  ..., -2.2251e+00,\n",
      "            1.8026e+00,  5.0297e+00],\n",
      "          [ 9.9156e-01,  6.8329e-04,  1.0516e+00,  ..., -8.9418e-01,\n",
      "            1.9043e-01,  5.1136e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6074e+00, -3.9516e-02,  6.0098e-01,  ...,  1.5637e+00,\n",
      "            1.7845e+00,  1.7723e+00],\n",
      "          [ 1.5167e-01,  1.2275e+00,  8.5187e-01,  ...,  2.1730e+00,\n",
      "            2.4235e+00,  2.2684e+00],\n",
      "          [ 5.0033e-01,  9.1163e-01,  3.6194e-01,  ...,  7.3052e-01,\n",
      "            8.5622e-01,  7.0456e-01],\n",
      "          ...,\n",
      "          [ 1.0464e+00,  1.3281e+00,  6.7670e-01,  ...,  1.6411e+00,\n",
      "            1.4255e+00,  1.6134e+00],\n",
      "          [ 1.0416e+00,  1.0533e+00,  8.5772e-01,  ...,  1.2328e+00,\n",
      "            9.9083e-01,  1.1238e+00],\n",
      "          [ 9.1024e-01,  9.9975e-01,  2.7811e-01,  ...,  1.1584e+00,\n",
      "            9.0197e-01,  1.0628e+00]],\n",
      "\n",
      "         [[ 1.5712e+00,  1.4861e+00,  8.3380e-01,  ...,  2.0281e+00,\n",
      "            2.2952e+00,  2.2651e+00],\n",
      "          [-1.1743e+00,  2.6996e+00,  1.6129e+00,  ...,  3.9709e-01,\n",
      "            7.7044e-01,  1.2890e-01],\n",
      "          [-4.7749e-01,  1.7920e+00,  1.5175e+00,  ...,  4.3294e-01,\n",
      "            6.4171e-02, -2.0847e-01],\n",
      "          ...,\n",
      "          [ 1.3707e+00,  2.1389e+00,  6.5369e-01,  ...,  2.7551e+00,\n",
      "            2.3871e+00,  2.5197e+00],\n",
      "          [ 9.3156e-01,  2.0776e+00, -2.0076e-01,  ...,  2.0180e+00,\n",
      "            1.5073e+00,  1.8058e+00],\n",
      "          [ 1.4308e+00,  1.7853e+00, -2.0786e-01,  ...,  2.3354e+00,\n",
      "            1.7614e+00,  2.1073e+00]],\n",
      "\n",
      "         [[ 1.1249e+00,  6.8226e-01, -3.7259e-01,  ...,  3.7331e-01,\n",
      "            4.3444e-01,  1.0563e-01],\n",
      "          [-7.9560e-01, -3.7720e+00, -2.8930e+00,  ..., -1.6697e+00,\n",
      "           -1.6089e+00, -1.6493e+00],\n",
      "          [-1.5767e-01, -1.3619e+00, -8.4134e-01,  ..., -1.0431e+00,\n",
      "           -6.7597e-01, -7.9203e-01],\n",
      "          ...,\n",
      "          [ 1.0846e+00, -1.4195e+00, -2.4206e+00,  ...,  3.9937e-02,\n",
      "           -1.0457e-01,  9.2762e-02],\n",
      "          [ 8.4365e-01, -1.4857e+00, -2.1833e+00,  ..., -3.3950e-01,\n",
      "           -2.5779e-01, -1.5747e-01],\n",
      "          [ 1.1807e+00, -1.1493e+00, -1.8029e+00,  ...,  5.5830e-02,\n",
      "            1.0698e-01,  1.6702e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.7372e-02,  1.2082e+00, -7.8707e-01,  ...,  4.4133e-01,\n",
      "           -4.1396e-01, -2.0828e-01],\n",
      "          [ 6.6861e-01, -7.9131e-01, -8.2214e-01,  ...,  2.6593e-01,\n",
      "            7.9627e-02, -1.0832e-01],\n",
      "          [ 1.2417e+00, -4.9569e-01,  5.6013e-01,  ...,  9.6231e-01,\n",
      "            1.2156e+00,  6.9625e-01],\n",
      "          ...,\n",
      "          [ 1.9128e-01,  3.4359e-01, -4.0594e-01,  ...,  4.7818e-01,\n",
      "            1.1182e-01,  3.2401e-01],\n",
      "          [-3.4552e-02,  2.5796e-01,  6.8832e-02,  ...,  3.7561e-01,\n",
      "            9.9425e-02,  3.3841e-01],\n",
      "          [ 2.3320e-01,  1.6502e-01, -2.6932e-01,  ...,  6.9030e-01,\n",
      "            5.0700e-01,  7.4176e-01]],\n",
      "\n",
      "         [[ 1.3309e+00,  1.2185e+00,  1.0083e+00,  ...,  6.7728e-01,\n",
      "            3.9249e-01, -3.7178e-02],\n",
      "          [ 4.7286e-01,  3.6719e-01,  1.3894e+00,  ...,  1.6409e-01,\n",
      "           -3.4512e-01, -6.1566e-01],\n",
      "          [ 1.0440e+00,  3.4773e+00,  1.2966e+00,  ...,  8.2790e-01,\n",
      "           -1.0420e-01, -7.4023e-01],\n",
      "          ...,\n",
      "          [ 1.2514e+00,  1.7574e+00,  1.8935e+00,  ...,  1.0040e+00,\n",
      "            2.3018e-01, -8.0032e-02],\n",
      "          [ 5.5228e-01,  1.9746e+00,  1.7614e+00,  ...,  1.8065e+00,\n",
      "            8.3222e-01, -3.8527e-02],\n",
      "          [ 4.1098e-01,  1.2667e+00,  1.2100e+00,  ...,  2.0239e+00,\n",
      "            1.6387e+00,  7.4577e-01]],\n",
      "\n",
      "         [[ 3.2147e-01,  1.5428e+00,  9.9961e-01,  ...,  1.5973e+00,\n",
      "            9.9423e-01,  9.1427e-01],\n",
      "          [ 1.7195e+00,  3.1028e-01,  4.2515e+00,  ...,  6.2164e-01,\n",
      "            6.4862e-01,  4.2137e-01],\n",
      "          [ 1.1400e+00,  3.2985e+00,  2.2017e+00,  ...,  5.4736e+00,\n",
      "            2.5474e+00,  2.1906e+00],\n",
      "          ...,\n",
      "          [ 9.8422e-01,  1.5179e-01,  1.3095e+00,  ...,  9.8327e-01,\n",
      "            2.7054e+00,  1.3409e+00],\n",
      "          [ 7.0158e-01,  7.5076e-01,  7.6644e-01,  ...,  1.8738e-01,\n",
      "            2.2386e+00,  3.2869e+00],\n",
      "          [ 9.4142e-01, -1.1837e+00,  7.3909e-01,  ..., -8.3825e-01,\n",
      "            8.6150e-01,  2.2560e+00]]]], grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[ 1.7937e+00, -8.4064e-01, -1.4199e+00,  ..., -5.8516e-01,\n",
      "           -1.7783e-01,  3.5469e+00],\n",
      "          [-1.7374e+00, -1.3940e+00, -6.5210e-01,  ...,  1.8573e-01,\n",
      "            4.8854e-01,  1.1897e+00],\n",
      "          [-1.1615e+00, -1.3435e-01, -5.8340e-01,  ...,  1.1945e+00,\n",
      "            1.0867e+00,  2.4352e+00],\n",
      "          ...,\n",
      "          [-4.4276e-01, -2.3291e-01, -7.5739e-01,  ...,  1.9843e-01,\n",
      "            9.0555e-01,  2.0329e+00],\n",
      "          [-1.0135e+00,  5.0783e-01,  2.0994e-02,  ...,  1.0231e+00,\n",
      "            2.4113e-01,  1.6467e+00],\n",
      "          [ 5.3897e+00,  1.1248e+00,  1.6349e+00,  ...,  2.2995e+00,\n",
      "            2.2401e+00,  7.4834e+00]],\n",
      "\n",
      "         [[ 2.5706e+00, -8.7843e-01, -5.2389e-01,  ..., -5.2266e-01,\n",
      "            9.1699e-01, -2.5404e+00],\n",
      "          [-2.2191e+00,  2.5819e+00,  2.8834e+00,  ...,  2.1181e+00,\n",
      "            2.9331e+00,  1.9984e+00],\n",
      "          [-2.2441e+00,  1.9006e+00,  1.7901e+00,  ...,  1.7962e+00,\n",
      "            1.9378e+00,  1.6897e+00],\n",
      "          ...,\n",
      "          [-1.4873e+00,  2.0493e+00,  2.4735e+00,  ...,  3.1347e+00,\n",
      "            1.5971e+00,  3.1766e+00],\n",
      "          [-1.9097e+00,  1.6928e+00,  2.0905e+00,  ...,  1.0273e+00,\n",
      "            3.3707e-02,  1.8879e+00],\n",
      "          [ 4.0064e-01,  1.5017e-01,  3.8771e-01,  ...,  1.4210e-01,\n",
      "            4.3190e-01,  2.8644e+00]],\n",
      "\n",
      "         [[ 4.3980e-01,  2.2593e+00,  2.2761e+00,  ...,  3.1911e-01,\n",
      "            9.6720e-01,  6.1515e-01],\n",
      "          [ 1.7817e+00,  9.1283e-02, -1.9809e+00,  ..., -2.7797e+00,\n",
      "           -2.3641e+00,  2.5571e+00],\n",
      "          [ 1.4935e+00,  8.9635e-02, -7.2876e-01,  ..., -2.8260e+00,\n",
      "           -1.9659e+00,  2.1144e+00],\n",
      "          ...,\n",
      "          [ 3.0278e+00, -2.7266e-01, -1.5365e+00,  ..., -4.0833e+00,\n",
      "           -1.7495e+00,  3.5699e+00],\n",
      "          [ 1.7480e+00, -3.2568e-01, -1.8036e+00,  ..., -2.3274e+00,\n",
      "           -2.1051e+00,  2.6969e+00],\n",
      "          [ 2.1054e+00, -1.1105e+00, -8.6387e-01,  ..., -1.1039e+00,\n",
      "           -3.9569e-01,  4.0170e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1541e-01,  5.0022e-01,  1.0297e+00,  ...,  1.5152e+00,\n",
      "            2.0409e-01,  3.1484e+00],\n",
      "          [ 1.7186e+00,  1.1672e+00,  5.3680e-01,  ..., -4.0641e-01,\n",
      "            8.8351e-01,  2.4266e+00],\n",
      "          [ 1.1601e+00,  1.0601e+00,  2.0027e+00,  ..., -4.5888e-04,\n",
      "            3.8784e-01,  2.7197e+00],\n",
      "          ...,\n",
      "          [ 1.4729e+00,  1.5166e-02,  2.4598e-01,  ..., -2.1078e+00,\n",
      "            1.1014e+00,  3.1336e+00],\n",
      "          [ 1.2127e-01,  1.5415e-01, -6.0644e-01,  ..., -6.2308e-01,\n",
      "           -1.5982e+00,  1.7808e+00],\n",
      "          [ 1.6672e+00, -1.0282e+00, -2.1481e-01,  ..., -5.1547e-02,\n",
      "            9.4623e-01,  4.9368e+00]],\n",
      "\n",
      "         [[ 6.9294e-01,  4.5013e-01,  8.9739e-02,  ..., -6.3238e-01,\n",
      "            1.8682e-01,  4.1676e+00],\n",
      "          [ 1.8087e+00,  1.2190e+00,  2.0633e-01,  ..., -2.6731e-02,\n",
      "            4.2201e-01,  4.4483e+00],\n",
      "          [ 2.2517e+00,  4.1975e+00,  1.1979e+00,  ...,  2.0830e-01,\n",
      "            1.0776e+00,  3.5014e+00],\n",
      "          ...,\n",
      "          [ 7.7902e-01,  3.7191e+00,  3.5238e+00,  ..., -8.0138e-02,\n",
      "            1.1564e+00,  2.8922e+00],\n",
      "          [-1.6753e-01,  3.9899e+00,  2.7492e+00,  ...,  8.8668e-01,\n",
      "            1.8523e-01,  1.8575e+00],\n",
      "          [ 9.2305e-01, -5.8787e-01, -3.3600e-01,  ..., -1.5793e-01,\n",
      "           -1.0728e-02,  5.4536e+00]],\n",
      "\n",
      "         [[ 9.5839e-01,  9.8235e-03, -7.6429e-01,  ..., -1.6211e+00,\n",
      "            1.4836e-01,  1.9968e+00],\n",
      "          [ 2.0555e+00,  1.5657e+00,  4.0374e+00,  ...,  8.3315e-01,\n",
      "           -6.4450e-01,  4.0457e+00],\n",
      "          [ 2.2923e+00,  1.0799e+00,  8.2937e-01,  ...,  3.0261e+00,\n",
      "            2.7396e+00,  3.9566e+00],\n",
      "          ...,\n",
      "          [ 2.9332e+00,  8.0359e-01, -9.7714e-02,  ...,  1.2469e+00,\n",
      "            6.3146e+00,  4.2047e+00],\n",
      "          [ 1.5031e+00,  1.6219e+00, -5.7516e-02,  ..., -2.2251e+00,\n",
      "            1.8026e+00,  5.0297e+00],\n",
      "          [ 9.9156e-01,  6.8329e-04,  1.0516e+00,  ..., -8.9418e-01,\n",
      "            1.9043e-01,  5.1136e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6074e+00, -3.9516e-02,  6.0098e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.5167e-01,  1.2275e+00,  8.5187e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.0033e-01,  9.1163e-01,  3.6194e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.0464e+00,  1.3281e+00,  6.7670e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0416e+00,  1.0533e+00,  8.5772e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 9.1024e-01,  9.9975e-01,  2.7811e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.5712e+00,  1.4861e+00,  8.3380e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1743e+00,  2.6996e+00,  1.6129e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-4.7749e-01,  1.7920e+00,  1.5175e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.3707e+00,  2.1389e+00,  6.5369e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 9.3156e-01,  2.0776e+00, -2.0076e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.4308e+00,  1.7853e+00, -2.0786e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.1249e+00,  6.8226e-01, -3.7259e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-7.9560e-01, -3.7720e+00, -2.8930e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.5767e-01, -1.3619e+00, -8.4134e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.0846e+00, -1.4195e+00, -2.4206e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 8.4365e-01, -1.4857e+00, -2.1833e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.1807e+00, -1.1493e+00, -1.8029e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.7372e-02,  1.2082e+00, -7.8707e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.6861e-01, -7.9131e-01, -8.2214e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.2417e+00, -4.9569e-01,  5.6013e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.9128e-01,  3.4359e-01, -4.0594e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-3.4552e-02,  2.5796e-01,  6.8832e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.3320e-01,  1.6502e-01, -2.6932e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.3309e+00,  1.2185e+00,  1.0083e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.7286e-01,  3.6719e-01,  1.3894e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0440e+00,  3.4773e+00,  1.2966e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.2514e+00,  1.7574e+00,  1.8935e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.5228e-01,  1.9746e+00,  1.7614e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.1098e-01,  1.2667e+00,  1.2100e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 3.2147e-01,  1.5428e+00,  9.9961e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.7195e+00,  3.1028e-01,  4.2515e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.1400e+00,  3.2985e+00,  2.2017e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 9.8422e-01,  1.5179e-01,  1.3095e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.0158e-01,  7.5076e-01,  7.6644e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 9.4142e-01, -1.1837e+00,  7.3909e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[1.4016e-01, 1.0058e-02, 5.6358e-03,  ..., 1.2986e-02,\n",
      "           1.9516e-02, 8.0915e-01],\n",
      "          [2.4002e-02, 3.3837e-02, 7.1051e-02,  ..., 1.6422e-01,\n",
      "           2.2230e-01, 4.4817e-01],\n",
      "          [1.5949e-02, 4.4547e-02, 2.8431e-02,  ..., 1.6824e-01,\n",
      "           1.5104e-01, 5.8179e-01],\n",
      "          ...,\n",
      "          [4.7889e-02, 5.9070e-02, 3.4961e-02,  ..., 9.0927e-02,\n",
      "           1.8441e-01, 5.6936e-01],\n",
      "          [2.9124e-02, 1.3334e-01, 8.1944e-02,  ..., 2.2323e-01,\n",
      "           1.0212e-01, 4.1643e-01],\n",
      "          [1.0818e-01, 1.5202e-03, 2.5319e-03,  ..., 4.9210e-03,\n",
      "           4.6375e-03, 8.7782e-01]],\n",
      "\n",
      "         [[7.5369e-01, 2.3950e-02, 3.4141e-02,  ..., 3.4183e-02,\n",
      "           1.4423e-01, 4.5451e-03],\n",
      "          [1.4842e-03, 1.8053e-01, 2.4407e-01,  ..., 1.1354e-01,\n",
      "           2.5649e-01, 1.0073e-01],\n",
      "          [2.7036e-03, 1.7060e-01, 1.5275e-01,  ..., 1.5368e-01,\n",
      "           1.7706e-01, 1.3816e-01],\n",
      "          ...,\n",
      "          [2.1553e-03, 7.4037e-02, 1.1315e-01,  ..., 2.1919e-01,\n",
      "           4.7101e-02, 2.2856e-01],\n",
      "          [4.2057e-03, 1.5432e-01, 2.2969e-01,  ..., 7.9317e-02,\n",
      "           2.9367e-02, 1.8756e-01],\n",
      "          [5.9608e-02, 4.6400e-02, 5.8842e-02,  ..., 4.6028e-02,\n",
      "           6.1500e-02, 7.0030e-01]],\n",
      "\n",
      "         [[5.7302e-02, 3.5349e-01, 3.5949e-01,  ..., 5.0787e-02,\n",
      "           9.7099e-02, 6.8284e-02],\n",
      "          [2.8333e-01, 5.2257e-02, 6.5798e-03,  ..., 2.9599e-03,\n",
      "           4.4853e-03, 6.1523e-01],\n",
      "          [3.0203e-01, 7.4189e-02, 3.2728e-02,  ..., 4.0186e-03,\n",
      "           9.4982e-03, 5.6194e-01],\n",
      "          ...,\n",
      "          [3.4768e-01, 1.2818e-02, 3.6221e-03,  ..., 2.8372e-04,\n",
      "           2.9271e-03, 5.9789e-01],\n",
      "          [2.4765e-01, 3.1137e-02, 7.1025e-03,  ..., 4.2066e-03,\n",
      "           5.2538e-03, 6.3968e-01],\n",
      "          [1.2419e-01, 4.9821e-03, 6.3756e-03,  ..., 5.0150e-03,\n",
      "           1.0182e-02, 8.3996e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.1879e-02, 4.1247e-02, 7.0043e-02,  ..., 1.1381e-01,\n",
      "           3.0675e-02, 5.8276e-01],\n",
      "          [1.9905e-01, 1.1468e-01, 6.1055e-02,  ..., 2.3774e-02,\n",
      "           8.6357e-02, 4.0406e-01],\n",
      "          [9.5771e-02, 8.6659e-02, 2.2242e-01,  ..., 3.0007e-02,\n",
      "           4.4245e-02, 4.5557e-01],\n",
      "          ...,\n",
      "          [1.2923e-01, 3.0079e-02, 3.7888e-02,  ..., 3.5997e-03,\n",
      "           8.9131e-02, 6.8014e-01],\n",
      "          [1.1155e-01, 1.1528e-01, 5.3882e-02,  ..., 5.2993e-02,\n",
      "           1.9986e-02, 5.8644e-01],\n",
      "          [3.5299e-02, 2.3833e-03, 5.3754e-03,  ..., 6.3287e-03,\n",
      "           1.7165e-02, 9.2835e-01]],\n",
      "\n",
      "         [[2.7980e-02, 2.1948e-02, 1.5307e-02,  ..., 7.4348e-03,\n",
      "           1.6867e-02, 9.0336e-01],\n",
      "          [6.1576e-02, 3.4143e-02, 1.2403e-02,  ..., 9.8244e-03,\n",
      "           1.5388e-02, 8.6256e-01],\n",
      "          [8.0865e-02, 5.6601e-01, 2.8192e-02,  ..., 1.0480e-02,\n",
      "           2.4997e-02, 2.8216e-01],\n",
      "          ...,\n",
      "          [2.0774e-02, 3.9298e-01, 3.2327e-01,  ..., 8.7981e-03,\n",
      "           3.0297e-02, 1.7189e-01],\n",
      "          [1.0201e-02, 6.5194e-01, 1.8852e-01,  ..., 2.9274e-02,\n",
      "           1.4516e-02, 7.7285e-02],\n",
      "          [1.0500e-02, 2.3175e-03, 2.9812e-03,  ..., 3.5623e-03,\n",
      "           4.1273e-03, 9.7456e-01]],\n",
      "\n",
      "         [[2.0174e-01, 7.8132e-02, 3.6028e-02,  ..., 1.5295e-02,\n",
      "           8.9743e-02, 5.6985e-01],\n",
      "          [4.7595e-02, 2.9164e-02, 3.4535e-01,  ..., 1.4018e-02,\n",
      "           3.1986e-03, 3.4824e-01],\n",
      "          [4.9139e-02, 1.4619e-02, 1.1379e-02,  ..., 1.0235e-01,\n",
      "           7.6860e-02, 2.5957e-01],\n",
      "          ...,\n",
      "          [2.9013e-02, 3.4491e-03, 1.4005e-03,  ..., 5.3734e-03,\n",
      "           8.5332e-01, 1.0346e-01],\n",
      "          [2.6448e-02, 2.9783e-02, 5.5541e-03,  ..., 6.3570e-04,\n",
      "           3.5681e-02, 8.9940e-01],\n",
      "          [1.5358e-02, 5.7016e-03, 1.6308e-02,  ..., 2.3300e-03,\n",
      "           6.8929e-03, 9.4730e-01]]],\n",
      "\n",
      "\n",
      "        [[[4.1166e-02, 7.9304e-03, 1.5047e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9671e-02, 5.7684e-02, 3.9620e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.4939e-02, 6.7802e-02, 3.9131e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.3595e-02, 5.7778e-02, 3.0120e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.4323e-02, 4.4847e-02, 3.6880e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.4059e-02, 4.8185e-02, 2.3416e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[4.0903e-01, 3.7566e-01, 1.9566e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.1008e-02, 5.2982e-01, 1.7873e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.1359e-02, 4.9688e-01, 3.7761e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [2.6314e-01, 5.6727e-01, 1.2846e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1470e-01, 6.7537e-01, 6.9193e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.6959e-01, 5.2685e-01, 7.1789e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[2.1329e-01, 1.3700e-01, 4.7711e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0382e-02, 1.0389e-03, 2.5024e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.3477e-01, 4.0420e-02, 6.8025e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [7.3797e-02, 6.0327e-03, 2.2168e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.0823e-02, 8.8423e-03, 4.4017e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.3400e-02, 9.0871e-03, 4.7267e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.2413e-02, 8.1880e-02, 1.1133e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.5469e-01, 3.5928e-02, 3.4837e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9385e-01, 3.4113e-02, 9.8053e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [3.1140e-02, 3.6263e-02, 1.7138e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.5579e-02, 4.7668e-02, 3.9454e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.6937e-02, 3.4503e-02, 2.2347e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[3.6289e-02, 3.2432e-02, 2.6284e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0055e-02, 9.0468e-03, 2.5144e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.6098e-02, 5.2535e-01, 5.9347e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.6241e-02, 2.6937e-02, 3.0865e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.0354e-02, 1.6734e-01, 1.3521e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.8577e-02, 9.0771e-02, 8.5772e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[9.7881e-02, 3.3200e-01, 1.9285e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.0431e-02, 9.8786e-03, 5.0856e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.4387e-02, 2.9774e-01, 9.9420e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.5729e-01, 6.8418e-02, 2.1774e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2064e-01, 1.2672e-01, 1.2872e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.7949e-01, 2.1435e-02, 1.4661e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[ 3.9999e-03, -1.0080e-01, -1.6491e-02,  ...,  5.9490e-02,\n",
      "            1.5340e-02, -2.5120e-02],\n",
      "          [ 2.6484e-01,  2.8152e-01, -3.3716e-02,  ...,  4.0007e-01,\n",
      "           -4.8286e-02,  2.2948e-01],\n",
      "          [ 1.6894e-01,  1.9208e-01, -9.5276e-02,  ...,  3.5928e-01,\n",
      "           -5.1251e-02,  1.4653e-01],\n",
      "          ...,\n",
      "          [ 2.0865e-01,  2.1024e-01, -2.5511e-02,  ...,  2.6408e-01,\n",
      "           -1.8333e-02,  1.7715e-01],\n",
      "          [ 2.7271e-02,  1.3432e-01, -1.9996e-01,  ...,  5.2926e-01,\n",
      "           -1.5752e-01,  1.2839e-01],\n",
      "          [-1.3248e-02, -9.9037e-02, -2.3183e-02,  ...,  2.5083e-02,\n",
      "            1.8367e-02, -2.9989e-02]],\n",
      "\n",
      "         [[ 2.7596e-01,  2.1082e-02, -1.6383e-01,  ..., -1.6959e-01,\n",
      "           -3.4193e-02, -2.8403e-01],\n",
      "          [ 1.8160e-01, -1.2097e-01,  3.1041e-01,  ...,  1.4285e-02,\n",
      "           -8.6723e-02, -1.0029e-01],\n",
      "          [ 2.1386e-01, -9.6139e-02,  2.3960e-01,  ..., -7.4123e-02,\n",
      "           -9.1041e-02, -2.2982e-02],\n",
      "          ...,\n",
      "          [ 2.3903e-01, -1.0621e-01,  1.3867e-01,  ..., -1.2152e-01,\n",
      "           -6.6058e-02,  5.1270e-02],\n",
      "          [ 2.4293e-01, -1.7836e-02,  1.3953e-01,  ..., -1.5899e-01,\n",
      "           -5.2011e-02,  1.8725e-01],\n",
      "          [ 8.1878e-02, -2.1404e-04,  4.5438e-02,  ..., -5.6930e-02,\n",
      "           -4.7886e-02, -3.0872e-02]],\n",
      "\n",
      "         [[-5.0766e-01, -5.8158e-01, -9.8185e-01,  ...,  3.8329e-01,\n",
      "           -5.0450e-01,  5.6484e-01],\n",
      "          [ 3.1708e-01,  9.7850e-02, -1.4635e-01,  ...,  6.8675e-02,\n",
      "           -6.9671e-02,  2.4276e-01],\n",
      "          [ 2.6773e-01,  5.7155e-02, -1.9841e-01,  ...,  9.0413e-02,\n",
      "           -9.0950e-02,  2.6557e-01],\n",
      "          ...,\n",
      "          [ 4.2160e-01,  1.8522e-01, -1.2256e-01,  ...,  3.8858e-02,\n",
      "           -4.6961e-02,  2.2792e-01],\n",
      "          [ 3.4002e-01,  1.2297e-01, -1.4568e-01,  ...,  5.6633e-02,\n",
      "           -7.6448e-02,  2.3097e-01],\n",
      "          [ 1.7627e-01,  6.9478e-02, -4.0933e-02,  ...,  2.9314e-02,\n",
      "           -1.8858e-02,  1.0419e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5004e-01, -1.1548e-01,  2.0211e-01,  ..., -1.2949e-01,\n",
      "            1.2787e-01,  1.1005e-01],\n",
      "          [ 1.6375e-01, -2.1434e-01,  1.7114e-01,  ..., -2.7409e-01,\n",
      "            1.6484e-01,  1.6651e-01],\n",
      "          [ 3.1275e-01, -5.2980e-02,  9.8925e-02,  ..., -2.9160e-01,\n",
      "            1.3436e-01,  3.2915e-01],\n",
      "          ...,\n",
      "          [ 5.2999e-02, -1.6623e-01,  5.0290e-02,  ..., -1.4154e-02,\n",
      "            9.3566e-02,  5.1071e-02],\n",
      "          [ 1.7518e-01, -6.4350e-02,  1.8418e-01,  ..., -2.6813e-01,\n",
      "            1.2463e-01,  1.5754e-01],\n",
      "          [ 8.4024e-04, -2.4108e-02,  4.9843e-02,  ...,  1.6310e-02,\n",
      "            3.0180e-02, -1.3283e-02]],\n",
      "\n",
      "         [[ 9.3610e-02, -3.4219e-03,  8.5824e-03,  ...,  3.0773e-02,\n",
      "           -4.5317e-02,  1.0411e-01],\n",
      "          [ 1.4099e-01, -1.5002e-02,  5.8452e-03,  ...,  2.7742e-02,\n",
      "           -8.4086e-02,  1.4795e-01],\n",
      "          [ 6.6867e-01, -4.5368e-01,  6.6045e-01,  ...,  3.9282e-02,\n",
      "           -4.2603e-01,  6.9671e-01],\n",
      "          ...,\n",
      "          [ 7.9604e-01, -5.0707e-01,  5.5735e-01,  ..., -8.8411e-02,\n",
      "           -3.5294e-01,  7.2986e-01],\n",
      "          [ 8.8580e-01, -6.2393e-01,  8.3974e-01,  ..., -1.8142e-02,\n",
      "           -4.8963e-01,  8.5264e-01],\n",
      "          [ 2.9582e-02,  2.9193e-02, -1.6841e-02,  ...,  4.0136e-02,\n",
      "           -9.7310e-03,  5.7251e-02]],\n",
      "\n",
      "         [[-9.6115e-02, -2.5948e-02, -2.5191e-01,  ...,  1.7016e-01,\n",
      "           -4.2598e-02,  9.7744e-03],\n",
      "          [-4.4109e-03, -1.9834e-01, -3.1887e-01,  ..., -3.0650e-01,\n",
      "           -3.6346e-01,  3.4939e-01],\n",
      "          [ 4.3431e-02, -1.7223e-04, -6.2304e-01,  ..., -5.9956e-01,\n",
      "           -3.8180e-01,  2.3375e-01],\n",
      "          ...,\n",
      "          [-6.6696e-01,  5.7000e-01, -1.1210e+00,  ..., -2.7123e-01,\n",
      "           -1.2674e+00,  9.6541e-02],\n",
      "          [-3.7243e-02,  9.6251e-03, -6.3599e-02,  ...,  4.9193e-02,\n",
      "           -1.7056e-02, -1.0534e-02],\n",
      "          [-1.0524e-02, -1.7590e-02, -4.2743e-02,  ...,  3.4847e-02,\n",
      "            5.1508e-03, -3.0879e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0567e-02, -8.2191e-02, -1.6098e-02,  ...,  3.4920e-02,\n",
      "            2.3941e-02,  1.2507e-02],\n",
      "          [-1.0040e-01, -8.7652e-02, -9.0220e-03,  ...,  6.0235e-02,\n",
      "           -6.3189e-02,  2.5660e-02],\n",
      "          [-1.1081e-01, -1.0923e-01, -2.0316e-03,  ...,  6.5976e-02,\n",
      "           -7.6681e-02,  2.2846e-02],\n",
      "          ...,\n",
      "          [-9.6424e-02, -1.0161e-01, -7.6936e-03,  ...,  5.2599e-02,\n",
      "           -5.9351e-02,  2.2340e-02],\n",
      "          [-8.1396e-02, -1.0308e-01, -2.8374e-03,  ...,  6.5485e-02,\n",
      "           -3.8800e-02,  1.7201e-02],\n",
      "          [-8.2889e-02, -9.6661e-02, -1.1391e-02,  ...,  4.3415e-02,\n",
      "           -4.2773e-02,  2.1051e-02]],\n",
      "\n",
      "         [[ 4.3039e-02, -5.9017e-01, -2.2120e-01,  ..., -4.7206e-01,\n",
      "           -4.3816e-02, -5.3000e-02],\n",
      "          [-3.7803e-02, -7.6342e-01,  5.8278e-02,  ..., -6.6099e-01,\n",
      "           -9.1055e-02,  6.8560e-04],\n",
      "          [-1.1485e-02, -7.6877e-01, -2.6301e-02,  ..., -7.3076e-01,\n",
      "           -9.3866e-02, -1.0593e-01],\n",
      "          ...,\n",
      "          [-8.4877e-03, -8.2971e-01, -6.8343e-02,  ..., -6.4023e-01,\n",
      "           -7.1632e-02,  1.5093e-02],\n",
      "          [-3.4170e-02, -9.6315e-01,  3.4463e-03,  ..., -7.1958e-01,\n",
      "           -8.3527e-02,  6.2106e-02],\n",
      "          [ 8.0808e-03, -7.6983e-01, -1.2679e-01,  ..., -5.5765e-01,\n",
      "           -5.6187e-02,  3.1536e-02]],\n",
      "\n",
      "         [[ 2.3356e-01,  4.4087e-01, -1.6469e-01,  ..., -4.7763e-02,\n",
      "           -4.2471e-02,  2.6480e-01],\n",
      "          [ 8.8816e-02,  4.8159e-02,  2.0267e-03,  ...,  6.5341e-02,\n",
      "           -1.5070e-02,  8.8134e-02],\n",
      "          [ 1.8450e-01,  2.2445e-01, -1.1392e-01,  ...,  3.4587e-02,\n",
      "            1.3478e-02,  1.9708e-01],\n",
      "          ...,\n",
      "          [ 1.4305e-01,  1.0187e-01, -3.2322e-02,  ...,  8.0759e-02,\n",
      "           -2.5579e-02,  1.3192e-01],\n",
      "          [ 1.5954e-01,  1.2146e-01, -4.4760e-02,  ...,  8.3187e-02,\n",
      "           -2.7231e-02,  1.4642e-01],\n",
      "          [ 1.6211e-01,  1.2414e-01, -4.6616e-02,  ...,  8.3786e-02,\n",
      "           -2.7440e-02,  1.4860e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7447e-02,  2.0966e-02,  5.7286e-02,  ..., -1.2028e-01,\n",
      "            9.3375e-03,  2.7591e-02],\n",
      "          [ 5.8005e-02, -9.6329e-02,  2.8407e-02,  ..., -1.2038e-01,\n",
      "            6.6853e-02,  8.0574e-02],\n",
      "          [ 9.5750e-02, -2.1344e-01,  1.4635e-02,  ..., -2.0392e-01,\n",
      "            3.5708e-02,  1.6509e-01],\n",
      "          ...,\n",
      "          [ 1.3216e-02,  1.0825e-03,  3.1288e-02,  ..., -6.7815e-02,\n",
      "            1.9859e-02,  2.1756e-02],\n",
      "          [ 2.6165e-02, -3.3311e-02,  3.2907e-02,  ..., -1.1124e-01,\n",
      "            1.3007e-03,  5.2755e-02],\n",
      "          [ 1.6776e-02, -1.0253e-02,  2.9297e-02,  ..., -7.3173e-02,\n",
      "            1.8955e-02,  2.8975e-02]],\n",
      "\n",
      "         [[ 7.4720e-02,  9.5169e-03, -4.3681e-02,  ..., -5.7925e-03,\n",
      "            3.1484e-02,  1.7032e-02],\n",
      "          [ 3.7891e-02,  3.2665e-02, -4.0007e-02,  ...,  2.0122e-02,\n",
      "            5.5206e-03,  2.2651e-02],\n",
      "          [ 3.0273e-01, -4.3311e-01,  1.7084e-01,  ..., -3.4252e-01,\n",
      "            7.1604e-01, -5.8652e-01],\n",
      "          ...,\n",
      "          [ 5.3026e-02,  1.4347e-02, -3.8828e-02,  ...,  4.5159e-03,\n",
      "            2.4277e-02,  6.1748e-03],\n",
      "          [ 1.5960e-01, -1.4996e-01, -6.0847e-02,  ..., -1.2305e-01,\n",
      "            1.1865e-01, -1.4210e-01],\n",
      "          [ 1.1457e-01, -6.4229e-02, -6.0710e-02,  ..., -5.9752e-02,\n",
      "            5.6658e-02, -5.0711e-02]],\n",
      "\n",
      "         [[-1.1183e-01,  1.4213e-01, -2.5748e-03,  ..., -2.1884e-02,\n",
      "           -1.8548e-01, -3.2219e-01],\n",
      "          [-2.9745e-01,  3.6884e-01, -3.8541e-01,  ...,  3.0264e-01,\n",
      "           -3.0413e-01,  4.9414e-02],\n",
      "          [-4.6324e-02,  8.7286e-02,  8.4363e-02,  ..., -8.7185e-02,\n",
      "           -1.5002e-01, -2.8714e-01],\n",
      "          ...,\n",
      "          [-1.6112e-01,  1.2915e-01, -2.5546e-01,  ...,  1.9588e-01,\n",
      "           -5.9892e-02, -1.2536e-01],\n",
      "          [-9.7794e-02,  7.6524e-02, -1.2728e-01,  ...,  9.1188e-02,\n",
      "           -4.7040e-02, -1.7849e-01],\n",
      "          [-1.3086e-01,  6.8339e-02, -2.6221e-01,  ...,  2.0461e-01,\n",
      "            2.0106e-02, -1.1432e-01]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[ 1.0372e-01,  9.9237e-01,  9.3897e-02,  ...,  2.4751e-01,\n",
      "           -5.6354e-01,  5.1585e-02],\n",
      "          [-1.1244e+00,  1.2978e-01,  1.0239e+00,  ...,  2.3673e-01,\n",
      "            1.8014e-01,  6.4315e-01],\n",
      "          [-5.7348e-03,  3.5640e-01, -6.8688e-02,  ..., -5.1179e-01,\n",
      "            4.4124e-01,  1.2268e+00],\n",
      "          ...,\n",
      "          [ 1.7596e+00,  4.2569e-01,  1.3130e-02,  ..., -2.1059e+00,\n",
      "            9.8861e-01,  1.4973e+00],\n",
      "          [ 1.8975e+00,  3.1748e-01,  8.5821e-01,  ..., -1.4015e+00,\n",
      "            1.6141e+00,  1.0632e+00],\n",
      "          [-2.7772e-01, -9.3746e-02, -2.8170e-01,  ...,  2.5277e-01,\n",
      "            7.8727e-02, -3.3508e+00]],\n",
      "\n",
      "         [[-4.7303e-01,  1.0974e-01, -3.4936e-01,  ..., -1.9656e-01,\n",
      "           -7.2388e-01, -1.1011e+00],\n",
      "          [-6.4620e-01,  1.5043e+00,  2.5274e-01,  ...,  1.3451e+00,\n",
      "            9.1243e-01,  5.2521e-02],\n",
      "          [ 4.7719e-01,  5.9299e-01, -7.8585e-01,  ...,  2.2104e-01,\n",
      "            1.8839e+00,  7.3134e-01],\n",
      "          ...,\n",
      "          [ 1.0586e+00, -5.8265e-01, -8.6277e-01,  ..., -2.2731e-01,\n",
      "            3.6303e+00, -7.4966e-01],\n",
      "          [ 1.9343e-01,  1.7240e+00, -4.2032e-01,  ..., -5.3080e-01,\n",
      "            1.1835e+00,  7.7017e-02],\n",
      "          [ 3.6103e-01, -2.3383e-01,  6.4186e-01,  ...,  6.3414e-01,\n",
      "            1.9658e-01, -5.3646e-01]],\n",
      "\n",
      "         [[-3.5183e-01, -7.5824e-01, -1.0200e+00,  ...,  1.0588e+00,\n",
      "            2.9369e-01,  4.4521e-01],\n",
      "          [ 1.8715e+00, -2.2343e-01, -3.1050e-01,  ...,  5.8845e-01,\n",
      "            9.5597e-01, -3.6241e-01],\n",
      "          [ 1.5797e+00, -2.2727e-01,  6.5390e-01,  ...,  3.1488e-01,\n",
      "            7.9407e-01, -1.1051e+00],\n",
      "          ...,\n",
      "          [ 2.0348e+00, -8.2775e-01, -3.9194e-01,  ..., -7.8802e-01,\n",
      "            1.2197e+00, -1.9158e-01],\n",
      "          [ 2.7335e+00, -3.5507e-02, -9.9259e-01,  ..., -3.0955e-02,\n",
      "            1.8405e+00,  6.5761e-02],\n",
      "          [ 2.9702e-01,  1.2668e-01, -6.9324e-01,  ...,  5.0737e-01,\n",
      "           -1.8376e-01,  1.4646e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1052e-01, -8.9362e-01, -6.6211e-02,  ...,  1.7810e-01,\n",
      "            1.5317e+00,  6.3434e-01],\n",
      "          [-1.0335e+00,  6.2703e-01, -5.7140e-01,  ...,  6.0688e-01,\n",
      "            5.6272e-01, -1.4235e+00],\n",
      "          [ 2.2303e-01,  2.4817e+00,  1.0866e+00,  ...,  1.9783e+00,\n",
      "            1.2016e+00, -3.3905e-01],\n",
      "          ...,\n",
      "          [-2.0553e+00,  1.1250e+00, -1.1706e+00,  ..., -2.8067e-01,\n",
      "            1.3515e+00,  2.8976e+00],\n",
      "          [ 6.4808e-01,  1.8527e+00, -5.7222e-01,  ...,  7.3159e-01,\n",
      "            1.1121e+00, -5.8145e-01],\n",
      "          [ 3.8617e-01, -1.6391e+00, -7.0958e-01,  ..., -2.8630e-01,\n",
      "            1.1355e+00,  7.1356e-01]],\n",
      "\n",
      "         [[ 4.6744e-01,  1.8163e-03, -1.0267e+00,  ...,  9.5459e-01,\n",
      "           -8.3473e-01,  5.3451e-01],\n",
      "          [ 2.7016e-01,  1.1205e-02, -1.2130e-01,  ...,  1.4918e+00,\n",
      "           -8.4949e-01,  1.3122e+00],\n",
      "          [-1.5719e-01,  8.0136e-01,  1.9743e+00,  ...,  1.0189e+00,\n",
      "           -6.7806e-01,  2.0769e+00],\n",
      "          ...,\n",
      "          [-2.1722e-01,  1.2226e+00, -5.0916e-01,  ...,  1.1970e+00,\n",
      "            1.6093e-01,  2.9556e+00],\n",
      "          [ 9.0667e-02,  2.2258e+00, -1.6415e+00,  ...,  7.2556e-01,\n",
      "           -7.9955e-01,  1.5484e+00],\n",
      "          [-2.1990e-01,  5.7362e-01, -1.3288e+00,  ...,  7.7877e-01,\n",
      "           -4.7990e-01, -3.5172e+00]],\n",
      "\n",
      "         [[ 1.3890e+00, -2.0659e-01,  6.3346e-01,  ...,  5.5692e-01,\n",
      "           -3.2731e+00,  1.9569e-01],\n",
      "          [-2.4572e-01, -1.7788e-03, -8.4159e-01,  ...,  1.3769e+00,\n",
      "            9.2770e-01, -4.5605e-01],\n",
      "          [-3.2332e-01,  1.7183e-01,  7.0330e-01,  ...,  1.4565e+00,\n",
      "            9.4904e-01, -9.1933e-01],\n",
      "          ...,\n",
      "          [ 8.0756e-01,  3.0033e-01, -3.2717e-01,  ...,  1.0445e+00,\n",
      "            3.4745e-01, -2.1221e+00],\n",
      "          [ 9.8548e-01, -5.6963e-01, -5.9984e-01,  ..., -6.6952e-01,\n",
      "            4.4175e-02, -1.6366e+00],\n",
      "          [-4.3474e-01,  2.0964e-02,  1.2844e+00,  ..., -3.2492e-01,\n",
      "           -3.5718e+00, -4.9506e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1365e-01,  7.2695e-01,  4.2420e-01,  ...,  5.0209e-01,\n",
      "           -1.2426e-01, -4.1290e-02],\n",
      "          [-4.8896e-01, -5.3184e-01,  6.8802e-01,  ...,  7.2528e-01,\n",
      "           -1.3257e+00,  2.1719e-01],\n",
      "          [-5.4202e-01,  5.9295e-01, -9.5020e-01,  ...,  5.5515e-01,\n",
      "           -6.2463e-01, -5.0634e-01],\n",
      "          ...,\n",
      "          [ 1.5124e-01,  2.2827e-01, -3.3178e-01,  ...,  2.4528e-01,\n",
      "           -9.0063e-01,  6.6595e-01],\n",
      "          [ 9.3393e-01, -2.4860e-01,  6.8227e-01,  ...,  7.4195e-01,\n",
      "           -1.2557e-01,  5.0603e-01],\n",
      "          [ 9.7694e-01, -2.1445e-01,  6.4124e-01,  ...,  5.2305e-01,\n",
      "            3.5493e-02,  1.2473e+00]],\n",
      "\n",
      "         [[-9.8015e-02,  4.1183e-01, -1.0092e+00,  ..., -3.8709e-01,\n",
      "           -4.9137e-01, -1.1110e+00],\n",
      "          [ 1.0825e+00,  1.1101e+00,  1.0386e-01,  ...,  1.5087e+00,\n",
      "            5.9656e-01, -6.1272e-01],\n",
      "          [ 6.3458e-01,  9.4300e-01,  4.2384e-01,  ...,  1.0221e+00,\n",
      "            3.3985e-01, -1.3538e-01],\n",
      "          ...,\n",
      "          [ 8.6161e-03, -1.0858e-01,  1.7893e-01,  ...,  4.9170e-01,\n",
      "            1.2039e+00, -6.0928e-01],\n",
      "          [ 8.4388e-01, -1.0046e+00, -8.9464e-01,  ...,  3.2506e-01,\n",
      "            2.7836e-01, -7.3289e-01],\n",
      "          [ 7.2463e-01, -1.5162e+00, -4.1642e-01,  ...,  2.1799e-01,\n",
      "           -4.9378e-02, -1.1280e+00]],\n",
      "\n",
      "         [[ 2.5370e-01, -7.3128e-01, -8.1535e-01,  ...,  1.2431e+00,\n",
      "            9.8562e-01, -2.3272e-01],\n",
      "          [ 8.9445e-01,  8.2372e-01, -3.1762e-01,  ..., -1.8336e-01,\n",
      "            5.8840e-01, -1.7152e+00],\n",
      "          [ 1.7847e+00,  5.0534e-01, -1.2326e-01,  ..., -9.8808e-01,\n",
      "           -4.0406e-01, -1.2282e+00],\n",
      "          ...,\n",
      "          [ 9.4668e-01, -5.7013e-01,  3.6016e-01,  ..., -7.0171e-01,\n",
      "           -8.7286e-01, -1.3093e-01],\n",
      "          [ 1.2468e+00, -3.4852e-01,  1.3580e-01,  ..., -1.2921e+00,\n",
      "           -3.3420e-01, -1.0313e-02],\n",
      "          [ 1.0172e+00, -1.8637e-01, -9.6680e-02,  ..., -1.3448e+00,\n",
      "           -4.8191e-01,  2.0804e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5793e-01, -6.6994e-01,  2.2647e-01,  ...,  1.0696e-01,\n",
      "            1.8023e+00,  6.0805e-01],\n",
      "          [-2.0818e+00,  7.4889e-01, -1.2772e+00,  ..., -1.8353e+00,\n",
      "            1.4904e+00, -5.8914e-01],\n",
      "          [-1.1315e+00,  1.4913e+00, -1.1855e+00,  ...,  1.8490e+00,\n",
      "            2.5610e+00,  6.7870e-01],\n",
      "          ...,\n",
      "          [ 3.5348e-01,  2.9760e+00, -3.7730e-01,  ..., -9.8931e-02,\n",
      "            2.5946e+00,  1.0891e+00],\n",
      "          [ 5.1469e-03,  2.6982e+00, -3.2162e-01,  ...,  1.3599e-02,\n",
      "            3.4884e+00,  6.4334e-01],\n",
      "          [-1.2776e-01,  1.7680e+00,  3.3869e-01,  ..., -3.3860e-01,\n",
      "            2.8281e+00,  8.0912e-01]],\n",
      "\n",
      "         [[ 1.0254e-01,  1.2311e-01, -1.0853e+00,  ...,  6.1453e-01,\n",
      "           -6.7444e-01,  7.8344e-01],\n",
      "          [-1.4892e+00, -1.4911e+00, -3.1084e-01,  ..., -1.9783e-01,\n",
      "           -1.8888e-01,  6.5497e-01],\n",
      "          [-1.0959e+00,  1.5773e+00, -4.1384e-01,  ...,  1.9504e+00,\n",
      "            4.2873e-01,  1.3040e+00],\n",
      "          ...,\n",
      "          [-9.4526e-01,  8.8880e-01, -5.8298e-01,  ...,  9.7585e-01,\n",
      "           -5.4410e-01,  2.4338e+00],\n",
      "          [-4.9150e-01,  2.2026e+00, -8.1743e-01,  ...,  2.8094e-01,\n",
      "           -1.3208e+00,  2.9064e+00],\n",
      "          [-1.5234e-01,  1.6635e+00, -1.2326e+00,  ..., -2.2048e-01,\n",
      "           -1.3316e+00,  3.3093e+00]],\n",
      "\n",
      "         [[ 1.3129e+00, -7.6047e-01,  6.9280e-01,  ...,  9.1525e-01,\n",
      "           -2.8095e+00,  2.1548e-01],\n",
      "          [-1.0097e+00,  6.4094e-02, -1.1788e+00,  ...,  2.6254e-01,\n",
      "            6.0854e-01, -4.7468e-01],\n",
      "          [-8.0169e-01, -3.5547e-01,  7.7983e-02,  ...,  1.6789e+00,\n",
      "            5.2301e-02,  4.5724e-01],\n",
      "          ...,\n",
      "          [-3.6614e-01, -1.0824e+00,  5.8073e-01,  ...,  8.8415e-01,\n",
      "           -4.0804e-01,  2.1441e-01],\n",
      "          [-1.0623e-01, -6.4082e-01, -1.0123e-01,  ...,  7.4923e-01,\n",
      "           -4.3334e-01,  5.6438e-01],\n",
      "          [-5.1599e-01, -1.0436e+00,  8.1668e-02,  ...,  1.2976e-01,\n",
      "           -4.0982e-01,  3.6019e-01]]]], grad_fn=<PermuteBackward0>), query layer: tensor([[[[-3.4523e-01, -6.7976e-01, -1.6201e+00,  ..., -5.8677e-01,\n",
      "            1.8650e-01, -2.1413e+00],\n",
      "          [-6.1888e-01,  5.1456e-01, -1.0698e+00,  ...,  3.3333e-01,\n",
      "            3.8527e-01, -2.3562e+00],\n",
      "          [ 8.6120e-01, -3.9680e-02, -1.2300e-02,  ...,  5.6016e-01,\n",
      "            5.6363e-01, -1.7415e+00],\n",
      "          ...,\n",
      "          [ 1.7452e+00, -1.4336e-01, -6.1095e-01,  ...,  3.1236e-01,\n",
      "           -4.3934e-01, -2.8630e+00],\n",
      "          [ 1.4393e+00, -1.2283e+00, -6.3960e-01,  ...,  7.4554e-01,\n",
      "            2.2728e-01, -2.0647e+00],\n",
      "          [-4.3350e-01, -2.9474e-02, -2.0203e-02,  ...,  2.9854e-01,\n",
      "            3.3701e-01, -2.3642e+00]],\n",
      "\n",
      "         [[ 1.0523e+00, -6.3418e-02,  9.3528e-01,  ...,  8.0876e-01,\n",
      "           -3.1713e-01,  6.2049e-01],\n",
      "          [ 9.2198e-01, -3.7138e-01,  1.0922e+00,  ...,  5.3820e-01,\n",
      "            7.1061e-01,  8.9389e-01],\n",
      "          [-4.1496e-01,  1.4744e+00,  2.0612e-01,  ...,  2.7209e+00,\n",
      "            2.9758e-01,  1.2738e+00],\n",
      "          ...,\n",
      "          [ 6.2688e-01, -1.0140e+00,  2.5465e-01,  ...,  3.5947e-01,\n",
      "            1.2131e+00,  8.9663e-01],\n",
      "          [ 2.5349e+00,  1.6214e-01, -8.1464e-01,  ..., -1.9648e-01,\n",
      "            1.2010e+00,  6.8038e-01],\n",
      "          [ 1.0276e+00, -1.9403e-01,  1.0859e+00,  ...,  8.5415e-01,\n",
      "            5.6227e-01, -5.7692e-01]],\n",
      "\n",
      "         [[-2.9100e-01, -1.8471e-01, -8.6212e-01,  ..., -5.5449e-02,\n",
      "           -4.5114e-01,  4.3061e-01],\n",
      "          [ 4.3849e-01, -1.2653e+00,  2.1354e-01,  ..., -9.3031e-01,\n",
      "           -7.6121e-01,  1.6506e+00],\n",
      "          [-2.6217e-01, -9.8028e-01,  1.5300e-01,  ..., -9.4255e-01,\n",
      "           -1.1845e+00,  8.0289e-01],\n",
      "          ...,\n",
      "          [ 1.0438e+00, -1.1175e+00,  1.4879e-01,  ...,  2.4122e-01,\n",
      "           -1.7543e+00,  4.4860e-01],\n",
      "          [-4.9030e-01, -5.3086e-01, -5.7083e-01,  ...,  4.9814e-01,\n",
      "           -2.6922e+00,  7.7261e-01],\n",
      "          [-1.3520e+00, -8.0962e-01, -2.3833e+00,  ...,  1.6698e-01,\n",
      "           -1.8063e+00,  1.7470e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1047e-01,  1.0152e+00, -9.4713e-01,  ..., -2.9635e-01,\n",
      "            8.0748e-01, -1.6430e+00],\n",
      "          [ 1.0479e-01,  6.4693e-01,  1.2611e+00,  ...,  1.8558e+00,\n",
      "            1.1427e+00,  9.7993e-01],\n",
      "          [-6.8163e-01,  9.2252e-02, -1.7028e+00,  ...,  9.7761e-01,\n",
      "            1.8850e+00,  2.3623e+00],\n",
      "          ...,\n",
      "          [ 1.6589e+00,  1.1213e-01, -9.7149e-01,  ..., -1.1181e+00,\n",
      "            7.2224e-01,  1.5100e+00],\n",
      "          [ 4.5104e-01, -1.6679e+00, -1.2561e+00,  ...,  5.3616e-01,\n",
      "            2.3388e+00,  2.2097e+00],\n",
      "          [-1.3814e-01, -5.8114e-01, -2.5001e-02,  ...,  1.1632e-01,\n",
      "            8.7211e-01,  7.4689e-01]],\n",
      "\n",
      "         [[ 1.0302e-01, -8.6401e-01, -5.7074e-01,  ...,  3.1338e-01,\n",
      "            1.3050e+00, -2.1198e+00],\n",
      "          [ 7.1977e-01, -3.3536e-01, -5.4109e-01,  ...,  9.7929e-01,\n",
      "            5.0284e-02, -1.9524e+00],\n",
      "          [ 1.2176e+00,  5.5233e-02,  3.4838e-02,  ...,  1.9871e+00,\n",
      "           -2.5415e-01, -1.9111e+00],\n",
      "          ...,\n",
      "          [ 1.8142e+00,  1.6257e+00,  6.7235e-01,  ...,  4.4090e-01,\n",
      "           -1.5270e+00, -9.3240e-01],\n",
      "          [ 5.0884e-01,  1.5247e+00, -7.7136e-01,  ...,  3.2380e-02,\n",
      "           -9.2188e-01, -1.9995e+00],\n",
      "          [ 1.7634e-01,  3.7310e-01, -1.1213e+00,  ...,  4.3668e-01,\n",
      "           -1.4931e-01, -1.6863e+00]],\n",
      "\n",
      "         [[-4.5883e-01,  1.1371e+00, -2.6494e-01,  ...,  2.4334e-01,\n",
      "           -9.8755e-01, -6.2421e-01],\n",
      "          [-5.8903e-01,  5.3670e-02,  9.1724e-01,  ...,  4.6332e-01,\n",
      "           -2.4886e+00, -6.9396e-01],\n",
      "          [ 8.7352e-03, -3.1864e-01,  3.9738e-01,  ...,  1.1399e+00,\n",
      "           -3.8308e+00, -5.9583e-01],\n",
      "          ...,\n",
      "          [-1.0845e+00, -3.8073e-01,  9.4346e-01,  ...,  1.5589e+00,\n",
      "           -4.3449e+00, -3.1131e+00],\n",
      "          [-3.3098e-01,  3.0777e+00,  1.2227e+00,  ..., -3.3377e-01,\n",
      "           -2.2893e+00, -1.8800e+00],\n",
      "          [-1.0868e+00, -1.6406e-01,  3.4442e-01,  ..., -4.0454e-01,\n",
      "           -2.0612e+00, -1.0914e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5409e-01, -6.8448e-01, -1.8686e+00,  ..., -3.1123e-01,\n",
      "            6.3449e-01, -2.6174e+00],\n",
      "          [-4.4728e-01,  4.1495e-02,  6.5719e-01,  ..., -6.6916e-01,\n",
      "            1.6397e+00, -8.3796e-01],\n",
      "          [ 5.9203e-01, -9.6052e-01, -5.1294e-01,  ...,  1.0197e+00,\n",
      "            7.4375e-01, -8.1215e-01],\n",
      "          ...,\n",
      "          [ 1.5474e+00, -1.6495e+00,  3.0063e-01,  ...,  4.1014e-01,\n",
      "            1.1197e-01, -2.8113e+00],\n",
      "          [ 1.8380e+00, -1.4194e+00, -1.1257e-01,  ...,  1.0846e+00,\n",
      "            6.2197e-01, -2.6004e+00],\n",
      "          [ 2.0181e+00, -1.4080e+00,  1.0048e-01,  ...,  7.8142e-01,\n",
      "            2.1387e-01, -2.6488e+00]],\n",
      "\n",
      "         [[ 7.6219e-01, -1.1435e+00,  8.5432e-01,  ...,  5.2486e-02,\n",
      "            1.4711e-01,  1.2846e+00],\n",
      "          [ 3.4419e-01,  5.6402e-01,  7.6250e-01,  ...,  1.6172e+00,\n",
      "            1.5545e+00,  1.4779e+00],\n",
      "          [-6.1485e-02,  3.0903e-01,  1.5107e+00,  ...,  2.3377e+00,\n",
      "            8.8234e-01, -1.3290e-01],\n",
      "          ...,\n",
      "          [ 9.7943e-02, -8.9099e-01,  3.1567e-01,  ...,  2.9796e-01,\n",
      "            1.3801e+00,  1.5964e+00],\n",
      "          [ 4.9551e-02, -1.3019e+00,  4.5541e-01,  ..., -3.5142e-01,\n",
      "            1.8261e+00,  1.4389e+00],\n",
      "          [ 1.4904e-01, -1.7396e+00,  2.1253e-02,  ..., -4.9883e-01,\n",
      "            1.7512e+00,  1.0963e+00]],\n",
      "\n",
      "         [[-8.6060e-01, -4.5640e-01, -7.9947e-01,  ...,  2.4849e-01,\n",
      "           -8.2607e-01,  1.1024e+00],\n",
      "          [-4.5203e-01, -8.4555e-01, -3.8927e-01,  ..., -5.2350e-01,\n",
      "           -1.2040e+00,  5.9376e-01],\n",
      "          [ 1.0025e-01, -8.3941e-01, -2.0672e+00,  ...,  6.2266e-01,\n",
      "           -1.9042e+00,  1.5516e+00],\n",
      "          ...,\n",
      "          [ 1.9238e-01, -8.4392e-01,  1.3714e-01,  ...,  2.8668e-01,\n",
      "           -1.4894e-02,  3.7704e-01],\n",
      "          [-3.5566e-01, -1.0474e+00, -4.8566e-01,  ...,  7.8819e-01,\n",
      "           -4.5879e-01,  6.1694e-01],\n",
      "          [ 7.1520e-02, -7.0583e-01,  1.6214e-02,  ...,  4.7450e-01,\n",
      "           -2.5624e-01, -1.3011e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.0010e-01,  3.4780e-01, -1.5506e+00,  ..., -9.8452e-02,\n",
      "            8.8025e-01, -5.6561e-01],\n",
      "          [-7.1338e-01,  4.9700e-01, -1.7503e+00,  ...,  2.8381e+00,\n",
      "           -4.0808e-02,  7.8442e-01],\n",
      "          [-3.6536e-01,  8.3415e-01, -1.5887e+00,  ...,  5.7690e-01,\n",
      "            1.6643e+00,  9.1253e-02],\n",
      "          ...,\n",
      "          [-5.0630e-01, -9.1988e-02, -2.2212e+00,  ...,  1.5163e-01,\n",
      "            6.7219e-01, -2.5611e-01],\n",
      "          [-1.5938e-01, -1.0061e+00, -1.3970e+00,  ..., -3.3748e-01,\n",
      "            1.2808e+00, -3.6699e-01],\n",
      "          [-4.4881e-01, -1.6134e+00, -1.4026e+00,  ..., -4.8248e-01,\n",
      "            2.8382e-01, -8.2333e-01]],\n",
      "\n",
      "         [[ 5.4065e-02, -6.8406e-01,  2.8828e-02,  ...,  5.9724e-01,\n",
      "            9.9982e-01, -2.0506e+00],\n",
      "          [ 7.6658e-01,  5.3656e-01, -1.0826e+00,  ...,  4.6067e-01,\n",
      "           -3.9222e-01, -1.9167e+00],\n",
      "          [-2.1809e-01, -1.6924e+00,  1.3171e-01,  ..., -4.0108e-01,\n",
      "            6.5913e-01, -1.2450e+00],\n",
      "          ...,\n",
      "          [-2.4445e-01,  9.9394e-01, -3.5395e-01,  ...,  1.2252e+00,\n",
      "            9.0729e-01, -3.5212e+00],\n",
      "          [-6.1588e-01,  9.4532e-01, -3.8430e-01,  ...,  5.2407e-01,\n",
      "            9.1801e-02, -2.4291e+00],\n",
      "          [-7.9855e-02,  1.6222e+00, -6.4528e-01,  ..., -2.0304e-01,\n",
      "           -5.0160e-01, -2.7615e+00]],\n",
      "\n",
      "         [[-8.4477e-01,  8.6244e-01,  2.1943e-01,  ...,  2.4317e-01,\n",
      "           -1.8973e+00, -2.4783e-01],\n",
      "          [-1.6404e+00,  2.4604e-01,  3.5397e-01,  ...,  9.0424e-01,\n",
      "           -1.8207e+00,  7.2524e-01],\n",
      "          [-1.7334e-01,  4.8278e-01, -9.6796e-01,  ..., -1.8959e-01,\n",
      "           -1.2644e+00,  2.1390e-01],\n",
      "          ...,\n",
      "          [-1.0422e+00,  5.0613e-02,  1.4314e+00,  ...,  4.7159e-01,\n",
      "           -1.6895e+00,  8.6067e-02],\n",
      "          [-1.4621e+00,  8.4796e-01,  1.4299e+00,  ...,  2.8598e-01,\n",
      "           -2.1630e+00,  1.7334e-02],\n",
      "          [-1.5139e+00,  7.8396e-01,  1.8093e+00,  ..., -1.4231e-01,\n",
      "           -2.3853e+00,  2.4511e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[-1.1615e-01, -8.9210e-01, -1.9544e-01,  ..., -1.4871e+00,\n",
      "           -2.2895e-01,  2.3990e+00],\n",
      "          [ 7.5658e-01,  7.8334e-01,  5.8806e-02,  ...,  2.2463e+00,\n",
      "            1.9168e+00,  1.9253e+00],\n",
      "          [ 2.5404e-01,  4.5461e-01,  1.8775e-01,  ...,  2.9741e+00,\n",
      "            3.2367e+00,  2.0199e+00],\n",
      "          ...,\n",
      "          [ 1.7672e+00, -9.1601e-01,  3.4122e-01,  ...,  2.6827e-01,\n",
      "            1.7882e+00,  4.4687e+00],\n",
      "          [ 6.6398e-01, -1.8744e+00, -5.1607e-01,  ..., -9.2238e-01,\n",
      "            8.0462e-01,  2.7629e+00],\n",
      "          [ 9.6010e-01, -6.5979e-01, -9.0318e-01,  ..., -1.4999e+00,\n",
      "            6.7364e-01,  4.6517e+00]],\n",
      "\n",
      "         [[ 7.3351e-01,  8.6305e-01,  6.9386e-01,  ..., -1.3122e+00,\n",
      "            1.7636e+00,  3.8378e+00],\n",
      "          [ 1.3795e+00,  2.7869e+00,  2.4088e+00,  ..., -3.4391e-01,\n",
      "            1.0442e+00,  6.1545e+00],\n",
      "          [ 1.9409e+00,  5.5587e+00,  2.7472e+00,  ..., -5.9867e-01,\n",
      "           -2.1755e-01,  5.7332e+00],\n",
      "          ...,\n",
      "          [ 2.1003e+00,  5.0053e+00,  3.5230e+00,  ...,  6.1638e-01,\n",
      "           -1.1174e-01,  6.5194e+00],\n",
      "          [ 3.0253e+00,  1.6909e+00,  2.2685e+00,  ..., -4.8770e-02,\n",
      "            1.8258e+00,  5.0080e+00],\n",
      "          [ 1.3586e+00,  1.7408e+00,  6.3720e-01,  ..., -3.4881e-01,\n",
      "            5.3948e-01,  6.3502e+00]],\n",
      "\n",
      "         [[ 3.4937e-01, -1.0002e+00, -2.0328e+00,  ..., -2.8762e+00,\n",
      "           -1.7428e+00,  2.0323e+00],\n",
      "          [ 6.5258e-01,  2.7100e-01,  7.4551e-01,  ..., -2.5062e-01,\n",
      "           -4.7455e-02,  7.3078e-01],\n",
      "          [ 1.2128e+00,  2.0917e-01,  4.8035e-01,  ..., -1.3811e-01,\n",
      "            1.1611e-01,  1.2360e+00],\n",
      "          ...,\n",
      "          [ 4.1218e-01,  9.4128e-01,  1.4122e+00,  ..., -2.1276e-01,\n",
      "           -2.0370e-01,  2.1038e+00],\n",
      "          [ 1.2906e+00,  1.3108e+00,  4.5243e-01,  ..., -1.3782e+00,\n",
      "           -1.1440e+00,  3.4154e+00],\n",
      "          [ 1.8070e+00, -5.0595e-01, -1.8810e+00,  ..., -2.3765e+00,\n",
      "           -1.4187e+00,  4.8301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7947e-01,  9.7843e-01, -1.0580e+00,  ..., -1.5856e+00,\n",
      "            1.3835e-04,  2.5244e+00],\n",
      "          [-7.6305e-01,  5.3699e-01,  6.3660e+00,  ...,  1.7525e+00,\n",
      "            1.1597e+00,  2.3733e+00],\n",
      "          [-5.6039e-01,  6.2919e-01,  7.9914e-01,  ...,  7.4546e+00,\n",
      "            4.4394e+00,  2.4552e+00],\n",
      "          ...,\n",
      "          [ 1.1530e+00,  9.8199e-01,  1.1084e+00,  ...,  1.6425e+00,\n",
      "            5.7811e+00,  3.8857e+00],\n",
      "          [ 2.1837e+00, -1.0168e+00, -6.4832e-01,  ..., -8.9048e-01,\n",
      "            1.2036e+00,  4.8383e+00],\n",
      "          [ 3.3683e+00, -1.3828e+00, -1.0052e+00,  ..., -1.6178e+00,\n",
      "           -5.5913e-01,  3.8676e+00]],\n",
      "\n",
      "         [[-2.8527e-01, -1.1980e-01,  6.3167e-01,  ...,  4.5557e-01,\n",
      "            1.3929e+00,  2.7050e+00],\n",
      "          [ 2.1350e+00,  8.2827e-01,  1.6500e+00,  ...,  9.4766e-02,\n",
      "            2.6485e+00,  4.3827e+00],\n",
      "          [ 2.3062e+00,  4.9825e+00,  2.0699e+00,  ...,  2.0765e-01,\n",
      "            1.6717e+00,  2.8190e+00],\n",
      "          ...,\n",
      "          [ 3.0798e+00,  3.9547e+00,  4.8194e+00,  ...,  2.0013e+00,\n",
      "            2.5542e+00,  3.5069e+00],\n",
      "          [ 1.9807e+00,  3.2286e+00,  4.1295e+00,  ...,  2.4658e+00,\n",
      "            2.4035e+00,  2.7566e+00],\n",
      "          [ 6.0429e-01, -5.6782e-01, -7.4074e-01,  ..., -9.3947e-01,\n",
      "            4.9735e-01,  4.4651e+00]],\n",
      "\n",
      "         [[ 1.0987e+00,  7.1837e-01, -2.5142e-01,  ..., -1.7825e+00,\n",
      "            8.1387e-01,  4.2825e+00],\n",
      "          [ 2.0395e+00,  1.9679e+00,  3.3553e+00,  ...,  2.7566e+00,\n",
      "            3.5221e+00,  4.0374e+00],\n",
      "          [ 1.6721e+00,  1.5602e+00,  1.2849e+00,  ...,  1.0669e+00,\n",
      "            2.8114e+00,  4.5025e+00],\n",
      "          ...,\n",
      "          [ 1.3173e+00,  1.1060e+00,  7.2760e-01,  ...,  1.0580e+00,\n",
      "            7.2845e-01,  5.8319e+00],\n",
      "          [ 1.8441e+00,  1.2202e+00,  6.3375e-01,  ...,  1.2430e+00,\n",
      "            1.7814e+00,  5.3056e+00],\n",
      "          [ 2.8568e-01, -4.3823e-01, -7.1402e-01,  ..., -6.6729e-01,\n",
      "           -2.2892e-01,  4.5024e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2794e-01, -1.2774e-01,  5.8077e-01,  ...,  1.7849e+00,\n",
      "            1.5205e+00,  1.3384e+00],\n",
      "          [ 1.2521e+00,  9.2392e-01,  8.1996e-01,  ...,  2.3997e+00,\n",
      "            1.6399e+00,  9.8981e-01],\n",
      "          [ 6.2399e-01,  9.8062e-01,  9.8224e-01,  ...,  3.1396e+00,\n",
      "            3.7239e+00,  3.1101e+00],\n",
      "          ...,\n",
      "          [ 8.9054e-01,  1.0040e-01,  4.8034e-01,  ...,  1.5313e+00,\n",
      "            3.4369e+00,  2.8683e+00],\n",
      "          [ 1.0204e+00, -7.1934e-01, -5.6381e-01,  ...,  1.0836e+00,\n",
      "            3.2659e+00,  3.7011e+00],\n",
      "          [ 8.8374e-01, -8.4537e-01, -1.5728e+00,  ...,  1.8133e-01,\n",
      "            2.0909e+00,  2.7301e+00]],\n",
      "\n",
      "         [[ 1.1233e+00,  3.5053e+00,  1.6360e+00,  ...,  2.1085e+00,\n",
      "            1.8367e+00,  1.2714e+00],\n",
      "          [ 7.3877e-01,  1.3950e+00,  1.1964e+00,  ...,  1.6619e+00,\n",
      "            2.2422e-01, -2.7413e-01],\n",
      "          [ 2.1746e+00,  4.2894e+00,  2.9809e+00,  ...,  2.9297e+00,\n",
      "            2.0969e+00,  1.0346e+00],\n",
      "          ...,\n",
      "          [ 9.3527e-01,  2.3582e+00,  3.2064e+00,  ...,  2.2255e+00,\n",
      "            2.0394e+00,  6.8719e-01],\n",
      "          [ 1.7471e+00,  2.1842e+00,  3.5491e+00,  ...,  3.7730e+00,\n",
      "            4.3064e+00,  2.9543e+00],\n",
      "          [ 1.6114e+00,  1.4020e+00,  2.3206e+00,  ...,  2.7644e+00,\n",
      "            3.8472e+00,  3.0411e+00]],\n",
      "\n",
      "         [[ 9.4636e-03, -1.6259e+00,  4.8753e-01,  ...,  9.6969e-01,\n",
      "            1.8592e+00,  1.5463e+00],\n",
      "          [ 5.5553e-01, -3.5676e-01,  1.4441e+00,  ...,  2.5370e-01,\n",
      "            6.2358e-01,  6.9932e-02],\n",
      "          [ 2.3274e+00,  2.9308e-01,  5.8960e-01,  ...,  1.5912e+00,\n",
      "            1.7073e+00,  1.6095e+00],\n",
      "          ...,\n",
      "          [ 1.1941e+00,  4.6220e-01,  1.7562e+00,  ...,  6.0593e-01,\n",
      "            1.2917e+00,  7.7102e-01],\n",
      "          [ 1.8360e+00,  4.1116e-01,  2.0566e+00,  ...,  1.2204e+00,\n",
      "            1.4573e+00,  1.1571e+00],\n",
      "          [ 1.0346e+00,  9.0452e-01,  2.1245e+00,  ...,  1.0696e+00,\n",
      "            1.5785e+00,  1.1235e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0544e+00,  1.6477e+00,  9.3508e-01,  ...,  2.8616e+00,\n",
      "            2.2142e+00,  1.7021e+00],\n",
      "          [ 3.9398e+00, -1.8890e+00,  8.1811e+00,  ...,  2.1472e+00,\n",
      "            2.9575e+00,  7.9805e-01],\n",
      "          [ 4.5111e-01,  2.1057e+00,  1.4268e+00,  ...,  5.4024e+00,\n",
      "            4.0356e+00,  3.4042e+00],\n",
      "          ...,\n",
      "          [ 2.0093e+00, -2.1138e-01,  2.1963e+00,  ...,  2.6116e+00,\n",
      "            4.9261e+00,  3.1267e+00],\n",
      "          [ 1.5448e+00, -8.0847e-01, -3.8894e-01,  ...,  2.3810e+00,\n",
      "            5.0333e+00,  5.2395e+00],\n",
      "          [ 1.8965e+00, -2.3775e+00, -6.3030e-01,  ...,  3.2140e-01,\n",
      "            3.9664e+00,  4.3022e+00]],\n",
      "\n",
      "         [[ 9.4932e-01,  1.9175e+00,  1.8295e+00,  ...,  1.5708e+00,\n",
      "            1.7990e+00,  8.7857e-01],\n",
      "          [ 3.6831e+00,  1.2386e+00,  2.6830e+00,  ...,  1.9268e+00,\n",
      "            1.1145e+00, -2.1847e-01],\n",
      "          [ 4.2569e-01,  3.7578e+00,  1.5425e+00,  ...,  1.7817e+00,\n",
      "            2.1840e-01, -6.6603e-01],\n",
      "          ...,\n",
      "          [ 2.4601e+00,  1.9841e+00,  4.8874e+00,  ...,  2.6130e+00,\n",
      "            2.6308e+00,  5.7498e-01],\n",
      "          [ 1.3483e+00,  1.9785e+00,  3.1386e+00,  ...,  3.5662e+00,\n",
      "            3.9104e+00,  2.1026e+00],\n",
      "          [ 1.4055e+00,  1.0210e+00,  2.4698e+00,  ...,  3.1312e+00,\n",
      "            4.8020e+00,  3.2380e+00]],\n",
      "\n",
      "         [[ 1.2982e+00,  1.3536e-01,  1.0208e+00,  ...,  7.9669e-01,\n",
      "            1.4283e+00,  7.6459e-01],\n",
      "          [ 2.2692e+00,  1.0348e+00,  3.4688e+00,  ...,  2.2223e+00,\n",
      "            2.9553e+00,  2.0687e+00],\n",
      "          [ 1.5001e+00,  1.2307e-01,  2.1221e+00,  ...,  4.7786e-01,\n",
      "            1.7372e+00,  1.5524e+00],\n",
      "          ...,\n",
      "          [ 7.4120e-01, -4.1229e-02,  1.9043e+00,  ...,  1.2500e+00,\n",
      "            2.5912e+00,  1.8864e+00],\n",
      "          [ 5.1648e-01, -4.7364e-02,  1.1619e+00,  ...,  4.6461e-01,\n",
      "            1.8636e+00,  1.4472e+00],\n",
      "          [ 4.8059e-01, -3.0515e-01,  8.2455e-01,  ...,  3.1691e-01,\n",
      "            1.4401e+00,  1.1342e+00]]]], grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[-1.1615e-01, -8.9210e-01, -1.9544e-01,  ..., -1.4871e+00,\n",
      "           -2.2895e-01,  2.3990e+00],\n",
      "          [ 7.5658e-01,  7.8334e-01,  5.8806e-02,  ...,  2.2463e+00,\n",
      "            1.9168e+00,  1.9253e+00],\n",
      "          [ 2.5404e-01,  4.5461e-01,  1.8775e-01,  ...,  2.9741e+00,\n",
      "            3.2367e+00,  2.0199e+00],\n",
      "          ...,\n",
      "          [ 1.7672e+00, -9.1601e-01,  3.4122e-01,  ...,  2.6827e-01,\n",
      "            1.7882e+00,  4.4687e+00],\n",
      "          [ 6.6398e-01, -1.8744e+00, -5.1607e-01,  ..., -9.2238e-01,\n",
      "            8.0462e-01,  2.7629e+00],\n",
      "          [ 9.6010e-01, -6.5979e-01, -9.0318e-01,  ..., -1.4999e+00,\n",
      "            6.7364e-01,  4.6517e+00]],\n",
      "\n",
      "         [[ 7.3351e-01,  8.6305e-01,  6.9386e-01,  ..., -1.3122e+00,\n",
      "            1.7636e+00,  3.8378e+00],\n",
      "          [ 1.3795e+00,  2.7869e+00,  2.4088e+00,  ..., -3.4391e-01,\n",
      "            1.0442e+00,  6.1545e+00],\n",
      "          [ 1.9409e+00,  5.5587e+00,  2.7472e+00,  ..., -5.9867e-01,\n",
      "           -2.1755e-01,  5.7332e+00],\n",
      "          ...,\n",
      "          [ 2.1003e+00,  5.0053e+00,  3.5230e+00,  ...,  6.1638e-01,\n",
      "           -1.1174e-01,  6.5194e+00],\n",
      "          [ 3.0253e+00,  1.6909e+00,  2.2685e+00,  ..., -4.8770e-02,\n",
      "            1.8258e+00,  5.0080e+00],\n",
      "          [ 1.3586e+00,  1.7408e+00,  6.3720e-01,  ..., -3.4881e-01,\n",
      "            5.3948e-01,  6.3502e+00]],\n",
      "\n",
      "         [[ 3.4937e-01, -1.0002e+00, -2.0328e+00,  ..., -2.8762e+00,\n",
      "           -1.7428e+00,  2.0323e+00],\n",
      "          [ 6.5258e-01,  2.7100e-01,  7.4551e-01,  ..., -2.5062e-01,\n",
      "           -4.7455e-02,  7.3078e-01],\n",
      "          [ 1.2128e+00,  2.0917e-01,  4.8035e-01,  ..., -1.3811e-01,\n",
      "            1.1611e-01,  1.2360e+00],\n",
      "          ...,\n",
      "          [ 4.1218e-01,  9.4128e-01,  1.4122e+00,  ..., -2.1276e-01,\n",
      "           -2.0370e-01,  2.1038e+00],\n",
      "          [ 1.2906e+00,  1.3108e+00,  4.5243e-01,  ..., -1.3782e+00,\n",
      "           -1.1440e+00,  3.4154e+00],\n",
      "          [ 1.8070e+00, -5.0595e-01, -1.8810e+00,  ..., -2.3765e+00,\n",
      "           -1.4187e+00,  4.8301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7947e-01,  9.7843e-01, -1.0580e+00,  ..., -1.5856e+00,\n",
      "            1.3835e-04,  2.5244e+00],\n",
      "          [-7.6305e-01,  5.3699e-01,  6.3660e+00,  ...,  1.7525e+00,\n",
      "            1.1597e+00,  2.3733e+00],\n",
      "          [-5.6039e-01,  6.2919e-01,  7.9914e-01,  ...,  7.4546e+00,\n",
      "            4.4394e+00,  2.4552e+00],\n",
      "          ...,\n",
      "          [ 1.1530e+00,  9.8199e-01,  1.1084e+00,  ...,  1.6425e+00,\n",
      "            5.7811e+00,  3.8857e+00],\n",
      "          [ 2.1837e+00, -1.0168e+00, -6.4832e-01,  ..., -8.9048e-01,\n",
      "            1.2036e+00,  4.8383e+00],\n",
      "          [ 3.3683e+00, -1.3828e+00, -1.0052e+00,  ..., -1.6178e+00,\n",
      "           -5.5913e-01,  3.8676e+00]],\n",
      "\n",
      "         [[-2.8527e-01, -1.1980e-01,  6.3167e-01,  ...,  4.5557e-01,\n",
      "            1.3929e+00,  2.7050e+00],\n",
      "          [ 2.1350e+00,  8.2827e-01,  1.6500e+00,  ...,  9.4766e-02,\n",
      "            2.6485e+00,  4.3827e+00],\n",
      "          [ 2.3062e+00,  4.9825e+00,  2.0699e+00,  ...,  2.0765e-01,\n",
      "            1.6717e+00,  2.8190e+00],\n",
      "          ...,\n",
      "          [ 3.0798e+00,  3.9547e+00,  4.8194e+00,  ...,  2.0013e+00,\n",
      "            2.5542e+00,  3.5069e+00],\n",
      "          [ 1.9807e+00,  3.2286e+00,  4.1295e+00,  ...,  2.4658e+00,\n",
      "            2.4035e+00,  2.7566e+00],\n",
      "          [ 6.0429e-01, -5.6782e-01, -7.4074e-01,  ..., -9.3947e-01,\n",
      "            4.9735e-01,  4.4651e+00]],\n",
      "\n",
      "         [[ 1.0987e+00,  7.1837e-01, -2.5142e-01,  ..., -1.7825e+00,\n",
      "            8.1387e-01,  4.2825e+00],\n",
      "          [ 2.0395e+00,  1.9679e+00,  3.3553e+00,  ...,  2.7566e+00,\n",
      "            3.5221e+00,  4.0374e+00],\n",
      "          [ 1.6721e+00,  1.5602e+00,  1.2849e+00,  ...,  1.0669e+00,\n",
      "            2.8114e+00,  4.5025e+00],\n",
      "          ...,\n",
      "          [ 1.3173e+00,  1.1060e+00,  7.2760e-01,  ...,  1.0580e+00,\n",
      "            7.2845e-01,  5.8319e+00],\n",
      "          [ 1.8441e+00,  1.2202e+00,  6.3375e-01,  ...,  1.2430e+00,\n",
      "            1.7814e+00,  5.3056e+00],\n",
      "          [ 2.8568e-01, -4.3823e-01, -7.1402e-01,  ..., -6.6729e-01,\n",
      "           -2.2892e-01,  4.5024e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2794e-01, -1.2774e-01,  5.8077e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.2521e+00,  9.2392e-01,  8.1996e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.2399e-01,  9.8062e-01,  9.8224e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 8.9054e-01,  1.0040e-01,  4.8034e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0204e+00, -7.1934e-01, -5.6381e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 8.8374e-01, -8.4537e-01, -1.5728e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.1233e+00,  3.5053e+00,  1.6360e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.3877e-01,  1.3950e+00,  1.1964e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.1746e+00,  4.2894e+00,  2.9809e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 9.3527e-01,  2.3582e+00,  3.2064e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.7471e+00,  2.1842e+00,  3.5491e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.6114e+00,  1.4020e+00,  2.3206e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 9.4636e-03, -1.6259e+00,  4.8753e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.5553e-01, -3.5676e-01,  1.4441e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.3274e+00,  2.9308e-01,  5.8960e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.1941e+00,  4.6220e-01,  1.7562e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.8360e+00,  4.1116e-01,  2.0566e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0346e+00,  9.0452e-01,  2.1245e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0544e+00,  1.6477e+00,  9.3508e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.9398e+00, -1.8890e+00,  8.1811e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.5111e-01,  2.1057e+00,  1.4268e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.0093e+00, -2.1138e-01,  2.1963e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.5448e+00, -8.0847e-01, -3.8894e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.8965e+00, -2.3775e+00, -6.3030e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 9.4932e-01,  1.9175e+00,  1.8295e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.6831e+00,  1.2386e+00,  2.6830e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.2569e-01,  3.7578e+00,  1.5425e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.4601e+00,  1.9841e+00,  4.8874e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.3483e+00,  1.9785e+00,  3.1386e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.4055e+00,  1.0210e+00,  2.4698e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.2982e+00,  1.3536e-01,  1.0208e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.2692e+00,  1.0348e+00,  3.4688e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.5001e+00,  1.2307e-01,  2.1221e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 7.4120e-01, -4.1229e-02,  1.9043e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.1648e-01, -4.7364e-02,  1.1619e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.8059e-01, -3.0515e-01,  8.2455e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[6.2666e-02, 2.8843e-02, 5.7889e-02,  ..., 1.5909e-02,\n",
      "           5.5981e-02, 7.7506e-01],\n",
      "          [6.6938e-02, 6.8753e-02, 3.3314e-02,  ..., 2.9692e-01,\n",
      "           2.1358e-01, 2.1540e-01],\n",
      "          [2.1834e-02, 2.6684e-02, 2.0434e-02,  ..., 3.3147e-01,\n",
      "           4.3102e-01, 1.2766e-01],\n",
      "          ...,\n",
      "          [5.6531e-02, 3.8634e-03, 1.3582e-02,  ..., 1.2627e-02,\n",
      "           5.7731e-02, 8.4244e-01],\n",
      "          [9.1011e-02, 7.1896e-03, 2.7964e-02,  ..., 1.8627e-02,\n",
      "           1.0475e-01, 7.4239e-01],\n",
      "          [2.3627e-02, 4.6764e-03, 3.6661e-03,  ..., 2.0187e-03,\n",
      "           1.7742e-02, 9.4767e-01]],\n",
      "\n",
      "         [[3.5070e-02, 3.9920e-02, 3.3707e-02,  ..., 4.5340e-03,\n",
      "           9.8241e-02, 7.8181e-01],\n",
      "          [7.8395e-03, 3.2027e-02, 2.1943e-02,  ..., 1.3990e-03,\n",
      "           5.6063e-03, 9.2905e-01],\n",
      "          [1.1664e-02, 4.3454e-01, 2.6122e-02,  ..., 9.2027e-04,\n",
      "           1.3472e-03, 5.1738e-01],\n",
      "          ...,\n",
      "          [8.6104e-03, 1.5727e-01, 3.5719e-02,  ..., 1.9524e-03,\n",
      "           9.4267e-04, 7.1487e-01],\n",
      "          [1.0054e-01, 2.6476e-02, 4.7172e-02,  ..., 4.6484e-03,\n",
      "           3.0300e-02, 7.3018e-01],\n",
      "          [6.6252e-03, 9.7096e-03, 3.2203e-03,  ..., 1.2014e-03,\n",
      "           2.9205e-03, 9.7506e-01]],\n",
      "\n",
      "         [[1.4408e-01, 3.7366e-02, 1.3306e-02,  ..., 5.7246e-03,\n",
      "           1.7782e-02, 7.7533e-01],\n",
      "          [1.9753e-01, 1.3487e-01, 2.1676e-01,  ..., 8.0052e-02,\n",
      "           9.8086e-02, 2.1359e-01],\n",
      "          [2.7950e-01, 1.0245e-01, 1.3436e-01,  ..., 7.2392e-02,\n",
      "           9.3347e-02, 2.8607e-01],\n",
      "          ...,\n",
      "          [7.9431e-02, 1.3483e-01, 2.1591e-01,  ..., 4.2519e-02,\n",
      "           4.2906e-02, 4.3118e-01],\n",
      "          [8.9616e-02, 9.1443e-02, 3.8758e-02,  ..., 6.2133e-03,\n",
      "           7.8535e-03, 7.5016e-01],\n",
      "          [4.5903e-02, 4.5431e-03, 1.1487e-03,  ..., 6.9983e-04,\n",
      "           1.8237e-03, 9.4358e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.6657e-02, 1.4819e-01, 1.9338e-02,  ..., 1.1410e-02,\n",
      "           5.5714e-02, 6.9538e-01],\n",
      "          [7.6543e-04, 2.8087e-03, 9.5502e-01,  ..., 9.4712e-03,\n",
      "           5.2352e-03, 1.7620e-02],\n",
      "          [3.1043e-04, 1.0200e-03, 1.2089e-03,  ..., 9.3935e-01,\n",
      "           4.6062e-02, 6.3329e-03],\n",
      "          ...,\n",
      "          [8.0808e-03, 6.8108e-03, 7.7283e-03,  ..., 1.3184e-02,\n",
      "           8.2682e-01, 1.2424e-01],\n",
      "          [6.3522e-02, 2.5879e-03, 3.7409e-03,  ..., 2.9364e-03,\n",
      "           2.3838e-02, 9.0321e-01],\n",
      "          [3.6993e-01, 3.1972e-03, 4.6641e-03,  ..., 2.5276e-03,\n",
      "           7.2859e-03, 6.0954e-01]],\n",
      "\n",
      "         [[3.0765e-02, 3.6302e-02, 7.6964e-02,  ..., 6.4537e-02,\n",
      "           1.6476e-01, 6.1198e-01],\n",
      "          [7.5720e-02, 2.0499e-02, 4.6625e-02,  ..., 9.8439e-03,\n",
      "           1.2654e-01, 7.1679e-01],\n",
      "          [5.3365e-02, 7.7545e-01, 4.2133e-02,  ..., 6.5445e-03,\n",
      "           2.8296e-02, 8.9122e-02],\n",
      "          ...,\n",
      "          [7.6744e-02, 1.8409e-01, 4.3706e-01,  ..., 2.6100e-02,\n",
      "           4.5373e-02, 1.1764e-01],\n",
      "          [5.0708e-02, 1.7662e-01, 4.3481e-01,  ..., 8.2363e-02,\n",
      "           7.7388e-02, 1.1017e-01],\n",
      "          [1.9859e-02, 6.1507e-03, 5.1740e-03,  ..., 4.2415e-03,\n",
      "           1.7845e-02, 9.4339e-01]],\n",
      "\n",
      "         [[3.6940e-02, 2.5253e-02, 9.5748e-03,  ..., 2.0711e-03,\n",
      "           2.7783e-02, 8.9160e-01],\n",
      "          [4.8232e-02, 4.4900e-02, 1.7980e-01,  ..., 9.8795e-02,\n",
      "           2.1242e-01, 3.5563e-01],\n",
      "          [4.2734e-02, 3.8211e-02, 2.9015e-02,  ..., 2.3330e-02,\n",
      "           1.3353e-01, 7.2440e-01],\n",
      "          ...,\n",
      "          [1.0499e-02, 8.4996e-03, 5.8217e-03,  ..., 8.1013e-03,\n",
      "           5.8267e-03, 9.5904e-01],\n",
      "          [2.8344e-02, 1.5188e-02, 8.4490e-03,  ..., 1.5539e-02,\n",
      "           2.6622e-02, 9.0318e-01],\n",
      "          [1.4119e-02, 6.8456e-03, 5.1956e-03,  ..., 5.4442e-03,\n",
      "           8.4395e-03, 9.5742e-01]]],\n",
      "\n",
      "\n",
      "        [[[6.9344e-02, 4.8589e-02, 9.8682e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.3538e-01, 9.7503e-02, 8.7877e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.3350e-01, 1.9071e-01, 1.9101e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [6.5956e-02, 2.9929e-02, 4.3763e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.2786e-02, 1.1023e-02, 1.2878e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.7327e-02, 6.6235e-03, 3.2001e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[4.0368e-02, 4.3702e-01, 6.7406e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.1003e-03, 2.1210e-03, 1.7388e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.1001e-02, 4.2268e-01, 1.1421e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [2.1720e-02, 9.0120e-02, 2.1047e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.4615e-02, 1.0004e-01, 3.9168e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.8936e-02, 5.5913e-02, 1.4011e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[5.7080e-02, 1.1124e-02, 9.2067e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4347e-01, 5.7618e-02, 3.4886e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.9439e-01, 6.4652e-02, 8.6968e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.5366e-01, 7.3906e-02, 2.6956e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4761e-01, 3.5505e-02, 1.8403e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.5033e-02, 8.3439e-02, 2.8262e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[7.1182e-02, 1.2883e-01, 6.3174e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4026e-02, 4.1259e-05, 9.7483e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.4322e-02, 1.7953e-01, 9.1051e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.6147e-01, 1.7525e-02, 1.9466e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.2311e-02, 4.9725e-03, 7.5645e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.7760e-02, 1.0829e-03, 6.2143e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[6.1575e-02, 1.6214e-01, 1.4847e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0093e-01, 1.7436e-02, 7.3912e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.4966e-02, 6.9898e-01, 7.6270e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.4421e-02, 3.3808e-02, 6.1648e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.1806e-02, 1.1607e-01, 3.7028e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.7181e-02, 5.9354e-02, 2.5272e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[3.8372e-02, 1.1995e-02, 2.9077e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.5578e-02, 2.1995e-02, 2.5082e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.1334e-01, 2.8599e-02, 2.1111e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [2.0324e-02, 9.2940e-03, 6.5036e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.1271e-02, 6.4135e-03, 2.1491e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.0940e-03, 3.6891e-03, 1.1417e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[ 2.5463e-02,  8.0551e-02,  9.2486e-02,  ..., -9.0835e-02,\n",
      "           -4.2795e-03, -5.3996e-02],\n",
      "          [ 3.7885e-01,  5.0676e-01,  5.5734e-02,  ..., -2.6174e-02,\n",
      "            2.8860e-01, -3.1429e-01],\n",
      "          [ 6.8746e-01,  7.0094e-01,  1.4542e-01,  ...,  8.0209e-02,\n",
      "            5.8274e-01, -3.3812e-01],\n",
      "          ...,\n",
      "          [ 2.0589e-02,  8.9762e-02,  3.1978e-02,  ..., -7.9420e-02,\n",
      "            9.3988e-03, -6.5398e-02],\n",
      "          [ 5.8326e-02,  1.3545e-01,  7.9915e-02,  ..., -8.5649e-02,\n",
      "            5.1735e-02, -6.6631e-02],\n",
      "          [-3.8848e-03,  4.1471e-02, -1.7505e-03,  ..., -6.1527e-02,\n",
      "           -3.3606e-02, -4.4822e-02]],\n",
      "\n",
      "         [[-4.9520e-02,  1.4286e-01, -1.0834e-01,  ..., -1.1368e-01,\n",
      "           -1.6124e-01, -1.5635e-01],\n",
      "          [-5.8430e-02,  5.6862e-02, -7.8293e-02,  ..., -2.1505e-02,\n",
      "           -1.7896e-02, -2.8040e-02],\n",
      "          [-7.6100e-02,  1.2164e-01, -2.9573e-02,  ...,  4.2601e-02,\n",
      "            1.4987e-02, -3.2984e-01],\n",
      "          ...,\n",
      "          [-9.2699e-02,  4.8944e-02, -8.9883e-02,  ...,  1.3785e-02,\n",
      "           -1.7306e-02, -7.7598e-02],\n",
      "          [-1.5206e-01,  1.4188e-01, -2.1502e-01,  ..., -1.3712e-01,\n",
      "           -5.9824e-02, -2.9508e-02],\n",
      "          [-5.3026e-02,  4.6024e-02, -6.8364e-02,  ..., -2.5920e-02,\n",
      "           -1.5648e-02, -1.0008e-02]],\n",
      "\n",
      "         [[-1.9485e-01, -6.5373e-02,  1.0259e-01,  ..., -1.3795e-02,\n",
      "            7.1518e-02,  3.8826e-02],\n",
      "          [ 6.8825e-02, -4.7000e-01, -1.8805e-01,  ...,  2.5048e-01,\n",
      "            5.2159e-01, -2.0882e-01],\n",
      "          [-1.3636e-01, -3.9856e-01, -4.6615e-02,  ...,  1.7976e-01,\n",
      "            3.9074e-01, -8.2009e-02],\n",
      "          ...,\n",
      "          [ 1.3026e-01, -3.2537e-01, -1.5135e-01,  ...,  1.8421e-01,\n",
      "            4.3083e-01, -1.9410e-01],\n",
      "          [-1.1467e-01, -7.3056e-02,  3.3210e-02,  ...,  3.4760e-02,\n",
      "            1.6922e-01, -1.3603e-03],\n",
      "          [-6.4934e-02,  2.7471e-02,  6.0845e-02,  ..., -5.7536e-02,\n",
      "           -1.4595e-02, -9.9203e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7150e-03,  9.9520e-02, -3.6784e-02,  ..., -5.7194e-02,\n",
      "            8.5169e-02,  1.7373e-01],\n",
      "          [ 4.9901e-01,  1.1829e-01,  2.4123e-01,  ..., -5.2998e-02,\n",
      "           -3.6743e-02,  5.2595e-01],\n",
      "          [ 3.2161e-01,  6.6090e-01, -3.2156e-01,  ...,  1.6479e-01,\n",
      "            3.5812e-01, -6.1815e-01],\n",
      "          ...,\n",
      "          [ 3.0171e-01,  5.7348e-01, -3.1160e-01,  ..., -9.1628e-01,\n",
      "           -7.8930e-02, -8.4520e-02],\n",
      "          [-7.8652e-03,  5.9873e-02,  5.5454e-02,  ...,  5.2500e-02,\n",
      "            2.0389e-03,  3.7589e-02],\n",
      "          [ 4.1781e-03,  1.4031e-02, -4.4529e-02,  ..., -1.4416e-02,\n",
      "           -1.8853e-01,  2.4482e-01]],\n",
      "\n",
      "         [[ 1.4229e-01,  1.8184e-01,  6.0656e-02,  ..., -1.7427e-02,\n",
      "           -2.2571e-02,  2.1024e-01],\n",
      "          [ 1.1385e-01,  1.2108e-01, -6.6167e-04,  ...,  3.2770e-02,\n",
      "           -4.0406e-02,  2.0592e-01],\n",
      "          [ 3.3532e-01, -1.4782e-01, -5.1309e-02,  ..., -1.0954e-01,\n",
      "            1.6313e-01,  4.6252e-01],\n",
      "          ...,\n",
      "          [ 5.8850e-01, -1.9349e-01,  1.1163e-01,  ..., -4.4432e-01,\n",
      "            1.1758e-01,  3.9445e-01],\n",
      "          [ 4.9969e-01, -1.0730e-01,  1.4756e-01,  ..., -4.2723e-01,\n",
      "            1.1322e-01,  3.5547e-01],\n",
      "          [ 4.6872e-02,  8.8455e-02, -2.1113e-02,  ...,  3.0523e-02,\n",
      "           -1.6410e-02,  8.0546e-02]],\n",
      "\n",
      "         [[ 9.8581e-06, -9.4778e-03,  1.0206e-01,  ...,  8.9949e-02,\n",
      "           -3.7064e-02,  1.3829e-01],\n",
      "          [ 3.6926e-01, -1.6706e-01, -2.7881e-02,  ...,  1.6265e-01,\n",
      "           -2.5139e-01,  6.4041e-01],\n",
      "          [ 9.5312e-02, -7.7575e-02,  4.8121e-02,  ...,  1.4707e-01,\n",
      "           -5.7086e-02,  3.1998e-01],\n",
      "          ...,\n",
      "          [-4.2205e-03,  2.0100e-03,  3.7793e-02,  ...,  5.7896e-02,\n",
      "           -1.2384e-02,  6.6544e-02],\n",
      "          [ 2.0273e-02, -6.8773e-03,  6.5411e-02,  ...,  7.4438e-02,\n",
      "           -3.3558e-02,  1.2855e-01],\n",
      "          [-6.7545e-03,  3.9956e-03,  4.6636e-02,  ...,  5.6598e-02,\n",
      "           -1.2884e-02,  7.0443e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7037e-02,  7.0124e-02, -5.8630e-02,  ..., -2.6328e-01,\n",
      "           -1.0382e-01, -1.6059e-02],\n",
      "          [-1.0566e-02,  9.8372e-02, -3.5280e-02,  ..., -3.1571e-01,\n",
      "           -1.4280e-01,  3.2503e-02],\n",
      "          [ 1.7103e-02,  1.0934e-01, -2.2787e-02,  ..., -5.4058e-01,\n",
      "           -1.2902e-01,  1.1835e-01],\n",
      "          ...,\n",
      "          [-2.1766e-02,  6.0254e-02, -4.4192e-02,  ..., -1.6734e-01,\n",
      "           -9.8748e-02, -2.9469e-02],\n",
      "          [-2.0418e-02,  5.4571e-02, -4.1295e-02,  ..., -1.0589e-01,\n",
      "           -9.7244e-02, -4.5665e-02],\n",
      "          [-9.5316e-03,  4.0482e-02, -3.4345e-02,  ..., -7.7699e-02,\n",
      "           -7.6200e-02, -4.7958e-02]],\n",
      "\n",
      "         [[ 2.6016e-01,  1.5484e-02,  5.7639e-02,  ..., -4.6354e-01,\n",
      "           -4.5631e-01, -1.4475e-01],\n",
      "          [-4.6901e-02,  3.2581e-02, -7.0835e-02,  ..., -2.4729e-02,\n",
      "           -1.6583e-02, -6.8262e-05],\n",
      "          [ 2.3442e-01,  2.9613e-02, -2.3722e-03,  ..., -5.0908e-01,\n",
      "           -4.7311e-01, -1.7915e-01],\n",
      "          ...,\n",
      "          [-3.0430e-02,  5.3450e-02, -2.3279e-01,  ..., -3.1091e-01,\n",
      "           -2.4145e-01, -1.8537e-01],\n",
      "          [-7.9869e-02,  1.0132e-01, -4.3276e-01,  ..., -5.3901e-01,\n",
      "           -3.6692e-01, -3.3242e-01],\n",
      "          [-6.5336e-02,  9.3208e-02, -2.3425e-01,  ..., -2.7629e-01,\n",
      "           -1.4442e-01, -1.2244e-01]],\n",
      "\n",
      "         [[-1.4312e-01,  1.1089e-01, -8.3149e-02,  ..., -4.8181e-02,\n",
      "           -1.0906e-01,  1.1790e-01],\n",
      "          [-4.1088e-01,  3.0903e-01, -4.7260e-01,  ..., -1.0863e-01,\n",
      "           -2.9374e-01,  4.4298e-01],\n",
      "          [-6.6462e-01, -6.1514e-02,  3.3022e-01,  ..., -6.2164e-03,\n",
      "           -1.8415e-01,  3.6556e-01],\n",
      "          ...,\n",
      "          [-3.6481e-01,  2.1399e-01, -3.6020e-01,  ..., -9.6998e-02,\n",
      "           -2.1947e-01,  3.3172e-01],\n",
      "          [-3.1042e-01,  1.5872e-01, -1.6811e-01,  ..., -6.4433e-02,\n",
      "           -1.8558e-01,  2.6839e-01],\n",
      "          [-2.9842e-01,  2.3692e-01, -4.6231e-01,  ..., -1.1193e-01,\n",
      "           -2.0385e-01,  2.9325e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3333e-02, -6.2306e-05, -6.3674e-02,  ..., -2.7590e-02,\n",
      "            3.7345e-02,  2.1513e-01],\n",
      "          [-3.5131e-01, -5.6449e-02, -5.7981e-01,  ..., -6.8211e-01,\n",
      "            3.9288e-01,  5.3277e-01],\n",
      "          [-4.7573e-02, -2.2685e-03, -9.5730e-02,  ..., -3.4240e-02,\n",
      "            7.5324e-02,  2.5654e-01],\n",
      "          ...,\n",
      "          [-6.6884e-02, -1.6579e-02, -1.2773e-01,  ..., -1.7156e-01,\n",
      "            1.8396e-02,  2.3279e-01],\n",
      "          [-1.5818e-02,  2.9814e-02,  5.4354e-02,  ...,  5.3983e-02,\n",
      "            1.6866e-02,  4.8872e-02],\n",
      "          [-1.2296e-02,  2.4561e-02,  4.6275e-02,  ...,  3.8254e-02,\n",
      "            1.6980e-04,  6.1011e-02]],\n",
      "\n",
      "         [[-3.8818e-02, -8.8905e-02, -2.2878e-01,  ..., -1.5704e-01,\n",
      "           -1.9826e-01,  1.0856e-02],\n",
      "          [ 1.2382e-01, -1.1668e-02, -1.2443e-01,  ..., -1.6131e-02,\n",
      "           -9.3267e-02,  1.8461e-01],\n",
      "          [-2.5374e-01, -1.9330e-01, -6.8055e-01,  ..., -6.8534e-01,\n",
      "           -1.3006e-01, -4.6456e-01],\n",
      "          ...,\n",
      "          [-8.8150e-02, -4.1858e-01, -2.2158e-01,  ..., -1.0770e-01,\n",
      "           -7.6200e-01,  2.8498e-01],\n",
      "          [-6.5434e-02, -2.5051e-01, -2.3966e-01,  ..., -1.4917e-01,\n",
      "           -4.6563e-01,  1.3136e-01],\n",
      "          [-3.4172e-03, -1.4435e-01, -1.6914e-01,  ..., -7.4355e-02,\n",
      "           -3.1955e-01,  1.4773e-01]],\n",
      "\n",
      "         [[-2.8219e-03,  2.5844e-03,  9.7557e-02,  ...,  3.7129e-02,\n",
      "           -7.5712e-02,  1.0902e-01],\n",
      "          [ 1.2347e-01, -4.6918e-02,  2.7041e-01,  ...,  1.9203e-02,\n",
      "           -3.1904e-01,  3.1978e-01],\n",
      "          [ 1.0843e-01, -1.8248e-02,  3.1683e-01,  ...,  1.2822e-02,\n",
      "           -3.3251e-01,  3.4185e-01],\n",
      "          ...,\n",
      "          [ 1.3519e-02, -1.6327e-02,  8.3627e-02,  ...,  3.9494e-02,\n",
      "           -8.4517e-02,  1.1064e-01],\n",
      "          [-1.1489e-02, -7.0009e-03,  4.6693e-02,  ...,  4.3202e-02,\n",
      "           -3.3805e-02,  6.7257e-02],\n",
      "          [-1.7171e-02, -4.1154e-03,  3.6426e-02,  ...,  4.3694e-02,\n",
      "           -1.8514e-02,  5.6901e-02]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[ 0.1830, -0.3152, -0.4591,  ..., -0.1363, -0.1225,  1.2073],\n",
      "          [-1.4042,  0.7777,  0.5943,  ..., -1.4513, -1.2725,  0.6345],\n",
      "          [-0.9567,  0.3471,  1.4658,  ..., -0.7335, -1.7255,  1.7638],\n",
      "          ...,\n",
      "          [-1.5428, -0.3344,  0.8411,  ..., -1.3646, -2.0845,  1.1267],\n",
      "          [-1.2208, -0.0544,  0.7719,  ..., -0.3777, -1.1967,  0.4031],\n",
      "          [-1.1380,  1.2668,  1.4708,  ..., -0.7882, -0.9505, -0.1553]],\n",
      "\n",
      "         [[ 0.4727,  0.8909, -1.0754,  ...,  1.9157, -0.5003,  0.2072],\n",
      "          [ 1.2828,  0.4802,  0.3744,  ...,  0.9979, -0.7281,  1.7390],\n",
      "          [ 1.0032,  1.4735, -0.8786,  ...,  0.3190, -1.4185,  1.4702],\n",
      "          ...,\n",
      "          [ 1.4640,  0.4052, -0.9684,  ...,  1.1156,  0.2570, -0.2583],\n",
      "          [ 2.3611,  0.6488, -1.1830,  ..., -0.4299, -0.3545,  0.2345],\n",
      "          [-0.2844,  0.6313, -0.5437,  ...,  0.4301,  0.3978,  0.2377]],\n",
      "\n",
      "         [[ 0.1341,  0.2906, -0.3830,  ...,  1.7292, -1.5367, -0.8074],\n",
      "          [ 0.4022,  0.2296, -0.3250,  ...,  0.6924, -0.7750,  0.8425],\n",
      "          [ 0.6038, -0.1255,  0.4827,  ...,  0.2090, -2.1105,  0.8529],\n",
      "          ...,\n",
      "          [-0.1295, -0.9727, -0.1505,  ..., -1.4303, -3.2998,  1.4107],\n",
      "          [-0.5980,  0.6664, -0.0203,  ...,  2.0694, -0.3137,  1.0071],\n",
      "          [-0.5169,  0.6861, -1.0698,  ...,  4.0103, -0.4949,  0.4285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7464,  2.4875, -0.0857,  ..., -0.5192,  0.6977,  0.3538],\n",
      "          [-0.8599,  0.1289, -0.9513,  ..., -0.2334,  0.9381, -1.2204],\n",
      "          [-0.6518,  1.0130, -1.8575,  ...,  0.6067,  0.3818, -2.0282],\n",
      "          ...,\n",
      "          [ 0.0263, -2.3592, -0.2899,  ...,  1.5396,  0.4075, -0.9333],\n",
      "          [-3.4102, -1.0685, -0.1325,  ...,  0.4909,  0.1463,  0.7803],\n",
      "          [ 0.1927,  0.6437,  0.4318,  ..., -0.6471, -0.5576,  1.1879]],\n",
      "\n",
      "         [[-1.4657, -1.2861,  2.1000,  ..., -1.1263, -0.1746,  1.1128],\n",
      "          [ 0.0290, -0.6146, -1.3960,  ...,  1.9753,  1.5421,  0.8263],\n",
      "          [-2.3196, -0.4893, -0.9834,  ...,  0.9022, -0.2578, -0.0888],\n",
      "          ...,\n",
      "          [-2.1915, -0.9834,  0.4053,  ...,  0.9307,  1.4268,  0.4377],\n",
      "          [-3.1699, -1.1046,  2.2749,  ...,  2.6304,  3.0069,  0.8976],\n",
      "          [-0.4045, -0.2206, -0.4777,  ...,  0.3672, -0.0284,  0.8239]],\n",
      "\n",
      "         [[-0.3719, -1.2905, -0.0506,  ..., -0.3948, -0.3153, -0.9130],\n",
      "          [ 0.2123,  0.7018,  0.9054,  ..., -0.4652, -0.8689,  0.3852],\n",
      "          [ 0.9605,  0.9723,  1.6048,  ...,  0.1510, -0.7512,  1.0391],\n",
      "          ...,\n",
      "          [-0.8992, -0.9634,  0.0462,  ..., -0.6733, -0.9781,  1.1154],\n",
      "          [ 0.9721, -2.4781,  0.6222,  ..., -0.4800, -0.4741, -1.0553],\n",
      "          [ 0.8804,  0.7721,  1.1931,  ..., -0.1421,  0.9501, -3.3427]]],\n",
      "\n",
      "\n",
      "        [[[-0.9599,  0.2727, -0.3532,  ..., -0.8165, -0.0088,  1.4011],\n",
      "          [-0.4208, -0.4998,  2.8740,  ..., -1.8184, -0.4806, -1.2693],\n",
      "          [-0.6512,  0.0504,  1.4882,  ..., -1.9407, -0.5118,  0.4635],\n",
      "          ...,\n",
      "          [-1.7255, -0.4630,  2.7794,  ..., -1.5499,  0.6433,  0.7324],\n",
      "          [-1.2327, -0.0628,  1.8906,  ..., -1.7548,  0.4304,  0.4811],\n",
      "          [-1.5965, -0.6500,  2.6662,  ..., -1.9030,  0.4025,  0.4179]],\n",
      "\n",
      "         [[ 0.3531,  1.3450, -0.6765,  ...,  2.0583, -0.8735,  0.3801],\n",
      "          [-0.3208,  0.3953,  0.7160,  ..., -0.1042, -0.1452,  0.1667],\n",
      "          [ 0.2776, -0.0498, -1.9971,  ...,  1.7989, -0.9027,  1.3086],\n",
      "          ...,\n",
      "          [-1.1076,  0.4690, -0.1422,  ..., -0.3007, -0.4493,  0.3001],\n",
      "          [-1.0299,  0.5871, -1.1712,  ...,  0.1465, -0.7382,  0.9453],\n",
      "          [-1.4095,  0.4736, -0.7027,  ..., -0.3184, -0.5994,  0.6318]],\n",
      "\n",
      "         [[ 0.5251,  0.4165, -0.6638,  ...,  1.9102, -0.6460, -0.7109],\n",
      "          [ 0.7294,  0.7351, -0.0949,  ...,  0.0323,  0.2818,  0.1170],\n",
      "          [ 0.8687,  1.1606,  0.5507,  ...,  0.3875, -0.9177,  2.0838],\n",
      "          ...,\n",
      "          [ 0.9074,  1.4254, -0.8897,  ...,  0.7096,  0.9038,  1.3403],\n",
      "          [ 0.0982,  1.8779, -0.6095,  ...,  0.7298,  0.6475,  1.0172],\n",
      "          [-0.2193,  1.8464, -0.7226,  ...,  0.1507,  1.0064,  0.2271]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3040,  1.6524, -0.0827,  ..., -1.0579,  0.3578,  0.8581],\n",
      "          [-1.8069, -1.9035, -0.1939,  ..., -2.4449,  0.3904, -0.7047],\n",
      "          [-2.0031,  0.7195, -0.3387,  ..., -0.2633,  0.1609, -1.7847],\n",
      "          ...,\n",
      "          [-0.8713, -1.3405, -0.6682,  ..., -0.9608, -0.2483, -1.4161],\n",
      "          [-1.6431, -0.6858, -0.7156,  ..., -0.6158,  0.1142, -0.6607],\n",
      "          [-0.4342, -1.2872, -0.5986,  ..., -0.5642, -0.4364, -0.1758]],\n",
      "\n",
      "         [[-0.9518, -0.7714,  1.3273,  ..., -1.2164, -0.5240,  1.6450],\n",
      "          [-1.0079,  0.7199, -1.3274,  ..., -0.1875,  0.2427,  1.4105],\n",
      "          [-0.6696,  0.7408,  0.3018,  ..., -0.3045, -0.6294,  1.3276],\n",
      "          ...,\n",
      "          [ 0.0754,  0.4576, -0.0828,  ..., -0.5033,  0.3662, -0.0988],\n",
      "          [ 0.3938,  0.4890,  0.1991,  ..., -0.4546,  0.8200, -0.4734],\n",
      "          [ 0.2812,  0.0376,  0.2390,  ..., -0.5655,  0.5802, -1.1611]],\n",
      "\n",
      "         [[ 0.3470, -1.6081, -0.1891,  ..., -0.1252, -0.1553, -1.2355],\n",
      "          [-1.0118, -0.3236,  0.7362,  ...,  0.6642,  0.9242,  0.4980],\n",
      "          [ 0.3632, -0.0543, -0.7800,  ..., -1.0829, -0.1147, -0.7469],\n",
      "          ...,\n",
      "          [ 0.2126, -0.3048,  1.0120,  ...,  0.2636,  0.6250, -0.5504],\n",
      "          [ 0.4351, -1.9793, -0.0609,  ...,  0.1198,  0.6235, -1.1483],\n",
      "          [ 0.2416, -1.7252,  1.2326,  ...,  0.6736,  1.0363, -0.4677]]]],\n",
      "       grad_fn=<PermuteBackward0>), query layer: tensor([[[[ 5.4681e-01, -7.1237e-01,  1.4623e+00,  ..., -7.9065e-01,\n",
      "           -1.2470e+00, -2.1822e-01],\n",
      "          [-1.0278e+00,  5.2694e-01,  1.6480e+00,  ..., -4.3727e-01,\n",
      "           -6.6037e-01,  1.2004e+00],\n",
      "          [ 5.2526e-01, -5.0249e-01,  2.3995e+00,  ..., -3.1658e-01,\n",
      "           -2.5833e+00,  1.4824e+00],\n",
      "          ...,\n",
      "          [-1.8496e-01,  5.1357e-01,  2.9458e+00,  ...,  5.4483e-03,\n",
      "           -5.8402e-01,  3.8694e-01],\n",
      "          [-1.0110e+00,  1.6910e+00,  2.5113e+00,  ..., -6.0068e-01,\n",
      "           -6.9817e-01, -1.2191e+00],\n",
      "          [-8.2830e-01,  1.3837e+00,  1.2974e+00,  ..., -5.3336e-01,\n",
      "           -4.1213e-01, -4.8200e-01]],\n",
      "\n",
      "         [[-4.9124e-01, -4.9275e-01,  8.1722e-01,  ..., -6.8279e-01,\n",
      "           -1.0841e+00, -8.3732e-01],\n",
      "          [-8.4278e-01, -2.5113e-01, -1.9345e-01,  ...,  1.3581e+00,\n",
      "           -1.5554e+00,  1.1800e+00],\n",
      "          [ 7.0406e-01,  5.7659e-01, -3.4505e-01,  ..., -1.1421e-01,\n",
      "           -1.1595e+00,  6.7222e-01],\n",
      "          ...,\n",
      "          [ 4.4258e-01, -4.2894e-01,  7.1011e-01,  ...,  9.5880e-01,\n",
      "            1.1120e+00,  1.4647e-01],\n",
      "          [-3.9701e-01, -2.3691e+00,  7.6830e-01,  ...,  4.7187e-01,\n",
      "            3.6481e-01,  1.1175e+00],\n",
      "          [-1.8422e-01,  6.5039e-01, -3.2398e-01,  ..., -2.1735e-01,\n",
      "            6.8115e-01,  1.4100e-01]],\n",
      "\n",
      "         [[ 9.5188e-01, -3.1605e-01,  1.4057e+00,  ...,  9.5258e-01,\n",
      "            6.9144e-01,  1.8541e-01],\n",
      "          [ 9.1688e-01,  7.3892e-01,  4.5630e-01,  ...,  3.4868e+00,\n",
      "           -7.2012e-01,  1.8201e+00],\n",
      "          [ 5.5153e-01,  8.2212e-02,  1.2971e+00,  ...,  2.5363e+00,\n",
      "           -2.0064e+00,  3.3050e+00],\n",
      "          ...,\n",
      "          [ 5.8634e-01,  1.8069e+00,  6.0276e-01,  ...,  2.9045e+00,\n",
      "           -1.1276e+00,  2.5724e+00],\n",
      "          [ 1.3175e+00,  4.8716e-01,  1.6425e+00,  ...,  2.6245e+00,\n",
      "           -1.2693e+00,  1.4790e+00],\n",
      "          [-2.9284e-01,  6.9609e-01, -2.9497e-01,  ...,  2.2738e+00,\n",
      "           -2.1665e-01,  5.6587e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3524e-01, -1.4567e+00,  1.8930e+00,  ...,  1.2635e+00,\n",
      "           -8.5327e-01,  1.5087e+00],\n",
      "          [-3.2823e-01, -3.1562e-02, -3.6676e-02,  ..., -5.1250e-01,\n",
      "           -5.7928e-01,  3.6816e-02],\n",
      "          [-5.3966e-01,  3.4575e-01, -8.5813e-02,  ...,  7.5020e-01,\n",
      "            8.5977e-01, -1.0672e+00],\n",
      "          ...,\n",
      "          [-5.3690e-01,  1.1377e+00, -1.5755e+00,  ...,  6.1010e-01,\n",
      "            4.8188e-01, -5.5509e-02],\n",
      "          [-3.6844e-01,  2.8773e-01, -1.7237e+00,  ...,  2.1290e-01,\n",
      "           -7.5311e-01,  3.4146e-01],\n",
      "          [ 2.5100e-01,  1.2646e-01,  4.4311e-01,  ..., -7.1501e-02,\n",
      "            3.6588e-01,  7.5011e-02]],\n",
      "\n",
      "         [[ 8.2013e-02,  3.2782e-01, -1.3348e+00,  ...,  1.6205e+00,\n",
      "           -8.5950e-03, -3.2638e-01],\n",
      "          [ 4.3265e-01,  3.9825e-01,  1.2527e-02,  ...,  3.9337e-01,\n",
      "            2.8388e-02,  4.4156e-01],\n",
      "          [-9.8447e-01,  9.9685e-01, -6.9713e-01,  ...,  3.2154e-01,\n",
      "            2.4976e+00, -7.9804e-01],\n",
      "          ...,\n",
      "          [ 6.7821e-01,  6.5308e-02, -3.8042e-02,  ...,  7.6970e-01,\n",
      "            1.4828e+00, -7.0156e-01],\n",
      "          [-1.2624e+00, -9.0293e-01, -2.1448e-01,  ...,  3.9161e-01,\n",
      "            2.1068e+00,  5.2111e-02],\n",
      "          [ 2.9577e-01,  1.9839e-01, -9.1723e-01,  ...,  7.0062e-01,\n",
      "           -2.5634e-01, -6.5272e-01]],\n",
      "\n",
      "         [[-5.5735e-01,  1.4169e+00,  1.1347e+00,  ...,  1.6186e-01,\n",
      "           -1.3366e-02, -3.1158e-01],\n",
      "          [ 1.7610e+00, -4.2383e-01,  5.7634e-01,  ...,  1.0243e-01,\n",
      "            1.0883e+00, -4.0754e+00],\n",
      "          [-6.9636e-01,  2.1229e-01,  1.1128e+00,  ...,  7.2579e-01,\n",
      "           -1.2295e+00, -3.5576e+00],\n",
      "          ...,\n",
      "          [ 3.2084e-01, -1.0666e-01,  3.1917e+00,  ..., -5.9307e-01,\n",
      "           -5.8430e-01, -3.6860e+00],\n",
      "          [-7.5153e-01, -1.7784e-01,  1.6583e+00,  ...,  1.5324e+00,\n",
      "           -1.5411e+00, -2.9862e+00],\n",
      "          [-1.4599e-01,  6.0430e-01,  1.3392e+00,  ...,  3.5572e-01,\n",
      "            5.9171e-01, -1.9044e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5836e-01, -8.9462e-01,  1.4047e+00,  ..., -1.0556e+00,\n",
      "            3.9792e-02, -2.4675e-01],\n",
      "          [-7.3242e-01,  1.6403e+00,  1.9452e+00,  ..., -3.0707e-01,\n",
      "            6.7549e-01,  1.7015e+00],\n",
      "          [-8.8745e-01, -1.3962e-01,  3.6778e-01,  ..., -1.4879e+00,\n",
      "           -4.0535e-01, -5.8420e-01],\n",
      "          ...,\n",
      "          [-5.8736e-01,  3.5724e-01,  6.1655e-01,  ..., -1.8712e-01,\n",
      "            1.1146e+00,  1.4094e-02],\n",
      "          [-5.4132e-01,  6.1657e-01,  5.6622e-03,  ..., -2.1765e-01,\n",
      "            1.4813e+00, -3.0347e-01],\n",
      "          [-7.0332e-01,  3.6377e-01,  4.6599e-03,  ..., -5.0990e-02,\n",
      "            1.6440e+00,  1.6219e-01]],\n",
      "\n",
      "         [[-9.5906e-01, -3.9116e-02,  3.3196e-01,  ..., -1.0610e+00,\n",
      "           -7.6825e-01,  6.1130e-02],\n",
      "          [-1.8015e+00,  4.7561e-02, -1.0853e+00,  ...,  7.7309e-01,\n",
      "            4.4213e-01, -2.1398e-01],\n",
      "          [-8.6110e-01, -1.8406e-01,  2.3619e-01,  ..., -2.0041e-02,\n",
      "           -4.1422e-01,  1.0558e+00],\n",
      "          ...,\n",
      "          [-1.7284e+00, -1.7187e-01,  1.2922e-01,  ...,  5.6354e-01,\n",
      "           -9.7162e-02,  2.1744e+00],\n",
      "          [-9.4846e-01, -1.1330e+00,  8.8445e-01,  ...,  1.7148e-01,\n",
      "           -3.4239e-01,  2.1859e+00],\n",
      "          [-1.5752e+00, -4.2689e-01,  3.1211e-01,  ...,  3.2579e-01,\n",
      "            2.7107e-01,  2.1182e+00]],\n",
      "\n",
      "         [[ 4.5517e-01,  4.2066e-03,  1.0573e+00,  ...,  1.4333e+00,\n",
      "            1.4052e-01,  7.9268e-01],\n",
      "          [ 4.9541e-01,  1.5238e+00, -5.1502e-01,  ...,  3.7449e+00,\n",
      "            8.0118e-01,  6.6360e-01],\n",
      "          [-1.3576e-01,  5.3931e-01,  1.0878e+00,  ...,  2.3729e+00,\n",
      "           -1.4073e+00,  1.3254e+00],\n",
      "          ...,\n",
      "          [ 8.9402e-01,  1.6704e-01, -3.6043e-01,  ...,  3.7002e+00,\n",
      "            4.4569e-01,  1.4658e+00],\n",
      "          [ 7.4776e-01, -3.7632e-01,  4.2451e-01,  ...,  3.2784e+00,\n",
      "           -2.6416e-01,  1.7273e+00],\n",
      "          [ 3.1813e-01, -1.6510e-01, -4.6439e-01,  ...,  3.5564e+00,\n",
      "            1.2207e-01,  1.2983e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9051e-01, -1.1951e+00,  1.1964e+00,  ...,  7.2542e-01,\n",
      "            1.7369e-01,  1.1468e+00],\n",
      "          [ 4.0535e-01,  9.2340e-02, -8.4220e-01,  ..., -5.2499e-01,\n",
      "            2.4835e-01,  5.1369e-02],\n",
      "          [-1.7132e+00,  4.1695e-01, -4.9511e-01,  ..., -1.2448e-01,\n",
      "            1.2243e+00, -4.1284e-01],\n",
      "          ...,\n",
      "          [-4.8567e-01, -8.1710e-01, -7.1017e-01,  ..., -1.3804e+00,\n",
      "           -9.1886e-01, -3.9224e-01],\n",
      "          [-1.3548e+00, -1.1383e+00, -7.9948e-01,  ..., -8.7503e-01,\n",
      "           -6.3672e-01, -2.8516e-01],\n",
      "          [-1.3226e+00, -1.2607e+00, -6.8001e-01,  ..., -1.3881e+00,\n",
      "           -9.5815e-01,  1.4014e-01]],\n",
      "\n",
      "         [[ 1.1032e-01,  3.9415e-01, -2.3501e+00,  ...,  1.5219e+00,\n",
      "           -3.7330e-01,  1.2546e-01],\n",
      "          [ 6.5334e-01,  4.7014e-01, -1.1447e+00,  ...,  4.4119e-01,\n",
      "            5.0797e-01,  7.7376e-01],\n",
      "          [-3.8189e-01,  1.1568e+00, -2.7796e+00,  ..., -2.7462e-01,\n",
      "            2.4986e-01,  1.9230e+00],\n",
      "          ...,\n",
      "          [ 6.0634e-01,  1.2458e+00, -1.4646e+00,  ...,  8.7986e-01,\n",
      "            7.0838e-01,  5.5433e-01],\n",
      "          [ 1.1560e-01,  8.9844e-01, -1.7875e+00,  ...,  6.8650e-02,\n",
      "            5.5302e-01, -5.9820e-02],\n",
      "          [ 3.7310e-01,  6.1811e-01, -1.0936e+00,  ...,  1.0439e+00,\n",
      "            7.4604e-01, -1.1519e-01]],\n",
      "\n",
      "         [[-1.4228e+00,  1.2067e+00,  8.0945e-01,  ..., -4.7693e-01,\n",
      "           -6.3253e-01, -8.8781e-01],\n",
      "          [ 1.5940e+00, -6.9761e-01,  1.2807e+00,  ..., -2.2787e-01,\n",
      "            1.2499e+00, -4.6934e+00],\n",
      "          [-2.4977e+00,  1.0636e+00,  2.4958e+00,  ...,  2.3879e+00,\n",
      "           -7.4628e-01, -2.0306e+00],\n",
      "          ...,\n",
      "          [-1.0644e+00,  1.3601e+00,  1.0311e+00,  ...,  5.9755e-01,\n",
      "           -1.8212e+00, -3.6887e+00],\n",
      "          [-2.1848e+00,  7.3505e-02,  1.8693e+00,  ...,  1.5127e+00,\n",
      "           -2.9131e+00, -3.2450e+00],\n",
      "          [-1.2530e+00, -8.1777e-01,  1.3990e+00,  ...,  6.8872e-01,\n",
      "           -2.7156e+00, -3.0803e+00]]]], grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[-0.8884,  2.6209,  2.6911,  ...,  0.8533,  3.2271,  2.0468],\n",
      "          [ 0.9296,  2.7628,  2.2055,  ...,  1.9878,  4.1042,  7.4697],\n",
      "          [ 1.5210,  2.5216,  3.6471,  ...,  3.0129,  4.7814,  8.0325],\n",
      "          ...,\n",
      "          [ 0.9902,  3.7281,  3.3452,  ...,  3.6499,  5.4121,  8.3249],\n",
      "          [ 0.5026,  2.6387,  2.7469,  ...,  2.9156,  4.9092,  7.3900],\n",
      "          [ 1.7470,  1.3611,  0.9075,  ...,  0.4347,  1.8578,  7.6226]],\n",
      "\n",
      "         [[-0.9884,  0.9171,  1.2729,  ..., -0.4088,  0.2309,  2.0461],\n",
      "          [ 2.0531,  1.9754,  2.0875,  ...,  1.2394,  1.6760,  4.0830],\n",
      "          [ 2.3203,  3.0799,  1.8438,  ...,  1.5149,  2.2409,  4.2384],\n",
      "          ...,\n",
      "          [ 0.7767,  2.4211,  1.6647,  ...,  1.4948,  1.4652,  4.9639],\n",
      "          [ 1.0567,  3.1895,  1.3826,  ...,  1.2614,  1.1823,  3.7300],\n",
      "          [ 1.4904,  1.0471,  0.0809,  ..., -0.1857,  0.6703,  5.8515]],\n",
      "\n",
      "         [[-0.9356,  2.6272,  3.0481,  ...,  1.3809,  3.4560,  1.9568],\n",
      "          [ 2.7515,  1.6962,  1.5158,  ...,  0.1938,  2.7255,  5.3967],\n",
      "          [ 2.8265,  1.5899,  1.7973,  ...,  1.6921,  3.0863,  5.4159],\n",
      "          ...,\n",
      "          [ 1.8244,  2.0592,  2.4247,  ...,  2.9311,  4.0516,  5.6893],\n",
      "          [ 2.2730,  1.7268,  2.6580,  ...,  2.4530,  2.2078,  4.6665],\n",
      "          [ 1.0938,  0.1909, -0.3249,  ..., -0.5282,  1.2276,  4.8478]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5582,  0.1578, -1.8055,  ..., -0.6749,  1.1922,  3.8049],\n",
      "          [ 2.3286,  1.7014,  0.7085,  ...,  0.2267,  2.4515,  5.7555],\n",
      "          [ 2.6361,  1.9373,  0.6774,  ...,  0.5801,  3.5506,  5.2397],\n",
      "          ...,\n",
      "          [ 2.5384,  3.7765,  3.9762,  ..., -0.3169,  3.7288,  4.2990],\n",
      "          [ 1.5461,  2.3811,  3.4871,  ...,  1.4337,  2.2700,  2.6508],\n",
      "          [ 0.7296, -0.2420, -0.9735,  ..., -0.6111,  0.5909,  4.4940]],\n",
      "\n",
      "         [[ 0.9308,  2.3916,  2.0433,  ...,  0.2580,  2.4581,  4.3360],\n",
      "          [ 2.5545,  4.0239,  1.7873,  ...,  1.2807,  3.9977,  7.4749],\n",
      "          [ 2.1705,  5.0770,  1.8076,  ...,  1.8537,  4.5180,  6.8752],\n",
      "          ...,\n",
      "          [ 2.4777,  6.1553,  3.8052,  ...,  1.8269,  4.5117,  8.0394],\n",
      "          [ 2.7081,  5.1696,  4.1416,  ...,  3.1427,  4.6438,  6.0396],\n",
      "          [ 0.8387,  2.0661,  1.5778,  ..., -0.2938,  1.1837,  5.4710]],\n",
      "\n",
      "         [[-0.4135,  2.1885, -0.7162,  ...,  0.3472,  3.6039,  2.1978],\n",
      "          [ 3.6131,  1.3728,  0.1793,  ...,  0.7165,  5.0915,  6.1077],\n",
      "          [ 4.3758,  4.9074,  2.8546,  ...,  0.7465,  3.1364,  3.6271],\n",
      "          ...,\n",
      "          [ 0.4790,  3.6365,  3.9862,  ...,  3.0509,  1.1400,  5.2945],\n",
      "          [ 0.6209,  0.5526, -0.1090,  ...,  4.0709,  2.6867,  4.2017],\n",
      "          [-0.3884,  0.0516, -0.7312,  ..., -0.7669,  0.6061,  4.4740]]],\n",
      "\n",
      "\n",
      "        [[[-0.3214,  4.0174,  0.9204,  ...,  2.8399,  1.3506,  1.4630],\n",
      "          [ 1.6317,  3.3645,  1.0594,  ...,  3.7502,  2.0431,  2.3349],\n",
      "          [ 1.0464,  2.3185,  3.5864,  ...,  1.9544,  1.4315,  0.9658],\n",
      "          ...,\n",
      "          [ 1.4499,  3.0121,  1.0041,  ...,  2.4142,  1.3186,  1.1628],\n",
      "          [ 1.8977,  3.3151,  2.3342,  ...,  2.3935,  1.5951,  1.0274],\n",
      "          [ 1.7638,  3.3487,  1.5378,  ...,  2.4239,  1.3271,  0.9549]],\n",
      "\n",
      "         [[ 0.0571,  1.4387, -0.0854,  ...,  1.7618,  1.6036,  1.5676],\n",
      "          [ 1.8608,  2.1075,  2.9909,  ...,  2.9620,  2.9534,  2.5436],\n",
      "          [ 0.4024,  3.3264,  1.1845,  ...,  2.7713,  2.5132,  2.1134],\n",
      "          ...,\n",
      "          [ 0.5476,  2.6130,  1.4134,  ...,  2.1583,  1.7694,  1.6261],\n",
      "          [ 0.5413,  3.6157,  1.8948,  ...,  2.4868,  1.6770,  1.6822],\n",
      "          [ 0.6796,  2.9005,  1.7613,  ...,  2.2296,  1.7529,  1.6558]],\n",
      "\n",
      "         [[ 0.6704,  2.8227,  3.4935,  ...,  2.5022,  3.1667,  1.7831],\n",
      "          [ 2.7046,  1.3680,  0.4974,  ...,  1.5658,  0.8550,  0.8680],\n",
      "          [ 2.1815,  1.4885,  1.7108,  ...,  0.9703,  1.2570, -0.2086],\n",
      "          ...,\n",
      "          [ 2.4532,  2.1641,  1.7830,  ...,  2.3097,  1.7057,  0.8022],\n",
      "          [ 2.2101,  1.6245,  2.1123,  ...,  1.9675,  1.6629,  0.4749],\n",
      "          [ 2.2654,  1.9363,  2.3509,  ...,  2.4812,  2.3221,  1.2265]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9787, -0.8393,  0.4166,  ...,  0.8792,  1.2825,  1.0609],\n",
      "          [ 3.2610,  1.1073,  2.2054,  ...,  2.4699,  2.0837,  1.4131],\n",
      "          [ 3.1783,  0.9844,  2.1688,  ...,  2.4851,  2.4411,  1.1429],\n",
      "          ...,\n",
      "          [ 1.8126,  2.4514,  2.8342,  ...,  2.7472,  2.7489,  1.5775],\n",
      "          [ 1.3489,  2.1826,  2.2616,  ...,  3.0559,  3.3385,  2.3063],\n",
      "          [ 1.6348,  2.3903,  2.2755,  ...,  3.1750,  4.0328,  2.9725]],\n",
      "\n",
      "         [[ 0.4456,  3.0354, -0.2023,  ...,  1.2685,  0.9308,  1.1025],\n",
      "          [ 1.5312,  2.4345,  2.1262,  ...,  2.4627,  2.2318,  1.9222],\n",
      "          [ 2.1289,  4.4190,  3.4236,  ...,  2.3795,  2.5950,  1.7033],\n",
      "          ...,\n",
      "          [ 1.6598,  4.0315,  1.1145,  ...,  2.6846,  1.8393,  1.5213],\n",
      "          [ 1.8198,  4.3833,  1.8674,  ...,  2.8222,  2.3498,  1.7409],\n",
      "          [ 1.6479,  3.6366,  1.1319,  ...,  2.7647,  2.2248,  1.8379]],\n",
      "\n",
      "         [[ 1.6739,  3.2266,  4.7563,  ...,  4.3615,  4.0399,  3.3194],\n",
      "          [ 5.0064,  0.9398,  4.3273,  ...,  3.7935,  3.6335,  1.6043],\n",
      "          [ 0.6484,  6.5227,  2.4803,  ...,  4.4128,  1.4650,  1.2573],\n",
      "          ...,\n",
      "          [ 3.5098,  1.5652,  6.1429,  ...,  3.5283,  3.7032,  1.1597],\n",
      "          [ 2.1695,  2.3147,  3.5331,  ...,  4.3022,  4.0249,  3.1880],\n",
      "          [ 3.0100,  0.0494,  2.9638,  ...,  2.6627,  3.9609,  2.7842]]]],\n",
      "       grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[-8.8836e-01,  2.6209e+00,  2.6911e+00,  ...,  8.5333e-01,\n",
      "            3.2271e+00,  2.0468e+00],\n",
      "          [ 9.2965e-01,  2.7628e+00,  2.2055e+00,  ...,  1.9878e+00,\n",
      "            4.1042e+00,  7.4697e+00],\n",
      "          [ 1.5210e+00,  2.5216e+00,  3.6471e+00,  ...,  3.0129e+00,\n",
      "            4.7814e+00,  8.0325e+00],\n",
      "          ...,\n",
      "          [ 9.9024e-01,  3.7281e+00,  3.3452e+00,  ...,  3.6499e+00,\n",
      "            5.4121e+00,  8.3249e+00],\n",
      "          [ 5.0261e-01,  2.6387e+00,  2.7469e+00,  ...,  2.9156e+00,\n",
      "            4.9092e+00,  7.3900e+00],\n",
      "          [ 1.7470e+00,  1.3611e+00,  9.0746e-01,  ...,  4.3474e-01,\n",
      "            1.8578e+00,  7.6226e+00]],\n",
      "\n",
      "         [[-9.8842e-01,  9.1713e-01,  1.2729e+00,  ..., -4.0880e-01,\n",
      "            2.3091e-01,  2.0461e+00],\n",
      "          [ 2.0531e+00,  1.9754e+00,  2.0875e+00,  ...,  1.2394e+00,\n",
      "            1.6760e+00,  4.0830e+00],\n",
      "          [ 2.3203e+00,  3.0799e+00,  1.8438e+00,  ...,  1.5149e+00,\n",
      "            2.2409e+00,  4.2384e+00],\n",
      "          ...,\n",
      "          [ 7.7671e-01,  2.4211e+00,  1.6647e+00,  ...,  1.4948e+00,\n",
      "            1.4652e+00,  4.9639e+00],\n",
      "          [ 1.0567e+00,  3.1895e+00,  1.3826e+00,  ...,  1.2614e+00,\n",
      "            1.1823e+00,  3.7300e+00],\n",
      "          [ 1.4904e+00,  1.0471e+00,  8.0908e-02,  ..., -1.8569e-01,\n",
      "            6.7032e-01,  5.8515e+00]],\n",
      "\n",
      "         [[-9.3565e-01,  2.6272e+00,  3.0481e+00,  ...,  1.3809e+00,\n",
      "            3.4560e+00,  1.9568e+00],\n",
      "          [ 2.7515e+00,  1.6962e+00,  1.5158e+00,  ...,  1.9381e-01,\n",
      "            2.7255e+00,  5.3967e+00],\n",
      "          [ 2.8265e+00,  1.5899e+00,  1.7973e+00,  ...,  1.6921e+00,\n",
      "            3.0863e+00,  5.4159e+00],\n",
      "          ...,\n",
      "          [ 1.8244e+00,  2.0592e+00,  2.4247e+00,  ...,  2.9311e+00,\n",
      "            4.0516e+00,  5.6893e+00],\n",
      "          [ 2.2730e+00,  1.7268e+00,  2.6580e+00,  ...,  2.4530e+00,\n",
      "            2.2078e+00,  4.6665e+00],\n",
      "          [ 1.0938e+00,  1.9092e-01, -3.2488e-01,  ..., -5.2825e-01,\n",
      "            1.2276e+00,  4.8478e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.5819e-01,  1.5784e-01, -1.8055e+00,  ..., -6.7490e-01,\n",
      "            1.1922e+00,  3.8049e+00],\n",
      "          [ 2.3286e+00,  1.7014e+00,  7.0849e-01,  ...,  2.2673e-01,\n",
      "            2.4515e+00,  5.7555e+00],\n",
      "          [ 2.6361e+00,  1.9373e+00,  6.7736e-01,  ...,  5.8013e-01,\n",
      "            3.5506e+00,  5.2397e+00],\n",
      "          ...,\n",
      "          [ 2.5384e+00,  3.7765e+00,  3.9762e+00,  ..., -3.1689e-01,\n",
      "            3.7288e+00,  4.2990e+00],\n",
      "          [ 1.5461e+00,  2.3811e+00,  3.4871e+00,  ...,  1.4337e+00,\n",
      "            2.2700e+00,  2.6508e+00],\n",
      "          [ 7.2958e-01, -2.4198e-01, -9.7352e-01,  ..., -6.1105e-01,\n",
      "            5.9087e-01,  4.4940e+00]],\n",
      "\n",
      "         [[ 9.3081e-01,  2.3916e+00,  2.0433e+00,  ...,  2.5800e-01,\n",
      "            2.4581e+00,  4.3360e+00],\n",
      "          [ 2.5545e+00,  4.0239e+00,  1.7873e+00,  ...,  1.2807e+00,\n",
      "            3.9977e+00,  7.4749e+00],\n",
      "          [ 2.1705e+00,  5.0770e+00,  1.8076e+00,  ...,  1.8537e+00,\n",
      "            4.5180e+00,  6.8752e+00],\n",
      "          ...,\n",
      "          [ 2.4777e+00,  6.1553e+00,  3.8052e+00,  ...,  1.8269e+00,\n",
      "            4.5117e+00,  8.0394e+00],\n",
      "          [ 2.7081e+00,  5.1696e+00,  4.1416e+00,  ...,  3.1427e+00,\n",
      "            4.6438e+00,  6.0396e+00],\n",
      "          [ 8.3869e-01,  2.0661e+00,  1.5778e+00,  ..., -2.9383e-01,\n",
      "            1.1837e+00,  5.4710e+00]],\n",
      "\n",
      "         [[-4.1351e-01,  2.1885e+00, -7.1621e-01,  ...,  3.4720e-01,\n",
      "            3.6039e+00,  2.1978e+00],\n",
      "          [ 3.6131e+00,  1.3728e+00,  1.7933e-01,  ...,  7.1653e-01,\n",
      "            5.0915e+00,  6.1077e+00],\n",
      "          [ 4.3758e+00,  4.9074e+00,  2.8546e+00,  ...,  7.4653e-01,\n",
      "            3.1364e+00,  3.6271e+00],\n",
      "          ...,\n",
      "          [ 4.7900e-01,  3.6365e+00,  3.9862e+00,  ...,  3.0509e+00,\n",
      "            1.1400e+00,  5.2945e+00],\n",
      "          [ 6.2086e-01,  5.5258e-01, -1.0902e-01,  ...,  4.0709e+00,\n",
      "            2.6867e+00,  4.2017e+00],\n",
      "          [-3.8840e-01,  5.1649e-02, -7.3115e-01,  ..., -7.6691e-01,\n",
      "            6.0608e-01,  4.4740e+00]]],\n",
      "\n",
      "\n",
      "        [[[-3.2144e-01,  4.0174e+00,  9.2035e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.6317e+00,  3.3645e+00,  1.0594e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0464e+00,  2.3185e+00,  3.5864e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.4499e+00,  3.0121e+00,  1.0041e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.8977e+00,  3.3151e+00,  2.3342e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.7638e+00,  3.3487e+00,  1.5378e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 5.7098e-02,  1.4387e+00, -8.5355e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.8608e+00,  2.1075e+00,  2.9909e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.0243e-01,  3.3264e+00,  1.1845e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 5.4760e-01,  2.6130e+00,  1.4134e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.4133e-01,  3.6157e+00,  1.8948e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.7956e-01,  2.9005e+00,  1.7613e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 6.7045e-01,  2.8227e+00,  3.4935e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.7046e+00,  1.3680e+00,  4.9735e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.1815e+00,  1.4885e+00,  1.7108e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.4532e+00,  2.1641e+00,  1.7830e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.2101e+00,  1.6245e+00,  2.1123e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.2654e+00,  1.9363e+00,  2.3509e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.7871e-01, -8.3932e-01,  4.1660e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.2610e+00,  1.1073e+00,  2.2054e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.1783e+00,  9.8442e-01,  2.1688e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.8126e+00,  2.4514e+00,  2.8342e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.3489e+00,  2.1826e+00,  2.2616e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.6348e+00,  2.3903e+00,  2.2755e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 4.4564e-01,  3.0354e+00, -2.0233e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.5312e+00,  2.4345e+00,  2.1262e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.1289e+00,  4.4190e+00,  3.4236e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.6598e+00,  4.0315e+00,  1.1145e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.8198e+00,  4.3833e+00,  1.8674e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.6479e+00,  3.6366e+00,  1.1319e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.6739e+00,  3.2266e+00,  4.7563e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.0064e+00,  9.3975e-01,  4.3273e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.4841e-01,  6.5227e+00,  2.4803e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 3.5098e+00,  1.5652e+00,  6.1429e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.1695e+00,  2.3147e+00,  3.5331e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.0100e+00,  4.9428e-02,  2.9638e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[6.0723e-03, 2.0296e-01, 2.1772e-01,  ..., 3.4655e-02,\n",
      "           3.7211e-01, 1.1431e-01],\n",
      "          [1.3678e-03, 8.5536e-03, 4.8992e-03,  ..., 3.9406e-03,\n",
      "           3.2714e-02, 9.4695e-01],\n",
      "          [1.3934e-03, 3.7900e-03, 1.1680e-02,  ..., 6.1944e-03,\n",
      "           3.6313e-02, 9.3753e-01],\n",
      "          ...,\n",
      "          [6.0229e-04, 9.3081e-03, 6.3465e-03,  ..., 8.6075e-03,\n",
      "           5.0140e-02, 9.2298e-01],\n",
      "          [8.9503e-04, 7.5777e-03, 8.4438e-03,  ..., 9.9953e-03,\n",
      "           7.3381e-02, 8.7699e-01],\n",
      "          [2.7786e-03, 1.8890e-03, 1.2002e-03,  ..., 7.4806e-04,\n",
      "           3.1044e-03, 9.8994e-01]],\n",
      "\n",
      "         [[2.1850e-02, 1.4690e-01, 2.0967e-01,  ..., 3.9010e-02,\n",
      "           7.3960e-02, 4.5429e-01],\n",
      "          [8.4605e-02, 7.8275e-02, 8.7563e-02,  ..., 3.7495e-02,\n",
      "           5.8022e-02, 6.4411e-01],\n",
      "          [8.3375e-02, 1.7821e-01, 5.1775e-02,  ..., 3.7262e-02,\n",
      "           7.7015e-02, 5.6762e-01],\n",
      "          ...,\n",
      "          [1.2605e-02, 6.5271e-02, 3.0634e-02,  ..., 2.5848e-02,\n",
      "           2.5094e-02, 8.2993e-01],\n",
      "          [3.5700e-02, 3.0126e-01, 4.9452e-02,  ..., 4.3810e-02,\n",
      "           4.0475e-02, 5.1721e-01],\n",
      "          [1.2357e-02, 7.9320e-03, 3.0183e-03,  ..., 2.3120e-03,\n",
      "           5.4418e-03, 9.6806e-01]],\n",
      "\n",
      "         [[4.8320e-03, 1.7039e-01, 2.5956e-01,  ..., 4.8999e-02,\n",
      "           3.9030e-01, 8.7154e-02],\n",
      "          [5.9325e-02, 2.0650e-02, 1.7240e-02,  ..., 4.5965e-03,\n",
      "           5.7800e-02, 8.3561e-01],\n",
      "          [5.9567e-02, 1.7296e-02, 2.1282e-02,  ..., 1.9157e-02,\n",
      "           7.7237e-02, 7.9351e-01],\n",
      "          ...,\n",
      "          [1.5208e-02, 1.9233e-02, 2.7719e-02,  ..., 4.5992e-02,\n",
      "           1.4104e-01, 7.2540e-01],\n",
      "          [5.8577e-02, 3.3925e-02, 8.6085e-02,  ..., 7.0132e-02,\n",
      "           5.4880e-02, 6.4156e-01],\n",
      "          [2.1824e-02, 8.8477e-03, 5.2822e-03,  ..., 4.3102e-03,\n",
      "           2.4948e-02, 9.3173e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.3648e-02, 2.2547e-02, 3.1653e-03,  ..., 9.8048e-03,\n",
      "           6.3432e-02, 8.6493e-01],\n",
      "          [2.9580e-02, 1.5799e-02, 5.8534e-03,  ..., 3.6156e-03,\n",
      "           3.3450e-02, 9.1049e-01],\n",
      "          [5.5936e-02, 2.7812e-02, 7.8893e-03,  ..., 7.1584e-03,\n",
      "           1.3959e-01, 7.5586e-01],\n",
      "          ...,\n",
      "          [5.5735e-02, 1.9222e-01, 2.3471e-01,  ..., 3.2068e-03,\n",
      "           1.8326e-01, 3.2415e-01],\n",
      "          [5.9167e-02, 1.3638e-01, 4.1218e-01,  ..., 5.2882e-02,\n",
      "           1.2203e-01, 1.7860e-01],\n",
      "          [2.1756e-02, 8.2343e-03, 3.9621e-03,  ..., 5.6930e-03,\n",
      "           1.8938e-02, 9.3852e-01]],\n",
      "\n",
      "         [[2.2641e-02, 9.7574e-02, 6.8872e-02,  ..., 1.1553e-02,\n",
      "           1.0428e-01, 6.8194e-01],\n",
      "          [6.7785e-03, 2.9462e-02, 3.1474e-03,  ..., 1.8963e-03,\n",
      "           2.8702e-02, 9.2907e-01],\n",
      "          [7.0466e-03, 1.2890e-01, 4.9021e-03,  ..., 5.1336e-03,\n",
      "           7.3703e-02, 7.7839e-01],\n",
      "          ...,\n",
      "          [3.1783e-03, 1.2570e-01, 1.1987e-02,  ..., 1.6578e-03,\n",
      "           2.4296e-02, 8.2721e-01],\n",
      "          [1.7042e-02, 1.9978e-01, 7.1464e-02,  ..., 2.6319e-02,\n",
      "           1.1809e-01, 4.7687e-01],\n",
      "          [8.9514e-03, 3.0546e-02, 1.8746e-02,  ..., 2.8843e-03,\n",
      "           1.2639e-02, 9.1974e-01]],\n",
      "\n",
      "         [[1.1479e-02, 1.5486e-01, 8.4807e-03,  ..., 2.4562e-02,\n",
      "           6.3772e-01, 1.5630e-01],\n",
      "          [5.6464e-02, 6.0093e-03, 1.8218e-03,  ..., 3.1175e-03,\n",
      "           2.4764e-01, 6.8419e-01],\n",
      "          [2.6680e-01, 4.5399e-01, 5.8280e-02,  ..., 7.0793e-03,\n",
      "           7.7249e-02, 1.2618e-01],\n",
      "          ...,\n",
      "          [1.3512e-03, 3.1770e-02, 4.5069e-02,  ..., 1.7688e-02,\n",
      "           2.6170e-03, 1.6675e-01],\n",
      "          [1.2292e-02, 1.1481e-02, 5.9243e-03,  ..., 3.8720e-01,\n",
      "           9.7003e-02, 4.4133e-01],\n",
      "          [7.3273e-03, 1.1378e-02, 5.2010e-03,  ..., 5.0183e-03,\n",
      "           1.9808e-02, 9.4770e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.0236e-02, 7.8429e-01, 3.5435e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.9695e-03, 1.6797e-02, 1.6754e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4048e-02, 5.0132e-02, 1.7813e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [7.9709e-03, 3.8016e-02, 5.1036e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.4705e-02, 1.0195e-01, 3.8224e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1584e-02, 1.0531e-01, 1.7218e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[7.6936e-02, 3.0632e-01, 6.6721e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.2436e-02, 2.8714e-02, 6.9460e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9678e-02, 3.6631e-01, 4.3017e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [8.4883e-03, 6.6962e-02, 2.0176e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0870e-02, 2.3518e-01, 4.2075e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.2966e-03, 7.6459e-02, 2.4474e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[3.1391e-02, 2.7011e-01, 5.2823e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0667e-02, 1.3312e-02, 5.5734e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.3494e-01, 6.7475e-02, 8.4276e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.5668e-02, 4.1690e-02, 2.8481e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.1081e-02, 5.0711e-02, 8.2594e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.1864e-02, 5.1709e-02, 7.8281e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.1254e-02, 8.3208e-03, 2.9215e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.2665e-02, 9.5940e-03, 2.8767e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.8574e-01, 2.0707e-02, 6.7684e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.0437e-02, 7.6592e-02, 1.1232e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.2073e-02, 9.6840e-02, 1.0481e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.1487e-02, 1.3088e-01, 1.1669e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.4125e-02, 1.8824e-01, 7.3891e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.3588e-03, 5.8206e-03, 4.2762e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.5421e-02, 1.5230e-01, 5.6283e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [9.5971e-03, 1.0284e-01, 5.5630e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4671e-02, 1.9045e-01, 1.5386e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.7459e-02, 1.2755e-01, 1.0421e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[3.4927e-02, 1.6501e-01, 7.6181e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.8243e-02, 9.9794e-04, 2.9531e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.5292e-03, 8.9984e-01, 1.5796e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.9121e-02, 8.4570e-03, 8.2272e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.5056e-01, 1.7408e-01, 5.8870e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.3734e-01, 2.2650e-02, 4.1762e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[-4.0917e-01, -1.0464e+00, -1.4503e+00,  ...,  6.9275e-01,\n",
      "           -4.9196e-01,  4.8159e-01],\n",
      "          [-1.1396e-02, -3.0443e-02, -7.9530e-02,  ...,  4.8130e-02,\n",
      "            1.7289e-02,  6.0711e-02],\n",
      "          [-2.0913e-02, -3.9427e-02, -9.5523e-02,  ...,  5.5019e-02,\n",
      "            7.5013e-03,  6.6979e-02],\n",
      "          ...,\n",
      "          [-3.6057e-02, -5.2259e-02, -1.2066e-01,  ...,  8.0739e-02,\n",
      "            3.4370e-03,  6.7580e-02],\n",
      "          [-5.8368e-02, -9.6551e-02, -1.7623e-01,  ...,  1.2997e-01,\n",
      "           -4.8250e-02,  7.7620e-02],\n",
      "          [ 2.4790e-02,  1.6586e-02, -7.3691e-03,  ..., -5.2124e-03,\n",
      "            4.1028e-02,  4.2388e-02]],\n",
      "\n",
      "         [[-4.2843e-01,  1.6575e-01,  1.4469e-01,  ..., -1.2321e-01,\n",
      "            1.4127e-02,  4.2184e-01],\n",
      "          [-2.1059e-01,  1.4840e-01,  3.3297e-02,  ..., -5.6659e-02,\n",
      "           -9.1935e-02,  2.3187e-01],\n",
      "          [-3.8261e-01,  1.8978e-01,  3.5274e-02,  ..., -9.2956e-02,\n",
      "           -1.0272e-01,  2.4920e-01],\n",
      "          ...,\n",
      "          [-1.4757e-01,  5.7133e-02,  1.5183e-03,  ..., -3.3792e-02,\n",
      "           -4.7746e-02,  1.3520e-01],\n",
      "          [-5.3801e-01,  1.5125e-01,  1.5468e-01,  ..., -1.2506e-01,\n",
      "           -2.8778e-02,  2.8807e-01],\n",
      "          [-2.0858e-02,  5.5486e-03, -1.7310e-02,  ...,  1.3916e-02,\n",
      "           -5.0609e-02,  2.5431e-02]],\n",
      "\n",
      "         [[ 5.3866e-01, -5.8093e-01,  2.1685e-01,  ..., -1.1657e-01,\n",
      "            6.8213e-03, -5.2973e-01],\n",
      "          [ 7.0435e-02, -3.4692e-02,  1.6433e-02,  ...,  4.6892e-02,\n",
      "           -3.3302e-02, -6.2875e-02],\n",
      "          [ 8.5720e-02, -6.2109e-02,  1.9324e-02,  ...,  5.3669e-02,\n",
      "           -1.9336e-02, -9.4370e-02],\n",
      "          ...,\n",
      "          [ 1.7017e-01, -1.4903e-01,  5.7836e-02,  ...,  6.7844e-02,\n",
      "            2.6666e-02, -1.9280e-01],\n",
      "          [ 3.8047e-02, -1.5839e-01, -7.0291e-02,  ..., -3.4201e-02,\n",
      "            3.6526e-02, -1.4120e-01],\n",
      "          [ 4.3595e-02, -6.7604e-03,  4.1492e-03,  ...,  4.8930e-02,\n",
      "           -8.9875e-03, -3.0649e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6297e-01, -4.6500e-05, -1.4280e-01,  ..., -3.0743e-02,\n",
      "            3.7617e-02, -2.6846e-02],\n",
      "          [ 1.3289e-01, -1.5454e-02, -1.4378e-01,  ..., -5.9290e-02,\n",
      "            2.4005e-02, -7.3721e-03],\n",
      "          [ 2.3840e-01,  3.0220e-02, -1.6501e-01,  ...,  3.4145e-02,\n",
      "            5.0035e-02, -7.5540e-02],\n",
      "          ...,\n",
      "          [ 3.2289e-01,  3.9151e-02,  5.4684e-02,  ...,  1.5783e-01,\n",
      "            3.1664e-01, -1.4321e-01],\n",
      "          [ 1.9253e-01, -8.7605e-02,  1.0858e-01,  ...,  2.2454e-01,\n",
      "            3.4539e-01, -1.3847e-01],\n",
      "          [ 1.1391e-01, -2.1223e-02, -1.4126e-01,  ..., -7.3560e-02,\n",
      "            1.6043e-02,  2.1688e-03]],\n",
      "\n",
      "         [[-1.2621e-01,  1.0908e-01,  1.4738e-03,  ...,  2.3729e-02,\n",
      "            3.4699e-02,  1.1717e-01],\n",
      "          [ 7.8008e-03,  3.9557e-02,  1.1919e-02,  ...,  4.5918e-02,\n",
      "            5.0665e-02,  1.5729e-02],\n",
      "          [-1.1589e-01,  9.0244e-02, -4.4996e-02,  ...,  1.7606e-02,\n",
      "            2.9398e-02,  1.6204e-01],\n",
      "          ...,\n",
      "          [-7.9097e-02,  7.1694e-02, -3.9897e-02,  ..., -1.2963e-02,\n",
      "            4.9817e-02,  1.4622e-01],\n",
      "          [-2.8674e-01,  1.4553e-01, -4.8055e-02,  ...,  1.2307e-02,\n",
      "            5.6473e-03,  3.3514e-01],\n",
      "          [ 1.3077e-02,  3.7439e-02,  2.0409e-02,  ...,  2.9161e-02,\n",
      "            6.0923e-02,  1.1915e-02]],\n",
      "\n",
      "         [[ 7.1605e-02, -1.8248e-01, -1.7969e-01,  ..., -1.0632e-01,\n",
      "            1.0058e-02,  2.4813e-02],\n",
      "          [ 7.2239e-02, -3.5270e-02, -7.6424e-02,  ..., -2.4199e-02,\n",
      "            1.0436e-01,  2.1987e-02],\n",
      "          [-1.6933e-01, -1.1151e-01,  5.5443e-02,  ..., -1.3119e-01,\n",
      "           -3.1064e-01,  6.6935e-02],\n",
      "          ...,\n",
      "          [-2.1149e-01,  9.3583e-01,  4.9405e-01,  ..., -6.8065e-02,\n",
      "           -4.7452e-01, -1.2037e-01],\n",
      "          [-3.0677e-01,  3.4815e-01, -5.2950e-02,  ..., -2.8998e-01,\n",
      "            4.7461e-01, -4.4120e-01],\n",
      "          [-1.0838e-02,  7.1532e-02, -1.4343e-02,  ..., -1.5386e-02,\n",
      "            5.7592e-02,  2.5200e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9718e-01, -2.1564e-01, -4.1668e-03,  ...,  4.3128e-01,\n",
      "           -1.0454e+00, -6.5600e-01],\n",
      "          [ 5.1598e-02,  3.6930e-02, -1.4831e-02,  ...,  8.3660e-03,\n",
      "            2.9112e-02,  3.0823e-02],\n",
      "          [ 2.3593e-01,  1.3300e-01,  2.8751e-02,  ...,  5.1870e-02,\n",
      "            1.1147e-01,  5.3629e-02],\n",
      "          ...,\n",
      "          [ 7.3653e-02,  3.3879e-02, -1.5811e-02,  ...,  2.2457e-02,\n",
      "            4.5583e-03,  1.5493e-02],\n",
      "          [ 1.6201e-01,  3.8764e-02, -1.3254e-02,  ...,  6.8301e-02,\n",
      "           -5.2426e-02, -2.3674e-02],\n",
      "          [ 1.4107e-01,  2.3760e-02, -1.7667e-02,  ...,  6.6302e-02,\n",
      "           -7.4050e-02, -3.4204e-02]],\n",
      "\n",
      "         [[ 2.3420e-01,  5.6615e-02, -1.3986e-01,  ..., -1.5452e-01,\n",
      "            5.4809e-03,  1.1068e-01],\n",
      "          [ 7.0993e-02, -6.1476e-02, -1.0724e-01,  ..., -7.9716e-03,\n",
      "           -8.5889e-02,  5.2228e-02],\n",
      "          [ 2.3245e-01,  1.0628e-01, -1.0611e-01,  ..., -1.8870e-01,\n",
      "            1.1417e-01,  9.4385e-02],\n",
      "          ...,\n",
      "          [ 5.0008e-02,  1.1611e-03, -5.4529e-02,  ..., -2.1934e-02,\n",
      "           -2.8788e-02,  4.1907e-02],\n",
      "          [ 1.5838e-01,  5.1940e-02, -9.2272e-02,  ..., -1.1753e-01,\n",
      "            5.2385e-02,  7.2093e-02],\n",
      "          [ 5.8380e-02,  1.1890e-03, -5.9851e-02,  ..., -2.7876e-02,\n",
      "           -2.5067e-02,  4.4188e-02]],\n",
      "\n",
      "         [[ 6.7277e-02, -7.3840e-01,  9.6065e-02,  ..., -4.0197e-01,\n",
      "           -3.3178e-01,  3.3835e-01],\n",
      "          [-5.3578e-03,  1.6639e-02, -1.5037e-02,  ...,  3.2761e-02,\n",
      "           -6.0319e-02, -2.8319e-02],\n",
      "          [-3.5285e-02, -7.2305e-02, -9.6344e-03,  ..., -4.3885e-02,\n",
      "           -1.7359e-01, -2.7328e-03],\n",
      "          ...,\n",
      "          [-2.1701e-02, -1.7935e-02, -1.3761e-02,  ...,  2.8314e-02,\n",
      "           -8.0406e-02,  2.9490e-03],\n",
      "          [-6.4444e-03, -8.0756e-02, -2.8526e-03,  ..., -4.4616e-02,\n",
      "           -1.3456e-01,  2.3257e-03],\n",
      "          [-4.8082e-03, -8.1309e-02, -2.4075e-03,  ..., -3.2278e-02,\n",
      "           -1.1759e-01,  1.2895e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.5432e-02, -4.8760e-02, -1.6597e-01,  ..., -9.7761e-02,\n",
      "            2.7606e-02,  3.8065e-02],\n",
      "          [ 8.1242e-02, -7.1611e-02, -1.8641e-01,  ..., -8.7815e-02,\n",
      "            3.1032e-02,  4.5113e-02],\n",
      "          [ 6.6673e-02, -1.4205e-01, -2.5667e-01,  ..., -6.5327e-02,\n",
      "            5.8648e-02,  7.3785e-02],\n",
      "          ...,\n",
      "          [ 5.4826e-02, -8.4597e-02, -1.5349e-01,  ..., -1.2552e-01,\n",
      "            5.4389e-02,  6.0481e-02],\n",
      "          [ 4.2792e-02, -1.0753e-01, -1.4924e-01,  ..., -1.2449e-01,\n",
      "            4.9300e-02,  6.5126e-02],\n",
      "          [ 2.2582e-02, -1.5063e-01, -1.5596e-01,  ..., -1.2339e-01,\n",
      "            5.3105e-02,  7.8852e-02]],\n",
      "\n",
      "         [[ 7.3565e-02, -1.0385e-01,  1.3901e-01,  ...,  1.6155e-02,\n",
      "           -5.3540e-02,  1.7783e-03],\n",
      "          [ 6.5381e-02,  2.2331e-02,  3.0164e-02,  ...,  3.5438e-02,\n",
      "            5.2347e-02, -3.1142e-02],\n",
      "          [ 9.4164e-02, -1.1551e-01,  1.5309e-01,  ..., -1.1043e-02,\n",
      "           -3.8658e-02, -1.7770e-02],\n",
      "          ...,\n",
      "          [ 7.0082e-02, -4.4672e-02,  8.9006e-02,  ...,  2.5861e-02,\n",
      "           -3.1143e-03, -1.4797e-02],\n",
      "          [ 7.7144e-02, -1.1122e-01,  1.4583e-01,  ...,  1.0860e-02,\n",
      "           -5.5926e-02,  2.9939e-04],\n",
      "          [ 7.6214e-02, -6.6038e-02,  1.1412e-01,  ...,  2.3108e-02,\n",
      "           -1.3225e-02, -1.8947e-02]],\n",
      "\n",
      "         [[-8.4957e-02,  5.4718e-01,  1.3620e-01,  ..., -9.3823e-02,\n",
      "           -2.0527e-01, -3.0335e-01],\n",
      "          [-1.0793e-02,  8.1386e-02,  2.0199e-02,  ..., -1.0155e-02,\n",
      "            7.2209e-02,  9.8164e-03],\n",
      "          [-1.6051e-02,  2.6241e-01, -7.5194e-01,  ..., -4.8441e-02,\n",
      "           -2.4987e-01, -1.7525e-01],\n",
      "          ...,\n",
      "          [-8.9332e-02,  5.4480e-01,  2.9413e-01,  ..., -9.2595e-02,\n",
      "           -1.6275e-01, -2.9586e-01],\n",
      "          [-6.3857e-02,  4.0848e-01,  8.9696e-02,  ..., -7.1309e-02,\n",
      "           -1.2908e-01, -2.5768e-01],\n",
      "          [-3.6191e-02,  1.8214e-01,  2.1194e-01,  ..., -3.5004e-02,\n",
      "            4.4588e-02, -2.0480e-01]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[ 5.0048e-02, -2.2587e-01,  2.5274e+00,  ...,  1.7283e+00,\n",
      "           -7.7499e-01, -6.4337e-01],\n",
      "          [-1.2425e+00, -1.4041e+00,  1.6899e-01,  ...,  7.4282e-01,\n",
      "            8.2464e-01, -1.6763e+00],\n",
      "          [-8.0569e-02, -8.2320e-01, -6.8749e-01,  ...,  7.4972e-01,\n",
      "            5.6309e-01, -1.6161e+00],\n",
      "          ...,\n",
      "          [-3.8144e-01, -2.0999e-01, -4.7510e-01,  ...,  7.1384e-02,\n",
      "            2.9141e-01, -2.2601e-01],\n",
      "          [-6.6122e-01, -3.3938e-01,  1.4679e+00,  ...,  1.2356e+00,\n",
      "           -1.2075e+00, -1.1294e+00],\n",
      "          [ 4.4889e-01, -9.8456e-02,  3.9789e+00,  ...,  3.2050e-01,\n",
      "            3.0278e-01, -1.1722e-01]],\n",
      "\n",
      "         [[-1.1869e+00, -1.0466e-01, -6.2933e-01,  ...,  1.3651e+00,\n",
      "            1.2821e+00,  1.5969e-01],\n",
      "          [ 1.4324e+00, -1.0370e+00, -6.3682e-01,  ..., -4.9861e-01,\n",
      "           -2.5539e-01, -1.1210e+00],\n",
      "          [ 5.6788e-01, -3.6968e-01,  1.0984e+00,  ..., -2.1147e-01,\n",
      "           -3.6764e-01, -1.2337e+00],\n",
      "          ...,\n",
      "          [ 1.6040e+00, -7.3115e-01, -2.4418e-01,  ..., -7.1874e-01,\n",
      "            7.7622e-01, -5.0640e-01],\n",
      "          [ 1.1610e+00,  3.3921e-01,  8.0442e-01,  ..., -3.1529e-01,\n",
      "           -7.5021e-01, -1.0165e+00],\n",
      "          [ 2.9043e-01,  9.0656e-01, -5.7808e-02,  ..., -2.3885e-01,\n",
      "           -2.9610e-02, -6.0656e-01]],\n",
      "\n",
      "         [[ 9.2587e-02,  7.2079e-02, -3.0204e-01,  ...,  3.8760e-01,\n",
      "            5.6018e-01,  5.7803e-02],\n",
      "          [ 3.5502e-01, -3.0617e-01, -1.2552e-01,  ...,  1.8098e-01,\n",
      "            3.3056e-01,  1.2148e+00],\n",
      "          [ 8.9005e-01, -7.4333e-01, -8.7767e-01,  ...,  7.8403e-01,\n",
      "           -1.6291e+00,  1.0194e+00],\n",
      "          ...,\n",
      "          [ 2.1100e+00,  8.0127e-01, -4.6686e-01,  ..., -2.0516e-01,\n",
      "           -3.6864e-01,  1.3426e+00],\n",
      "          [ 1.0086e+00,  1.0023e+00,  1.0960e+00,  ...,  2.0554e-02,\n",
      "           -6.7285e-01,  3.4615e-01],\n",
      "          [-9.2261e-02,  3.6504e-01,  1.2827e-01,  ...,  1.7770e-01,\n",
      "            7.7852e-02, -1.9278e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4386e-01,  5.0746e-02, -9.1489e-01,  ...,  2.6072e-01,\n",
      "           -1.3291e+00, -5.1694e-01],\n",
      "          [-3.4878e-01,  6.9451e-01,  9.5606e-01,  ...,  3.1618e-01,\n",
      "           -3.4501e-01, -3.3824e-01],\n",
      "          [-2.3557e-02,  9.5304e-01,  7.0068e-02,  ..., -8.4849e-01,\n",
      "           -1.5514e+00,  6.1634e-01],\n",
      "          ...,\n",
      "          [ 3.3506e-01,  6.1188e-01, -4.6185e-01,  ..., -7.3369e-01,\n",
      "           -1.2618e+00,  7.6071e-01],\n",
      "          [-6.8587e-01, -2.1745e-01,  3.7820e-01,  ...,  8.6381e-01,\n",
      "           -1.3547e+00, -1.4326e+00],\n",
      "          [-2.3527e-01,  5.0312e-01, -3.2215e-01,  ..., -1.9430e-01,\n",
      "           -1.5049e+00, -3.7748e+00]],\n",
      "\n",
      "         [[ 5.3064e-01, -8.8650e-01, -7.5539e-01,  ...,  4.6593e-01,\n",
      "            8.0430e-01,  7.0023e-02],\n",
      "          [-1.6701e+00,  2.5854e-01,  6.7720e-01,  ..., -1.0860e+00,\n",
      "           -1.1465e-01, -9.4454e-01],\n",
      "          [-3.7409e+00,  1.6663e-01, -9.6362e-02,  ..., -1.4989e-01,\n",
      "            2.7450e-02, -7.3485e-01],\n",
      "          ...,\n",
      "          [-1.1721e+00,  1.0452e+00,  6.2673e-01,  ...,  9.5490e-01,\n",
      "            1.8659e+00, -1.5199e+00],\n",
      "          [-1.3261e+00,  8.6139e-01,  5.8075e-01,  ...,  1.1766e+00,\n",
      "           -8.7899e-01, -3.9654e-01],\n",
      "          [-7.0366e-01,  9.2332e-01,  1.0674e-01,  ..., -5.0582e-01,\n",
      "            3.6364e-01,  4.7365e-02]],\n",
      "\n",
      "         [[ 6.1313e-01,  5.6341e-01, -9.6850e-01,  ..., -2.2877e-01,\n",
      "            2.8617e-01, -1.5930e-01],\n",
      "          [-5.3578e-01,  4.5209e-01, -6.1493e-01,  ..., -4.1044e-01,\n",
      "           -2.2039e+00, -1.8849e-01],\n",
      "          [-1.9259e+00,  7.1957e-01, -4.4728e-01,  ..., -1.9035e-01,\n",
      "           -2.9708e-01, -2.7992e-01],\n",
      "          ...,\n",
      "          [ 6.4613e-02,  2.9554e-01,  2.8151e-01,  ..., -1.1240e+00,\n",
      "           -1.5337e+00, -2.8501e-01],\n",
      "          [-1.5160e+00,  1.1675e+00, -2.5540e+00,  ..., -2.3717e+00,\n",
      "           -1.2546e+00, -3.9149e-01],\n",
      "          [-6.5768e-01,  2.3284e-01, -4.0192e-01,  ..., -9.8602e-01,\n",
      "            4.9089e-01, -3.0844e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0228e+00, -1.0194e+00,  2.3328e+00,  ...,  7.5359e-01,\n",
      "           -5.4941e-02, -8.9445e-01],\n",
      "          [ 4.5713e-01, -1.5621e-01,  1.5970e+00,  ...,  2.6158e-01,\n",
      "            9.4235e-01, -4.6379e-01],\n",
      "          [ 5.0709e-01, -1.1825e-01,  1.3507e+00,  ..., -1.4824e-02,\n",
      "            1.0191e+00, -2.2554e+00],\n",
      "          ...,\n",
      "          [-9.5545e-01, -1.5474e+00,  1.2478e+00,  ..., -6.1673e-01,\n",
      "            2.5971e-02, -1.2034e+00],\n",
      "          [-6.7516e-01, -1.2727e+00,  1.5603e+00,  ..., -2.6988e-01,\n",
      "            3.9689e-01, -1.5208e+00],\n",
      "          [-8.7933e-01, -1.6628e+00,  1.3822e+00,  ...,  1.2149e-01,\n",
      "           -1.3193e-01, -1.4328e+00]],\n",
      "\n",
      "         [[-1.0115e+00,  6.9979e-01, -5.6321e-01,  ..., -1.0881e-01,\n",
      "            1.1334e+00,  9.5142e-02],\n",
      "          [ 2.4454e+00, -5.4527e-01, -6.6515e-01,  ..., -2.2186e+00,\n",
      "           -1.2526e+00, -1.9648e-01],\n",
      "          [-2.1483e-01, -9.1715e-01,  1.0303e+00,  ..., -3.6976e-01,\n",
      "           -3.9706e-01, -1.1621e+00],\n",
      "          ...,\n",
      "          [ 1.8840e+00, -6.3862e-01, -5.4425e-01,  ..., -4.9752e-01,\n",
      "            3.7827e-01,  3.2005e-01],\n",
      "          [ 9.7822e-01, -4.6337e-01, -6.3155e-01,  ..., -4.6704e-01,\n",
      "            4.1196e-01,  1.8355e-01],\n",
      "          [ 1.5700e+00, -1.7357e-01, -3.2585e-01,  ..., -3.6346e-01,\n",
      "            9.4695e-01,  6.2369e-01]],\n",
      "\n",
      "         [[ 7.3723e-02,  1.2957e+00, -5.2536e-01,  ..., -4.1357e-01,\n",
      "            1.1433e+00, -1.5834e-01],\n",
      "          [-1.3912e+00,  7.4416e-01,  3.8426e-01,  ..., -3.6206e-01,\n",
      "            1.3036e-01,  6.0853e-01],\n",
      "          [ 8.9445e-01,  5.4682e-01, -9.6283e-01,  ..., -3.8919e-01,\n",
      "            6.2209e-01,  3.7063e-01],\n",
      "          ...,\n",
      "          [-1.2915e+00,  3.3032e-01, -1.6222e+00,  ..., -7.1655e-01,\n",
      "            5.4369e-01, -2.6827e-01],\n",
      "          [-9.0233e-01,  1.5593e+00, -1.0369e+00,  ..., -5.5925e-01,\n",
      "            7.1377e-01,  1.5794e-01],\n",
      "          [-1.7560e+00,  1.4656e+00, -5.3297e-01,  ..., -3.4051e-01,\n",
      "            4.4291e-01, -1.3391e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6581e-02, -1.2600e+00, -1.8694e-01,  ..., -3.0267e-01,\n",
      "           -1.6180e+00, -1.3885e+00],\n",
      "          [-7.9451e-01, -1.1991e+00, -6.4676e-01,  ...,  1.1207e+00,\n",
      "           -4.9135e-01, -4.8348e-01],\n",
      "          [-1.6138e+00, -1.2703e+00, -2.5200e+00,  ...,  3.6561e-01,\n",
      "           -9.4657e-01,  1.1134e-01],\n",
      "          ...,\n",
      "          [-3.5452e-01, -5.1008e-01,  4.7434e-01,  ...,  6.5799e-01,\n",
      "           -5.0890e-01,  3.9777e-02],\n",
      "          [-5.8369e-01, -1.0350e+00, -3.7046e-01,  ...,  1.2162e-01,\n",
      "           -1.3524e+00, -1.9425e-03],\n",
      "          [ 1.6793e-01, -2.3595e-01,  8.4272e-01,  ...,  4.4916e-01,\n",
      "           -6.0841e-01,  2.5555e-02]],\n",
      "\n",
      "         [[ 4.9290e-01, -4.9269e-01,  1.0289e+00,  ...,  1.0680e+00,\n",
      "            6.2941e-01, -4.1464e-01],\n",
      "          [-9.6716e-01,  8.2647e-01,  9.8854e-01,  ...,  7.2037e-01,\n",
      "           -9.5210e-01,  8.9208e-01],\n",
      "          [-1.8391e+00, -9.3955e-01,  1.0750e+00,  ...,  1.6173e+00,\n",
      "           -6.1047e-01, -8.6250e-01],\n",
      "          ...,\n",
      "          [-1.4586e+00,  1.2021e+00,  1.0529e+00,  ..., -1.9282e-01,\n",
      "           -9.3806e-01, -1.2965e+00],\n",
      "          [-1.3795e+00,  4.9324e-01,  1.5376e+00,  ...,  3.7295e-01,\n",
      "           -1.0028e+00, -1.2982e+00],\n",
      "          [-9.5904e-01,  1.5249e+00,  1.1175e+00,  ..., -1.4295e-01,\n",
      "           -1.0438e+00, -1.1659e+00]],\n",
      "\n",
      "         [[-3.4282e-01,  3.6466e-01, -1.4828e+00,  ..., -9.5436e-01,\n",
      "           -1.2868e+00,  6.0470e-03],\n",
      "          [-1.7954e+00,  1.2674e+00,  7.6041e-01,  ...,  8.6516e-01,\n",
      "           -4.5197e-01, -2.0101e-02],\n",
      "          [-3.4659e+00,  9.9889e-01, -2.2898e+00,  ..., -4.4175e-01,\n",
      "           -1.3585e+00, -1.6843e+00],\n",
      "          ...,\n",
      "          [-1.2973e+00,  1.1711e+00, -2.0274e+00,  ...,  3.7572e-01,\n",
      "           -1.4334e+00, -3.3719e-01],\n",
      "          [-1.7846e+00,  1.3017e+00, -2.8667e+00,  ...,  2.0752e-01,\n",
      "           -1.5762e+00, -1.9774e+00],\n",
      "          [-1.4160e+00,  1.0881e+00, -1.9576e+00,  ...,  2.4489e-01,\n",
      "           -1.5683e+00, -9.7504e-01]]]], grad_fn=<PermuteBackward0>), query layer: tensor([[[[-1.0027e+00,  7.6448e-01,  2.1572e+00,  ...,  2.8946e-01,\n",
      "            8.4539e-01,  1.7793e-01],\n",
      "          [ 8.6233e-01, -4.2944e-01,  2.3179e+00,  ...,  1.2662e-01,\n",
      "            7.2797e-01,  1.8581e-01],\n",
      "          [ 7.3711e-01, -1.6310e-01,  1.5416e+00,  ...,  1.6263e-01,\n",
      "            1.3611e+00,  8.3083e-01],\n",
      "          ...,\n",
      "          [ 5.4773e-01, -1.3791e+00,  2.2065e+00,  ...,  3.6065e-01,\n",
      "            1.2453e+00,  1.0327e+00],\n",
      "          [ 7.9917e-01, -5.9706e-01,  1.9036e+00,  ...,  1.0922e+00,\n",
      "            1.9377e+00,  2.0730e-01],\n",
      "          [ 9.6555e-01, -2.1880e-02,  2.6500e+00,  ..., -3.7735e-01,\n",
      "            3.7413e-01, -1.0740e-01]],\n",
      "\n",
      "         [[ 3.4847e-01, -8.7069e-01, -1.0529e+00,  ...,  5.4865e-01,\n",
      "            5.0418e-01, -1.0245e+00],\n",
      "          [ 2.9985e-03, -1.1338e+00,  4.0211e-01,  ..., -4.7658e-01,\n",
      "           -1.1045e-01,  2.7667e-01],\n",
      "          [-4.8715e-01, -1.3815e+00, -2.4135e-02,  ..., -1.3001e+00,\n",
      "           -1.7245e+00, -1.0474e-01],\n",
      "          ...,\n",
      "          [-4.4365e-01, -4.3148e-01,  8.2872e-02,  ..., -1.6446e+00,\n",
      "           -1.6005e-01,  1.4215e+00],\n",
      "          [-9.4840e-01, -7.4699e-01,  5.1441e-01,  ...,  5.7957e-02,\n",
      "           -5.9660e-02, -4.3574e-01],\n",
      "          [ 2.3267e-01,  5.1243e-01,  9.4211e-02,  ..., -3.2528e-01,\n",
      "           -3.9653e-02, -7.7828e-01]],\n",
      "\n",
      "         [[-2.8741e+00, -4.8723e-01,  9.1348e-02,  ...,  6.4009e-01,\n",
      "           -5.4614e-01,  1.5717e-02],\n",
      "          [-1.5086e-02, -1.0755e+00, -9.7388e-01,  ...,  1.6549e+00,\n",
      "            6.0735e-01,  2.1345e-01],\n",
      "          [-2.5447e-01,  4.1035e-01, -6.9781e-01,  ...,  8.0041e-01,\n",
      "           -1.3241e+00, -1.2011e+00],\n",
      "          ...,\n",
      "          [ 5.8378e-01, -3.7802e-01,  8.3665e-01,  ...,  2.4621e+00,\n",
      "           -8.1339e-01,  3.9550e-01],\n",
      "          [-1.1160e+00, -1.2683e+00,  8.3082e-01,  ...,  1.3566e+00,\n",
      "            4.1701e-01,  6.3160e-01],\n",
      "          [ 9.2251e-02,  1.5040e-02,  5.7161e-01,  ...,  1.2582e-01,\n",
      "           -2.4079e-01, -3.5536e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0681e+00,  1.2966e+00, -6.1928e-01,  ..., -5.5419e-01,\n",
      "           -9.1491e-01, -2.5961e+00],\n",
      "          [-2.6433e-01,  2.0380e+00,  3.0332e-01,  ..., -2.7821e-01,\n",
      "           -5.8534e-02, -3.1203e+00],\n",
      "          [ 1.1380e-02,  1.1247e+00, -6.0101e-01,  ..., -9.7973e-01,\n",
      "            1.5407e-01, -1.6134e+00],\n",
      "          ...,\n",
      "          [ 1.6657e+00,  1.4837e-01, -8.6561e-01,  ...,  9.0777e-01,\n",
      "           -1.4112e+00, -2.2185e+00],\n",
      "          [ 5.0401e-01,  9.1262e-01,  4.3433e-01,  ...,  2.9351e-01,\n",
      "           -1.2170e+00, -2.6260e+00],\n",
      "          [ 2.0693e-01,  1.1150e+00, -4.0663e-02,  ..., -2.1726e-01,\n",
      "           -8.2649e-01, -2.2156e+00]],\n",
      "\n",
      "         [[-1.5965e+00,  6.2072e-01,  1.8524e-01,  ..., -2.6796e+00,\n",
      "           -6.8507e-01,  2.7633e-01],\n",
      "          [-1.0941e+00,  1.0116e+00,  8.0302e-01,  ..., -5.2840e-02,\n",
      "           -1.5195e-01,  3.4323e-01],\n",
      "          [-1.5729e+00,  3.6693e-01,  3.3655e-01,  ..., -2.2036e-01,\n",
      "           -3.4429e-01,  3.6614e-01],\n",
      "          ...,\n",
      "          [-1.6860e+00, -1.7619e-01, -7.2984e-01,  ...,  3.6118e-01,\n",
      "           -2.4193e-02, -2.8043e-02],\n",
      "          [ 2.8531e-03,  7.0910e-02, -7.9409e-01,  ..., -1.6707e-01,\n",
      "           -5.1865e-01, -1.1813e+00],\n",
      "          [-1.2221e+00,  5.4526e-01, -9.4180e-02,  ..., -7.2250e-01,\n",
      "            7.6591e-01,  7.1436e-02]],\n",
      "\n",
      "         [[-1.2114e+00,  2.0006e+00, -5.1562e-01,  ..., -1.0778e+00,\n",
      "           -5.7858e-01, -6.1039e-01],\n",
      "          [ 9.9942e-02,  1.5417e+00, -5.3643e-01,  ..., -2.3233e-01,\n",
      "           -2.6212e-01,  6.7613e-02],\n",
      "          [ 6.4842e-01,  5.8117e-01, -4.2229e-01,  ...,  6.4712e-01,\n",
      "           -7.4138e-01, -1.4127e+00],\n",
      "          ...,\n",
      "          [-9.5115e-01, -3.4761e-01, -2.4173e-01,  ..., -4.4085e-01,\n",
      "           -4.5063e-01, -8.3386e-01],\n",
      "          [ 1.8492e-01,  1.0850e-01,  1.1225e-01,  ..., -1.4367e+00,\n",
      "           -1.8072e+00,  4.6295e-02],\n",
      "          [-3.3809e-01,  6.8820e-01,  2.1112e-02,  ..., -8.9129e-01,\n",
      "            1.0536e-01, -2.5682e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0898e+00,  2.3907e-01,  1.8163e+00,  ...,  1.1565e-01,\n",
      "           -1.4149e-01, -1.3770e-01],\n",
      "          [-1.1767e+00, -2.0470e+00,  1.7210e+00,  ...,  2.6456e-01,\n",
      "            1.1244e+00,  1.2483e+00],\n",
      "          [-1.7624e+00, -9.8402e-02,  1.9535e+00,  ..., -1.0990e-01,\n",
      "            1.0113e+00,  2.3776e-01],\n",
      "          ...,\n",
      "          [-5.7940e-01, -9.1658e-01,  1.7823e+00,  ...,  5.2692e-01,\n",
      "            1.6400e+00,  1.7288e+00],\n",
      "          [-4.2177e-01, -2.9006e-01,  2.3570e+00,  ..., -3.8498e-01,\n",
      "            1.3736e+00,  1.1900e+00],\n",
      "          [-5.4056e-01, -1.7276e-01,  2.3503e+00,  ...,  4.5850e-02,\n",
      "            1.6071e+00,  1.0797e+00]],\n",
      "\n",
      "         [[ 5.6384e-01,  4.8213e-02, -1.2973e-01,  ...,  5.1087e-01,\n",
      "            6.6453e-02, -1.2470e+00],\n",
      "          [ 5.0644e-01, -5.3723e-01,  9.3874e-01,  ..., -2.8140e+00,\n",
      "           -8.8420e-01,  1.2335e-01],\n",
      "          [-4.7116e-02, -2.0162e-01,  7.2378e-01,  ..., -6.8663e-01,\n",
      "            1.4747e-01, -1.0989e+00],\n",
      "          ...,\n",
      "          [ 1.6258e+00,  8.9166e-01,  6.4159e-01,  ..., -1.2473e+00,\n",
      "           -8.6948e-01, -4.9199e-01],\n",
      "          [ 1.4985e+00,  8.9418e-01,  1.4879e+00,  ..., -4.6324e-01,\n",
      "           -2.9645e-01, -1.3360e+00],\n",
      "          [ 1.2320e+00,  9.1605e-01,  5.3827e-01,  ..., -7.3787e-01,\n",
      "           -6.8472e-01, -6.3408e-01]],\n",
      "\n",
      "         [[-2.7519e+00,  3.0656e-01,  8.7246e-01,  ...,  7.0343e-01,\n",
      "           -7.7671e-01,  2.7964e-01],\n",
      "          [ 1.1236e+00,  6.9317e-01, -1.4973e-01,  ...,  1.0001e+00,\n",
      "            1.1033e+00, -1.5221e-01],\n",
      "          [-2.0903e+00, -4.2444e-01, -7.9366e-01,  ...,  8.6167e-02,\n",
      "           -2.3001e-01,  6.6820e-01],\n",
      "          ...,\n",
      "          [ 1.9191e-01, -1.6931e-01, -5.9501e-02,  ..., -9.4755e-01,\n",
      "           -4.6680e-01,  1.3454e+00],\n",
      "          [-1.1685e+00,  2.3545e-01,  8.4443e-01,  ..., -5.8257e-01,\n",
      "           -7.8382e-01,  1.3979e+00],\n",
      "          [-7.5493e-01,  3.0610e-01,  1.4377e+00,  ..., -9.1115e-01,\n",
      "           -5.0523e-01,  1.3123e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.9607e-01,  1.3371e+00,  1.8739e-01,  ..., -5.8817e-01,\n",
      "           -1.3094e+00, -1.6350e+00],\n",
      "          [ 5.2552e-01,  1.5047e-01,  4.5251e-01,  ...,  1.1751e-01,\n",
      "           -8.3114e-01, -1.9277e+00],\n",
      "          [ 1.6040e+00,  3.4925e-01,  9.9392e-01,  ...,  4.2197e-02,\n",
      "           -1.0720e+00, -1.8367e+00],\n",
      "          ...,\n",
      "          [-2.7133e-01,  9.3565e-01,  7.9673e-01,  ..., -4.4892e-01,\n",
      "           -2.0327e+00, -2.9867e+00],\n",
      "          [ 9.7335e-02,  5.7187e-01,  6.8058e-01,  ..., -1.0557e+00,\n",
      "           -1.4893e+00, -2.5371e+00],\n",
      "          [-5.6854e-01,  6.0635e-01,  9.2600e-01,  ..., -8.9448e-01,\n",
      "           -2.1819e+00, -2.4687e+00]],\n",
      "\n",
      "         [[-1.5483e+00,  8.8648e-01,  4.7489e-01,  ..., -2.4355e+00,\n",
      "           -5.7894e-01,  5.9940e-01],\n",
      "          [-7.6704e-01, -3.6284e-01,  4.0744e-01,  ..., -1.1191e+00,\n",
      "           -7.2456e-01, -1.5936e+00],\n",
      "          [-2.3461e+00,  4.0505e-01,  4.1724e-01,  ..., -6.7163e-01,\n",
      "           -1.1946e-01, -1.3618e+00],\n",
      "          ...,\n",
      "          [ 5.2608e-01,  1.1377e+00,  8.2510e-01,  ...,  7.1954e-01,\n",
      "            8.1150e-02, -2.2181e+00],\n",
      "          [ 4.8806e-01,  1.9192e+00,  1.3656e-01,  ...,  3.5930e-01,\n",
      "            3.9685e-01, -1.8471e+00],\n",
      "          [ 9.9264e-01,  1.4893e+00,  4.3560e-01,  ...,  9.5739e-01,\n",
      "            2.5069e-01, -1.3093e+00]],\n",
      "\n",
      "         [[-9.4161e-01,  7.0589e-01, -1.3354e-01,  ..., -5.1168e-01,\n",
      "           -1.3428e+00, -1.6397e+00],\n",
      "          [-1.6042e+00,  4.4067e-01, -1.1342e-02,  ..., -1.3723e+00,\n",
      "           -1.6187e+00,  6.0028e-01],\n",
      "          [ 7.3071e-01,  7.0454e-01,  2.0887e+00,  ...,  1.5000e-01,\n",
      "           -9.6619e-01,  4.8051e-02],\n",
      "          ...,\n",
      "          [-2.1477e-01, -1.6210e+00, -5.9046e-01,  ...,  3.5773e-01,\n",
      "           -1.4979e+00,  4.3506e-01],\n",
      "          [ 1.1813e+00, -1.7067e+00,  8.9928e-02,  ...,  7.1018e-01,\n",
      "           -2.3076e+00, -2.1806e-01],\n",
      "          [ 5.3262e-01, -1.8946e+00, -1.0717e+00,  ...,  5.1125e-01,\n",
      "           -1.5441e+00, -2.7610e-01]]]], grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[-1.3007,  2.0529,  2.0554,  ...,  0.7585,  2.4428,  3.8575],\n",
      "          [ 1.0219,  2.3818,  1.7906,  ...,  1.3755,  1.1386,  5.2729],\n",
      "          [ 1.1934,  2.9125,  2.2359,  ...,  1.2970,  0.2846,  4.9121],\n",
      "          ...,\n",
      "          [ 1.6547,  3.5535,  3.5769,  ...,  1.5022,  2.3418,  5.0998],\n",
      "          [ 0.9177,  3.0961,  2.8818,  ...,  2.3757,  2.3391,  3.8944],\n",
      "          [ 1.3707,  0.7479,  0.4510,  ..., -0.2979,  1.1013,  5.5646]],\n",
      "\n",
      "         [[-0.7265, -0.9281, -0.8055,  ..., -1.3299, -1.2845,  0.8287],\n",
      "          [ 0.7576,  0.9592,  1.3946,  ...,  1.5444,  2.5796,  2.6880],\n",
      "          [ 0.9303,  1.1146, -0.4935,  ...,  1.3106,  2.9064,  2.8938],\n",
      "          ...,\n",
      "          [ 1.5769,  1.1880,  0.3657,  ...,  0.9359,  3.2092,  4.0119],\n",
      "          [ 0.6264,  0.2993, -0.0834,  ..., -0.5364,  1.2947,  3.6291],\n",
      "          [ 0.4474,  0.3402, -0.2979,  ..., -1.1570,  0.4767,  5.3836]],\n",
      "\n",
      "         [[ 1.0326, -0.5905, -1.3680,  ..., -1.9061, -2.0931,  2.2480],\n",
      "          [ 0.0577,  0.8317,  2.6119,  ...,  0.6349,  0.2072,  2.8977],\n",
      "          [ 0.3279,  1.4789,  1.1566,  ...,  1.4806,  2.3016,  3.8625],\n",
      "          ...,\n",
      "          [ 1.6463,  1.4774, -0.2620,  ...,  0.7849,  3.6025,  4.1355],\n",
      "          [ 1.8206,  1.2586, -0.7168,  ..., -1.0415,  0.2525,  3.5390],\n",
      "          [ 0.6382,  0.3356, -0.1269,  ..., -1.0209, -0.0372,  4.3464]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.8182,  0.2824,  0.3954,  ...,  0.7838,  1.9636,  4.2549],\n",
      "          [ 2.0898,  2.5671,  1.1178,  ...,  0.9728,  3.4841,  4.8951],\n",
      "          [ 3.0719,  3.0684,  1.5082,  ...,  1.4007,  3.7548,  4.8818],\n",
      "          ...,\n",
      "          [ 3.2727,  2.7369,  2.6665,  ...,  1.0401,  2.8884,  5.3306],\n",
      "          [ 3.0327,  3.1337,  3.7924,  ...,  2.1250,  3.3176,  3.8168],\n",
      "          [ 0.8862,  0.5706, -0.1675,  ..., -0.1327,  1.5235,  4.9020]],\n",
      "\n",
      "         [[-0.8312,  1.3983, -0.4218,  ..., -0.7353,  0.5611,  2.3500],\n",
      "          [ 0.1053,  2.0847,  1.3799,  ...,  0.2004,  2.8792,  3.1119],\n",
      "          [ 0.4501,  2.6032,  0.6509,  ...,  1.3855,  3.4135,  3.9570],\n",
      "          ...,\n",
      "          [ 0.5714,  1.2014,  0.3626,  ...,  2.3868,  3.5141,  4.3629],\n",
      "          [ 1.6742,  3.2567,  2.0969,  ...,  0.8091,  2.0410,  3.0341],\n",
      "          [ 1.1928,  1.4314,  0.4305,  ..., -0.6727,  0.6772,  5.5276]],\n",
      "\n",
      "         [[ 2.7645,  1.9904,  0.7473,  ...,  3.0708,  8.7793,  3.9041],\n",
      "          [ 2.6975,  1.9329,  0.2447,  ...,  0.5261,  3.2512,  5.4944],\n",
      "          [ 1.2061,  4.7893,  3.3549,  ...,  1.7477,  1.3452,  5.6149],\n",
      "          ...,\n",
      "          [ 1.9033,  2.2791,  1.9463,  ...,  2.7162,  2.2615,  7.5369],\n",
      "          [ 2.0213,  2.1343,  1.0302,  ...,  3.2020,  2.9738,  5.6127],\n",
      "          [ 0.9739, -0.0091, -1.1400,  ..., -0.6064,  1.5330,  5.1663]]],\n",
      "\n",
      "\n",
      "        [[[-1.4702,  2.5242,  1.2839,  ...,  2.5046,  1.2895,  2.1589],\n",
      "          [ 1.5585,  2.3733,  2.0494,  ...,  2.0335,  1.5343,  1.3331],\n",
      "          [ 0.8742,  2.6909,  1.8517,  ...,  2.2016,  1.5499,  1.5167],\n",
      "          ...,\n",
      "          [ 1.1198,  3.2019,  2.4685,  ...,  2.0391,  1.4047,  0.8508],\n",
      "          [ 0.7789,  3.3607,  2.6669,  ...,  2.5560,  1.6998,  1.3454],\n",
      "          [ 1.6453,  3.1707,  2.8215,  ...,  2.3871,  2.0738,  1.5654]],\n",
      "\n",
      "         [[ 0.2382,  0.6849,  0.4582,  ...,  0.5089,  0.8798,  1.4862],\n",
      "          [ 1.6892,  1.8865,  2.3043,  ...,  1.3558,  1.9590,  1.8016],\n",
      "          [ 0.6034,  0.7048,  1.3405,  ...,  1.6745,  1.7596,  1.8690],\n",
      "          ...,\n",
      "          [ 0.2572,  2.2715,  1.1848,  ...,  0.8646,  1.2981,  1.6067],\n",
      "          [-0.0209,  1.2436,  1.5821,  ...,  0.5403,  0.8171,  1.5850],\n",
      "          [ 0.4402,  1.4008,  0.7638,  ..., -0.2480,  0.3590,  1.0201]],\n",
      "\n",
      "         [[ 0.4750,  1.9044, -1.1605,  ...,  1.7434,  0.8175,  0.9931],\n",
      "          [ 2.0055,  0.9934,  4.5951,  ...,  1.2023,  2.2042,  0.6119],\n",
      "          [ 1.5170,  2.9132,  0.3719,  ...,  3.8445,  2.0188,  2.0725],\n",
      "          ...,\n",
      "          [ 0.9811,  1.8908,  2.9423,  ...,  0.7928,  3.2757,  1.7954],\n",
      "          [ 1.4313,  2.5906,  1.0345,  ...,  1.6743,  3.2881,  3.2045],\n",
      "          [ 1.0404,  1.3861,  1.2987,  ..., -0.3274,  2.5776,  2.2357]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2347,  1.6653,  0.9979,  ...,  1.1609,  0.9186,  1.2930],\n",
      "          [ 2.6821,  2.6418,  2.8809,  ...,  2.1419,  2.4646,  1.5604],\n",
      "          [ 4.0358,  2.4013,  2.2745,  ...,  2.5293,  2.6629,  1.8797],\n",
      "          ...,\n",
      "          [ 2.6417,  3.5966,  3.8980,  ...,  3.2219,  3.7959,  2.5876],\n",
      "          [ 2.4845,  2.7262,  2.8712,  ...,  3.3007,  3.5875,  2.7300],\n",
      "          [ 2.7845,  2.9843,  3.3097,  ...,  3.5075,  4.6099,  3.6568]],\n",
      "\n",
      "         [[-1.8446,  0.1130, -1.3049,  ...,  0.9065,  0.2284,  1.8084],\n",
      "          [ 0.2101,  0.8582,  0.9513,  ...,  2.4335,  1.6423,  2.8925],\n",
      "          [ 0.5423,  2.1429,  1.2473,  ...,  2.5264,  1.7571,  2.5847],\n",
      "          ...,\n",
      "          [ 1.1584,  1.7803,  1.2270,  ...,  2.4367,  2.7266,  3.2983],\n",
      "          [ 1.0841,  1.2622,  0.5154,  ...,  1.9287,  2.1349,  3.1446],\n",
      "          [ 1.0627,  0.9799,  0.4968,  ...,  1.1867,  1.7457,  2.8655]],\n",
      "\n",
      "         [[ 2.4483,  3.2076,  5.6953,  ...,  2.7534,  5.1471,  2.4902],\n",
      "          [ 3.2936,  2.9933,  2.7217,  ...,  3.0703,  2.3273,  1.5704],\n",
      "          [ 1.7163,  5.4937,  0.7078,  ...,  3.3846,  1.2852,  1.8666],\n",
      "          ...,\n",
      "          [ 2.6814,  3.3256,  3.3187,  ...,  2.5742,  2.6226,  1.0041],\n",
      "          [ 1.6978,  3.8057,  2.0446,  ...,  3.4237,  3.2055,  2.5799],\n",
      "          [ 2.3312,  2.1455,  2.2673,  ...,  2.6635,  3.7878,  2.8229]]]],\n",
      "       grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[-1.3007e+00,  2.0529e+00,  2.0554e+00,  ...,  7.5848e-01,\n",
      "            2.4428e+00,  3.8575e+00],\n",
      "          [ 1.0219e+00,  2.3818e+00,  1.7906e+00,  ...,  1.3755e+00,\n",
      "            1.1386e+00,  5.2729e+00],\n",
      "          [ 1.1934e+00,  2.9125e+00,  2.2359e+00,  ...,  1.2970e+00,\n",
      "            2.8459e-01,  4.9121e+00],\n",
      "          ...,\n",
      "          [ 1.6547e+00,  3.5535e+00,  3.5769e+00,  ...,  1.5022e+00,\n",
      "            2.3418e+00,  5.0998e+00],\n",
      "          [ 9.1765e-01,  3.0961e+00,  2.8818e+00,  ...,  2.3757e+00,\n",
      "            2.3391e+00,  3.8944e+00],\n",
      "          [ 1.3707e+00,  7.4785e-01,  4.5104e-01,  ..., -2.9788e-01,\n",
      "            1.1013e+00,  5.5646e+00]],\n",
      "\n",
      "         [[-7.2649e-01, -9.2805e-01, -8.0551e-01,  ..., -1.3299e+00,\n",
      "           -1.2845e+00,  8.2873e-01],\n",
      "          [ 7.5763e-01,  9.5918e-01,  1.3946e+00,  ...,  1.5444e+00,\n",
      "            2.5796e+00,  2.6880e+00],\n",
      "          [ 9.3027e-01,  1.1146e+00, -4.9348e-01,  ...,  1.3106e+00,\n",
      "            2.9064e+00,  2.8938e+00],\n",
      "          ...,\n",
      "          [ 1.5769e+00,  1.1880e+00,  3.6571e-01,  ...,  9.3594e-01,\n",
      "            3.2092e+00,  4.0119e+00],\n",
      "          [ 6.2643e-01,  2.9932e-01, -8.3388e-02,  ..., -5.3641e-01,\n",
      "            1.2947e+00,  3.6291e+00],\n",
      "          [ 4.4739e-01,  3.4018e-01, -2.9793e-01,  ..., -1.1570e+00,\n",
      "            4.7675e-01,  5.3836e+00]],\n",
      "\n",
      "         [[ 1.0326e+00, -5.9054e-01, -1.3680e+00,  ..., -1.9061e+00,\n",
      "           -2.0931e+00,  2.2480e+00],\n",
      "          [ 5.7701e-02,  8.3170e-01,  2.6119e+00,  ...,  6.3488e-01,\n",
      "            2.0716e-01,  2.8977e+00],\n",
      "          [ 3.2786e-01,  1.4789e+00,  1.1566e+00,  ...,  1.4806e+00,\n",
      "            2.3016e+00,  3.8625e+00],\n",
      "          ...,\n",
      "          [ 1.6463e+00,  1.4774e+00, -2.6202e-01,  ...,  7.8492e-01,\n",
      "            3.6025e+00,  4.1355e+00],\n",
      "          [ 1.8206e+00,  1.2586e+00, -7.1679e-01,  ..., -1.0415e+00,\n",
      "            2.5248e-01,  3.5390e+00],\n",
      "          [ 6.3825e-01,  3.3565e-01, -1.2694e-01,  ..., -1.0209e+00,\n",
      "           -3.7192e-02,  4.3464e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.1822e-01,  2.8242e-01,  3.9536e-01,  ...,  7.8381e-01,\n",
      "            1.9636e+00,  4.2549e+00],\n",
      "          [ 2.0898e+00,  2.5671e+00,  1.1178e+00,  ...,  9.7281e-01,\n",
      "            3.4841e+00,  4.8951e+00],\n",
      "          [ 3.0719e+00,  3.0684e+00,  1.5082e+00,  ...,  1.4007e+00,\n",
      "            3.7548e+00,  4.8818e+00],\n",
      "          ...,\n",
      "          [ 3.2727e+00,  2.7369e+00,  2.6665e+00,  ...,  1.0401e+00,\n",
      "            2.8884e+00,  5.3306e+00],\n",
      "          [ 3.0327e+00,  3.1337e+00,  3.7924e+00,  ...,  2.1250e+00,\n",
      "            3.3176e+00,  3.8168e+00],\n",
      "          [ 8.8615e-01,  5.7064e-01, -1.6747e-01,  ..., -1.3273e-01,\n",
      "            1.5235e+00,  4.9020e+00]],\n",
      "\n",
      "         [[-8.3117e-01,  1.3983e+00, -4.2180e-01,  ..., -7.3528e-01,\n",
      "            5.6106e-01,  2.3500e+00],\n",
      "          [ 1.0525e-01,  2.0847e+00,  1.3799e+00,  ...,  2.0039e-01,\n",
      "            2.8792e+00,  3.1119e+00],\n",
      "          [ 4.5011e-01,  2.6032e+00,  6.5094e-01,  ...,  1.3855e+00,\n",
      "            3.4135e+00,  3.9570e+00],\n",
      "          ...,\n",
      "          [ 5.7139e-01,  1.2014e+00,  3.6261e-01,  ...,  2.3868e+00,\n",
      "            3.5141e+00,  4.3629e+00],\n",
      "          [ 1.6742e+00,  3.2567e+00,  2.0969e+00,  ...,  8.0907e-01,\n",
      "            2.0410e+00,  3.0341e+00],\n",
      "          [ 1.1928e+00,  1.4314e+00,  4.3050e-01,  ..., -6.7273e-01,\n",
      "            6.7717e-01,  5.5276e+00]],\n",
      "\n",
      "         [[ 2.7645e+00,  1.9904e+00,  7.4725e-01,  ...,  3.0708e+00,\n",
      "            8.7793e+00,  3.9041e+00],\n",
      "          [ 2.6975e+00,  1.9329e+00,  2.4467e-01,  ...,  5.2611e-01,\n",
      "            3.2512e+00,  5.4944e+00],\n",
      "          [ 1.2061e+00,  4.7893e+00,  3.3549e+00,  ...,  1.7477e+00,\n",
      "            1.3452e+00,  5.6149e+00],\n",
      "          ...,\n",
      "          [ 1.9033e+00,  2.2791e+00,  1.9463e+00,  ...,  2.7162e+00,\n",
      "            2.2615e+00,  7.5369e+00],\n",
      "          [ 2.0213e+00,  2.1343e+00,  1.0302e+00,  ...,  3.2020e+00,\n",
      "            2.9738e+00,  5.6127e+00],\n",
      "          [ 9.7392e-01, -9.1088e-03, -1.1400e+00,  ..., -6.0636e-01,\n",
      "            1.5330e+00,  5.1663e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.4702e+00,  2.5242e+00,  1.2839e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.5585e+00,  2.3733e+00,  2.0494e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 8.7421e-01,  2.6909e+00,  1.8517e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.1198e+00,  3.2019e+00,  2.4685e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.7894e-01,  3.3607e+00,  2.6669e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.6453e+00,  3.1707e+00,  2.8215e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 2.3819e-01,  6.8487e-01,  4.5819e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.6892e+00,  1.8865e+00,  2.3043e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.0341e-01,  7.0479e-01,  1.3405e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.5723e-01,  2.2715e+00,  1.1848e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-2.0856e-02,  1.2436e+00,  1.5821e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.4024e-01,  1.4008e+00,  7.6384e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 4.7498e-01,  1.9044e+00, -1.1605e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.0055e+00,  9.9337e-01,  4.5951e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.5170e+00,  2.9132e+00,  3.7189e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 9.8112e-01,  1.8908e+00,  2.9423e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.4313e+00,  2.5906e+00,  1.0345e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0404e+00,  1.3861e+00,  1.2987e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2347e+00,  1.6653e+00,  9.9789e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.6821e+00,  2.6418e+00,  2.8809e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.0358e+00,  2.4013e+00,  2.2745e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.6417e+00,  3.5966e+00,  3.8980e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.4845e+00,  2.7262e+00,  2.8712e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.7845e+00,  2.9843e+00,  3.3097e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-1.8446e+00,  1.1304e-01, -1.3049e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.1008e-01,  8.5821e-01,  9.5130e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.4234e-01,  2.1429e+00,  1.2473e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.1584e+00,  1.7803e+00,  1.2270e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0841e+00,  1.2622e+00,  5.1537e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.0627e+00,  9.7987e-01,  4.9681e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 2.4483e+00,  3.2076e+00,  5.6953e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.2936e+00,  2.9933e+00,  2.7217e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.7163e+00,  5.4937e+00,  7.0777e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.6814e+00,  3.3256e+00,  3.3187e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.6978e+00,  3.8057e+00,  2.0446e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.3312e+00,  2.1455e+00,  2.2673e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[3.4894e-03, 9.9816e-02, 1.0006e-01,  ..., 2.7354e-02,\n",
      "           1.4740e-01, 6.0660e-01],\n",
      "          [1.2412e-02, 4.8354e-02, 2.6773e-02,  ..., 1.7677e-02,\n",
      "           1.3949e-02, 8.7100e-01],\n",
      "          [1.8936e-02, 1.0566e-01, 5.3707e-02,  ..., 2.1002e-02,\n",
      "           7.6311e-03, 7.8037e-01],\n",
      "          ...,\n",
      "          [1.9775e-02, 1.3205e-01, 1.3519e-01,  ..., 1.6979e-02,\n",
      "           3.9314e-02, 6.1986e-01],\n",
      "          [2.1018e-02, 1.8566e-01, 1.4984e-01,  ..., 9.0329e-02,\n",
      "           8.7085e-02, 4.1248e-01],\n",
      "          [1.4423e-02, 7.7369e-03, 5.7499e-03,  ..., 2.7190e-03,\n",
      "           1.1017e-02, 9.5604e-01]],\n",
      "\n",
      "         [[1.0194e-01, 8.3331e-02, 9.4194e-02,  ..., 5.5758e-02,\n",
      "           5.8347e-02, 4.8280e-01],\n",
      "          [4.5174e-02, 5.5261e-02, 8.5417e-02,  ..., 9.9214e-02,\n",
      "           2.7936e-01, 3.1135e-01],\n",
      "          [5.1524e-02, 6.1950e-02, 1.2407e-02,  ..., 7.5366e-02,\n",
      "           3.7174e-01, 3.6708e-01],\n",
      "          ...,\n",
      "          [5.1036e-02, 3.4590e-02, 1.5200e-02,  ..., 2.6884e-02,\n",
      "           2.6107e-01, 5.8257e-01],\n",
      "          [3.9162e-02, 2.8236e-02, 1.9257e-02,  ..., 1.2242e-02,\n",
      "           7.6402e-02, 7.8871e-01],\n",
      "          [6.9872e-03, 6.2768e-03, 3.3160e-03,  ..., 1.4045e-03,\n",
      "           7.1953e-03, 9.7286e-01]],\n",
      "\n",
      "         [[2.0399e-01, 4.0243e-02, 1.8494e-02,  ..., 1.0799e-02,\n",
      "           8.9569e-03, 6.8778e-01],\n",
      "          [2.6183e-02, 5.6776e-02, 3.3673e-01,  ..., 4.6632e-02,\n",
      "           3.0404e-02, 4.4816e-01],\n",
      "          [1.7315e-02, 5.4738e-02, 3.9657e-02,  ..., 5.4836e-02,\n",
      "           1.2462e-01, 5.9360e-01],\n",
      "          ...,\n",
      "          [4.5396e-02, 3.8341e-02, 6.7338e-03,  ..., 1.9184e-02,\n",
      "           3.2106e-01, 5.4709e-01],\n",
      "          [1.3204e-01, 7.5269e-02, 1.0440e-02,  ..., 7.5455e-03,\n",
      "           2.7521e-02, 7.3618e-01],\n",
      "          [2.2734e-02, 1.6798e-02, 1.0577e-02,  ..., 4.3261e-03,\n",
      "           1.1570e-02, 9.2703e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.6487e-02, 1.5500e-02, 1.7353e-02,  ..., 2.5591e-02,\n",
      "           8.3268e-02, 8.2331e-01],\n",
      "          [4.1722e-02, 6.7246e-02, 1.5786e-02,  ..., 1.3655e-02,\n",
      "           1.6824e-01, 6.8976e-01],\n",
      "          [9.4662e-02, 9.4337e-02, 1.9819e-02,  ..., 1.7800e-02,\n",
      "           1.8740e-01, 5.7838e-01],\n",
      "          ...,\n",
      "          [8.9819e-02, 5.2565e-02, 4.8989e-02,  ..., 9.6334e-03,\n",
      "           6.1159e-02, 7.0323e-01],\n",
      "          [1.1207e-01, 1.2398e-01, 2.3955e-01,  ..., 4.5213e-02,\n",
      "           1.4901e-01, 2.4548e-01],\n",
      "          [1.6674e-02, 1.2162e-02, 5.8139e-03,  ..., 6.0194e-03,\n",
      "           3.1538e-02, 9.2490e-01]],\n",
      "\n",
      "         [[2.3454e-02, 2.1800e-01, 3.5318e-02,  ..., 2.5814e-02,\n",
      "           9.4374e-02, 5.6464e-01],\n",
      "          [2.0214e-02, 1.4632e-01, 7.2316e-02,  ..., 2.2231e-02,\n",
      "           3.2386e-01, 4.0871e-01],\n",
      "          [1.4967e-02, 1.2889e-01, 1.8296e-02,  ..., 3.8138e-02,\n",
      "           2.8982e-01, 4.9905e-01],\n",
      "          ...,\n",
      "          [1.3335e-02, 2.5038e-02, 1.0823e-02,  ..., 8.1925e-02,\n",
      "           2.5295e-01, 5.9106e-01],\n",
      "          [7.2513e-02, 3.5290e-01, 1.1066e-01,  ..., 3.0526e-02,\n",
      "           1.0464e-01, 2.8249e-01],\n",
      "          [1.2495e-02, 1.5862e-02, 5.8300e-03,  ..., 1.9344e-03,\n",
      "           7.4609e-03, 9.5349e-01]],\n",
      "\n",
      "         [[2.4037e-03, 1.1083e-03, 3.1974e-04,  ..., 3.2651e-03,\n",
      "           9.8417e-01, 7.5126e-03],\n",
      "          [5.0362e-02, 2.3445e-02, 4.3338e-03,  ..., 5.7424e-03,\n",
      "           8.7619e-02, 8.2567e-01],\n",
      "          [7.2210e-03, 2.5988e-01, 6.1920e-02,  ..., 1.2411e-02,\n",
      "           8.2992e-03, 5.9339e-01],\n",
      "          ...,\n",
      "          [3.4546e-03, 5.0302e-03, 3.6064e-03,  ..., 7.7878e-03,\n",
      "           4.9427e-03, 9.6610e-01],\n",
      "          [2.2010e-02, 2.4642e-02, 8.1694e-03,  ..., 7.1678e-02,\n",
      "           5.7053e-02, 7.9860e-01],\n",
      "          [1.4345e-02, 5.3676e-03, 1.7323e-03,  ..., 2.9539e-03,\n",
      "           2.5091e-02, 9.4934e-01]]],\n",
      "\n",
      "\n",
      "        [[[5.1612e-03, 2.8022e-01, 8.1067e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.6695e-02, 8.2885e-02, 5.9953e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.9239e-02, 2.4138e-01, 1.0429e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.7242e-02, 1.3830e-01, 6.6427e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.7916e-03, 1.2945e-01, 6.4682e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.0458e-02, 1.4002e-01, 9.8744e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.4763e-01, 2.3077e-01, 1.8396e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.1818e-02, 6.3119e-02, 9.5860e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.7623e-02, 5.2704e-02, 9.9529e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.4648e-02, 1.0980e-01, 3.7037e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.4863e-03, 1.9429e-02, 2.7254e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.4486e-03, 2.4690e-02, 1.3059e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.2805e-01, 5.3475e-01, 2.4950e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0626e-02, 1.8399e-02, 6.7458e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.7862e-02, 3.1453e-01, 2.4774e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [6.7702e-02, 1.6814e-01, 4.8120e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.1434e-01, 3.6450e-01, 7.6891e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.1987e-01, 1.6937e-01, 1.5521e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.7723e-02, 5.8023e-02, 2.9769e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.8026e-02, 6.5341e-02, 8.2988e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.6516e-01, 7.1218e-02, 6.2741e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.9689e-02, 1.2911e-01, 1.7452e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.7678e-02, 9.8926e-02, 1.1436e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0422e-01, 1.2728e-01, 1.7623e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[2.5900e-02, 1.8345e-01, 4.4433e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1917e-02, 4.1903e-02, 4.5992e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.6408e-02, 2.7954e-01, 1.1416e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.9197e-02, 1.1025e-01, 6.3404e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.2734e-02, 5.1062e-02, 2.4198e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.7193e-02, 3.4237e-02, 2.1121e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[3.2370e-02, 6.9166e-02, 8.3238e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.0993e-02, 4.5173e-02, 3.4428e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.6671e-02, 7.2855e-01, 6.0810e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.0126e-01, 1.9285e-01, 1.9153e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.2680e-02, 5.9824e-01, 1.0281e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.8833e-01, 1.5641e-01, 1.7666e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[-8.6014e-03,  5.4203e-02,  1.0094e-02,  ..., -2.4973e-01,\n",
      "            2.5475e-01,  3.5803e-03],\n",
      "          [-2.9804e-02,  8.0722e-02,  4.6469e-02,  ..., -6.0081e-02,\n",
      "            1.0754e-01, -1.2649e-02],\n",
      "          [ 1.6591e-02,  1.5789e-01,  1.1679e-01,  ..., -1.1313e-01,\n",
      "            1.7398e-01, -6.3592e-02],\n",
      "          ...,\n",
      "          [ 3.4606e-02,  2.0705e-01,  1.5174e-01,  ..., -2.1013e-01,\n",
      "            2.9106e-01, -1.0316e-01],\n",
      "          [ 6.4009e-02,  2.4431e-01,  1.7943e-01,  ..., -3.5756e-01,\n",
      "            3.7268e-01, -8.5405e-02],\n",
      "          [-5.8224e-02,  2.5195e-02,  9.0260e-04,  ...,  3.5285e-03,\n",
      "            5.5884e-02,  1.7462e-02]],\n",
      "\n",
      "         [[-2.2743e-03, -1.8998e-01, -1.1626e-01,  ...,  5.8856e-02,\n",
      "            1.4603e-01,  2.5620e-01],\n",
      "          [-2.3626e-01, -3.4496e-01, -1.1317e-01,  ...,  5.2549e-02,\n",
      "            2.9098e-01,  2.1015e-01],\n",
      "          [-4.0604e-01, -3.5272e-01, -6.9806e-02,  ..., -2.8305e-02,\n",
      "            2.6074e-01,  1.3199e-01],\n",
      "          ...,\n",
      "          [-2.9703e-01, -2.1932e-01, -6.4234e-02,  ..., -3.3484e-02,\n",
      "            1.5341e-01,  8.3695e-02],\n",
      "          [-9.1457e-02, -9.5313e-02, -4.0399e-02,  ...,  3.9944e-03,\n",
      "            6.8767e-02,  9.1239e-02],\n",
      "          [-2.9073e-02, -2.8898e-02, -1.1869e-02,  ...,  5.8755e-04,\n",
      "            1.8832e-02,  3.0991e-02]],\n",
      "\n",
      "         [[ 7.9483e-02, -5.6550e-02,  5.0613e-02,  ..., -9.3100e-02,\n",
      "            3.9781e-02, -3.2096e-02],\n",
      "          [-1.7890e-01,  5.1363e-02, -1.2753e-01,  ...,  9.5223e-03,\n",
      "           -3.5386e-01, -2.4974e-01],\n",
      "          [-1.2070e-01,  1.0527e-01, -8.1950e-02,  ..., -4.0632e-02,\n",
      "            6.5814e-02,  2.8527e-02],\n",
      "          ...,\n",
      "          [-1.0507e-01,  2.3644e-01, -1.9713e-01,  ..., -7.0599e-02,\n",
      "            2.1387e-01,  2.2655e-01],\n",
      "          [ 3.9359e-02, -8.0361e-04,  4.2176e-02,  ..., -7.4984e-02,\n",
      "            2.8299e-02, -8.3328e-02],\n",
      "          [-1.3840e-02,  5.4758e-02,  2.0148e-02,  ...,  2.2200e-02,\n",
      "           -4.9204e-02, -5.1190e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.6088e-02, -1.6702e-02, -4.6879e-03,  ..., -5.5666e-02,\n",
      "           -1.4447e-01,  3.1076e-04],\n",
      "          [-1.0473e-01, -4.7080e-02, -1.9502e-02,  ..., -4.5760e-02,\n",
      "           -1.5913e-01,  9.5236e-03],\n",
      "          [-7.3481e-02, -4.8578e-02, -1.0259e-02,  ..., -3.5448e-02,\n",
      "           -2.0796e-01,  1.8230e-02],\n",
      "          ...,\n",
      "          [ 1.7030e-02,  2.4329e-02, -3.0188e-02,  ..., -3.4243e-03,\n",
      "           -1.8598e-01,  2.1999e-02],\n",
      "          [ 2.4882e-01,  7.4148e-02, -2.1434e-01,  ..., -2.0978e-01,\n",
      "           -2.8310e-01,  1.6361e-02],\n",
      "          [-7.2387e-02, -2.6604e-03,  1.6585e-03,  ...,  1.2148e-02,\n",
      "           -1.0078e-01,  1.4030e-02]],\n",
      "\n",
      "         [[ 4.9859e-02,  3.1428e-01,  8.7372e-02,  ...,  9.8100e-02,\n",
      "            1.0027e-01, -2.3051e-02],\n",
      "          [ 4.8069e-01,  3.3284e-01,  2.0920e-01,  ...,  1.5257e-01,\n",
      "           -3.7027e-02, -2.8468e-02],\n",
      "          [ 4.4131e-01,  2.9047e-01,  1.4479e-01,  ...,  1.0649e-01,\n",
      "           -4.9697e-02,  6.6810e-03],\n",
      "          ...,\n",
      "          [ 5.4961e-01,  2.3132e-01,  9.1915e-02,  ...,  6.0700e-02,\n",
      "           -3.6541e-02,  3.1516e-02],\n",
      "          [ 1.2619e-02,  5.1218e-01,  1.9428e-01,  ...,  2.0034e-01,\n",
      "            2.0035e-01, -6.8011e-02],\n",
      "          [ 6.2392e-03,  4.7418e-02, -2.3388e-02,  ..., -8.0954e-03,\n",
      "            4.9860e-03,  6.8529e-03]],\n",
      "\n",
      "         [[-4.7329e-01,  4.7644e-01, -4.6096e-01,  ...,  9.9973e-01,\n",
      "            6.0996e-01, -3.9706e-02],\n",
      "          [-3.0436e-02,  6.5223e-02, -6.3961e-02,  ...,  7.9806e-02,\n",
      "            8.2834e-02,  4.0321e-03],\n",
      "          [-1.1855e-01,  2.0671e-01, -5.7668e-02,  ...,  2.2756e-01,\n",
      "            4.3494e-01,  1.0524e-01],\n",
      "          ...,\n",
      "          [-6.7136e-03,  2.7769e-02, -3.1927e-03,  ...,  1.1730e-02,\n",
      "            2.0610e-02,  4.8751e-03],\n",
      "          [-1.1686e-01,  1.3572e-02,  6.2292e-03,  ...,  1.3394e-01,\n",
      "            9.5950e-02,  6.6447e-04],\n",
      "          [ 3.3339e-03,  3.5676e-02, -2.5075e-02,  ...,  1.8144e-02,\n",
      "            2.5617e-02,  3.6744e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7259e-02,  5.6591e-02, -1.0779e-01,  ..., -9.5133e-02,\n",
      "            4.8498e-02, -2.5391e-01],\n",
      "          [-6.7291e-03,  1.0543e-02, -7.6224e-02,  ...,  1.8815e-02,\n",
      "            1.1490e-01, -2.8695e-02],\n",
      "          [ 5.6675e-02,  2.3906e-02, -1.2809e-01,  ..., -4.3332e-02,\n",
      "            1.1899e-01, -1.8399e-01],\n",
      "          ...,\n",
      "          [ 7.3587e-03,  2.0975e-02, -8.1321e-02,  ..., -1.6451e-02,\n",
      "            9.0859e-02, -9.8365e-02],\n",
      "          [ 1.1638e-03,  1.8134e-02, -7.6031e-02,  ..., -1.4977e-02,\n",
      "            8.7445e-02, -9.4015e-02],\n",
      "          [ 1.4913e-02, -9.8387e-03, -1.0531e-01,  ...,  1.0388e-02,\n",
      "            1.4640e-01, -8.2246e-02]],\n",
      "\n",
      "         [[ 3.7835e-01, -3.6257e-01, -5.3245e-01,  ..., -1.0534e-03,\n",
      "            8.0129e-02,  3.5265e-01],\n",
      "          [ 9.7140e-02, -1.5795e-01, -2.1057e-01,  ..., -3.7486e-03,\n",
      "            4.8490e-03,  1.3794e-01],\n",
      "          [ 8.1565e-02, -1.5331e-01, -2.0109e-01,  ..., -1.4054e-03,\n",
      "           -1.6842e-03,  1.3140e-01],\n",
      "          ...,\n",
      "          [ 1.1191e-01, -1.0761e-01, -1.7948e-01,  ..., -2.6697e-02,\n",
      "            1.1114e-01,  1.5834e-01],\n",
      "          [ 2.2260e-03, -5.5464e-02, -6.7620e-02,  ..., -1.7200e-02,\n",
      "            1.2508e-02,  5.3970e-02],\n",
      "          [ 1.1614e-02, -4.9893e-02, -6.0380e-02,  ..., -2.1702e-02,\n",
      "            1.2285e-02,  4.6085e-02]],\n",
      "\n",
      "         [[-5.8120e-02, -8.1495e-02,  4.4548e-01,  ..., -1.0419e-01,\n",
      "            2.8811e-01, -1.8983e-01],\n",
      "          [-7.4264e-01, -9.6339e-01, -8.6351e-01,  ..., -4.3141e-01,\n",
      "           -1.2501e-01, -1.2826e-01],\n",
      "          [-4.8572e-02, -4.1173e-02,  2.6204e-01,  ..., -5.5785e-02,\n",
      "            1.4370e-01, -1.2914e-01],\n",
      "          ...,\n",
      "          [-5.4203e-01, -6.9628e-01, -4.7866e-01,  ..., -3.2969e-01,\n",
      "           -5.1694e-03, -1.4498e-01],\n",
      "          [-9.3076e-02, -1.4525e-01,  2.3973e-01,  ..., -1.1699e-01,\n",
      "            1.7282e-01, -1.5162e-01],\n",
      "          [-1.4043e-01, -2.6189e-01, -1.5527e-02,  ..., -1.5808e-01,\n",
      "            4.0667e-02, -1.1223e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3243e-01, -2.5744e-02,  6.8928e-02,  ..., -1.0871e-02,\n",
      "           -6.5792e-02, -7.2273e-03],\n",
      "          [-1.4492e-01, -6.4353e-02,  1.4765e-01,  ..., -4.2493e-02,\n",
      "           -8.5418e-02, -1.1866e-02],\n",
      "          [-4.3244e-01, -2.5522e-01,  4.6841e-01,  ...,  1.6767e-02,\n",
      "           -3.1911e-02, -9.6346e-02],\n",
      "          ...,\n",
      "          [-1.4787e-01, -8.8540e-02,  1.8328e-01,  ..., -1.3184e-01,\n",
      "           -1.2272e-01, -1.7332e-02],\n",
      "          [-1.7125e-01, -8.4255e-02,  1.7379e-01,  ..., -7.5809e-02,\n",
      "           -9.4347e-02, -2.1836e-02],\n",
      "          [-1.9575e-01, -1.2513e-01,  2.4799e-01,  ..., -1.2303e-01,\n",
      "           -1.1583e-01, -3.1291e-02]],\n",
      "\n",
      "         [[ 1.3942e-01,  1.8196e-01,  7.8538e-02,  ..., -1.9630e-01,\n",
      "           -2.7561e-01, -1.0297e-01],\n",
      "          [ 3.5105e-02,  9.2035e-02,  2.9393e-02,  ..., -4.4833e-02,\n",
      "           -1.0924e-01, -2.2933e-02],\n",
      "          [ 2.2605e-01,  3.2760e-01,  1.8700e-01,  ..., -2.8329e-01,\n",
      "           -4.8904e-01, -1.8866e-01],\n",
      "          ...,\n",
      "          [ 1.0940e-01,  1.5729e-01,  7.6349e-02,  ..., -1.0051e-01,\n",
      "           -2.5957e-01, -6.4945e-02],\n",
      "          [ 5.7475e-02,  7.2052e-02,  1.3630e-02,  ..., -4.5681e-02,\n",
      "           -1.3475e-01, -1.3676e-02],\n",
      "          [ 4.1682e-02,  5.7448e-02,  3.7970e-03,  ..., -3.0204e-02,\n",
      "           -1.0442e-01, -3.3459e-03]],\n",
      "\n",
      "         [[-5.0102e-02,  3.8476e-01, -3.8080e-02,  ...,  1.0845e+00,\n",
      "            8.9512e-01, -5.7528e-01],\n",
      "          [ 1.5626e-02,  5.4370e-02, -5.3411e-02,  ...,  1.4293e-02,\n",
      "            3.6650e-02, -4.1399e-02],\n",
      "          [-1.6297e-01,  4.4728e-01, -3.6460e-01,  ..., -6.2477e-02,\n",
      "            5.7810e-01, -9.8768e-02],\n",
      "          ...,\n",
      "          [-2.7401e-02,  1.9440e-01, -1.3726e-01,  ...,  1.9589e-01,\n",
      "            2.9716e-01, -1.8524e-01],\n",
      "          [-1.2866e-01,  3.9980e-01, -3.2235e-01,  ...,  5.5585e-02,\n",
      "            5.4519e-01, -1.6946e-01],\n",
      "          [-4.9327e-03,  1.5242e-01, -1.5458e-01,  ...,  1.4607e-01,\n",
      "            2.0853e-01, -2.0590e-01]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[-1.2245,  1.2873,  0.2422,  ...,  0.4244, -0.7834, -0.1347],\n",
      "          [-0.9765,  0.3000,  0.9529,  ..., -1.4892,  0.0359, -0.3771],\n",
      "          [ 0.1753,  0.2529,  0.2901,  ..., -0.4067, -0.4720,  1.1145],\n",
      "          ...,\n",
      "          [-0.0273, -0.1548,  0.5128,  ..., -1.2157, -1.2270, -0.7754],\n",
      "          [-1.6327, -0.3436,  0.2499,  ..., -1.2658, -1.3898, -0.8009],\n",
      "          [-0.7799, -1.0675,  0.2845,  ..., -2.7782, -0.5587, -0.1479]],\n",
      "\n",
      "         [[-0.5133, -0.2527, -0.1181,  ..., -0.4282, -0.7031,  0.0134],\n",
      "          [-1.6589,  0.3339,  0.5060,  ...,  0.3872,  0.1888, -0.0443],\n",
      "          [-1.4153, -0.0104, -0.1789,  ...,  0.8727, -0.3391, -0.1900],\n",
      "          ...,\n",
      "          [-1.4102,  1.1122,  0.0841,  ...,  1.0020, -0.4298,  0.4971],\n",
      "          [-0.5791,  2.2825,  1.6468,  ...,  0.9877, -0.2087,  1.1174],\n",
      "          [-0.2044,  0.0716, -0.1107,  ..., -0.2704, -0.2868, -0.0682]],\n",
      "\n",
      "         [[-0.0701, -0.0876, -0.5418,  ..., -1.0650,  2.1510,  1.7987],\n",
      "          [ 0.0360, -0.0300, -0.6368,  ..., -2.1650,  1.1530, -0.0524],\n",
      "          [-0.0397, -0.1791, -0.4947,  ..., -2.0059,  0.4975,  0.0046],\n",
      "          ...,\n",
      "          [ 1.7233, -0.9347, -1.3231,  ...,  0.2216, -0.0442, -0.0959],\n",
      "          [-0.6127, -1.4680, -1.7149,  ..., -1.7752,  0.5658,  0.0988],\n",
      "          [-0.3700, -1.0336,  0.1787,  ..., -2.7906,  1.0030,  0.3441]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2549, -0.3318,  0.2477,  ...,  0.6506, -0.7567,  0.4131],\n",
      "          [-0.9362, -0.5171, -0.0498,  ...,  1.4190,  0.2341,  0.6630],\n",
      "          [ 1.1457, -0.8813, -0.5828,  ...,  0.7950, -0.6021,  0.5136],\n",
      "          ...,\n",
      "          [ 0.6592, -0.7800, -0.1804,  ...,  0.3423, -0.7374, -0.2600],\n",
      "          [-0.3260, -0.7842, -1.4718,  ...,  0.2274, -0.4969,  0.6327],\n",
      "          [-1.0533, -0.0685,  0.3955,  ...,  0.7802, -0.8232,  0.5647]],\n",
      "\n",
      "         [[ 1.0773,  0.0404,  0.4591,  ...,  0.8550, -0.4698, -0.4835],\n",
      "          [-0.2244, -0.3496, -1.9819,  ..., -1.1509, -0.2528,  1.0059],\n",
      "          [ 0.0716,  0.1748, -0.0867,  ..., -0.1089, -0.4828,  0.5828],\n",
      "          ...,\n",
      "          [-1.5744,  0.5702,  0.3166,  ...,  0.0103, -1.1809,  0.5558],\n",
      "          [-0.4306,  0.3847, -1.3127,  ..., -0.9333,  0.5293,  0.0510],\n",
      "          [-0.1739, -0.7654, -1.1668,  ...,  0.3954,  0.3209,  0.4190]],\n",
      "\n",
      "         [[ 1.7707,  0.5594,  1.1399,  ...,  0.7143,  0.3791, -0.9847],\n",
      "          [ 0.1557,  1.5415,  0.5066,  ...,  1.4346,  0.1335, -0.0722],\n",
      "          [-0.1053, -0.0244, -0.6885,  ...,  0.1389, -0.1065,  0.2376],\n",
      "          ...,\n",
      "          [-0.2840,  0.0189,  0.2681,  ...,  0.3814, -0.7678, -0.3546],\n",
      "          [ 1.3679,  0.9276,  0.9156,  ...,  1.7374,  0.5747, -1.5731],\n",
      "          [ 0.7055,  1.5016,  0.9719,  ...,  0.5184, -0.1954, -1.4120]]],\n",
      "\n",
      "\n",
      "        [[[-0.4209,  1.1395,  0.5827,  ..., -0.2504, -0.2332, -0.5383],\n",
      "          [-0.4070, -1.0692,  1.1360,  ..., -1.2377, -0.3887, -0.9150],\n",
      "          [-1.3219, -0.6367,  0.0448,  ...,  0.0315, -0.7786, -0.2508],\n",
      "          ...,\n",
      "          [ 0.4670,  1.2080,  1.4729,  ..., -0.8516, -0.9723, -0.5783],\n",
      "          [-0.7082,  0.2758,  0.8439,  ..., -0.3587, -1.2577, -1.4931],\n",
      "          [-0.4901,  1.2078,  1.9672,  ..., -1.2878, -1.5163, -1.5275]],\n",
      "\n",
      "         [[-0.5784, -0.1742, -0.7370,  ...,  0.4570, -0.2402, -0.1909],\n",
      "          [-1.8277, -0.4504,  1.1358,  ...,  0.2010,  0.5902,  0.1209],\n",
      "          [-1.4340,  0.4329,  0.9198,  ...,  1.3171,  0.5131,  1.0740],\n",
      "          ...,\n",
      "          [-1.7188,  0.0199, -1.1170,  ...,  0.3990,  0.2781,  0.5457],\n",
      "          [-1.3307,  0.7491,  0.2795,  ...,  0.7674,  0.5251, -0.2841],\n",
      "          [-1.7447,  0.6585, -0.8258,  ..., -0.0266,  0.3201,  0.1242]],\n",
      "\n",
      "         [[ 0.2590, -0.8144, -0.2446,  ..., -0.8917,  0.7555,  1.0563],\n",
      "          [-0.2201, -0.8513, -0.0310,  ..., -1.5285,  0.0257,  0.0641],\n",
      "          [-0.6021, -2.3926, -0.2333,  ..., -2.8378,  1.3445,  1.4242],\n",
      "          ...,\n",
      "          [ 0.3463, -0.0936,  1.1494,  ..., -1.2980, -0.1390,  0.7142],\n",
      "          [-0.2294, -0.3355, -0.1038,  ..., -1.7965,  0.9370,  0.7688],\n",
      "          [-0.0992,  0.5797,  0.5346,  ..., -1.5610,  0.3468,  0.9062]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6765, -1.5450, -0.0551,  ...,  0.9928, -0.9790, -0.0287],\n",
      "          [-0.0244, -0.9640,  0.1320,  ...,  1.0067,  0.1383,  1.4000],\n",
      "          [ 0.1451, -1.8730, -0.3208,  ...,  1.9469, -0.2017, -0.6223],\n",
      "          ...,\n",
      "          [ 0.5833, -0.2299, -0.3392,  ...,  1.5037, -0.4549,  0.0410],\n",
      "          [-0.0048, -0.5425, -0.3556,  ...,  2.3000, -0.6138, -0.5925],\n",
      "          [ 0.0844,  0.5165,  0.0282,  ...,  2.2165, -0.4716, -0.2160]],\n",
      "\n",
      "         [[ 1.3345, -0.5598,  1.2514,  ...,  0.3380, -0.2183,  0.4058],\n",
      "          [-1.6588,  0.3813, -0.6999,  ...,  0.7834,  0.4426,  1.2601],\n",
      "          [-0.6643, -0.3084,  0.4338,  ...,  0.1533,  0.4623, -0.1490],\n",
      "          ...,\n",
      "          [-1.1164,  0.1402, -0.2176,  ..., -0.4005,  1.3021,  0.4314],\n",
      "          [-1.0032,  0.2640,  0.0745,  ...,  0.4202,  1.0638, -0.2497],\n",
      "          [-1.0011, -0.0156, -0.2547,  ..., -0.1708,  1.2492,  0.3525]],\n",
      "\n",
      "         [[ 1.2535,  1.0714,  0.6488,  ..., -0.3228,  1.2635, -0.0708],\n",
      "          [ 0.0258,  1.5000,  0.4111,  ...,  0.9381, -0.9457, -1.8751],\n",
      "          [ 0.8817,  0.0217,  1.6352,  ...,  1.1323,  0.2905, -0.8600],\n",
      "          ...,\n",
      "          [ 0.0832,  1.4260,  0.8991,  ..., -1.0987, -0.1299, -1.3874],\n",
      "          [ 0.0522,  0.8275,  1.4008,  ..., -0.3511,  0.9449, -1.0272],\n",
      "          [ 0.2496,  1.2955,  1.2373,  ..., -1.0649,  0.4438, -1.7899]]]],\n",
      "       grad_fn=<PermuteBackward0>), query layer: tensor([[[[-0.1721,  0.4172,  0.0166,  ..., -1.7742, -0.4596,  0.5962],\n",
      "          [-0.5317,  1.2749,  0.3959,  ..., -2.0205,  1.0708,  0.6287],\n",
      "          [-1.1603,  1.2314,  0.9647,  ..., -2.8948, -0.1055,  0.8489],\n",
      "          ...,\n",
      "          [-1.3364,  0.3951,  0.5183,  ..., -1.3825, -1.4747,  0.5627],\n",
      "          [-0.6084,  1.0513,  1.6526,  ..., -1.9681, -0.9960,  1.1299],\n",
      "          [-0.2475, -0.6642,  0.0868,  ..., -1.7946, -0.3323,  0.1633]],\n",
      "\n",
      "         [[-0.1653, -0.4873, -0.1326,  ..., -0.4114, -0.3225, -0.4461],\n",
      "          [ 0.4626,  1.0670, -0.4480,  ..., -0.7952, -1.0358, -1.1845],\n",
      "          [ 0.2926,  0.5233,  1.3937,  ..., -0.8416, -1.7367, -1.7181],\n",
      "          ...,\n",
      "          [-0.3098,  0.2919, -0.4724,  ..., -0.4825, -0.3669, -2.4473],\n",
      "          [ 1.0113,  0.4993,  0.2796,  ..., -0.0611, -0.7603, -0.8322],\n",
      "          [-0.3119,  0.6248,  0.6820,  ...,  0.0725,  0.1786,  0.4724]],\n",
      "\n",
      "         [[ 1.7751, -2.1402, -0.3518,  ..., -0.3990,  0.4416,  0.0319],\n",
      "          [-0.0489, -0.1356, -0.3023,  ..., -3.4441, -1.0098, -0.6046],\n",
      "          [ 0.5975,  0.0477, -0.6253,  ..., -1.5893, -0.1999, -0.2476],\n",
      "          ...,\n",
      "          [-0.3905, -0.7059, -1.4722,  ..., -1.0538,  0.9499, -0.4271],\n",
      "          [-0.2403, -0.8936,  1.1752,  ..., -1.2691,  0.6765,  0.1070],\n",
      "          [ 0.3116, -0.7297,  0.3320,  ..., -1.3484,  0.8031,  0.0802]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9354,  0.2966,  0.7173,  ..., -0.1908,  0.4742,  0.0878],\n",
      "          [ 0.3669, -0.9331, -1.3666,  ..., -0.0803, -0.3066, -0.4961],\n",
      "          [-0.8751, -1.3709, -1.5245,  ...,  0.1238, -0.5889, -0.0117],\n",
      "          ...,\n",
      "          [-1.8177, -0.3901, -1.3509,  ...,  0.3181,  0.6115, -0.8518],\n",
      "          [-1.0358,  0.1096,  0.3187,  ...,  1.3668,  0.2426, -0.2684],\n",
      "          [-0.3324, -0.0086,  0.3086,  ...,  0.6231, -1.0410,  0.5463]],\n",
      "\n",
      "         [[-0.6944, -0.6513, -0.7932,  ...,  1.1542,  0.1963,  0.4405],\n",
      "          [-0.8710, -0.3920, -0.5702,  ...,  0.1990,  1.4970,  0.0198],\n",
      "          [-1.3235,  0.5548, -0.2746,  ...,  0.1717,  0.6195, -0.0148],\n",
      "          ...,\n",
      "          [-0.1812, -0.4602, -0.3191,  ..., -0.0694,  0.3583, -0.1847],\n",
      "          [-0.6472, -0.5008, -0.7771,  ...,  0.0098,  0.5581, -0.3963],\n",
      "          [-0.2269, -0.1300, -0.7149,  ...,  0.3775,  0.0774, -0.0505]],\n",
      "\n",
      "         [[-0.8034, -0.6448, -0.4321,  ..., -2.0436, -0.0161, -2.7310],\n",
      "          [ 0.5670, -0.1823, -0.1984,  ..., -0.5937,  1.0612, -0.5177],\n",
      "          [ 0.6446, -0.1540,  0.7128,  ..., -1.3032,  0.5800, -1.7409],\n",
      "          ...,\n",
      "          [-0.5396,  1.1240,  1.4237,  ...,  0.7170, -0.6161, -1.1833],\n",
      "          [-0.5349, -0.1109,  1.0828,  ...,  0.4426,  1.0992, -0.6061],\n",
      "          [ 0.1064,  0.6419,  0.9711,  ...,  0.2533, -0.2513, -0.7525]]],\n",
      "\n",
      "\n",
      "        [[[-1.1195, -0.1355,  0.4478,  ..., -1.1145, -0.6518,  1.0152],\n",
      "          [-0.5108,  0.6870,  0.8202,  ..., -0.5623,  0.0155, -0.2218],\n",
      "          [-0.4707,  0.4623, -0.0095,  ..., -1.6239, -1.0779, -0.0763],\n",
      "          ...,\n",
      "          [-2.5272,  0.4252,  0.3508,  ..., -1.4713, -0.6432, -0.1255],\n",
      "          [-2.1523,  0.4246,  0.7708,  ..., -2.3075, -1.8262,  0.2654],\n",
      "          [-2.6877, -0.3313,  0.8618,  ..., -1.5054, -0.6077, -0.5616]],\n",
      "\n",
      "         [[-0.8020, -1.5474, -0.5957,  ..., -0.5414, -0.5062, -0.5105],\n",
      "          [ 1.6011,  0.3921, -0.7443,  ..., -1.2033, -0.2074, -1.6383],\n",
      "          [ 0.2754, -2.1856, -0.4885,  ..., -1.1347,  0.6380, -0.7466],\n",
      "          ...,\n",
      "          [-0.7779,  0.0377, -0.1955,  ..., -0.7891,  0.4838, -1.8778],\n",
      "          [-0.5726, -0.7488, -0.3062,  ..., -0.4005,  0.6048, -1.1141],\n",
      "          [-0.5625,  0.3245, -0.5285,  ..., -0.6625,  0.5869, -1.4279]],\n",
      "\n",
      "         [[ 1.6882, -1.3357,  0.4864,  ..., -1.8148, -0.0524, -0.9919],\n",
      "          [-0.2351, -2.2002,  1.1242,  ..., -2.3755, -1.0238, -0.0946],\n",
      "          [ 0.5482, -0.6449,  0.6263,  ..., -1.8519,  0.5320,  0.4656],\n",
      "          ...,\n",
      "          [-0.2288, -1.0484,  0.0179,  ..., -1.9296, -0.6127, -0.0482],\n",
      "          [ 0.4765,  0.0161,  0.2288,  ..., -1.1310, -0.2998,  0.1190],\n",
      "          [-0.1235, -0.9411, -0.1038,  ..., -1.5933, -0.5081,  0.1092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3080,  0.1864, -0.5972,  ..., -0.0555, -0.0644, -0.0960],\n",
      "          [-0.0194, -1.1135, -0.7100,  ...,  1.1982,  1.0550, -1.0755],\n",
      "          [ 1.7058, -1.3704, -0.8392,  ..., -0.7222, -1.4941,  0.1277],\n",
      "          ...,\n",
      "          [ 0.1270, -1.1639, -0.9726,  ...,  1.5017, -0.4059, -1.0278],\n",
      "          [ 0.6169, -0.7419, -1.1820,  ...,  1.0061, -1.1491, -0.4811],\n",
      "          [-0.0618, -0.7455, -0.9059,  ...,  1.8682,  0.2241, -0.7729]],\n",
      "\n",
      "         [[-0.6594, -1.4988, -0.9504,  ...,  0.4123,  0.2614, -0.0156],\n",
      "          [-0.8491, -1.7061, -1.3123,  ..., -1.7237,  1.2033, -0.4501],\n",
      "          [-0.9154, -0.2702,  0.0350,  ...,  0.7795, -0.5730,  0.0106],\n",
      "          ...,\n",
      "          [ 0.0537,  0.1662, -0.3556,  ...,  0.7540, -0.0513,  0.1834],\n",
      "          [-0.2237, -0.2412,  0.5252,  ...,  1.3849, -0.3633,  0.5538],\n",
      "          [ 0.4001,  0.2753, -0.1851,  ...,  0.9844,  0.0382,  0.6668]],\n",
      "\n",
      "         [[-0.8828, -1.0237,  1.1511,  ..., -1.3597, -0.6050, -2.9811],\n",
      "          [ 1.3323,  0.5671,  0.5472,  ...,  0.0280, -0.4744, -0.3802],\n",
      "          [ 0.6253, -0.7940,  0.8301,  ..., -1.8027, -0.6584, -0.8211],\n",
      "          ...,\n",
      "          [-0.6741, -0.1407,  0.5894,  ...,  0.3733, -0.3682, -0.5933],\n",
      "          [-0.2697, -0.4455,  1.4668,  ..., -0.2697, -0.7761, -1.2833],\n",
      "          [-0.6413, -0.5650,  0.7863,  ...,  0.0079, -0.1867, -1.1280]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[ 1.0082e+00, -8.0516e-01, -1.0189e+00,  ..., -1.2735e+00,\n",
      "            4.2528e-01,  2.6514e+00],\n",
      "          [ 3.2429e+00,  2.7704e+00,  1.4443e+00,  ...,  2.0903e-01,\n",
      "            1.9812e+00,  4.6814e+00],\n",
      "          [ 3.2021e+00,  2.9685e+00,  1.8332e+00,  ...,  5.5590e-01,\n",
      "            2.9073e+00,  4.5958e+00],\n",
      "          ...,\n",
      "          [ 2.7989e+00,  2.0586e+00,  9.0455e-01,  ...,  1.7345e-01,\n",
      "            2.4253e+00,  4.9031e+00],\n",
      "          [ 2.1764e+00,  1.7800e+00,  9.5688e-01,  ...,  8.9440e-01,\n",
      "            2.0622e+00,  4.6539e+00],\n",
      "          [ 2.0554e+00,  1.1582e+00, -8.0676e-02,  ..., -1.2417e-01,\n",
      "            7.7693e-01,  5.5201e+00]],\n",
      "\n",
      "         [[-1.9157e-01, -9.8394e-02,  3.8342e-01,  ..., -1.0505e-01,\n",
      "            6.9513e-02,  2.2180e+00],\n",
      "          [ 6.2669e-01, -1.4164e+00, -3.2600e-01,  ..., -1.2063e+00,\n",
      "           -3.2985e-01,  3.6941e+00],\n",
      "          [ 6.7961e-01, -1.2357e+00, -1.1459e+00,  ..., -1.0892e+00,\n",
      "            9.8283e-02,  3.8126e+00],\n",
      "          ...,\n",
      "          [ 1.4480e+00, -1.3164e+00, -1.3164e+00,  ..., -1.5071e+00,\n",
      "           -1.6851e-01,  3.7750e+00],\n",
      "          [ 7.9414e-01, -1.0317e+00, -8.6363e-01,  ...,  8.0213e-02,\n",
      "            8.9433e-02,  3.9040e+00],\n",
      "          [ 5.0779e-01,  7.0002e-01, -3.6463e-01,  ..., -2.0776e-01,\n",
      "            1.1462e+00,  3.8696e+00]],\n",
      "\n",
      "         [[ 3.4566e-01,  2.3469e+00, -6.9978e-01,  ..., -7.4592e-01,\n",
      "           -5.2592e-02,  3.3435e+00],\n",
      "          [ 1.9391e+00,  3.0314e+00,  5.9061e+00,  ...,  1.2037e+00,\n",
      "            2.0072e+00,  5.6014e+00],\n",
      "          [ 5.7663e-01,  3.1628e+00,  2.8757e+00,  ...,  2.2331e+00,\n",
      "            2.6277e+00,  5.9331e+00],\n",
      "          ...,\n",
      "          [ 3.0131e+00,  1.4842e+00,  9.9986e-01,  ...,  2.9217e+00,\n",
      "            5.6108e+00,  5.6268e+00],\n",
      "          [ 3.1817e+00,  1.2984e+00, -8.0555e-01,  ..., -2.8254e-01,\n",
      "            1.2602e+00,  4.9299e+00],\n",
      "          [ 1.0279e+00,  9.7346e-01,  4.7943e-01,  ..., -2.2556e-01,\n",
      "            5.4235e-01,  5.3555e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.5037e-01, -5.9054e-01, -2.2398e+00,  ..., -7.5513e-01,\n",
      "            1.2161e-01,  2.2116e+00],\n",
      "          [ 1.3899e+00,  6.7063e-01,  1.6316e+00,  ...,  1.5891e+00,\n",
      "            4.1311e+00,  2.1537e+00],\n",
      "          [ 2.1564e+00,  1.5163e+00,  2.5725e-01,  ...,  1.5838e+00,\n",
      "            3.9090e+00,  2.8362e+00],\n",
      "          ...,\n",
      "          [ 2.7746e+00,  1.7042e+00,  1.1080e-01,  ...,  1.8179e+00,\n",
      "            3.3155e+00,  3.3420e+00],\n",
      "          [ 2.5048e+00,  2.9654e+00,  5.4591e-01,  ...,  2.4457e+00,\n",
      "            1.3970e+00,  3.5533e+00],\n",
      "          [ 1.0882e+00,  1.3110e+00, -1.5549e-01,  ...,  5.1139e-01,\n",
      "            1.2379e+00,  4.7416e+00]],\n",
      "\n",
      "         [[ 3.8500e-02, -3.7473e-01, -2.1228e+00,  ..., -1.9220e+00,\n",
      "           -6.3371e-01,  4.3429e+00],\n",
      "          [ 2.8542e-01,  2.0124e+00,  3.4090e-01,  ...,  5.9523e-01,\n",
      "            2.3421e+00,  3.2163e+00],\n",
      "          [ 1.1071e+00,  4.1507e+00,  1.1004e+00,  ...,  8.2771e-01,\n",
      "            2.0508e+00,  3.8334e+00],\n",
      "          ...,\n",
      "          [ 5.9326e-01,  3.2492e+00,  9.0930e-01,  ...,  6.9731e-01,\n",
      "            2.7474e+00,  4.6859e+00],\n",
      "          [ 1.4945e+00,  3.2181e+00,  1.0509e+00,  ...,  9.8142e-01,\n",
      "            2.3083e+00,  3.5158e+00],\n",
      "          [ 1.1890e+00,  2.0669e+00,  4.6194e-01,  ...,  8.2653e-02,\n",
      "            1.6555e+00,  6.3983e+00]],\n",
      "\n",
      "         [[ 7.1868e-01, -2.2947e+00, -1.4291e+00,  ..., -2.1299e+00,\n",
      "           -7.3592e-02,  3.6885e+00],\n",
      "          [ 4.4224e-01,  1.0233e+00,  1.6621e+00,  ...,  1.3770e+00,\n",
      "            2.1558e+00,  2.6660e+00],\n",
      "          [ 2.2371e+00,  2.2236e+00,  1.8624e+00,  ...,  1.7423e+00,\n",
      "            1.6199e+00,  5.1678e+00],\n",
      "          ...,\n",
      "          [ 1.9731e+00,  3.8095e+00,  3.4717e+00,  ...,  2.1617e+00,\n",
      "            3.3496e+00,  5.1641e+00],\n",
      "          [ 1.2965e+00,  2.3426e+00,  2.3799e+00,  ...,  2.1188e+00,\n",
      "            1.6556e+00,  3.4020e+00],\n",
      "          [ 9.9667e-01,  9.1122e-01,  4.9752e-01,  ...,  6.0987e-01,\n",
      "            1.3572e+00,  4.9310e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6724e-01, -6.6830e-01,  7.0053e-01,  ...,  1.1508e+00,\n",
      "            5.5158e-01,  1.9511e+00],\n",
      "          [ 2.4034e+00,  1.1306e+00,  8.1238e-01,  ...,  2.6380e+00,\n",
      "            1.4840e+00,  2.7504e+00],\n",
      "          [ 2.1188e+00,  8.5266e-01,  5.5887e-01,  ...,  9.0544e-01,\n",
      "            5.6238e-01,  1.3355e+00],\n",
      "          ...,\n",
      "          [ 1.0476e+00,  1.5166e+00,  8.7869e-01,  ...,  2.2258e-01,\n",
      "            1.3500e+00,  1.4734e+00],\n",
      "          [ 1.8312e+00,  6.6891e-01,  7.1563e-01,  ..., -1.5157e-01,\n",
      "            5.9979e-01,  1.1766e+00],\n",
      "          [ 1.9381e+00,  1.2417e+00,  6.3918e-01,  ..., -4.3114e-01,\n",
      "            7.3321e-01,  1.2668e+00]],\n",
      "\n",
      "         [[-8.9469e-01,  1.3021e+00,  1.5702e-01,  ...,  5.9033e-01,\n",
      "           -9.2060e-01,  1.6877e-01],\n",
      "          [ 7.5647e-01, -4.9610e-01,  2.2871e-01,  ..., -1.3096e-01,\n",
      "            2.2033e-01, -6.3328e-02],\n",
      "          [-6.6398e-01,  1.4054e-01, -9.8626e-02,  ...,  2.2265e-01,\n",
      "           -9.7179e-01, -8.2097e-02],\n",
      "          ...,\n",
      "          [ 1.1604e-01,  1.0800e+00,  1.0264e+00,  ...,  1.1710e+00,\n",
      "            9.8262e-01,  1.3362e+00],\n",
      "          [ 3.2135e-03,  6.5950e-01,  8.9008e-01,  ...,  8.0456e-01,\n",
      "            1.0572e-01,  8.0253e-01],\n",
      "          [ 4.5310e-01,  8.6532e-01,  9.5950e-01,  ...,  1.0512e+00,\n",
      "            8.2264e-01,  1.2195e+00]],\n",
      "\n",
      "         [[ 1.0409e+00,  5.7212e+00,  1.1658e+00,  ...,  4.0109e+00,\n",
      "            2.1550e+00,  3.7917e+00],\n",
      "          [ 3.7955e+00,  2.8030e+00,  8.3797e+00,  ...,  3.3249e+00,\n",
      "            5.9549e+00,  3.5344e+00],\n",
      "          [ 3.1211e-01,  5.2960e+00,  2.2487e+00,  ...,  3.5344e+00,\n",
      "            2.6321e+00,  3.5378e+00],\n",
      "          ...,\n",
      "          [ 4.7337e+00,  4.2887e+00,  6.6155e+00,  ...,  3.3478e+00,\n",
      "            6.3268e+00,  4.0117e+00],\n",
      "          [ 2.4599e+00,  4.2788e+00,  2.4097e+00,  ...,  3.2388e+00,\n",
      "            3.8258e+00,  3.8720e+00],\n",
      "          [ 3.8602e+00,  2.9875e+00,  5.3130e+00,  ...,  2.7474e+00,\n",
      "            5.5342e+00,  3.6485e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.0769e-01,  9.9661e-01, -1.2989e+00,  ...,  1.5631e+00,\n",
      "            5.5355e-01,  1.8594e+00],\n",
      "          [ 2.1329e+00,  1.1818e+00,  2.2935e+00,  ...,  2.6292e+00,\n",
      "            2.3368e+00,  2.8265e+00],\n",
      "          [ 2.6894e+00,  2.9730e+00,  1.7696e+00,  ...,  3.3872e+00,\n",
      "            2.3515e+00,  3.2864e+00],\n",
      "          ...,\n",
      "          [ 2.1678e+00,  2.8135e+00,  1.9461e+00,  ...,  2.2909e+00,\n",
      "            2.3831e+00,  2.7641e+00],\n",
      "          [ 2.1885e+00,  3.3178e+00,  1.5778e+00,  ...,  3.0858e+00,\n",
      "            2.2069e+00,  3.5365e+00],\n",
      "          [ 2.0216e+00,  2.7075e+00,  1.5656e+00,  ...,  1.8933e+00,\n",
      "            2.1108e+00,  2.8717e+00]],\n",
      "\n",
      "         [[-2.4441e+00,  1.1985e-01, -1.6522e+00,  ...,  1.9703e-01,\n",
      "           -1.0887e+00,  6.6294e-01],\n",
      "          [-1.0971e+00,  1.6986e+00,  1.0160e+00,  ...,  1.7838e+00,\n",
      "            5.0125e-01,  1.7837e+00],\n",
      "          [ 8.9267e-01,  3.9651e+00,  2.1778e+00,  ...,  2.6863e+00,\n",
      "            1.8170e+00,  2.5884e+00],\n",
      "          ...,\n",
      "          [ 8.6032e-01,  2.3079e+00,  2.5676e-01,  ...,  1.3585e+00,\n",
      "            2.6950e-01,  1.4070e+00],\n",
      "          [ 6.6236e-01,  3.1225e+00,  7.8900e-01,  ...,  2.1234e+00,\n",
      "            7.3175e-01,  2.1397e+00],\n",
      "          [ 6.6541e-01,  2.4265e+00,  1.6622e-01,  ...,  1.3875e+00,\n",
      "            5.2034e-02,  1.4884e+00]],\n",
      "\n",
      "         [[ 2.4849e-01, -2.1264e-01,  1.4756e-01,  ...,  1.1047e+00,\n",
      "            1.5961e-01,  1.2023e+00],\n",
      "          [ 2.0025e+00,  1.9801e+00,  2.3121e+00,  ...,  1.7904e+00,\n",
      "            1.6978e+00,  1.4828e+00],\n",
      "          [ 2.4742e+00,  3.1975e+00,  3.2931e+00,  ...,  3.6935e+00,\n",
      "            2.9190e+00,  3.0532e+00],\n",
      "          ...,\n",
      "          [ 1.6358e+00,  4.0293e+00,  3.0548e+00,  ...,  1.4521e+00,\n",
      "            1.6206e+00,  7.4856e-01],\n",
      "          [ 2.0244e+00,  3.9591e+00,  3.2089e+00,  ...,  2.7066e+00,\n",
      "            2.0966e+00,  2.0333e+00],\n",
      "          [ 1.8524e+00,  3.8205e+00,  2.5934e+00,  ...,  1.6629e+00,\n",
      "            1.6538e+00,  1.3212e+00]]]], grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[ 1.0082e+00, -8.0516e-01, -1.0189e+00,  ..., -1.2735e+00,\n",
      "            4.2528e-01,  2.6514e+00],\n",
      "          [ 3.2429e+00,  2.7704e+00,  1.4443e+00,  ...,  2.0903e-01,\n",
      "            1.9812e+00,  4.6814e+00],\n",
      "          [ 3.2021e+00,  2.9685e+00,  1.8332e+00,  ...,  5.5590e-01,\n",
      "            2.9073e+00,  4.5958e+00],\n",
      "          ...,\n",
      "          [ 2.7989e+00,  2.0586e+00,  9.0455e-01,  ...,  1.7345e-01,\n",
      "            2.4253e+00,  4.9031e+00],\n",
      "          [ 2.1764e+00,  1.7800e+00,  9.5688e-01,  ...,  8.9440e-01,\n",
      "            2.0622e+00,  4.6539e+00],\n",
      "          [ 2.0554e+00,  1.1582e+00, -8.0676e-02,  ..., -1.2417e-01,\n",
      "            7.7693e-01,  5.5201e+00]],\n",
      "\n",
      "         [[-1.9157e-01, -9.8394e-02,  3.8342e-01,  ..., -1.0505e-01,\n",
      "            6.9513e-02,  2.2180e+00],\n",
      "          [ 6.2669e-01, -1.4164e+00, -3.2600e-01,  ..., -1.2063e+00,\n",
      "           -3.2985e-01,  3.6941e+00],\n",
      "          [ 6.7961e-01, -1.2357e+00, -1.1459e+00,  ..., -1.0892e+00,\n",
      "            9.8283e-02,  3.8126e+00],\n",
      "          ...,\n",
      "          [ 1.4480e+00, -1.3164e+00, -1.3164e+00,  ..., -1.5071e+00,\n",
      "           -1.6851e-01,  3.7750e+00],\n",
      "          [ 7.9414e-01, -1.0317e+00, -8.6363e-01,  ...,  8.0213e-02,\n",
      "            8.9433e-02,  3.9040e+00],\n",
      "          [ 5.0779e-01,  7.0002e-01, -3.6463e-01,  ..., -2.0776e-01,\n",
      "            1.1462e+00,  3.8696e+00]],\n",
      "\n",
      "         [[ 3.4566e-01,  2.3469e+00, -6.9978e-01,  ..., -7.4592e-01,\n",
      "           -5.2592e-02,  3.3435e+00],\n",
      "          [ 1.9391e+00,  3.0314e+00,  5.9061e+00,  ...,  1.2037e+00,\n",
      "            2.0072e+00,  5.6014e+00],\n",
      "          [ 5.7663e-01,  3.1628e+00,  2.8757e+00,  ...,  2.2331e+00,\n",
      "            2.6277e+00,  5.9331e+00],\n",
      "          ...,\n",
      "          [ 3.0131e+00,  1.4842e+00,  9.9986e-01,  ...,  2.9217e+00,\n",
      "            5.6108e+00,  5.6268e+00],\n",
      "          [ 3.1817e+00,  1.2984e+00, -8.0555e-01,  ..., -2.8254e-01,\n",
      "            1.2602e+00,  4.9299e+00],\n",
      "          [ 1.0279e+00,  9.7346e-01,  4.7943e-01,  ..., -2.2556e-01,\n",
      "            5.4235e-01,  5.3555e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.5037e-01, -5.9054e-01, -2.2398e+00,  ..., -7.5513e-01,\n",
      "            1.2161e-01,  2.2116e+00],\n",
      "          [ 1.3899e+00,  6.7063e-01,  1.6316e+00,  ...,  1.5891e+00,\n",
      "            4.1311e+00,  2.1537e+00],\n",
      "          [ 2.1564e+00,  1.5163e+00,  2.5725e-01,  ...,  1.5838e+00,\n",
      "            3.9090e+00,  2.8362e+00],\n",
      "          ...,\n",
      "          [ 2.7746e+00,  1.7042e+00,  1.1080e-01,  ...,  1.8179e+00,\n",
      "            3.3155e+00,  3.3420e+00],\n",
      "          [ 2.5048e+00,  2.9654e+00,  5.4591e-01,  ...,  2.4457e+00,\n",
      "            1.3970e+00,  3.5533e+00],\n",
      "          [ 1.0882e+00,  1.3110e+00, -1.5549e-01,  ...,  5.1139e-01,\n",
      "            1.2379e+00,  4.7416e+00]],\n",
      "\n",
      "         [[ 3.8500e-02, -3.7473e-01, -2.1228e+00,  ..., -1.9220e+00,\n",
      "           -6.3371e-01,  4.3429e+00],\n",
      "          [ 2.8542e-01,  2.0124e+00,  3.4090e-01,  ...,  5.9523e-01,\n",
      "            2.3421e+00,  3.2163e+00],\n",
      "          [ 1.1071e+00,  4.1507e+00,  1.1004e+00,  ...,  8.2771e-01,\n",
      "            2.0508e+00,  3.8334e+00],\n",
      "          ...,\n",
      "          [ 5.9326e-01,  3.2492e+00,  9.0930e-01,  ...,  6.9731e-01,\n",
      "            2.7474e+00,  4.6859e+00],\n",
      "          [ 1.4945e+00,  3.2181e+00,  1.0509e+00,  ...,  9.8142e-01,\n",
      "            2.3083e+00,  3.5158e+00],\n",
      "          [ 1.1890e+00,  2.0669e+00,  4.6194e-01,  ...,  8.2653e-02,\n",
      "            1.6555e+00,  6.3983e+00]],\n",
      "\n",
      "         [[ 7.1868e-01, -2.2947e+00, -1.4291e+00,  ..., -2.1299e+00,\n",
      "           -7.3592e-02,  3.6885e+00],\n",
      "          [ 4.4224e-01,  1.0233e+00,  1.6621e+00,  ...,  1.3770e+00,\n",
      "            2.1558e+00,  2.6660e+00],\n",
      "          [ 2.2371e+00,  2.2236e+00,  1.8624e+00,  ...,  1.7423e+00,\n",
      "            1.6199e+00,  5.1678e+00],\n",
      "          ...,\n",
      "          [ 1.9731e+00,  3.8095e+00,  3.4717e+00,  ...,  2.1617e+00,\n",
      "            3.3496e+00,  5.1641e+00],\n",
      "          [ 1.2965e+00,  2.3426e+00,  2.3799e+00,  ...,  2.1188e+00,\n",
      "            1.6556e+00,  3.4020e+00],\n",
      "          [ 9.9667e-01,  9.1122e-01,  4.9752e-01,  ...,  6.0987e-01,\n",
      "            1.3572e+00,  4.9310e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6724e-01, -6.6830e-01,  7.0053e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.4034e+00,  1.1306e+00,  8.1238e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.1188e+00,  8.5266e-01,  5.5887e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.0476e+00,  1.5166e+00,  8.7869e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.8312e+00,  6.6891e-01,  7.1563e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.9381e+00,  1.2417e+00,  6.3918e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-8.9469e-01,  1.3021e+00,  1.5702e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.5647e-01, -4.9610e-01,  2.2871e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-6.6398e-01,  1.4054e-01, -9.8626e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.1604e-01,  1.0800e+00,  1.0264e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.2135e-03,  6.5950e-01,  8.9008e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.5310e-01,  8.6532e-01,  9.5950e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.0409e+00,  5.7212e+00,  1.1658e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.7955e+00,  2.8030e+00,  8.3797e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.1211e-01,  5.2960e+00,  2.2487e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 4.7337e+00,  4.2887e+00,  6.6155e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.4599e+00,  4.2788e+00,  2.4097e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.8602e+00,  2.9875e+00,  5.3130e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.0769e-01,  9.9661e-01, -1.2989e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.1329e+00,  1.1818e+00,  2.2935e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.6894e+00,  2.9730e+00,  1.7696e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.1678e+00,  2.8135e+00,  1.9461e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.1885e+00,  3.3178e+00,  1.5778e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.0216e+00,  2.7075e+00,  1.5656e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-2.4441e+00,  1.1985e-01, -1.6522e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.0971e+00,  1.6986e+00,  1.0160e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 8.9267e-01,  3.9651e+00,  2.1778e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 8.6032e-01,  2.3079e+00,  2.5676e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.6236e-01,  3.1225e+00,  7.8900e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.6541e-01,  2.4265e+00,  1.6622e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 2.4849e-01, -2.1264e-01,  1.4756e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.0025e+00,  1.9801e+00,  2.3121e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.4742e+00,  3.1975e+00,  3.2931e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.6358e+00,  4.0293e+00,  3.0548e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.0244e+00,  3.9591e+00,  3.2089e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.8524e+00,  3.8205e+00,  2.5934e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[0.1398, 0.0228, 0.0184,  ..., 0.0143, 0.0781, 0.7233],\n",
      "          [0.1560, 0.0972, 0.0258,  ..., 0.0075, 0.0442, 0.6573],\n",
      "          [0.1440, 0.1140, 0.0366,  ..., 0.0102, 0.1073, 0.5804],\n",
      "          ...,\n",
      "          [0.0941, 0.0449, 0.0142,  ..., 0.0068, 0.0648, 0.7719],\n",
      "          [0.0656, 0.0441, 0.0194,  ..., 0.0182, 0.0585, 0.7813],\n",
      "          [0.0295, 0.0120, 0.0035,  ..., 0.0033, 0.0082, 0.9420]],\n",
      "\n",
      "         [[0.0553, 0.0607, 0.0983,  ..., 0.0603, 0.0718, 0.6156],\n",
      "          [0.0422, 0.0055, 0.0163,  ..., 0.0068, 0.0162, 0.9071],\n",
      "          [0.0399, 0.0059, 0.0064,  ..., 0.0068, 0.0223, 0.9150],\n",
      "          ...,\n",
      "          [0.0855, 0.0054, 0.0054,  ..., 0.0045, 0.0170, 0.8759],\n",
      "          [0.0399, 0.0064, 0.0076,  ..., 0.0195, 0.0197, 0.8935],\n",
      "          [0.0291, 0.0353, 0.0122,  ..., 0.0142, 0.0551, 0.8394]],\n",
      "\n",
      "         [[0.0335, 0.2477, 0.0118,  ..., 0.0112, 0.0225, 0.6710],\n",
      "          [0.0101, 0.0301, 0.5330,  ..., 0.0048, 0.0108, 0.3930],\n",
      "          [0.0038, 0.0510, 0.0383,  ..., 0.0201, 0.0299, 0.8144],\n",
      "          ...,\n",
      "          [0.0339, 0.0073, 0.0045,  ..., 0.0309, 0.4547, 0.4620],\n",
      "          [0.1408, 0.0214, 0.0026,  ..., 0.0044, 0.0206, 0.8090],\n",
      "          [0.0126, 0.0119, 0.0073,  ..., 0.0036, 0.0078, 0.9545]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0323, 0.0463, 0.0089,  ..., 0.0393, 0.0945, 0.7638],\n",
      "          [0.0445, 0.0217, 0.0567,  ..., 0.0543, 0.6903, 0.0956],\n",
      "          [0.0979, 0.0516, 0.0147,  ..., 0.0552, 0.5651, 0.1933],\n",
      "          ...,\n",
      "          [0.1805, 0.0619, 0.0126,  ..., 0.0694, 0.3101, 0.3184],\n",
      "          [0.1340, 0.2125, 0.0189,  ..., 0.1263, 0.0443, 0.3825],\n",
      "          [0.0232, 0.0290, 0.0067,  ..., 0.0130, 0.0269, 0.8950]],\n",
      "\n",
      "         [[0.0131, 0.0086, 0.0015,  ..., 0.0018, 0.0067, 0.9674],\n",
      "          [0.0277, 0.1559, 0.0293,  ..., 0.0378, 0.2168, 0.5197],\n",
      "          [0.0239, 0.5021, 0.0238,  ..., 0.0181, 0.0615, 0.3656],\n",
      "          ...,\n",
      "          [0.0115, 0.1644, 0.0158,  ..., 0.0128, 0.0995, 0.6915],\n",
      "          [0.0559, 0.3131, 0.0359,  ..., 0.0334, 0.1261, 0.4217],\n",
      "          [0.0053, 0.0127, 0.0026,  ..., 0.0018, 0.0084, 0.9683]],\n",
      "\n",
      "         [[0.0471, 0.0023, 0.0055,  ..., 0.0027, 0.0213, 0.9172],\n",
      "          [0.0416, 0.0743, 0.1408,  ..., 0.1058, 0.2306, 0.3842],\n",
      "          [0.0441, 0.0436, 0.0304,  ..., 0.0269, 0.0238, 0.8274],\n",
      "          ...,\n",
      "          [0.0236, 0.1478, 0.1054,  ..., 0.0284, 0.0933, 0.5727],\n",
      "          [0.0491, 0.1398, 0.1451,  ..., 0.1118, 0.0703, 0.4033],\n",
      "          [0.0178, 0.0163, 0.0108,  ..., 0.0121, 0.0255, 0.9098]]],\n",
      "\n",
      "\n",
      "        [[[0.0440, 0.0173, 0.0678,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2095, 0.0587, 0.0427,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0526, 0.0148, 0.0110,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0384, 0.0615, 0.0325,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0178, 0.0056, 0.0058,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0456, 0.0227, 0.0124,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0262, 0.2357, 0.0750,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0432, 0.0123, 0.0255,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0174, 0.0388, 0.0306,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0148, 0.0387, 0.0367,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0187, 0.0361, 0.0454,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0278, 0.0420, 0.0461,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0070, 0.7506, 0.0079,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0096, 0.0036, 0.9440,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0032, 0.4676, 0.0222,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1166, 0.0747, 0.7655,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0560, 0.3450, 0.0532,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1581, 0.0661, 0.6760,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0284, 0.1277, 0.0129,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2497, 0.0965, 0.2932,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0774, 0.1027, 0.0308,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1235, 0.2356, 0.0990,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0249, 0.0770, 0.0135,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1034, 0.2053, 0.0655,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0011, 0.0140, 0.0024,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0092, 0.1499, 0.0757,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0093, 0.2003, 0.0335,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0488, 0.2074, 0.0267,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0079, 0.0928, 0.0090,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0355, 0.2068, 0.0216,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0435, 0.0274, 0.0393,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1311, 0.1281, 0.1786,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0783, 0.1613, 0.1775,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0372, 0.4078, 0.1539,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0295, 0.2043, 0.0965,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0516, 0.3691, 0.1082,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[ 8.5399e-03, -9.2580e-02, -6.1356e-02,  ..., -8.5712e-02,\n",
      "            1.8671e-02,  1.3973e-01],\n",
      "          [-6.0918e-04, -3.8311e-03, -4.4247e-03,  ..., -1.0533e-01,\n",
      "            1.8190e-02,  1.1588e-01],\n",
      "          [-1.8994e-02, -8.6280e-02, -4.8520e-02,  ..., -1.3983e-01,\n",
      "            1.3175e-02,  1.5120e-01],\n",
      "          ...,\n",
      "          [-5.9754e-03, -5.8239e-02, -4.9861e-02,  ..., -7.8496e-02,\n",
      "            1.7920e-02,  8.9635e-02],\n",
      "          [-4.5259e-02, -6.9547e-02, -3.5763e-02,  ..., -7.4077e-02,\n",
      "            3.2767e-02,  1.0709e-01],\n",
      "          [-1.3500e-02,  8.1406e-03, -2.7418e-02,  ..., -2.6356e-02,\n",
      "            2.2409e-02,  8.9431e-03]],\n",
      "\n",
      "         [[ 2.5200e-01,  1.2635e-01, -1.8326e-01,  ...,  3.8046e-01,\n",
      "           -1.1773e-02,  2.5952e-02],\n",
      "          [ 1.1488e-02,  2.4854e-02, -5.8677e-02,  ...,  6.1491e-02,\n",
      "           -7.3229e-02, -4.0556e-02],\n",
      "          [ 1.8071e-02,  2.9444e-02, -5.0402e-02,  ...,  5.1714e-02,\n",
      "           -7.2453e-02, -2.7159e-02],\n",
      "          ...,\n",
      "          [ 1.7962e-02, -9.2571e-03, -7.5006e-02,  ...,  7.8227e-02,\n",
      "           -1.4583e-01, -4.7017e-02],\n",
      "          [ 2.6473e-02,  1.5592e-02, -7.3463e-02,  ...,  7.6549e-02,\n",
      "           -5.7419e-02, -1.9970e-02],\n",
      "          [ 1.2221e-01,  8.5362e-02, -6.4763e-02,  ...,  1.4031e-01,\n",
      "           -3.8275e-02,  3.5625e-02]],\n",
      "\n",
      "         [[ 2.4512e-02,  3.3312e-02,  1.7833e-02,  ...,  1.7819e-01,\n",
      "           -5.1971e-02, -3.5808e-02],\n",
      "          [-5.0216e-02, -5.9829e-02, -1.1366e-01,  ...,  5.1760e-01,\n",
      "           -3.9740e-03,  3.6217e-01],\n",
      "          [ 2.7131e-03, -2.5852e-02, -5.9186e-02,  ...,  8.8942e-02,\n",
      "           -2.2151e-02,  9.9431e-02],\n",
      "          ...,\n",
      "          [-1.9660e-01, -4.6052e-01, -9.8118e-02,  ...,  1.8661e-01,\n",
      "           -8.6691e-02,  6.3562e-01],\n",
      "          [-5.4603e-02, -3.1563e-02, -5.3101e-02,  ...,  1.5705e-01,\n",
      "            4.8737e-02,  9.6529e-02],\n",
      "          [-5.1611e-03, -8.5746e-03, -8.5339e-03,  ...,  6.1173e-02,\n",
      "           -6.1599e-03,  3.4241e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5601e-01,  1.0613e-01,  5.1310e-03,  ..., -2.3292e-01,\n",
      "            9.1938e-02,  9.7759e-02],\n",
      "          [-1.0249e+00,  5.9942e-01,  2.5095e-01,  ..., -1.2020e+00,\n",
      "            5.0557e-01,  3.5544e-01],\n",
      "          [-8.5363e-01,  5.6351e-01,  2.1335e-01,  ..., -1.0662e+00,\n",
      "            4.0955e-01,  2.9970e-01],\n",
      "          ...,\n",
      "          [-6.3775e-01,  3.8365e-01,  7.1575e-02,  ..., -7.6826e-01,\n",
      "            2.7067e-01,  1.3803e-01],\n",
      "          [-4.9524e-01,  1.7154e-01, -1.5737e-01,  ..., -4.6455e-01,\n",
      "            3.4289e-01,  9.1992e-02],\n",
      "          [-1.1864e-01,  3.9981e-02, -3.1128e-03,  ..., -7.8846e-02,\n",
      "            7.8969e-03,  6.1265e-02]],\n",
      "\n",
      "         [[ 2.0016e-02, -8.7973e-03,  6.5765e-03,  ...,  1.9958e-02,\n",
      "           -1.6843e-04, -1.1096e-02],\n",
      "          [ 7.0695e-02,  2.6509e-01,  6.8964e-02,  ..., -3.2487e-02,\n",
      "           -6.4795e-02, -1.2773e-01],\n",
      "          [ 1.3757e-01,  5.1241e-01,  2.5792e-01,  ..., -1.0233e-01,\n",
      "           -4.0941e-01, -4.1643e-01],\n",
      "          ...,\n",
      "          [ 6.1012e-02,  1.9847e-01,  7.8466e-02,  ..., -2.5315e-02,\n",
      "           -1.0519e-01, -1.4653e-01],\n",
      "          [ 1.0908e-01,  3.8095e-01,  1.7678e-01,  ..., -5.5707e-02,\n",
      "           -2.2417e-01, -2.3720e-01],\n",
      "          [ 2.0547e-02, -1.9475e-03,  3.7792e-03,  ...,  1.6432e-02,\n",
      "           -4.9048e-03, -1.6559e-02]],\n",
      "\n",
      "         [[ 9.0537e-02, -1.7296e-02, -1.6880e-02,  ..., -6.3551e-02,\n",
      "           -1.9382e-02, -1.1222e-01],\n",
      "          [ 2.3744e-01,  3.0076e-02,  5.3344e-01,  ..., -3.3282e-01,\n",
      "           -1.8111e-01, -1.5156e-01],\n",
      "          [ 9.8647e-02, -1.1723e-02,  6.8750e-02,  ..., -9.1725e-02,\n",
      "           -2.5986e-02, -1.1005e-01],\n",
      "          ...,\n",
      "          [ 1.3473e-01,  5.3460e-02,  3.4408e-01,  ..., -2.3287e-01,\n",
      "           -5.7211e-02, -1.4210e-01],\n",
      "          [ 2.0699e-01, -4.8065e-02,  4.2902e-01,  ..., -2.8148e-01,\n",
      "           -7.9377e-02, -7.3659e-02],\n",
      "          [ 8.6233e-02,  7.4603e-03,  1.8571e-02,  ..., -5.9695e-02,\n",
      "           -2.0695e-02, -9.6841e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.5842e-02,  1.5160e-02,  2.5983e-02,  ..., -1.6960e-02,\n",
      "           -7.4911e-02,  3.9713e-02],\n",
      "          [ 1.8965e-01,  1.0870e-01, -4.5879e-02,  ...,  6.5910e-02,\n",
      "           -1.7291e-01,  1.4501e-01],\n",
      "          [ 4.0221e-02,  2.0492e-02, -2.0874e-02,  ...,  1.3424e-02,\n",
      "           -1.1593e-02,  1.8262e-02],\n",
      "          ...,\n",
      "          [-7.3544e-03,  6.7207e-02,  2.5291e-02,  ...,  7.5573e-04,\n",
      "           -5.7853e-02,  4.9143e-02],\n",
      "          [ 4.9999e-03,  1.2929e-03, -1.3779e-02,  ...,  9.7629e-04,\n",
      "            2.1728e-02, -8.7471e-03],\n",
      "          [ 2.9170e-02,  2.7428e-02, -1.2629e-02,  ...,  1.0469e-02,\n",
      "           -1.4009e-02,  2.0049e-02]],\n",
      "\n",
      "         [[ 6.0394e-02, -1.4514e-01,  7.6119e-02,  ..., -6.3661e-02,\n",
      "            1.5370e-01,  2.8360e-03],\n",
      "          [-3.1602e-02, -5.4412e-02,  2.3764e-02,  ...,  1.6013e-02,\n",
      "           -1.5033e-01,  1.4394e-02],\n",
      "          [-1.1956e-02, -3.3881e-02,  2.4108e-02,  ..., -5.9496e-03,\n",
      "           -5.4900e-02,  1.9871e-03],\n",
      "          ...,\n",
      "          [-6.3228e-03, -3.3429e-02,  2.6030e-02,  ..., -6.1516e-03,\n",
      "           -5.4235e-02,  6.0563e-03],\n",
      "          [-1.7941e-03, -4.1794e-02,  3.0180e-02,  ..., -1.5670e-03,\n",
      "           -7.5611e-02,  1.5742e-02],\n",
      "          [-3.5600e-03, -5.6294e-02,  3.3534e-02,  ...,  1.1765e-03,\n",
      "           -9.0535e-02,  1.9083e-02]],\n",
      "\n",
      "         [[ 7.4995e-01,  4.1006e-01,  6.3390e-01,  ...,  2.2021e-01,\n",
      "           -2.9931e-02,  5.5699e-01],\n",
      "          [-7.5134e-01,  1.3941e-01,  2.8071e-01,  ...,  8.7548e-01,\n",
      "            4.1483e-01,  8.0286e-01],\n",
      "          [ 4.5446e-01,  2.5021e-01,  4.0024e-01,  ...,  1.6765e-01,\n",
      "           -1.7043e-02,  3.7832e-01],\n",
      "          ...,\n",
      "          [-5.5798e-01,  1.6700e-01,  2.7374e-01,  ...,  8.1840e-01,\n",
      "            3.7140e-01,  6.8967e-01],\n",
      "          [ 2.9595e-01,  1.9358e-01,  2.9919e-01,  ...,  2.0884e-01,\n",
      "            1.9706e-02,  3.1160e-01],\n",
      "          [-5.0325e-01,  1.5363e-01,  2.3451e-01,  ...,  7.7064e-01,\n",
      "            3.4641e-01,  6.0508e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2438e-02, -8.2581e-02, -6.8097e-02,  ..., -8.2978e-02,\n",
      "            3.3721e-02, -7.1511e-03],\n",
      "          [-1.7198e-01,  2.7102e-01, -1.0037e-02,  ..., -7.6456e-01,\n",
      "            2.3708e-01,  1.4600e-01],\n",
      "          [ 7.6934e-04, -4.4175e-03, -4.5417e-02,  ..., -1.7591e-01,\n",
      "            4.9315e-02,  1.6400e-02],\n",
      "          ...,\n",
      "          [ 5.2087e-02, -5.2864e-02, -1.1442e-01,  ..., -3.6244e-01,\n",
      "            1.5258e-01, -1.4902e-02],\n",
      "          [ 6.8345e-03, -4.0021e-02, -3.9045e-02,  ..., -6.6381e-02,\n",
      "            1.2458e-02,  1.7422e-02],\n",
      "          [ 5.1176e-02, -5.8084e-02, -1.0054e-01,  ..., -2.8313e-01,\n",
      "            1.1683e-01, -1.6249e-02]],\n",
      "\n",
      "         [[ 1.2053e-02, -3.0730e-02,  1.9689e-02,  ...,  1.1403e-02,\n",
      "            9.3538e-03, -1.0139e-02],\n",
      "          [ 4.6988e-02, -7.6189e-02,  2.2759e-01,  ...,  1.0072e-01,\n",
      "           -2.6528e-02, -1.4358e-01],\n",
      "          [ 5.5917e-02, -1.0174e-01,  2.5722e-01,  ...,  4.9437e-02,\n",
      "           -1.5372e-02, -1.4563e-01],\n",
      "          ...,\n",
      "          [ 7.9145e-02, -1.1236e-01,  2.6010e-01,  ...,  6.7353e-02,\n",
      "           -2.2419e-02, -1.5523e-01],\n",
      "          [ 3.2261e-02, -6.2225e-02,  1.1561e-01,  ...,  2.1940e-02,\n",
      "            3.8086e-04, -6.3880e-02],\n",
      "          [ 7.1478e-02, -1.1050e-01,  2.5617e-01,  ...,  5.2527e-02,\n",
      "           -1.7642e-02, -1.4812e-01]],\n",
      "\n",
      "         [[ 1.6435e-02,  4.0806e-02, -3.8986e-02,  ..., -5.3514e-02,\n",
      "            2.5029e-03, -1.2513e-01],\n",
      "          [-6.3424e-02,  1.2414e-01, -7.8074e-05,  ..., -1.6725e-01,\n",
      "            3.6932e-02, -1.7228e-01],\n",
      "          [-4.4676e-02,  1.5395e-01, -2.0086e-02,  ..., -1.4942e-01,\n",
      "            4.1730e-02, -1.3341e-01],\n",
      "          ...,\n",
      "          [ 4.4266e-02,  3.4469e-01, -1.1200e-01,  ..., -5.6566e-02,\n",
      "            7.0265e-02, -7.5327e-02],\n",
      "          [ 2.8719e-02,  1.8340e-01, -7.3405e-02,  ..., -5.6789e-02,\n",
      "            3.4787e-02, -9.4746e-02],\n",
      "          [ 6.1537e-02,  3.0941e-01, -1.1535e-01,  ..., -2.7301e-02,\n",
      "            5.7670e-02, -8.8872e-02]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[-1.0002e+00, -3.6761e-01,  7.5139e-02,  ...,  7.4490e-02,\n",
      "            2.7313e-01,  9.6902e-01],\n",
      "          [ 3.7736e-01,  2.3690e+00, -2.6957e-01,  ...,  9.0428e-01,\n",
      "            1.3038e+00,  9.9926e-02],\n",
      "          [ 2.0654e-01,  1.7682e+00, -7.7856e-01,  ...,  3.6967e-01,\n",
      "            1.3760e+00,  4.9265e-01],\n",
      "          ...,\n",
      "          [-1.6007e+00,  2.1163e+00,  8.9370e-02,  ..., -9.0600e-01,\n",
      "            5.1157e-01,  5.5009e-01],\n",
      "          [-1.1521e+00,  1.5879e+00, -1.6560e-01,  ...,  1.9811e+00,\n",
      "            3.6126e-04,  8.4787e-01],\n",
      "          [-9.9792e-01,  1.7843e+00, -3.5940e-01,  ...,  1.3561e+00,\n",
      "            9.9344e-01,  3.8788e-01]],\n",
      "\n",
      "         [[ 5.7851e-01, -1.4219e-03, -5.0470e-01,  ...,  8.2853e-01,\n",
      "            9.6649e-01, -9.2882e-01],\n",
      "          [-4.9251e-01, -3.5193e-02, -4.2536e-01,  ..., -7.1328e-01,\n",
      "            4.8819e-01, -8.2761e-01],\n",
      "          [ 6.6977e-01, -2.5015e-01, -4.8169e-01,  ..., -7.8868e-01,\n",
      "            8.3089e-01, -1.5267e+00],\n",
      "          ...,\n",
      "          [-1.0965e-01, -2.1280e-01, -3.2647e-01,  ..., -7.5542e-01,\n",
      "           -2.2718e-01,  8.9369e-01],\n",
      "          [-1.0402e-02, -1.0907e+00, -1.6911e-01,  ...,  5.3941e-01,\n",
      "            1.7446e-01, -7.3874e-01],\n",
      "          [-8.5115e-01, -2.0022e+00,  1.8316e+00,  ..., -3.4050e-01,\n",
      "            1.9533e+00,  2.5203e-03]],\n",
      "\n",
      "         [[ 1.1232e+00, -4.6267e-01,  1.4173e+00,  ..., -1.1679e+00,\n",
      "            1.4707e-01,  9.1328e-01],\n",
      "          [ 9.5886e-01, -1.8228e+00,  7.3274e-01,  ...,  2.2914e-01,\n",
      "           -9.7945e-01, -2.7806e-01],\n",
      "          [ 1.2869e+00, -1.7660e+00,  1.5796e+00,  ...,  1.1083e+00,\n",
      "           -9.3404e-01,  7.3427e-01],\n",
      "          ...,\n",
      "          [ 2.9599e-01, -6.7356e-01,  1.2116e+00,  ...,  3.5766e-01,\n",
      "           -4.7508e-02, -5.4738e-01],\n",
      "          [ 1.2013e+00,  2.3248e-02,  2.0458e-01,  ...,  4.8244e-01,\n",
      "            8.8140e-01,  2.0941e-01],\n",
      "          [ 2.2493e+00, -6.3387e-01,  1.3965e-01,  ...,  1.1980e+00,\n",
      "            2.7665e-01, -5.3783e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0380e-01, -5.8282e-01,  1.3199e+00,  ..., -9.8996e-02,\n",
      "            6.6474e-01, -1.6446e+00],\n",
      "          [ 1.3150e+00, -1.2898e-01,  1.6009e+00,  ...,  1.7117e-02,\n",
      "            2.2012e-01, -4.0745e-01],\n",
      "          [ 5.8348e-02,  1.9963e-01,  9.0635e-01,  ..., -4.4475e-01,\n",
      "           -4.1987e-02, -1.2984e+00],\n",
      "          ...,\n",
      "          [ 9.8816e-01, -2.2277e-01,  1.5994e+00,  ...,  8.8964e-01,\n",
      "            6.5238e-01,  4.6764e-01],\n",
      "          [-6.0976e-01, -1.0413e-01, -5.1894e-01,  ...,  6.6130e-01,\n",
      "            5.8623e-01, -5.6316e-01],\n",
      "          [-5.8269e-01, -3.4576e-01,  6.1200e-01,  ..., -1.0991e-01,\n",
      "            1.8788e-01, -1.0744e+00]],\n",
      "\n",
      "         [[ 3.2057e-03, -2.1639e+00, -8.6862e-01,  ..., -1.1509e-01,\n",
      "            5.3007e-01, -1.4197e+00],\n",
      "          [-1.6943e+00,  5.1490e-02, -1.0850e+00,  ..., -1.5433e-01,\n",
      "           -1.3221e+00, -7.3123e-02],\n",
      "          [-1.5658e+00, -2.5691e-01, -1.7128e+00,  ...,  1.8233e-01,\n",
      "           -7.1862e-01,  1.0184e+00],\n",
      "          ...,\n",
      "          [-1.1060e+00,  1.8630e-01, -1.6119e+00,  ..., -1.5428e+00,\n",
      "           -6.2981e-01,  2.6719e-01],\n",
      "          [-1.1578e+00, -1.2725e-01, -1.6436e+00,  ..., -1.6291e+00,\n",
      "            5.5190e-01,  6.1285e-01],\n",
      "          [-5.9089e-01, -5.8927e-01,  4.0990e-01,  ..., -1.2583e+00,\n",
      "           -3.3418e-01,  1.4072e+00]],\n",
      "\n",
      "         [[-1.2782e-01, -5.1706e-01, -8.2116e-01,  ..., -9.4313e-01,\n",
      "           -1.8604e-01,  1.4313e+00],\n",
      "          [-2.3022e-01, -9.7128e-02, -4.2087e-01,  ...,  7.5967e-02,\n",
      "            2.1021e-02, -7.2524e-01],\n",
      "          [ 3.3987e-01, -1.0367e+00, -7.0151e-01,  ...,  2.7959e-01,\n",
      "            7.6093e-01,  5.0272e-01],\n",
      "          ...,\n",
      "          [ 2.2745e-01, -3.1174e-01, -4.3520e-01,  ...,  7.7562e-01,\n",
      "            8.2796e-01, -1.3699e+00],\n",
      "          [-2.6469e-01, -6.9922e-02, -7.5825e-01,  ...,  9.9540e-01,\n",
      "           -1.2263e-01,  5.1762e-01],\n",
      "          [-1.0965e-01,  1.5392e-01,  1.8052e-01,  ..., -4.8562e-01,\n",
      "            3.4157e-01,  3.9524e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7018e+00, -8.5109e-01,  1.2353e+00,  ..., -1.0630e+00,\n",
      "            1.0204e+00,  4.9797e-01],\n",
      "          [-5.3309e-01,  1.1759e+00,  8.6973e-01,  ..., -1.8468e-01,\n",
      "            1.3675e+00, -7.1168e-01],\n",
      "          [-1.0990e+00,  2.6940e-01, -5.2603e-03,  ..., -6.3628e-01,\n",
      "            9.2809e-01,  1.2372e+00],\n",
      "          ...,\n",
      "          [-9.3451e-01, -8.9120e-01,  1.3273e+00,  ..., -1.6143e+00,\n",
      "            1.3616e+00, -1.0091e+00],\n",
      "          [-8.3531e-01, -3.1483e-01,  7.8148e-01,  ..., -1.3237e+00,\n",
      "            1.0233e+00,  2.9012e-01],\n",
      "          [-1.1266e+00, -5.6191e-01,  1.4267e+00,  ..., -1.7152e+00,\n",
      "            1.0643e+00, -4.7425e-01]],\n",
      "\n",
      "         [[ 7.2090e-01, -3.2241e-01, -2.2465e-01,  ...,  6.6088e-01,\n",
      "           -2.3987e-01, -1.8605e+00],\n",
      "          [-6.7163e-02,  2.4350e-01,  1.4123e+00,  ..., -1.2223e+00,\n",
      "            6.0528e-01, -1.6732e-01],\n",
      "          [-2.9634e-01,  9.5801e-01,  8.9456e-01,  ...,  1.2249e+00,\n",
      "            4.4423e-01, -1.9798e+00],\n",
      "          ...,\n",
      "          [-1.3659e+00,  1.1980e+00,  3.4836e-01,  ...,  3.6399e-01,\n",
      "           -6.3777e-01, -1.2925e+00],\n",
      "          [-1.2359e+00,  1.2585e+00,  4.0162e-01,  ...,  9.2295e-01,\n",
      "           -3.4451e-01, -2.0138e+00],\n",
      "          [-1.2280e+00,  1.0405e+00,  5.1167e-01,  ...,  2.8922e-02,\n",
      "            1.7998e-01, -1.6819e+00]],\n",
      "\n",
      "         [[ 1.7144e+00, -7.7268e-01,  1.6112e+00,  ..., -1.8525e+00,\n",
      "           -5.9008e-01,  5.9703e-01],\n",
      "          [ 1.9314e+00,  7.6218e-01,  1.3089e+00,  ..., -2.4237e-01,\n",
      "           -5.4535e-01,  6.7080e-01],\n",
      "          [ 2.0320e+00, -1.1474e+00,  1.1433e+00,  ..., -1.9076e-01,\n",
      "           -7.0053e-02,  4.1670e-01],\n",
      "          ...,\n",
      "          [ 3.7476e-01,  1.2650e+00,  5.7977e-01,  ..., -7.2518e-02,\n",
      "           -1.4473e-01,  1.0939e+00],\n",
      "          [ 2.1181e+00,  7.1482e-02,  5.8863e-01,  ..., -4.3483e-01,\n",
      "           -2.4511e-01,  1.5287e+00],\n",
      "          [ 3.7516e-01,  9.8501e-01,  3.6327e-01,  ..., -1.7999e-02,\n",
      "           -2.7778e-01,  8.8519e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.9648e-01,  3.0697e-01,  1.5196e+00,  ...,  1.1979e+00,\n",
      "            1.4339e+00, -2.4086e+00],\n",
      "          [-5.2834e-01,  3.8538e-01,  1.9798e+00,  ...,  1.1274e-01,\n",
      "           -1.2128e+00, -1.5661e+00],\n",
      "          [-4.2626e-01, -1.7325e-02,  1.5636e+00,  ...,  5.0710e-02,\n",
      "           -6.2530e-01, -3.1582e+00],\n",
      "          ...,\n",
      "          [ 2.6362e-02,  6.1281e-01, -6.9056e-01,  ...,  4.1350e-01,\n",
      "           -3.9930e-01, -4.7292e-01],\n",
      "          [-8.2672e-01,  9.7040e-01,  6.8506e-01,  ..., -3.5176e-01,\n",
      "           -1.2962e-01, -2.0515e+00],\n",
      "          [ 8.0372e-02,  7.0091e-01, -5.6953e-01,  ..., -1.7528e-01,\n",
      "           -3.1647e-02, -5.9161e-01]],\n",
      "\n",
      "         [[-1.4326e+00, -2.0386e+00, -9.7672e-01,  ..., -6.9402e-02,\n",
      "            3.0809e-01, -1.7227e+00],\n",
      "          [-1.6797e+00, -1.1757e-01, -9.4627e-01,  ...,  3.5397e-01,\n",
      "           -5.0705e-01,  8.6506e-01],\n",
      "          [-1.6702e+00, -6.3347e-01, -1.0469e+00,  ...,  1.0701e+00,\n",
      "           -2.7879e-01,  7.2603e-01],\n",
      "          ...,\n",
      "          [-1.1025e+00, -1.0561e+00, -1.6123e+00,  ...,  3.7145e-01,\n",
      "           -2.0735e-01,  8.6526e-01],\n",
      "          [-7.4482e-01, -1.6005e+00, -2.2899e+00,  ...,  8.6580e-01,\n",
      "           -9.9851e-02,  1.1540e+00],\n",
      "          [-3.7529e-01, -1.3556e+00, -2.3471e+00,  ...,  5.8672e-02,\n",
      "           -1.9725e-01,  1.0990e+00]],\n",
      "\n",
      "         [[-1.0526e+00, -2.0249e-01, -4.3571e-01,  ..., -9.5521e-01,\n",
      "           -2.4664e-01,  8.2637e-01],\n",
      "          [-1.2029e-01, -5.7647e-01, -4.2449e-01,  ..., -4.6261e-01,\n",
      "            2.4868e+00, -1.2932e-01],\n",
      "          [-5.5955e-01,  7.4257e-01, -4.3499e-01,  ...,  7.0674e-01,\n",
      "            1.0063e+00,  1.1743e-01],\n",
      "          ...,\n",
      "          [ 1.3299e-01, -2.1712e-01,  3.2397e-01,  ...,  6.4214e-01,\n",
      "            9.8513e-01, -7.1270e-01],\n",
      "          [-5.8359e-01, -4.9792e-02, -7.5660e-02,  ...,  1.4766e+00,\n",
      "            9.6106e-01, -7.5928e-01],\n",
      "          [-2.2520e-02, -4.7742e-01,  5.0926e-01,  ...,  8.0619e-01,\n",
      "            7.9033e-01, -7.5979e-01]]]], grad_fn=<PermuteBackward0>), query layer: tensor([[[[-0.1941,  0.7770, -0.0623,  ...,  1.1674,  0.9914,  0.0294],\n",
      "          [ 1.5692,  2.3986, -0.1460,  ...,  0.7379,  0.4657, -0.0040],\n",
      "          [-0.1785,  1.8390,  0.1810,  ...,  0.3734,  1.8667, -0.5012],\n",
      "          ...,\n",
      "          [-1.6531,  2.0249, -0.9254,  ..., -0.9697,  1.0413,  0.7193],\n",
      "          [ 0.4013,  1.5795,  0.6434,  ...,  0.6311,  0.8635,  0.3024],\n",
      "          [-0.5636,  0.8925, -1.5613,  ...,  1.3145,  1.4876, -0.0531]],\n",
      "\n",
      "         [[ 0.1867, -2.1628,  1.0026,  ...,  0.2666,  0.2600, -0.3912],\n",
      "          [ 0.0883, -2.1116, -0.2741,  ..., -0.9658, -1.5910, -0.7210],\n",
      "          [ 0.9381, -1.4841, -1.2551,  ..., -0.6483, -0.3978, -0.3709],\n",
      "          ...,\n",
      "          [ 0.3514, -1.5384,  0.1402,  ..., -1.0876,  0.5108, -0.6699],\n",
      "          [ 0.4766, -1.6653,  0.0305,  ..., -1.2336, -0.6728, -0.3305],\n",
      "          [-0.7763, -0.5762,  0.6744,  ..., -0.1248, -0.2420, -0.3526]],\n",
      "\n",
      "         [[-0.5212,  0.0216, -0.2051,  ...,  0.8441,  0.0282, -0.4458],\n",
      "          [ 1.6050, -0.5138, -1.2028,  ..., -0.3207,  0.1161, -1.1706],\n",
      "          [ 1.8662, -0.6678, -1.4874,  ..., -0.8648, -0.2212, -0.9377],\n",
      "          ...,\n",
      "          [ 2.2827,  0.3974, -1.4301,  ...,  0.5998, -0.2441, -0.9531],\n",
      "          [ 0.8744, -0.1414,  0.5630,  ...,  0.3978, -1.2550, -0.4301],\n",
      "          [ 1.2164, -0.6993, -0.7085,  ...,  0.9728, -0.0846,  0.3460]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0252, -0.9850, -0.2446,  ...,  2.0778,  1.2329, -0.2705],\n",
      "          [-0.9699,  0.7447,  0.1934,  ..., -0.9749, -0.2908, -2.0713],\n",
      "          [ 0.6973,  0.6251, -0.4294,  ..., -1.4631, -0.7863, -1.1078],\n",
      "          ...,\n",
      "          [ 0.0519, -0.1960, -0.0577,  ..., -0.6733,  0.1279, -1.3834],\n",
      "          [ 0.5751,  1.4200,  0.4426,  ..., -0.6324,  0.0390, -2.7316],\n",
      "          [-0.1825, -0.5538,  0.0058,  ...,  0.4026, -0.2224, -0.9554]],\n",
      "\n",
      "         [[ 0.9162, -1.5722, -1.1629,  ..., -1.2418, -0.0559,  1.0531],\n",
      "          [-0.0595, -1.7067, -1.0536,  ..., -1.2214, -0.2894,  0.5601],\n",
      "          [-0.0491, -1.3002, -1.0952,  ..., -0.2149, -0.3852,  0.3600],\n",
      "          ...,\n",
      "          [ 0.8395, -2.0383, -0.6111,  ..., -0.2366, -1.0322, -0.8062],\n",
      "          [ 0.0479,  0.1631,  0.6587,  ...,  0.4958, -1.3081, -0.8522],\n",
      "          [-0.4497, -0.5285, -0.0173,  ..., -0.3789,  0.4566,  0.4057]],\n",
      "\n",
      "         [[ 0.0834,  0.7160, -0.3095,  ...,  0.2631, -0.3186,  0.0385],\n",
      "          [-0.0275, -0.2695, -0.4556,  ...,  0.1172, -0.5707, -0.2672],\n",
      "          [-0.1564,  1.3024,  0.6226,  ...,  0.1666, -1.0573,  0.8147],\n",
      "          ...,\n",
      "          [-0.4653, -0.7715, -0.1271,  ...,  0.1063, -1.7024,  1.6632],\n",
      "          [-0.6824, -0.1370,  0.4704,  ..., -0.8206, -1.5843, -0.4097],\n",
      "          [-0.0769,  0.0970,  0.0941,  ..., -0.2431,  0.1080,  0.1988]]],\n",
      "\n",
      "\n",
      "        [[[-0.6349,  0.7529,  1.0155,  ...,  0.2311,  2.2033,  0.3724],\n",
      "          [-0.5967,  0.2182, -1.0136,  ..., -0.4637,  1.2726, -0.4763],\n",
      "          [-0.5675, -0.4086,  0.9658,  ...,  0.0415,  1.0532, -1.1092],\n",
      "          ...,\n",
      "          [-0.5412, -0.6807,  1.2950,  ..., -0.6967,  1.1421, -0.6533],\n",
      "          [-0.8253, -1.3124,  1.9117,  ..., -1.0853,  1.1033,  0.2346],\n",
      "          [-0.4747, -0.7413,  1.2712,  ..., -0.7112,  0.6660, -0.1340]],\n",
      "\n",
      "         [[-0.3159, -1.7934,  0.4175,  ...,  0.1753,  0.4221, -1.1209],\n",
      "          [-1.5349, -0.2240,  2.3436,  ..., -1.7004,  0.4903,  0.7144],\n",
      "          [ 0.0388, -0.6144,  0.5831,  ..., -0.8857, -0.1789, -1.0664],\n",
      "          ...,\n",
      "          [-0.2560, -0.3504,  0.4933,  ..., -2.0251, -0.4249, -0.7658],\n",
      "          [ 0.1893, -1.2561, -0.1395,  ..., -2.0026, -0.6138, -1.6637],\n",
      "          [-0.1350, -0.7633,  0.1192,  ..., -2.0747, -0.5612, -0.7757]],\n",
      "\n",
      "         [[-1.5376,  0.8144,  1.2884,  ...,  1.0589,  0.3370, -0.6285],\n",
      "          [ 0.9404,  0.1200, -0.5123,  ...,  0.5746,  0.3631, -1.6539],\n",
      "          [ 1.7262,  0.0160,  0.6021,  ..., -1.4166,  0.1179,  0.0256],\n",
      "          ...,\n",
      "          [ 1.7891,  0.3794,  0.6837,  ...,  0.6125, -0.4130, -0.8056],\n",
      "          [ 0.9841,  0.2982,  1.2630,  ..., -0.2903, -0.5748, -0.5471],\n",
      "          [ 1.3356,  0.4176,  0.8622,  ...,  0.3478, -0.6117, -0.7999]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6946, -1.1526,  1.0050,  ...,  0.5822,  0.6909, -1.1441],\n",
      "          [-0.2765,  0.5633,  1.5277,  ..., -1.6342,  0.5647, -2.6053],\n",
      "          [ 1.4092,  2.4175,  1.9432,  ..., -0.7719,  0.1116, -2.6104],\n",
      "          ...,\n",
      "          [ 0.6786,  1.4085,  2.9543,  ..., -1.6217,  0.1144, -3.4589],\n",
      "          [ 1.9338,  2.3535,  2.3986,  ..., -1.1331, -0.2481, -3.2176],\n",
      "          [ 0.7998,  1.0748,  2.5514,  ..., -1.2551, -0.3208, -3.1939]],\n",
      "\n",
      "         [[ 0.8710, -0.5638, -0.1818,  ..., -0.9064,  0.8017,  1.4421],\n",
      "          [-0.1897, -0.8525,  1.0985,  ..., -0.1964,  0.0795,  1.2419],\n",
      "          [ 0.4163, -0.6808,  0.1996,  ..., -0.4870,  0.8963,  0.3664],\n",
      "          ...,\n",
      "          [ 0.0390,  0.1868,  0.7981,  ..., -1.3820,  0.9419,  2.1335],\n",
      "          [ 0.7211, -0.4989,  1.3811,  ..., -1.1385,  1.1128,  0.7231],\n",
      "          [-0.0268,  0.0097,  1.1630,  ..., -1.4025,  0.8011,  1.9753]],\n",
      "\n",
      "         [[ 0.1594,  1.1827, -0.2854,  ...,  0.2419, -1.5726,  0.5457],\n",
      "          [-0.1740,  0.3682, -0.4781,  ...,  0.6014, -2.3444,  0.6281],\n",
      "          [ 1.1789,  1.1797,  0.1356,  ..., -0.2826, -2.1488,  0.4399],\n",
      "          ...,\n",
      "          [-0.1859,  1.2768, -0.2583,  ..., -0.7641, -2.0778,  0.9794],\n",
      "          [ 0.9407,  0.9174,  0.0077,  ..., -0.8751, -2.2831,  1.2770],\n",
      "          [-0.0079,  1.2180, -0.3752,  ..., -0.7515, -1.7231,  0.9013]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[ 5.4312e-01,  2.2337e+00,  2.9065e+00,  ...,  1.5390e+00,\n",
      "            3.2112e+00,  3.2704e+00],\n",
      "          [ 1.6069e+00,  4.5076e+00,  2.8663e+00,  ...,  3.2731e+00,\n",
      "            4.9071e+00,  7.1215e+00],\n",
      "          [ 2.0765e+00,  3.5471e+00,  4.2197e+00,  ...,  3.4783e+00,\n",
      "            4.3470e+00,  7.0333e+00],\n",
      "          ...,\n",
      "          [ 2.1208e+00,  2.8535e+00,  2.8527e+00,  ...,  5.8330e+00,\n",
      "            4.7267e+00,  6.4312e+00],\n",
      "          [ 2.2836e+00,  3.8964e+00,  3.0960e+00,  ...,  4.6015e+00,\n",
      "            5.5288e+00,  7.1678e+00],\n",
      "          [ 5.6172e-01,  2.6214e+00,  2.7710e+00,  ...,  2.8530e+00,\n",
      "            2.7753e+00,  6.7160e+00]],\n",
      "\n",
      "         [[ 2.0869e-03,  8.8513e-01, -1.7719e-01,  ..., -1.4415e-03,\n",
      "            1.6497e+00,  3.1565e+00],\n",
      "          [ 4.1087e+00,  1.9116e+00,  5.0501e-01,  ...,  7.6793e-01,\n",
      "            1.5401e+00,  5.1124e+00],\n",
      "          [ 4.6720e+00,  2.9267e+00,  8.2990e-01,  ...,  1.1919e+00,\n",
      "            1.5509e+00,  5.6926e+00],\n",
      "          ...,\n",
      "          [ 2.5443e+00,  2.3305e+00,  1.4557e+00,  ...,  1.2883e+00,\n",
      "            1.2467e+00,  4.6754e+00],\n",
      "          [ 3.0827e+00,  2.7680e+00,  1.4915e+00,  ...,  1.8163e-01,\n",
      "            1.1931e+00,  4.0078e+00],\n",
      "          [ 2.2820e+00,  1.4796e+00,  5.5609e-01,  ...,  4.0252e-01,\n",
      "            1.2093e+00,  4.2269e+00]],\n",
      "\n",
      "         [[-1.2284e+00, -1.9770e+00, -6.7417e-01,  ..., -1.7428e+00,\n",
      "           -1.0655e+00,  3.2878e+00],\n",
      "          [ 1.8366e+00,  1.0499e+00,  1.4648e+00,  ..., -5.0898e-02,\n",
      "            2.6435e-01,  4.6615e+00],\n",
      "          [ 3.1581e+00,  3.0625e+00,  1.0972e+00,  ...,  9.1900e-01,\n",
      "            1.4573e+00,  4.9860e+00],\n",
      "          ...,\n",
      "          [ 2.4978e+00,  3.2142e+00,  2.7787e+00,  ...,  4.0590e-01,\n",
      "            1.3895e+00,  4.0089e+00],\n",
      "          [ 2.5331e+00,  3.8375e+00,  2.7457e+00,  ...,  2.2899e+00,\n",
      "            1.4401e+00,  3.7576e+00],\n",
      "          [ 9.1128e-01,  1.7201e+00,  2.6572e+00,  ...,  1.2214e+00,\n",
      "            1.8823e+00,  3.9671e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7867e+00,  9.2597e-01,  6.2303e-01,  ...,  1.7248e+00,\n",
      "            2.2017e+00,  4.7058e+00],\n",
      "          [ 1.8398e+00,  3.8089e-01,  1.6916e+00,  ...,  8.0407e-01,\n",
      "            2.0145e+00,  4.1976e+00],\n",
      "          [ 9.6947e-01,  2.7780e+00,  1.2724e+00,  ...,  1.2177e+00,\n",
      "            2.0688e+00,  4.7047e+00],\n",
      "          ...,\n",
      "          [ 1.7939e+00,  2.1638e+00,  7.4966e-01,  ...,  1.9930e+00,\n",
      "            2.7669e+00,  3.9954e+00],\n",
      "          [ 1.5689e+00,  2.0629e+00,  1.4907e+00,  ...,  1.7999e+00,\n",
      "            2.1151e+00,  4.1343e+00],\n",
      "          [ 1.4570e+00,  1.0306e+00,  1.1675e+00,  ...,  5.9261e-01,\n",
      "            1.3151e+00,  3.7887e+00]],\n",
      "\n",
      "         [[-1.8833e-01, -8.5407e-01, -1.0889e+00,  ..., -7.5602e-01,\n",
      "           -8.9045e-01,  1.9544e+00],\n",
      "          [ 2.9722e+00,  2.5113e+00,  2.5186e+00,  ...,  2.8507e+00,\n",
      "            2.5832e+00,  3.7950e+00],\n",
      "          [ 3.3638e+00,  2.0227e+00,  9.0149e-01,  ...,  3.3742e+00,\n",
      "            2.5807e+00,  3.6997e+00],\n",
      "          ...,\n",
      "          [ 3.8376e+00,  2.6114e+00,  2.4960e+00,  ...,  2.7867e+00,\n",
      "            1.9083e+00,  3.5419e+00],\n",
      "          [ 3.8624e+00,  2.5966e+00,  2.0567e+00,  ...,  2.7335e+00,\n",
      "            2.0685e+00,  4.6207e+00],\n",
      "          [ 1.4715e+00,  1.5113e+00,  1.9181e+00,  ...,  1.4679e+00,\n",
      "            1.0278e+00,  3.5402e+00]],\n",
      "\n",
      "         [[ 4.1725e-02, -7.2343e-02, -3.1614e-03,  ...,  1.2441e-01,\n",
      "            5.6571e-01,  1.7257e+00],\n",
      "          [ 2.9034e-01, -5.3986e-01, -2.3026e+00,  ..., -1.4511e+00,\n",
      "            2.9279e-01,  2.4144e+00],\n",
      "          [ 8.7132e-01, -1.2934e+00, -2.8853e+00,  ..., -2.5109e+00,\n",
      "           -3.8103e-01,  2.8782e+00],\n",
      "          ...,\n",
      "          [ 9.5559e-01, -2.5241e-01, -2.2686e+00,  ..., -4.9234e+00,\n",
      "           -6.2173e-02,  2.0145e+00],\n",
      "          [ 5.0794e-01, -2.3946e-02, -1.7516e+00,  ..., -1.7551e+00,\n",
      "           -1.4432e+00,  2.8112e+00],\n",
      "          [ 1.0065e+00,  1.8289e-01,  7.4460e-01,  ...,  7.7388e-02,\n",
      "            3.0893e-01,  1.0128e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2236e+00,  3.4235e+00,  4.0105e+00,  ...,  1.7906e+00,\n",
      "            2.8553e+00,  1.5060e+00],\n",
      "          [ 2.7633e+00,  6.9629e+00,  3.5340e+00,  ...,  3.4067e+00,\n",
      "            3.4231e+00,  3.5768e+00],\n",
      "          [ 4.0513e+00,  6.0539e+00,  5.3962e+00,  ...,  1.9188e+00,\n",
      "            2.1318e+00,  1.2135e+00],\n",
      "          ...,\n",
      "          [ 3.5083e+00,  9.0717e+00,  4.4219e+00,  ...,  5.7023e+00,\n",
      "            4.7658e+00,  5.8364e+00],\n",
      "          [ 5.4230e+00,  7.9567e+00,  6.9981e+00,  ...,  4.2213e+00,\n",
      "            5.0729e+00,  3.9740e+00],\n",
      "          [ 3.4114e+00,  8.6265e+00,  4.4723e+00,  ...,  5.3049e+00,\n",
      "            4.6981e+00,  5.6011e+00]],\n",
      "\n",
      "         [[ 1.4018e+00,  1.1782e+00,  1.0969e+00,  ...,  1.0285e+00,\n",
      "            1.5722e+00,  1.4294e+00],\n",
      "          [ 1.7922e+00,  2.1544e+00, -6.0736e-01,  ...,  1.6668e+00,\n",
      "            7.3581e-01,  1.9104e+00],\n",
      "          [ 4.9798e+00,  2.8310e+00,  1.4267e+00,  ...,  2.7948e+00,\n",
      "            1.4943e+00,  2.5463e+00],\n",
      "          ...,\n",
      "          [ 2.7686e+00,  2.4508e+00,  3.8508e-01,  ...,  9.7639e-01,\n",
      "            1.2989e+00,  1.0025e+00],\n",
      "          [ 5.0024e+00,  2.8126e+00,  1.7199e+00,  ...,  1.7191e+00,\n",
      "            1.1938e+00,  1.5105e+00],\n",
      "          [ 3.0793e+00,  2.5307e+00,  4.0770e-01,  ...,  8.7977e-01,\n",
      "            9.7386e-01,  9.1657e-01]],\n",
      "\n",
      "         [[-9.9930e-01, -3.6243e-01, -8.7262e-01,  ...,  6.6967e-01,\n",
      "            1.9633e-01,  1.4009e+00],\n",
      "          [ 9.5773e-01,  2.2729e+00,  1.1477e+00,  ...,  1.5486e+00,\n",
      "            1.3580e+00,  1.8564e+00],\n",
      "          [ 2.0356e+00,  3.9913e+00,  2.8774e+00,  ...,  3.4142e+00,\n",
      "            2.9418e+00,  3.8132e+00],\n",
      "          ...,\n",
      "          [ 1.4692e+00,  4.2005e+00,  2.6306e+00,  ...,  2.1484e+00,\n",
      "            1.4602e+00,  2.1776e+00],\n",
      "          [ 2.0078e+00,  4.4602e+00,  3.2080e+00,  ...,  3.2261e+00,\n",
      "            1.9939e+00,  3.4413e+00],\n",
      "          [ 1.6277e+00,  4.1885e+00,  2.6269e+00,  ...,  2.2897e+00,\n",
      "            1.6672e+00,  2.4702e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1294e+00,  2.2792e+00,  2.7405e+00,  ...,  1.7584e+00,\n",
      "            1.8880e+00,  1.9352e+00],\n",
      "          [ 3.0799e+00,  8.5916e-01,  3.3027e+00,  ...,  1.1628e+00,\n",
      "            3.2321e+00,  1.5515e+00],\n",
      "          [ 2.6094e+00,  4.0249e+00,  3.1549e+00,  ...,  4.0623e+00,\n",
      "            3.9412e+00,  4.2299e+00],\n",
      "          ...,\n",
      "          [ 4.1130e+00,  4.1637e+00,  5.0592e+00,  ...,  2.4810e+00,\n",
      "            4.3852e+00,  2.7642e+00],\n",
      "          [ 3.2486e+00,  4.5195e+00,  4.3952e+00,  ...,  4.0423e+00,\n",
      "            4.4017e+00,  4.2408e+00],\n",
      "          [ 3.8587e+00,  3.7626e+00,  4.6305e+00,  ...,  2.3544e+00,\n",
      "            4.0341e+00,  2.6686e+00]],\n",
      "\n",
      "         [[-1.9488e-01, -1.9946e-01, -3.6100e-01,  ...,  4.7094e-01,\n",
      "           -3.7633e-02,  1.3780e+00],\n",
      "          [ 3.2046e+00,  1.3855e+00,  2.4797e+00,  ...,  1.5845e+00,\n",
      "            1.9884e+00,  1.5376e+00],\n",
      "          [ 2.7984e+00,  2.0109e+00,  1.0327e+00,  ...,  1.1171e+00,\n",
      "            5.6763e-01,  1.1413e+00],\n",
      "          ...,\n",
      "          [ 3.6388e+00,  2.2479e+00,  2.4819e+00,  ...,  1.6389e+00,\n",
      "            2.4767e+00,  2.1872e+00],\n",
      "          [ 3.0331e+00,  1.7325e+00,  9.5256e-01,  ...,  7.3127e-01,\n",
      "            8.4297e-01,  1.1346e+00],\n",
      "          [ 3.4285e+00,  2.1527e+00,  1.9364e+00,  ...,  1.2968e+00,\n",
      "            2.0827e+00,  1.9378e+00]],\n",
      "\n",
      "         [[ 6.3389e-02, -3.1270e-01, -3.6601e-01,  ...,  2.7965e-01,\n",
      "            1.1165e-01,  6.2359e-01],\n",
      "          [ 2.0523e-01, -3.5001e+00, -1.3142e+00,  ..., -9.3007e-02,\n",
      "           -3.6556e-01,  5.0268e-01],\n",
      "          [-8.3871e-01, -1.7351e+00, -1.6831e+00,  ...,  5.4851e-01,\n",
      "           -2.5038e-01,  1.0419e+00],\n",
      "          ...,\n",
      "          [ 3.7389e-01, -1.4251e+00, -3.1646e-01,  ..., -5.3177e-02,\n",
      "            1.9540e-01,  4.9619e-01],\n",
      "          [ 1.2709e-01, -1.3219e+00, -3.8292e-01,  ...,  6.9198e-01,\n",
      "            1.1127e-01,  1.1057e+00],\n",
      "          [ 4.9288e-01, -9.1530e-01,  7.7820e-02,  ...,  3.4619e-01,\n",
      "            4.9403e-01,  7.1276e-01]]]], grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[ 5.4312e-01,  2.2337e+00,  2.9065e+00,  ...,  1.5390e+00,\n",
      "            3.2112e+00,  3.2704e+00],\n",
      "          [ 1.6069e+00,  4.5076e+00,  2.8663e+00,  ...,  3.2731e+00,\n",
      "            4.9071e+00,  7.1215e+00],\n",
      "          [ 2.0765e+00,  3.5471e+00,  4.2197e+00,  ...,  3.4783e+00,\n",
      "            4.3470e+00,  7.0333e+00],\n",
      "          ...,\n",
      "          [ 2.1208e+00,  2.8535e+00,  2.8527e+00,  ...,  5.8330e+00,\n",
      "            4.7267e+00,  6.4312e+00],\n",
      "          [ 2.2836e+00,  3.8964e+00,  3.0960e+00,  ...,  4.6015e+00,\n",
      "            5.5288e+00,  7.1678e+00],\n",
      "          [ 5.6172e-01,  2.6214e+00,  2.7710e+00,  ...,  2.8530e+00,\n",
      "            2.7753e+00,  6.7160e+00]],\n",
      "\n",
      "         [[ 2.0869e-03,  8.8513e-01, -1.7719e-01,  ..., -1.4415e-03,\n",
      "            1.6497e+00,  3.1565e+00],\n",
      "          [ 4.1087e+00,  1.9116e+00,  5.0501e-01,  ...,  7.6793e-01,\n",
      "            1.5401e+00,  5.1124e+00],\n",
      "          [ 4.6720e+00,  2.9267e+00,  8.2990e-01,  ...,  1.1919e+00,\n",
      "            1.5509e+00,  5.6926e+00],\n",
      "          ...,\n",
      "          [ 2.5443e+00,  2.3305e+00,  1.4557e+00,  ...,  1.2883e+00,\n",
      "            1.2467e+00,  4.6754e+00],\n",
      "          [ 3.0827e+00,  2.7680e+00,  1.4915e+00,  ...,  1.8163e-01,\n",
      "            1.1931e+00,  4.0078e+00],\n",
      "          [ 2.2820e+00,  1.4796e+00,  5.5609e-01,  ...,  4.0252e-01,\n",
      "            1.2093e+00,  4.2269e+00]],\n",
      "\n",
      "         [[-1.2284e+00, -1.9770e+00, -6.7417e-01,  ..., -1.7428e+00,\n",
      "           -1.0655e+00,  3.2878e+00],\n",
      "          [ 1.8366e+00,  1.0499e+00,  1.4648e+00,  ..., -5.0898e-02,\n",
      "            2.6435e-01,  4.6615e+00],\n",
      "          [ 3.1581e+00,  3.0625e+00,  1.0972e+00,  ...,  9.1900e-01,\n",
      "            1.4573e+00,  4.9860e+00],\n",
      "          ...,\n",
      "          [ 2.4978e+00,  3.2142e+00,  2.7787e+00,  ...,  4.0590e-01,\n",
      "            1.3895e+00,  4.0089e+00],\n",
      "          [ 2.5331e+00,  3.8375e+00,  2.7457e+00,  ...,  2.2899e+00,\n",
      "            1.4401e+00,  3.7576e+00],\n",
      "          [ 9.1128e-01,  1.7201e+00,  2.6572e+00,  ...,  1.2214e+00,\n",
      "            1.8823e+00,  3.9671e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7867e+00,  9.2597e-01,  6.2303e-01,  ...,  1.7248e+00,\n",
      "            2.2017e+00,  4.7058e+00],\n",
      "          [ 1.8398e+00,  3.8089e-01,  1.6916e+00,  ...,  8.0407e-01,\n",
      "            2.0145e+00,  4.1976e+00],\n",
      "          [ 9.6947e-01,  2.7780e+00,  1.2724e+00,  ...,  1.2177e+00,\n",
      "            2.0688e+00,  4.7047e+00],\n",
      "          ...,\n",
      "          [ 1.7939e+00,  2.1638e+00,  7.4966e-01,  ...,  1.9930e+00,\n",
      "            2.7669e+00,  3.9954e+00],\n",
      "          [ 1.5689e+00,  2.0629e+00,  1.4907e+00,  ...,  1.7999e+00,\n",
      "            2.1151e+00,  4.1343e+00],\n",
      "          [ 1.4570e+00,  1.0306e+00,  1.1675e+00,  ...,  5.9261e-01,\n",
      "            1.3151e+00,  3.7887e+00]],\n",
      "\n",
      "         [[-1.8833e-01, -8.5407e-01, -1.0889e+00,  ..., -7.5602e-01,\n",
      "           -8.9045e-01,  1.9544e+00],\n",
      "          [ 2.9722e+00,  2.5113e+00,  2.5186e+00,  ...,  2.8507e+00,\n",
      "            2.5832e+00,  3.7950e+00],\n",
      "          [ 3.3638e+00,  2.0227e+00,  9.0149e-01,  ...,  3.3742e+00,\n",
      "            2.5807e+00,  3.6997e+00],\n",
      "          ...,\n",
      "          [ 3.8376e+00,  2.6114e+00,  2.4960e+00,  ...,  2.7867e+00,\n",
      "            1.9083e+00,  3.5419e+00],\n",
      "          [ 3.8624e+00,  2.5966e+00,  2.0567e+00,  ...,  2.7335e+00,\n",
      "            2.0685e+00,  4.6207e+00],\n",
      "          [ 1.4715e+00,  1.5113e+00,  1.9181e+00,  ...,  1.4679e+00,\n",
      "            1.0278e+00,  3.5402e+00]],\n",
      "\n",
      "         [[ 4.1725e-02, -7.2343e-02, -3.1614e-03,  ...,  1.2441e-01,\n",
      "            5.6571e-01,  1.7257e+00],\n",
      "          [ 2.9034e-01, -5.3986e-01, -2.3026e+00,  ..., -1.4511e+00,\n",
      "            2.9279e-01,  2.4144e+00],\n",
      "          [ 8.7132e-01, -1.2934e+00, -2.8853e+00,  ..., -2.5109e+00,\n",
      "           -3.8103e-01,  2.8782e+00],\n",
      "          ...,\n",
      "          [ 9.5559e-01, -2.5241e-01, -2.2686e+00,  ..., -4.9234e+00,\n",
      "           -6.2173e-02,  2.0145e+00],\n",
      "          [ 5.0794e-01, -2.3946e-02, -1.7516e+00,  ..., -1.7551e+00,\n",
      "           -1.4432e+00,  2.8112e+00],\n",
      "          [ 1.0065e+00,  1.8289e-01,  7.4460e-01,  ...,  7.7388e-02,\n",
      "            3.0893e-01,  1.0128e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2236e+00,  3.4235e+00,  4.0105e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.7633e+00,  6.9629e+00,  3.5340e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.0513e+00,  6.0539e+00,  5.3962e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 3.5083e+00,  9.0717e+00,  4.4219e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.4230e+00,  7.9567e+00,  6.9981e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.4114e+00,  8.6265e+00,  4.4723e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 1.4018e+00,  1.1782e+00,  1.0969e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.7922e+00,  2.1544e+00, -6.0736e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.9798e+00,  2.8310e+00,  1.4267e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 2.7686e+00,  2.4508e+00,  3.8508e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.0024e+00,  2.8126e+00,  1.7199e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.0793e+00,  2.5307e+00,  4.0770e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-9.9930e-01, -3.6243e-01, -8.7262e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 9.5773e-01,  2.2729e+00,  1.1477e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.0356e+00,  3.9913e+00,  2.8774e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 1.4692e+00,  4.2005e+00,  2.6306e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.0078e+00,  4.4602e+00,  3.2080e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.6277e+00,  4.1885e+00,  2.6269e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1294e+00,  2.2792e+00,  2.7405e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.0799e+00,  8.5916e-01,  3.3027e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.6094e+00,  4.0249e+00,  3.1549e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 4.1130e+00,  4.1637e+00,  5.0592e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.2486e+00,  4.5195e+00,  4.3952e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.8587e+00,  3.7626e+00,  4.6305e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-1.9488e-01, -1.9946e-01, -3.6100e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.2046e+00,  1.3855e+00,  2.4797e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.7984e+00,  2.0109e+00,  1.0327e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 3.6388e+00,  2.2479e+00,  2.4819e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.0331e+00,  1.7325e+00,  9.5256e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.4285e+00,  2.1527e+00,  1.9364e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 6.3389e-02, -3.1270e-01, -3.6601e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 2.0523e-01, -3.5001e+00, -1.3142e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-8.3871e-01, -1.7351e+00, -1.6831e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 3.7389e-01, -1.4251e+00, -3.1646e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.2709e-01, -1.3219e+00, -3.8292e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 4.9288e-01, -9.1530e-01,  7.7820e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[1.8558e-02, 1.0064e-01, 1.9722e-01,  ..., 5.0239e-02,\n",
      "           2.6747e-01, 2.8376e-01],\n",
      "          [3.2852e-03, 5.9747e-02, 1.1574e-02,  ..., 1.7384e-02,\n",
      "           8.9085e-02, 8.1569e-01],\n",
      "          [5.8059e-03, 2.5267e-02, 4.9505e-02,  ..., 2.3588e-02,\n",
      "           5.6225e-02, 8.2524e-01],\n",
      "          ...,\n",
      "          [7.2572e-03, 1.5100e-02, 1.5089e-02,  ..., 2.9716e-01,\n",
      "           9.8293e-02, 5.4044e-01],\n",
      "          [5.6164e-03, 2.8176e-02, 1.2656e-02,  ..., 5.7030e-02,\n",
      "           1.4416e-01, 7.4242e-01],\n",
      "          [1.9597e-03, 1.5371e-02, 1.7852e-02,  ..., 1.9377e-02,\n",
      "           1.7929e-02, 9.2248e-01]],\n",
      "\n",
      "         [[2.9176e-02, 7.0555e-02, 2.4388e-02,  ..., 2.9073e-02,\n",
      "           1.5156e-01, 6.8385e-01],\n",
      "          [2.5109e-01, 2.7902e-02, 6.8356e-03,  ..., 8.8911e-03,\n",
      "           1.9245e-02, 6.8509e-01],\n",
      "          [2.4686e-01, 4.3100e-02, 5.2947e-03,  ..., 7.6039e-03,\n",
      "           1.0889e-02, 6.8501e-01],\n",
      "          ...,\n",
      "          [8.9644e-02, 7.2389e-02, 3.0182e-02,  ..., 2.5528e-02,\n",
      "           2.4489e-02, 7.5513e-01],\n",
      "          [2.1336e-01, 1.5576e-01, 4.3458e-02,  ..., 1.1727e-02,\n",
      "           3.2246e-02, 5.3814e-01],\n",
      "          [1.0914e-01, 4.8923e-02, 1.9429e-02,  ..., 1.6663e-02,\n",
      "           3.7334e-02, 7.6323e-01]],\n",
      "\n",
      "         [[1.0318e-02, 4.8811e-03, 1.7960e-02,  ..., 6.1692e-03,\n",
      "           1.2144e-02, 9.4402e-01],\n",
      "          [5.1475e-02, 2.3438e-02, 3.5492e-02,  ..., 7.7958e-03,\n",
      "           1.0685e-02, 8.6782e-01],\n",
      "          [1.1548e-01, 1.0495e-01, 1.4706e-02,  ..., 1.2305e-02,\n",
      "           2.1080e-02, 7.1837e-01],\n",
      "          ...,\n",
      "          [1.0450e-01, 2.1391e-01, 1.3839e-01,  ..., 1.2900e-02,\n",
      "           3.4495e-02, 4.7354e-01],\n",
      "          [9.1824e-02, 3.3839e-01, 1.1357e-01,  ..., 7.1999e-02,\n",
      "           3.0780e-02, 3.1241e-01],\n",
      "          [2.8728e-02, 6.4498e-02, 1.6464e-01,  ..., 3.9173e-02,\n",
      "           7.5857e-02, 6.1011e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.3720e-02, 1.8487e-02, 1.3655e-02,  ..., 4.1097e-02,\n",
      "           6.6207e-02, 8.0993e-01],\n",
      "          [6.9258e-02, 1.6103e-02, 5.9722e-02,  ..., 2.4585e-02,\n",
      "           8.2480e-02, 7.3191e-01],\n",
      "          [1.7733e-02, 1.0820e-01, 2.4007e-02,  ..., 2.2729e-02,\n",
      "           5.3236e-02, 7.4296e-01],\n",
      "          ...,\n",
      "          [5.0486e-02, 7.3082e-02, 1.7769e-02,  ..., 6.1608e-02,\n",
      "           1.3358e-01, 4.5634e-01],\n",
      "          [4.7727e-02, 7.8220e-02, 4.4137e-02,  ..., 6.0128e-02,\n",
      "           8.2408e-02, 6.2073e-01],\n",
      "          [7.0231e-02, 4.5850e-02, 5.2576e-02,  ..., 2.9589e-02,\n",
      "           6.0940e-02, 7.2308e-01]],\n",
      "\n",
      "         [[8.3326e-02, 4.2821e-02, 3.3858e-02,  ..., 4.7232e-02,\n",
      "           4.1291e-02, 7.1014e-01],\n",
      "          [1.5377e-01, 9.6983e-02, 9.7702e-02,  ..., 1.3618e-01,\n",
      "           1.0422e-01, 3.5011e-01],\n",
      "          [2.2499e-01, 5.8846e-02, 1.9177e-02,  ..., 2.2734e-01,\n",
      "           1.0282e-01, 3.1481e-01],\n",
      "          ...,\n",
      "          [3.5032e-01, 1.0279e-01, 9.1588e-02,  ..., 1.2248e-01,\n",
      "           5.0884e-02, 2.6066e-01],\n",
      "          [2.4231e-01, 6.8331e-02, 3.9822e-02,  ..., 7.8354e-02,\n",
      "           4.0295e-02, 5.1721e-01],\n",
      "          [7.4345e-02, 7.7358e-02, 1.1620e-01,  ..., 7.4073e-02,\n",
      "           4.7701e-02, 5.8841e-01]],\n",
      "\n",
      "         [[8.4882e-02, 7.5731e-02, 8.1156e-02,  ..., 9.2199e-02,\n",
      "           1.4334e-01, 4.5724e-01],\n",
      "          [8.8391e-02, 3.8535e-02, 6.6115e-03,  ..., 1.5492e-02,\n",
      "           8.8608e-02, 7.3942e-01],\n",
      "          [1.1195e-01, 1.2850e-02, 2.6155e-03,  ..., 3.8030e-03,\n",
      "           3.1999e-02, 8.3296e-01],\n",
      "          ...,\n",
      "          [2.1695e-01, 6.4823e-02, 8.6323e-03,  ..., 6.0695e-04,\n",
      "           7.8406e-02, 6.2551e-01],\n",
      "          [8.2617e-02, 4.8537e-02, 8.6251e-03,  ..., 8.5949e-03,\n",
      "           1.1741e-02, 8.2672e-01],\n",
      "          [2.2575e-01, 9.9074e-02, 1.7374e-01,  ..., 8.9153e-02,\n",
      "           1.1238e-01, 2.2718e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.6897e-01, 2.0638e-01, 3.7117e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.8130e-03, 4.5414e-01, 1.4725e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.8796e-02, 3.6151e-01, 1.8728e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [3.6379e-03, 9.4841e-01, 9.0701e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.1826e-02, 6.5306e-01, 2.5040e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.1183e-03, 9.4195e-01, 1.4787e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[7.7710e-02, 6.2140e-02, 5.7286e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.7774e-02, 6.8631e-02, 4.3360e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.7223e-01, 6.6736e-02, 1.6387e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.7649e-01, 1.2843e-01, 1.6276e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.9107e-01, 7.7361e-02, 2.5939e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.9403e-01, 1.6988e-01, 2.0331e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.5397e-02, 2.9109e-02, 1.7476e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.8066e-02, 6.7306e-02, 2.1846e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.5991e-02, 1.8372e-01, 6.0308e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [2.3656e-02, 3.6321e-01, 7.5574e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.7337e-02, 4.3371e-01, 1.2398e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.4373e-02, 4.4503e-01, 9.3366e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.6325e-02, 7.7038e-02, 1.2219e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.7130e-01, 2.9443e-02, 3.3901e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.3098e-02, 3.4226e-01, 1.4339e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.5955e-01, 1.6785e-01, 4.1097e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0798e-01, 3.8486e-01, 3.3987e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0014e-01, 1.8181e-01, 4.3308e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[4.6969e-02, 4.6754e-02, 3.9780e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.6234e-01, 2.6327e-02, 7.8632e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.2230e-02, 4.1962e-02, 1.5778e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.1240e-01, 2.7970e-02, 3.5346e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.8106e-02, 1.0379e-02, 4.7582e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.2536e-02, 2.5835e-02, 2.0811e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[8.3938e-02, 5.7627e-02, 5.4635e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.7054e-02, 9.1125e-04, 8.1085e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.2255e-02, 9.0811e-03, 9.5653e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.7707e-02, 2.9299e-03, 8.8784e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.5533e-02, 5.9951e-03, 1.5332e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.8528e-02, 6.9777e-03, 1.8837e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[ 5.3813e-02, -1.8883e-01, -2.3988e-02,  ...,  7.4560e-02,\n",
      "            1.2123e-02,  1.9223e-01],\n",
      "          [-2.0970e-01, -8.1032e-02, -9.7057e-03,  ...,  2.4206e-02,\n",
      "            2.6538e-03, -1.2128e-01],\n",
      "          [-1.5814e-01, -7.7757e-02,  1.6055e-02,  ...,  3.7482e-02,\n",
      "           -2.4060e-02, -1.2247e-01],\n",
      "          ...,\n",
      "          [ 8.6338e-02, -5.6185e-02, -2.4547e-01,  ...,  7.7644e-02,\n",
      "            2.0035e-01, -1.1208e-01],\n",
      "          [-1.9851e-01, -8.3996e-02, -6.9862e-02,  ...,  2.2805e-02,\n",
      "            6.7218e-02, -8.7343e-02],\n",
      "          [-1.9400e-01, -5.7106e-02,  1.8032e-02,  ...,  3.1131e-02,\n",
      "           -2.6478e-02, -1.7808e-01]],\n",
      "\n",
      "         [[ 1.2226e-01, -1.8584e-01,  9.3102e-02,  ..., -7.6960e-02,\n",
      "            1.3649e-01,  2.3228e-01],\n",
      "          [-3.4877e-01, -1.3109e-01,  6.3259e-02,  ..., -9.5347e-02,\n",
      "           -2.2393e-02,  9.3880e-02],\n",
      "          [-3.4293e-01, -1.3071e-01,  7.2932e-02,  ..., -9.4679e-02,\n",
      "           -1.1822e-02,  7.9804e-02],\n",
      "          ...,\n",
      "          [-5.1039e-02, -9.2183e-02,  8.2119e-02,  ..., -7.8773e-02,\n",
      "            8.2869e-02,  9.0725e-02],\n",
      "          [-2.5520e-01, -1.8558e-01,  1.7136e-01,  ..., -1.0873e-01,\n",
      "            1.1964e-01,  1.2633e-01],\n",
      "          [-8.8965e-02, -9.8275e-02,  6.4273e-02,  ..., -7.6221e-02,\n",
      "            5.0547e-02,  9.9340e-02]],\n",
      "\n",
      "         [[-3.7610e-02,  3.7355e-02,  1.0481e-02,  ..., -4.4895e-02,\n",
      "           -1.7322e-03, -2.4424e-02],\n",
      "          [ 4.6936e-03,  6.0518e-02,  3.1357e-03,  ..., -4.4167e-02,\n",
      "           -3.7304e-02, -3.6166e-03],\n",
      "          [-1.9851e-03,  8.3798e-02,  2.9793e-02,  ..., -2.4890e-03,\n",
      "           -8.5155e-02, -4.8048e-02],\n",
      "          ...,\n",
      "          [ 3.6593e-01,  1.2127e-01, -7.4109e-02,  ..., -8.4879e-02,\n",
      "           -1.3080e-01,  7.2400e-02],\n",
      "          [ 4.1346e-01,  1.1776e-01, -8.4977e-02,  ..., -8.3181e-02,\n",
      "           -1.3123e-01, -9.7289e-03],\n",
      "          [ 3.4528e-01,  9.9480e-02, -1.7815e-01,  ..., -2.5290e-01,\n",
      "            4.9725e-02,  1.1595e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3145e-02, -4.2178e-02,  1.3720e-02,  ...,  5.0418e-04,\n",
      "           -5.3131e-02, -6.0514e-04],\n",
      "          [ 4.6865e-02, -4.7164e-02, -3.6184e-03,  ...,  1.9940e-02,\n",
      "           -5.9371e-02,  5.8547e-03],\n",
      "          [-1.5177e-02, -1.9386e-02, -1.5746e-03,  ...,  3.1039e-02,\n",
      "           -1.1208e-01, -1.4768e-02],\n",
      "          ...,\n",
      "          [ 1.8360e-01, -8.3915e-03, -7.3302e-02,  ...,  6.0921e-02,\n",
      "           -1.3144e-01, -2.3376e-01],\n",
      "          [ 7.7175e-02, -4.3348e-02, -2.5836e-02,  ...,  6.3032e-02,\n",
      "           -1.0210e-01, -5.3685e-02],\n",
      "          [ 4.8485e-02, -4.8347e-02, -2.0017e-02,  ...,  3.2620e-02,\n",
      "           -7.3701e-02,  8.7912e-03]],\n",
      "\n",
      "         [[ 2.7044e-01, -3.3292e-02,  6.1576e-02,  ...,  5.8047e-03,\n",
      "           -2.5982e-03,  3.2534e-02],\n",
      "          [ 5.8195e-01, -7.4878e-02,  7.3213e-02,  ..., -1.2792e-02,\n",
      "            1.2276e-01,  1.1605e-01],\n",
      "          [ 6.5672e-01, -2.5480e-02,  3.4373e-02,  ..., -1.0035e-01,\n",
      "            2.7503e-02,  1.1348e-01],\n",
      "          ...,\n",
      "          [ 7.9892e-01,  7.9035e-02,  3.3079e-03,  ...,  7.7059e-02,\n",
      "           -3.9018e-01,  2.0118e-01],\n",
      "          [ 5.3051e-01,  4.6350e-02,  1.7788e-02,  ...,  5.1394e-02,\n",
      "           -2.9596e-01,  1.1416e-01],\n",
      "          [ 3.1956e-01, -6.7304e-02,  5.2882e-02,  ...,  4.6888e-02,\n",
      "            1.1125e-01,  7.8977e-02]],\n",
      "\n",
      "         [[-4.1737e-02, -1.7974e-01,  4.8076e-01,  ..., -1.6785e-02,\n",
      "            1.0968e-01, -7.2484e-02],\n",
      "          [-8.7366e-02,  4.1189e-02,  2.6457e-01,  ...,  7.0371e-02,\n",
      "            7.1219e-02,  5.7790e-02],\n",
      "          [-9.6452e-02,  1.3560e-01,  2.1101e-01,  ...,  8.6204e-02,\n",
      "            3.2909e-02,  6.8385e-02],\n",
      "          ...,\n",
      "          [-2.2430e-01,  1.9644e-01,  4.7381e-01,  ...,  1.5640e-01,\n",
      "            6.9811e-02,  1.4828e-02],\n",
      "          [-7.9836e-02,  7.2576e-02,  1.9897e-01,  ...,  6.0006e-02,\n",
      "            4.0699e-02,  4.4744e-02],\n",
      "          [-1.7505e-01, -9.3381e-02,  7.6492e-01,  ...,  1.3815e-02,\n",
      "            7.7920e-02, -2.1434e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8212e-01, -4.5533e-01,  2.2432e-01,  ...,  3.8447e-01,\n",
      "            1.4827e-01, -5.5752e-01],\n",
      "          [ 6.3370e-01, -3.8538e-01, -2.6562e-04,  ...,  3.8268e-01,\n",
      "           -3.0490e-01, -2.0010e-01],\n",
      "          [ 6.4504e-01, -4.4419e-01,  9.2638e-02,  ...,  3.7260e-01,\n",
      "           -1.1614e-01, -3.1852e-01],\n",
      "          ...,\n",
      "          [ 1.5831e+00, -7.4710e-01, -3.9186e-02,  ...,  7.7961e-01,\n",
      "           -6.1915e-01, -1.5057e-01],\n",
      "          [ 1.2881e+00, -7.0806e-01,  9.8632e-02,  ...,  6.2156e-01,\n",
      "           -2.5530e-01, -3.1568e-01],\n",
      "          [ 1.5768e+00, -7.4653e-01, -3.5831e-02,  ...,  7.7660e-01,\n",
      "           -6.1074e-01, -1.5492e-01]],\n",
      "\n",
      "         [[-2.2025e-01, -1.0749e-02, -1.5285e-01,  ..., -5.4333e-02,\n",
      "            8.7817e-02, -7.8151e-02],\n",
      "          [-1.6742e-01, -2.0025e-02, -9.0700e-02,  ..., -3.6036e-02,\n",
      "            7.4108e-02, -9.0324e-02],\n",
      "          [-1.4446e+00,  1.7086e-01, -3.9551e-01,  ..., -1.4539e-01,\n",
      "            1.2482e-01, -3.2921e-02],\n",
      "          ...,\n",
      "          [-5.7475e-01, -7.0222e-03, -2.2273e-01,  ..., -8.1252e-02,\n",
      "            1.3463e-01, -1.6380e-01],\n",
      "          [-1.7503e+00,  2.0740e-01, -4.8002e-01,  ..., -1.7490e-01,\n",
      "            1.4667e-01, -3.6012e-02],\n",
      "          [-9.2714e-01,  1.2719e-02, -3.2613e-01,  ..., -1.1724e-01,\n",
      "            1.7794e-01, -2.1174e-01]],\n",
      "\n",
      "         [[-2.8449e-02, -1.4320e-02,  2.6569e-02,  ..., -1.4011e-02,\n",
      "            7.1252e-03, -1.7168e-02],\n",
      "          [-9.5547e-03, -5.2235e-03, -1.1853e-03,  ...,  9.8091e-03,\n",
      "            1.5793e-03, -3.1176e-02],\n",
      "          [ 5.8003e-02,  2.7813e-02, -8.6468e-02,  ...,  1.0846e-01,\n",
      "           -3.4845e-02, -9.1434e-02],\n",
      "          ...,\n",
      "          [ 1.4788e-01,  6.8029e-02, -2.2040e-01,  ...,  2.1531e-01,\n",
      "           -6.1060e-02, -1.5098e-01],\n",
      "          [ 1.9682e-01,  9.4205e-02, -2.7051e-01,  ...,  3.0085e-01,\n",
      "           -1.0003e-01, -2.0660e-01],\n",
      "          [ 1.9062e-01,  8.9775e-02, -2.7884e-01,  ...,  2.7494e-01,\n",
      "           -7.8043e-02, -1.8776e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.6893e-02,  2.1555e-02,  1.8649e-01,  ...,  5.6862e-02,\n",
      "           -5.0783e-02, -4.0436e-02],\n",
      "          [-2.5521e-02, -1.2585e-01,  4.3137e-01,  ...,  2.8755e-01,\n",
      "           -5.2270e-02, -1.7637e-02],\n",
      "          [-1.9764e-01,  2.4628e-01,  3.7568e-01,  ...,  8.9217e-02,\n",
      "           -8.2609e-02, -2.3811e-01],\n",
      "          ...,\n",
      "          [-1.0727e-01,  7.2489e-02,  5.9899e-01,  ...,  3.0143e-01,\n",
      "           -6.0268e-02, -1.3856e-01],\n",
      "          [-2.1955e-01,  2.8804e-01,  6.4283e-01,  ...,  2.4004e-01,\n",
      "           -8.4500e-02, -2.9376e-01],\n",
      "          [-1.1038e-01,  6.1741e-02,  6.3639e-01,  ...,  3.3329e-01,\n",
      "           -6.3814e-02, -1.4857e-01]],\n",
      "\n",
      "         [[-2.3880e-02,  6.5040e-02,  2.2572e-02,  ..., -3.8331e-02,\n",
      "           -8.4501e-02, -6.4578e-02],\n",
      "          [ 4.3935e-02,  1.8510e-01, -1.7653e-02,  ...,  1.4225e-03,\n",
      "           -1.6284e-01, -6.7633e-02],\n",
      "          [ 1.2650e-02,  7.2670e-02,  5.1608e-03,  ...,  5.6216e-03,\n",
      "           -1.0862e-01, -5.9056e-02],\n",
      "          ...,\n",
      "          [ 2.8040e-02,  1.0533e-01,  6.9783e-05,  ...,  1.1775e-02,\n",
      "           -1.1509e-01, -5.5231e-02],\n",
      "          [ 8.3103e-03,  1.8488e-02,  3.0434e-02,  ...,  1.8287e-02,\n",
      "           -3.2508e-02, -3.0513e-02],\n",
      "          [ 2.2897e-02,  7.5976e-02,  7.6154e-03,  ...,  1.6269e-02,\n",
      "           -9.3990e-02, -4.8963e-02]],\n",
      "\n",
      "         [[-1.5967e-01, -1.3052e-01,  4.3602e-02,  ..., -2.3099e-02,\n",
      "            1.1667e-01, -1.2871e-01],\n",
      "          [-2.9072e-02, -8.7791e-04,  2.2742e-02,  ..., -3.7007e-03,\n",
      "            5.3321e-02,  3.9404e-02],\n",
      "          [-1.7532e-02, -1.0520e-02,  2.5519e-03,  ..., -7.8215e-03,\n",
      "            5.3530e-02,  4.7324e-02],\n",
      "          ...,\n",
      "          [-7.6799e-03, -1.9246e-03, -2.0912e-03,  ..., -4.5686e-03,\n",
      "            4.9780e-02,  6.2820e-02],\n",
      "          [-2.4420e-02, -1.4435e-02,  2.8757e-03,  ..., -4.5915e-03,\n",
      "            5.7212e-02,  4.4630e-02],\n",
      "          [-3.1580e-02, -2.0283e-02,  4.0698e-03,  ..., -4.2211e-03,\n",
      "            6.0699e-02,  3.7470e-02]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[-1.9098e+00,  1.7818e-02, -2.9481e-01,  ...,  7.0638e-01,\n",
      "           -2.2272e-01,  3.2188e-01],\n",
      "          [-8.7798e-01,  1.2615e+00, -1.4578e+00,  ...,  5.1321e-02,\n",
      "           -1.5977e+00,  1.8549e+00],\n",
      "          [ 5.8883e-02,  1.2704e+00, -4.1489e-01,  ..., -1.6792e-02,\n",
      "           -7.8446e-02,  6.0104e-01],\n",
      "          ...,\n",
      "          [-1.3784e+00,  1.1941e+00,  5.6262e-01,  ...,  4.8484e-02,\n",
      "           -1.3268e+00, -6.6070e-01],\n",
      "          [-7.9788e-01,  1.3386e+00, -3.5362e-01,  ..., -9.6514e-01,\n",
      "           -7.1998e-01,  1.8111e+00],\n",
      "          [-2.2755e-01, -4.1552e-01, -5.4022e-01,  ...,  1.9135e-01,\n",
      "            3.5328e-01,  1.3892e+00]],\n",
      "\n",
      "         [[ 3.3963e-01,  7.0134e-02, -2.6032e-01,  ..., -3.9504e-02,\n",
      "            1.7239e-01,  7.4458e-01],\n",
      "          [-4.5523e-01, -6.9185e-01,  5.0619e-01,  ...,  1.1608e-01,\n",
      "           -3.0601e-01, -3.8624e-01],\n",
      "          [-5.4041e-01,  6.0181e-01,  4.9548e-01,  ..., -2.4804e-01,\n",
      "            4.2061e-01, -8.3695e-01],\n",
      "          ...,\n",
      "          [ 1.0800e+00,  6.5210e-01,  2.0216e+00,  ...,  5.7706e-01,\n",
      "            1.7241e+00,  7.6380e-02],\n",
      "          [ 1.1181e+00,  9.0652e-01,  1.3579e+00,  ..., -4.7430e-01,\n",
      "           -7.6513e-01,  4.0443e-01],\n",
      "          [-8.3964e-02,  1.2417e+00,  9.8793e-01,  ..., -3.1365e-01,\n",
      "            6.8181e-01, -8.9752e-01]],\n",
      "\n",
      "         [[ 3.8443e-01, -7.3945e-01, -8.9576e-01,  ..., -1.2502e+00,\n",
      "           -1.1646e+00,  4.0336e-02],\n",
      "          [-1.7810e-01, -6.5722e-01,  3.5412e-01,  ..., -1.2567e+00,\n",
      "           -1.3093e+00,  8.2605e-01],\n",
      "          [ 1.9867e-01,  3.4756e-01,  5.5962e-01,  ..., -8.6767e-01,\n",
      "           -1.7567e+00,  7.3536e-01],\n",
      "          ...,\n",
      "          [ 6.3450e-01, -1.8008e-01,  1.6398e-01,  ..., -5.1299e-01,\n",
      "           -1.7034e+00,  9.0381e-01],\n",
      "          [ 4.6180e-01, -4.7914e-01,  1.1261e+00,  ..., -8.8364e-03,\n",
      "           -4.5742e-01,  1.4585e+00],\n",
      "          [ 9.7474e-02,  1.1807e-01, -7.2006e-02,  ..., -4.3385e-01,\n",
      "           -1.0210e+00, -4.8859e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5920e+00,  1.6658e-01,  9.6030e-02,  ...,  1.2053e-01,\n",
      "            5.5456e-01,  1.4594e+00],\n",
      "          [ 5.1793e-02, -9.1801e-01,  1.1069e+00,  ..., -2.7319e-01,\n",
      "            7.3961e-01,  7.6673e-01],\n",
      "          [ 1.0750e+00, -8.5380e-01,  1.7617e+00,  ...,  3.6500e-01,\n",
      "            8.7249e-01, -9.2131e-02],\n",
      "          ...,\n",
      "          [-1.6995e-01, -7.6633e-01,  2.0416e+00,  ...,  9.6904e-01,\n",
      "            9.5436e-01, -1.0999e+00],\n",
      "          [ 1.1715e+00, -5.9633e-01,  1.4655e+00,  ...,  6.4437e-01,\n",
      "            8.1264e-01, -4.0660e-01],\n",
      "          [-5.7577e-02,  3.2286e-01,  2.1383e-01,  ...,  1.9445e-01,\n",
      "           -5.8656e-01, -1.9386e-01]],\n",
      "\n",
      "         [[ 4.0211e-01, -3.7081e-01,  1.6291e-01,  ...,  1.7472e+00,\n",
      "            1.1533e+00, -5.8603e-01],\n",
      "          [ 5.9225e-01,  8.1612e-01, -3.0513e-03,  ...,  1.5343e+00,\n",
      "            3.7481e-01, -3.0789e-01],\n",
      "          [ 7.5285e-01,  4.5345e-01, -4.1255e-01,  ...,  1.3480e+00,\n",
      "            5.5124e-01,  5.8747e-02],\n",
      "          ...,\n",
      "          [ 1.2532e+00, -2.2720e-01, -1.2217e+00,  ...,  6.6868e-01,\n",
      "            9.0012e-01, -6.1606e-02],\n",
      "          [ 1.4761e+00, -1.2667e-01, -1.1956e+00,  ...,  5.2364e-01,\n",
      "            2.3104e-01,  3.0274e-01],\n",
      "          [ 3.0173e-01,  8.0392e-01,  3.7343e-01,  ...,  5.8116e-01,\n",
      "           -1.7083e+00,  3.8580e-01]],\n",
      "\n",
      "         [[-1.8055e-01, -1.1810e+00,  6.9035e-01,  ...,  9.9943e-01,\n",
      "           -7.6236e-01, -1.3871e+00],\n",
      "          [-9.3260e-01,  1.4415e+00, -6.3288e-01,  ..., -4.6597e-01,\n",
      "           -2.8775e-01, -6.1450e-01],\n",
      "          [-1.0199e+00,  1.0787e+00, -1.1481e+00,  ...,  1.2038e+00,\n",
      "            2.9400e-02,  6.5860e-01],\n",
      "          ...,\n",
      "          [-5.9086e-01,  1.9759e+00, -5.0261e-01,  ..., -8.4281e-02,\n",
      "            6.8241e-01, -1.0286e+00],\n",
      "          [-8.6334e-01,  8.1767e-01, -5.8643e-01,  ...,  1.4039e-01,\n",
      "           -6.3986e-01, -1.5141e+00],\n",
      "          [-2.7760e-01,  1.0093e+00,  3.3657e-01,  ..., -1.0260e+00,\n",
      "           -5.2062e-01, -4.2349e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.1423e-01, -1.4426e+00,  4.0128e-01,  ..., -2.2747e-01,\n",
      "            6.7371e-01, -1.3563e-01],\n",
      "          [-6.6288e-01, -5.8708e-01, -8.7193e-01,  ...,  1.6434e+00,\n",
      "            1.3928e-03, -1.6369e-01],\n",
      "          [-1.0424e+00, -7.9707e-02, -2.3404e-01,  ...,  1.0214e+00,\n",
      "            1.5535e+00,  6.5328e-01],\n",
      "          ...,\n",
      "          [-3.9641e-01, -9.7633e-01, -4.8422e-01,  ...,  2.4863e-01,\n",
      "           -1.5622e+00,  9.2961e-02],\n",
      "          [-1.0279e-01, -6.0308e-01, -9.5431e-02,  ...,  2.3129e-01,\n",
      "           -2.8489e-01,  3.2610e-01],\n",
      "          [-2.3175e-01, -8.1278e-01, -4.5465e-01,  ...,  1.0668e-01,\n",
      "           -1.5684e+00,  1.6228e-02]],\n",
      "\n",
      "         [[ 5.2148e-01,  1.2210e-01, -2.2120e-01,  ..., -8.2712e-02,\n",
      "           -4.4183e-01,  1.1806e+00],\n",
      "          [-5.7008e-01, -1.5652e+00,  4.1192e-01,  ..., -5.5447e-01,\n",
      "           -6.2328e-01,  1.6903e+00],\n",
      "          [ 4.8360e-01,  6.0558e-02,  2.4733e-01,  ...,  3.0282e-01,\n",
      "            3.7635e-01,  1.7094e+00],\n",
      "          ...,\n",
      "          [-3.6277e-01, -2.7636e+00, -6.6903e-01,  ...,  4.7809e-01,\n",
      "           -3.0142e-01,  2.2752e+00],\n",
      "          [ 2.5619e-01, -1.2888e+00,  1.6053e-01,  ...,  5.7055e-01,\n",
      "            2.9059e-02,  2.0963e+00],\n",
      "          [-2.9922e-01, -2.7337e+00, -5.7888e-01,  ...,  7.3650e-01,\n",
      "           -3.5210e-01,  2.7912e+00]],\n",
      "\n",
      "         [[ 3.3265e-01, -1.7594e+00, -9.0855e-01,  ..., -2.7949e-01,\n",
      "           -1.9320e+00,  2.0328e-01],\n",
      "          [-9.5892e-01,  1.0128e+00, -1.9011e+00,  ...,  4.9679e-02,\n",
      "           -1.8860e+00,  1.5069e+00],\n",
      "          [-1.4521e-01, -5.1138e-02, -7.6742e-01,  ...,  7.9118e-01,\n",
      "           -1.7434e+00,  1.1997e+00],\n",
      "          ...,\n",
      "          [ 3.6365e-01, -5.8633e-02, -1.0244e+00,  ...,  1.6426e+00,\n",
      "           -2.3637e+00,  1.0653e+00],\n",
      "          [ 9.1327e-01, -1.0393e+00, -1.7189e-01,  ...,  1.7987e+00,\n",
      "           -1.8786e+00,  1.2023e+00],\n",
      "          [ 6.1336e-01, -2.2273e-01, -5.9380e-01,  ...,  1.7618e+00,\n",
      "           -2.3031e+00,  7.8623e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2312e-01,  2.5406e-01, -5.3525e-01,  ...,  2.2235e-03,\n",
      "            2.8562e-01,  2.0026e+00],\n",
      "          [ 5.9902e-01, -1.1698e+00, -9.2997e-01,  ..., -7.4934e-02,\n",
      "           -4.6165e-01,  9.1176e-01],\n",
      "          [ 1.3759e+00, -9.7716e-01,  8.5868e-01,  ...,  1.8172e+00,\n",
      "            1.0667e+00,  1.3941e+00],\n",
      "          ...,\n",
      "          [ 2.3604e-02, -3.1042e+00, -1.0867e+00,  ..., -9.9916e-01,\n",
      "           -9.0837e-01,  2.8699e+00],\n",
      "          [ 6.3303e-01, -2.1815e+00,  5.1136e-01,  ...,  1.1924e+00,\n",
      "            9.0037e-01,  2.5305e+00],\n",
      "          [ 1.6260e-02, -3.3440e+00, -8.9759e-01,  ..., -1.2019e+00,\n",
      "           -7.1509e-01,  2.6040e+00]],\n",
      "\n",
      "         [[ 4.7229e-02, -2.5995e-01, -3.2942e-01,  ...,  4.2132e-01,\n",
      "            4.2554e-01, -1.3518e-01],\n",
      "          [ 1.2965e+00,  2.3933e+00, -9.7075e-01,  ..., -5.7366e-02,\n",
      "            4.7430e-01,  1.1894e-01],\n",
      "          [ 5.3566e-01,  7.8031e-01, -1.9528e+00,  ..., -4.8962e-01,\n",
      "            5.4191e-01,  1.0177e+00],\n",
      "          ...,\n",
      "          [ 1.3725e-01,  5.8775e-01, -5.3749e-01,  ..., -6.8352e-02,\n",
      "            5.5961e-02,  2.8608e-01],\n",
      "          [ 2.7623e-01,  1.4942e+00, -1.8493e+00,  ...,  2.5593e-01,\n",
      "            1.6162e-01,  6.1622e-01],\n",
      "          [ 4.4075e-01,  5.2254e-01, -6.3067e-01,  ..., -9.8606e-02,\n",
      "            2.6156e-01,  6.1534e-02]],\n",
      "\n",
      "         [[-4.6941e-01, -7.0446e-01,  6.0666e-01,  ...,  4.6269e-01,\n",
      "            4.4251e-01, -1.7352e-01],\n",
      "          [-3.0491e-01,  1.1733e+00, -1.0177e+00,  ..., -5.7697e-01,\n",
      "           -2.6048e-01, -3.6712e-01],\n",
      "          [-8.7090e-01,  1.4116e+00, -9.3527e-01,  ..., -4.0022e-01,\n",
      "            4.6471e-01, -6.0420e-01],\n",
      "          ...,\n",
      "          [-4.4889e-01,  8.7532e-01, -1.6938e+00,  ..., -1.6836e-01,\n",
      "            3.6401e-02, -1.1935e+00],\n",
      "          [-8.4304e-01,  1.1097e+00, -1.1652e+00,  ..., -1.7514e-01,\n",
      "            6.4591e-01, -1.3939e+00],\n",
      "          [-7.3045e-01,  1.0598e+00, -1.6456e+00,  ..., -1.6161e-01,\n",
      "            2.3167e-01, -1.1426e+00]]]], grad_fn=<PermuteBackward0>), query layer: tensor([[[[ 0.1357,  0.3490, -0.2780,  ..., -0.3877,  1.5879,  1.5679],\n",
      "          [-0.1964,  1.4438,  1.0748,  ...,  0.8446,  1.4442,  2.5390],\n",
      "          [-0.3371,  1.1459,  1.3378,  ...,  1.2262,  0.8435,  2.5572],\n",
      "          ...,\n",
      "          [-0.9570,  1.0210,  1.5364,  ...,  1.2913,  1.1215,  1.3134],\n",
      "          [ 0.2075,  1.9782,  2.4944,  ...,  0.9698,  1.8207,  2.3031],\n",
      "          [-0.2296, -0.2774,  0.0706,  ...,  0.2492,  0.5397,  0.6532]],\n",
      "\n",
      "         [[ 1.6496, -0.7433,  0.5379,  ..., -1.2801, -1.3817,  0.3199],\n",
      "          [ 0.0052,  0.7569,  0.4087,  ..., -0.1337,  1.4908, -1.8499],\n",
      "          [ 0.6393,  0.6458,  0.2675,  ..., -1.0315,  1.6758, -1.6245],\n",
      "          ...,\n",
      "          [ 1.2139,  0.8743,  0.8317,  ..., -0.0597,  2.5207, -0.7715],\n",
      "          [ 1.8875,  0.8830,  0.7502,  ...,  0.7462,  0.7107,  0.4530],\n",
      "          [ 0.5112,  0.9838,  0.0192,  ...,  0.2344,  1.0469, -1.7358]],\n",
      "\n",
      "         [[ 0.7100,  0.6043, -0.5948,  ...,  0.2625,  0.3620, -0.4832],\n",
      "          [-1.5653,  0.0883,  0.5019,  ...,  1.0430, -1.2565,  0.0059],\n",
      "          [-1.5872, -0.0579, -0.1212,  ...,  0.6172, -1.0959,  0.2939],\n",
      "          ...,\n",
      "          [-1.6900,  1.2698, -0.1434,  ...,  3.6924, -1.2294, -0.7401],\n",
      "          [-0.7501, -0.2835,  0.8233,  ...,  1.5013, -0.4164, -1.0563],\n",
      "          [-0.0925,  0.1860, -0.0901,  ...,  0.2681, -0.1725, -0.9408]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0777,  0.7165, -1.4574,  ..., -0.0651, -0.1536,  0.4275],\n",
      "          [ 1.0745,  0.2191,  0.5275,  ...,  0.1181, -0.1111,  0.5768],\n",
      "          [ 1.3873, -0.4421,  1.3521,  ..., -0.4265, -0.2196, -0.4261],\n",
      "          ...,\n",
      "          [ 0.8223,  1.3074,  2.7240,  ..., -0.2305, -0.3833, -1.2535],\n",
      "          [ 2.1381,  0.5974,  0.2300,  ...,  0.1039, -1.0929, -0.9279],\n",
      "          [-0.0517,  1.2928,  0.0307,  ...,  0.1201, -0.4693, -0.5322]],\n",
      "\n",
      "         [[ 1.3355,  0.3919,  1.5316,  ...,  0.4480, -0.6831, -1.0326],\n",
      "          [ 0.7067,  1.3508,  1.8826,  ...,  0.1756,  0.6694, -0.1236],\n",
      "          [ 1.6723,  0.5759,  1.7043,  ...,  1.7429,  1.0906, -0.0619],\n",
      "          ...,\n",
      "          [ 2.3571,  0.3487,  0.7748,  ...,  0.6437,  0.3513, -1.1160],\n",
      "          [ 1.9702,  0.2415,  1.7796,  ...,  0.3702,  0.9383,  0.4419],\n",
      "          [ 0.3598, -0.0065,  0.6236,  ...,  0.1511, -0.6909, -0.4354]],\n",
      "\n",
      "         [[-0.1463, -0.3650, -0.6899,  ...,  0.2456, -0.0494, -1.1514],\n",
      "          [ 1.4462,  0.2503,  0.5091,  ..., -1.6230,  0.5250, -0.2631],\n",
      "          [ 0.1279, -0.1370,  0.7532,  ..., -2.5485, -0.7280, -0.9216],\n",
      "          ...,\n",
      "          [-0.8686,  0.3607,  1.5873,  ..., -1.2895, -0.7265,  0.4026],\n",
      "          [ 0.6848, -0.2372,  0.4278,  ..., -2.8466,  0.8181,  0.1448],\n",
      "          [-0.6659,  0.5757,  0.9680,  ..., -1.1763, -0.1930, -0.4425]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7516,  0.5682,  0.4846,  ..., -0.5415,  2.4323,  2.3702],\n",
      "          [ 0.0835,  0.6215,  0.5680,  ...,  1.5839,  3.2863,  2.5996],\n",
      "          [-0.1663,  0.4832,  1.3395,  ...,  1.7357,  2.7416,  2.5551],\n",
      "          ...,\n",
      "          [ 0.4966,  0.5503,  0.8505,  ..., -0.7613,  1.4937,  1.7859],\n",
      "          [-0.0434,  0.1346,  2.2728,  ...,  0.4223,  2.2075,  2.0238],\n",
      "          [ 0.5878,  0.2772,  1.0533,  ..., -0.6145,  1.5524,  1.7042]],\n",
      "\n",
      "         [[ 1.3457, -0.3996,  0.6944,  ..., -2.0279, -1.3215,  0.4470],\n",
      "          [ 1.2400, -0.0197,  0.3804,  ..., -1.4612,  0.0762,  0.0832],\n",
      "          [ 1.9518,  1.2983,  1.0180,  ..., -1.0549,  0.0897, -0.6756],\n",
      "          ...,\n",
      "          [ 0.5989, -0.0920,  0.5782,  ..., -1.1294, -0.8149,  0.9185],\n",
      "          [ 1.4774,  1.4203,  1.2441,  ..., -1.0581, -0.8524,  0.1224],\n",
      "          [ 0.8582,  0.1064,  0.5994,  ..., -0.8347, -0.9752,  1.0110]],\n",
      "\n",
      "         [[ 0.9508,  0.3738, -0.4447,  ...,  0.9652,  1.1436, -0.5820],\n",
      "          [-1.6994,  1.3693, -1.7725,  ...,  1.6041, -0.4353, -1.2748],\n",
      "          [-0.9089,  1.2071, -1.4173,  ...,  1.4006,  0.9049, -0.4152],\n",
      "          ...,\n",
      "          [-0.4828,  1.1500, -1.0837,  ...,  0.2859, -0.0611, -1.4328],\n",
      "          [-0.8708,  1.0308, -1.2119,  ...,  1.2924,  0.6462, -1.0177],\n",
      "          [-0.0804,  0.9317, -1.0750,  ...,  0.5957, -0.2800, -1.3745]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3535,  0.6853, -0.7699,  ...,  0.5634, -0.5401,  0.4188],\n",
      "          [ 1.2341, -0.0216, -0.3520,  ..., -1.3956, -0.8935,  1.4033],\n",
      "          [ 2.5831,  0.0597, -0.2790,  ...,  0.7616,  0.3460,  0.9890],\n",
      "          ...,\n",
      "          [ 1.6808, -1.4232, -1.0012,  ..., -0.4404, -0.8557,  1.4090],\n",
      "          [ 2.9882, -0.5548, -0.5013,  ...,  1.7319,  0.5447,  0.7050],\n",
      "          [ 1.9842, -1.6023, -0.9351,  ..., -0.1277, -0.5150,  1.0986]],\n",
      "\n",
      "         [[ 1.5974,  1.3337,  0.6871,  ..., -1.1432,  1.0097, -0.2007],\n",
      "          [ 2.5946,  3.5334,  1.5285,  ...,  0.3157,  0.6497,  0.8895],\n",
      "          [ 2.2246,  1.0871,  1.0704,  ..., -0.7261,  0.8767,  1.1863],\n",
      "          ...,\n",
      "          [ 1.3837,  1.8988,  1.6379,  ...,  0.5303, -0.4156,  1.2213],\n",
      "          [ 2.0094,  1.4023,  1.1784,  ..., -0.6377,  0.4385,  1.9865],\n",
      "          [ 1.5783,  1.4588,  1.6439,  ...,  0.5079, -0.5703,  1.4439]],\n",
      "\n",
      "         [[-0.5902,  1.4864, -2.1273,  ...,  0.3938,  0.5175, -0.5415],\n",
      "          [ 0.7526,  1.1410, -0.0485,  ..., -1.6134, -0.5030,  1.0656],\n",
      "          [ 0.5520,  0.6339, -1.3643,  ..., -1.4912,  0.8293,  1.0409],\n",
      "          ...,\n",
      "          [ 0.5913,  1.8234, -0.7882,  ..., -1.4870,  1.3496, -0.0045],\n",
      "          [ 0.4447,  1.1260, -2.0844,  ..., -1.9355,  1.6858,  0.6046],\n",
      "          [ 0.6343,  1.5728, -1.3003,  ..., -1.5421,  1.3764, -0.0767]]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[ 0.6071, -0.2294,  1.0685,  ..., -0.8751, -0.1195,  1.4363],\n",
      "          [ 1.2467,  0.3280,  1.3469,  ...,  0.4468,  1.3010,  2.8279],\n",
      "          [ 2.2600,  0.9059,  1.4629,  ..., -0.1366,  1.0791,  2.7997],\n",
      "          ...,\n",
      "          [ 0.5025, -0.3334,  1.0744,  ...,  0.5059,  0.0794,  2.4088],\n",
      "          [ 0.0928, -1.2061, -0.2863,  ..., -1.2692, -0.6058,  2.3535],\n",
      "          [-1.0531, -0.9407, -1.1219,  ..., -0.8912, -0.5056,  1.7823]],\n",
      "\n",
      "         [[-0.7438,  0.4321,  0.4631,  ..., -0.8901, -0.7342,  2.6247],\n",
      "          [-1.5273, -0.1925, -0.3001,  ..., -0.3413, -0.0473,  5.2202],\n",
      "          [-0.9333, -0.4612,  1.1939,  ...,  1.2604, -0.3428,  3.7152],\n",
      "          ...,\n",
      "          [-1.5892, -0.7704, -0.0468,  ...,  2.9363,  1.3162,  5.3637],\n",
      "          [-1.3011, -0.8871, -0.5569,  ...,  1.2267,  2.0724,  4.7333],\n",
      "          [-1.2279, -0.9945, -0.5570,  ..., -1.2024, -0.6381,  4.7991]],\n",
      "\n",
      "         [[-1.4830, -0.8144,  0.2819,  ..., -0.8298, -0.2669,  2.4565],\n",
      "          [ 0.3155, -0.4656,  0.2584,  ..., -0.7645,  0.9308,  2.1330],\n",
      "          [ 0.3576, -1.8830, -1.2734,  ..., -1.2878, -0.2463,  2.1712],\n",
      "          ...,\n",
      "          [-0.1965, -3.2076, -1.8746,  ..., -1.4792,  0.4411,  2.0136],\n",
      "          [ 0.8183, -2.0181, -1.5499,  ..., -0.1254,  1.5896,  1.7845],\n",
      "          [-0.8984, -0.3555, -0.3512,  ..., -1.3191, -1.0873,  2.4185]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1574,  0.5003, -0.1636,  ..., -1.5420, -1.5760,  3.5806],\n",
      "          [-1.5864,  2.5984,  1.7255,  ...,  0.5350,  0.3148,  4.7823],\n",
      "          [-1.5652,  1.3352,  5.8504,  ...,  0.5138,  0.0513,  3.5814],\n",
      "          ...,\n",
      "          [-1.2805,  0.3015,  2.3859,  ...,  4.7276,  1.4521,  4.8286],\n",
      "          [-2.1894,  0.0339,  1.1087,  ...,  0.6334,  3.3528,  4.6624],\n",
      "          [-2.0153,  0.2470, -0.0670,  ..., -0.5722, -0.0588,  5.4910]],\n",
      "\n",
      "         [[-1.6656,  0.1180, -0.6959,  ..., -2.5024, -1.1689,  1.4515],\n",
      "          [ 3.1171,  3.4109,  0.5066,  ..., -0.2906,  3.4460,  0.9496],\n",
      "          [ 3.8841,  2.8815,  2.4667,  ...,  0.8320,  3.0767,  1.0745],\n",
      "          ...,\n",
      "          [ 3.6615,  0.7799, -0.6859,  ...,  5.6836,  2.8713,  0.6079],\n",
      "          [ 3.6183,  1.7753, -0.6088,  ..., -0.0956,  5.5245,  0.7785],\n",
      "          [-0.1064, -0.4624, -0.3291,  ..., -1.1752, -0.6960,  0.4846]],\n",
      "\n",
      "         [[ 0.2030, -0.0349, -0.0823,  ..., -0.3510,  0.7564,  0.9109],\n",
      "          [-4.2457, -0.4649, -0.0816,  ...,  0.1105,  1.6944,  2.4145],\n",
      "          [-4.6115,  0.0349, -0.7458,  ..., -0.2634,  1.9383,  2.3394],\n",
      "          ...,\n",
      "          [-3.9271, -0.7852, -0.3907,  ..., -0.3642,  0.7958,  2.3825],\n",
      "          [-3.9473, -0.2434,  0.2025,  ...,  0.0516,  0.6004,  1.7942],\n",
      "          [ 0.3278, -0.6807, -1.3168,  ..., -1.4926, -0.5588,  2.5678]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5101,  0.8516,  1.0807,  ...,  0.2292,  0.9347,  0.4013],\n",
      "          [-1.1321,  1.5123,  1.0694,  ..., -0.0154,  0.4332,  0.0782],\n",
      "          [-0.4972, -0.7291, -0.3767,  ..., -1.1031, -0.7618, -1.1602],\n",
      "          ...,\n",
      "          [-1.6816, -1.4222, -1.6017,  ..., -1.6920, -1.8027, -1.6117],\n",
      "          [-0.1378, -0.8905, -0.6259,  ..., -0.8527, -0.3546, -0.8420],\n",
      "          [-1.5335, -1.6391, -1.6106,  ..., -1.6078, -1.5969, -1.5474]],\n",
      "\n",
      "         [[-0.3147,  1.4597,  0.1682,  ..., -2.2208, -0.8060, -2.1538],\n",
      "          [-1.0851,  1.9922, -0.5318,  ..., -4.6364, -2.5596, -4.5776],\n",
      "          [-0.0351, -0.3354,  1.2625,  ..., -3.8827, -0.7902, -4.0317],\n",
      "          ...,\n",
      "          [-0.0923,  2.7416,  0.0303,  ..., -0.1712,  0.3461,  0.0256],\n",
      "          [-0.0963,  1.4677,  0.6369,  ..., -2.6961, -0.2133, -2.6053],\n",
      "          [-0.3476,  2.7000, -0.1438,  ..., -0.3874,  0.2188, -0.0098]],\n",
      "\n",
      "         [[-0.3687, -1.4752,  0.5024,  ...,  0.2817,  0.3330,  0.5091],\n",
      "          [-0.3752,  2.4077,  1.8530,  ...,  1.2104,  1.2493,  1.1453],\n",
      "          [ 0.3223,  0.3364,  1.0484,  ...,  0.7418,  0.2918,  0.8029],\n",
      "          ...,\n",
      "          [-1.2250,  0.0293,  0.7034,  ..., -1.5990, -0.5383, -1.4396],\n",
      "          [-0.3479, -0.5330,  0.0825,  ..., -0.1403, -0.2132,  0.0198],\n",
      "          [-1.0932, -0.3632,  0.6456,  ..., -1.6606, -0.5117, -1.4458]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7818,  0.7435,  1.7362,  ..., -3.0060, -0.1736, -3.0586],\n",
      "          [-1.9877,  4.1159, -0.0592,  ..., -3.5335, -2.4681, -3.5344],\n",
      "          [-0.4102,  0.2858,  4.9962,  ..., -4.6422,  0.1883, -4.7413],\n",
      "          ...,\n",
      "          [ 0.9409,  5.2881,  1.3850,  ...,  1.4122,  1.6143,  1.2811],\n",
      "          [ 1.6601,  3.3180,  5.2811,  ..., -3.2415,  2.4223, -3.2011],\n",
      "          [ 0.7605,  5.0445,  1.2826,  ...,  0.8413,  1.5355,  0.9293]],\n",
      "\n",
      "         [[ 2.2669,  1.1637,  2.7420,  ...,  0.6775,  2.2114,  0.9602],\n",
      "          [ 5.0141,  7.9687,  3.6973,  ...,  7.1228,  6.7644,  7.3920],\n",
      "          [ 7.0247,  5.8748,  5.8444,  ...,  6.7611,  7.8227,  7.1925],\n",
      "          ...,\n",
      "          [ 3.5473,  5.1546,  2.4206,  ...,  3.6629,  4.2009,  3.8382],\n",
      "          [ 6.1595,  5.8466,  5.0553,  ...,  5.7166,  7.2608,  6.1742],\n",
      "          [ 3.3238,  4.2848,  1.9521,  ...,  3.0795,  3.7463,  3.3827]],\n",
      "\n",
      "         [[-1.8095,  0.9652, -0.2443,  ...,  0.9048,  0.1630,  1.2758],\n",
      "          [-2.9087, -1.1057, -0.0914,  ..., -0.9256, -0.3335, -0.6403],\n",
      "          [-1.9320,  0.9316,  1.4009,  ...,  0.8221,  0.6559,  0.9970],\n",
      "          ...,\n",
      "          [-1.3681, -0.1758,  0.8011,  ..., -0.4789,  0.4086, -0.3196],\n",
      "          [-0.8606,  1.5762,  1.9740,  ...,  1.3034,  1.0575,  1.4132],\n",
      "          [-1.1176,  0.1377,  0.8598,  ..., -0.2989,  0.4084, -0.1304]]]],\n",
      "       grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[ 6.0713e-01, -2.2942e-01,  1.0685e+00,  ..., -8.7514e-01,\n",
      "           -1.1951e-01,  1.4363e+00],\n",
      "          [ 1.2467e+00,  3.2800e-01,  1.3469e+00,  ...,  4.4680e-01,\n",
      "            1.3010e+00,  2.8279e+00],\n",
      "          [ 2.2600e+00,  9.0593e-01,  1.4629e+00,  ..., -1.3663e-01,\n",
      "            1.0791e+00,  2.7997e+00],\n",
      "          ...,\n",
      "          [ 5.0248e-01, -3.3340e-01,  1.0744e+00,  ...,  5.0591e-01,\n",
      "            7.9369e-02,  2.4088e+00],\n",
      "          [ 9.2829e-02, -1.2061e+00, -2.8634e-01,  ..., -1.2692e+00,\n",
      "           -6.0585e-01,  2.3535e+00],\n",
      "          [-1.0531e+00, -9.4070e-01, -1.1219e+00,  ..., -8.9123e-01,\n",
      "           -5.0559e-01,  1.7823e+00]],\n",
      "\n",
      "         [[-7.4379e-01,  4.3211e-01,  4.6311e-01,  ..., -8.9010e-01,\n",
      "           -7.3418e-01,  2.6247e+00],\n",
      "          [-1.5273e+00, -1.9246e-01, -3.0009e-01,  ..., -3.4132e-01,\n",
      "           -4.7253e-02,  5.2202e+00],\n",
      "          [-9.3329e-01, -4.6121e-01,  1.1939e+00,  ...,  1.2604e+00,\n",
      "           -3.4280e-01,  3.7152e+00],\n",
      "          ...,\n",
      "          [-1.5892e+00, -7.7036e-01, -4.6783e-02,  ...,  2.9363e+00,\n",
      "            1.3162e+00,  5.3637e+00],\n",
      "          [-1.3011e+00, -8.8709e-01, -5.5688e-01,  ...,  1.2267e+00,\n",
      "            2.0724e+00,  4.7333e+00],\n",
      "          [-1.2279e+00, -9.9449e-01, -5.5701e-01,  ..., -1.2024e+00,\n",
      "           -6.3813e-01,  4.7991e+00]],\n",
      "\n",
      "         [[-1.4830e+00, -8.1438e-01,  2.8192e-01,  ..., -8.2985e-01,\n",
      "           -2.6687e-01,  2.4565e+00],\n",
      "          [ 3.1545e-01, -4.6556e-01,  2.5837e-01,  ..., -7.6454e-01,\n",
      "            9.3082e-01,  2.1330e+00],\n",
      "          [ 3.5763e-01, -1.8830e+00, -1.2734e+00,  ..., -1.2878e+00,\n",
      "           -2.4627e-01,  2.1712e+00],\n",
      "          ...,\n",
      "          [-1.9649e-01, -3.2076e+00, -1.8746e+00,  ..., -1.4792e+00,\n",
      "            4.4112e-01,  2.0136e+00],\n",
      "          [ 8.1832e-01, -2.0181e+00, -1.5499e+00,  ..., -1.2542e-01,\n",
      "            1.5896e+00,  1.7845e+00],\n",
      "          [-8.9838e-01, -3.5553e-01, -3.5116e-01,  ..., -1.3191e+00,\n",
      "           -1.0873e+00,  2.4185e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5740e-01,  5.0029e-01, -1.6359e-01,  ..., -1.5420e+00,\n",
      "           -1.5760e+00,  3.5806e+00],\n",
      "          [-1.5864e+00,  2.5984e+00,  1.7255e+00,  ...,  5.3498e-01,\n",
      "            3.1479e-01,  4.7823e+00],\n",
      "          [-1.5652e+00,  1.3352e+00,  5.8504e+00,  ...,  5.1383e-01,\n",
      "            5.1272e-02,  3.5814e+00],\n",
      "          ...,\n",
      "          [-1.2805e+00,  3.0151e-01,  2.3859e+00,  ...,  4.7276e+00,\n",
      "            1.4521e+00,  4.8286e+00],\n",
      "          [-2.1894e+00,  3.3947e-02,  1.1087e+00,  ...,  6.3339e-01,\n",
      "            3.3528e+00,  4.6624e+00],\n",
      "          [-2.0153e+00,  2.4698e-01, -6.7018e-02,  ..., -5.7220e-01,\n",
      "           -5.8814e-02,  5.4910e+00]],\n",
      "\n",
      "         [[-1.6656e+00,  1.1797e-01, -6.9590e-01,  ..., -2.5024e+00,\n",
      "           -1.1689e+00,  1.4515e+00],\n",
      "          [ 3.1171e+00,  3.4109e+00,  5.0662e-01,  ..., -2.9058e-01,\n",
      "            3.4460e+00,  9.4958e-01],\n",
      "          [ 3.8841e+00,  2.8815e+00,  2.4667e+00,  ...,  8.3196e-01,\n",
      "            3.0767e+00,  1.0745e+00],\n",
      "          ...,\n",
      "          [ 3.6615e+00,  7.7995e-01, -6.8590e-01,  ...,  5.6836e+00,\n",
      "            2.8713e+00,  6.0795e-01],\n",
      "          [ 3.6183e+00,  1.7753e+00, -6.0880e-01,  ..., -9.5598e-02,\n",
      "            5.5245e+00,  7.7851e-01],\n",
      "          [-1.0642e-01, -4.6236e-01, -3.2914e-01,  ..., -1.1752e+00,\n",
      "           -6.9598e-01,  4.8456e-01]],\n",
      "\n",
      "         [[ 2.0302e-01, -3.4931e-02, -8.2256e-02,  ..., -3.5103e-01,\n",
      "            7.5635e-01,  9.1094e-01],\n",
      "          [-4.2457e+00, -4.6491e-01, -8.1626e-02,  ...,  1.1052e-01,\n",
      "            1.6944e+00,  2.4145e+00],\n",
      "          [-4.6115e+00,  3.4943e-02, -7.4583e-01,  ..., -2.6339e-01,\n",
      "            1.9383e+00,  2.3394e+00],\n",
      "          ...,\n",
      "          [-3.9271e+00, -7.8523e-01, -3.9075e-01,  ..., -3.6420e-01,\n",
      "            7.9584e-01,  2.3825e+00],\n",
      "          [-3.9473e+00, -2.4345e-01,  2.0253e-01,  ...,  5.1569e-02,\n",
      "            6.0042e-01,  1.7942e+00],\n",
      "          [ 3.2777e-01, -6.8071e-01, -1.3168e+00,  ..., -1.4926e+00,\n",
      "           -5.5876e-01,  2.5678e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1013e-01,  8.5157e-01,  1.0807e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1321e+00,  1.5123e+00,  1.0694e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-4.9720e-01, -7.2908e-01, -3.7674e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-1.6816e+00, -1.4222e+00, -1.6017e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.3781e-01, -8.9045e-01, -6.2593e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.5335e+00, -1.6391e+00, -1.6106e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-3.1466e-01,  1.4597e+00,  1.6817e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.0851e+00,  1.9922e+00, -5.3176e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-3.5139e-02, -3.3540e-01,  1.2625e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-9.2258e-02,  2.7416e+00,  3.0344e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-9.6337e-02,  1.4677e+00,  6.3686e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-3.4764e-01,  2.7000e+00, -1.4380e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-3.6874e-01, -1.4752e+00,  5.0242e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-3.7518e-01,  2.4077e+00,  1.8530e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.2234e-01,  3.3644e-01,  1.0484e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-1.2250e+00,  2.9342e-02,  7.0344e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-3.4789e-01, -5.3301e-01,  8.2485e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.0932e+00, -3.6318e-01,  6.4563e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.8179e-01,  7.4351e-01,  1.7362e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.9877e+00,  4.1159e+00, -5.9202e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-4.1022e-01,  2.8583e-01,  4.9962e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 9.4093e-01,  5.2881e+00,  1.3850e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 1.6601e+00,  3.3180e+00,  5.2811e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.6051e-01,  5.0445e+00,  1.2826e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[ 2.2669e+00,  1.1637e+00,  2.7420e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.0141e+00,  7.9687e+00,  3.6973e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 7.0247e+00,  5.8748e+00,  5.8444e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [ 3.5473e+00,  5.1546e+00,  2.4206e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 6.1595e+00,  5.8466e+00,  5.0553e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 3.3238e+00,  4.2848e+00,  1.9521e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-1.8095e+00,  9.6516e-01, -2.4433e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-2.9087e+00, -1.1057e+00, -9.1383e-02,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.9320e+00,  9.3162e-01,  1.4009e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-1.3681e+00, -1.7584e-01,  8.0106e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-8.6060e-01,  1.5762e+00,  1.9740e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1176e+00,  1.3765e-01,  8.5976e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[1.4587e-01, 6.3192e-02, 2.3138e-01,  ..., 3.3131e-02,\n",
      "           7.0534e-02, 3.3426e-01],\n",
      "          [9.9531e-02, 3.9718e-02, 1.1002e-01,  ..., 4.4728e-02,\n",
      "           1.0509e-01, 4.8380e-01],\n",
      "          [2.2471e-01, 5.8017e-02, 1.0127e-01,  ..., 2.0454e-02,\n",
      "           6.8984e-02, 3.8549e-01],\n",
      "          ...,\n",
      "          [7.4406e-02, 3.2254e-02, 1.3182e-01,  ..., 7.4662e-02,\n",
      "           4.8736e-02, 5.0063e-01],\n",
      "          [7.8317e-02, 2.1366e-02, 5.3603e-02,  ..., 2.0061e-02,\n",
      "           3.8943e-02, 7.5101e-01],\n",
      "          [4.2065e-02, 4.7069e-02, 3.9267e-02,  ..., 4.9456e-02,\n",
      "           7.2728e-02, 7.1664e-01]],\n",
      "\n",
      "         [[2.3734e-02, 7.6925e-02, 7.9347e-02,  ..., 2.0504e-02,\n",
      "           2.3964e-02, 6.8915e-01],\n",
      "          [1.1521e-03, 4.3773e-03, 3.9306e-03,  ..., 3.7718e-03,\n",
      "           5.0613e-03, 9.8154e-01],\n",
      "          [7.9087e-03, 1.2680e-02, 6.6363e-02,  ..., 7.0928e-02,\n",
      "           1.4274e-02, 8.2588e-01],\n",
      "          ...,\n",
      "          [8.5843e-04, 1.9468e-03, 4.0140e-03,  ..., 7.9271e-02,\n",
      "           1.5685e-02, 8.9809e-01],\n",
      "          [2.1541e-03, 3.2588e-03, 4.5338e-03,  ..., 2.6982e-02,\n",
      "           6.2858e-02, 8.9941e-01],\n",
      "          [2.3711e-03, 2.9944e-03, 4.6377e-03,  ..., 2.4323e-03,\n",
      "           4.2764e-03, 9.8268e-01]],\n",
      "\n",
      "         [[1.4827e-02, 2.8935e-02, 8.6604e-02,  ..., 2.8491e-02,\n",
      "           5.0027e-02, 7.6201e-01],\n",
      "          [9.1303e-02, 4.1811e-02, 8.6237e-02,  ..., 3.1006e-02,\n",
      "           1.6894e-01, 5.6211e-01],\n",
      "          [1.2081e-01, 1.2854e-02, 2.3647e-02,  ..., 2.3309e-02,\n",
      "           6.6046e-02, 7.4088e-01],\n",
      "          ...,\n",
      "          [7.8918e-02, 3.8856e-03, 1.4736e-02,  ..., 2.1882e-02,\n",
      "           1.4931e-01, 7.1948e-01],\n",
      "          [1.5503e-01, 9.0907e-03, 1.4518e-02,  ..., 6.0333e-02,\n",
      "           3.3527e-01, 4.0740e-01],\n",
      "          [2.9257e-02, 5.0349e-02, 5.0569e-02,  ..., 1.9209e-02,\n",
      "           2.4221e-02, 8.0676e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.9162e-02, 4.1089e-02, 2.1155e-02,  ..., 5.3305e-03,\n",
      "           5.1522e-03, 8.9431e-01],\n",
      "          [1.4364e-03, 9.4344e-02, 3.9411e-02,  ..., 1.1983e-02,\n",
      "           9.6148e-03, 8.3783e-01],\n",
      "          [5.3193e-04, 9.6712e-03, 8.8394e-01,  ..., 4.2538e-03,\n",
      "           2.6785e-03, 9.1410e-02],\n",
      "          ...,\n",
      "          [1.0862e-03, 5.2841e-03, 4.2483e-02,  ..., 4.4177e-01,\n",
      "           1.6698e-02, 4.8871e-01],\n",
      "          [7.9355e-04, 7.3313e-03, 2.1476e-02,  ..., 1.3351e-02,\n",
      "           2.0256e-01, 7.5036e-01],\n",
      "          [5.4060e-04, 5.1927e-03, 3.7934e-03,  ..., 2.2889e-03,\n",
      "           3.8246e-03, 9.8366e-01]],\n",
      "\n",
      "         [[2.8394e-02, 1.6897e-01, 7.4877e-02,  ..., 1.2297e-02,\n",
      "           4.6660e-02, 6.4115e-01],\n",
      "          [2.5026e-01, 3.3573e-01, 1.8393e-02,  ..., 8.2879e-03,\n",
      "           3.4771e-01, 2.8644e-02],\n",
      "          [4.5276e-01, 1.6613e-01, 1.0971e-01,  ..., 2.1395e-02,\n",
      "           2.0194e-01, 2.7269e-02],\n",
      "          ...,\n",
      "          [1.0844e-01, 6.0777e-03, 1.4032e-03,  ..., 8.1914e-01,\n",
      "           4.9206e-02, 5.1173e-03],\n",
      "          [1.2510e-01, 1.9809e-02, 1.8258e-03,  ..., 3.0502e-03,\n",
      "           8.4163e-01, 7.3106e-03],\n",
      "          [1.7884e-01, 1.2528e-01, 1.4314e-01,  ..., 6.1420e-02,\n",
      "           9.9182e-02, 3.2295e-01]],\n",
      "\n",
      "         [[1.3332e-01, 1.0509e-01, 1.0023e-01,  ..., 7.6610e-02,\n",
      "           2.3186e-01, 2.7062e-01],\n",
      "          [7.2583e-04, 3.1828e-02, 4.6695e-02,  ..., 5.6587e-02,\n",
      "           2.7580e-01, 5.6666e-01],\n",
      "          [4.9979e-04, 5.2085e-02, 2.3858e-02,  ..., 3.8650e-02,\n",
      "           3.4941e-01, 5.2184e-01],\n",
      "          ...,\n",
      "          [1.3082e-03, 3.0281e-02, 4.4925e-02,  ..., 4.6133e-02,\n",
      "           1.4717e-01, 7.1923e-01],\n",
      "          [1.6568e-03, 6.7271e-02, 1.0508e-01,  ..., 9.0355e-02,\n",
      "           1.5643e-01, 5.1612e-01],\n",
      "          [8.6331e-02, 3.1491e-02, 1.6671e-02,  ..., 1.3983e-02,\n",
      "           3.5575e-02, 8.1097e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.5308e-01, 2.1538e-01, 2.7084e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0894e-02, 1.5332e-01, 9.8461e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.6807e-02, 2.9189e-02, 4.1519e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.8511e-03, 7.5835e-03, 6.3375e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.4588e-02, 2.1006e-02, 2.7367e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.0305e-03, 6.3256e-03, 6.5091e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[2.4769e-02, 1.4604e-01, 4.0141e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2586e-03, 2.7309e-02, 2.1887e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.5226e-02, 1.1277e-02, 5.5738e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [2.4601e-02, 4.1849e-01, 2.7810e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1850e-02, 1.0441e-01, 4.5486e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9714e-02, 4.1529e-01, 2.4172e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[4.4488e-02, 1.4714e-02, 1.0631e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.7608e-02, 2.8464e-01, 1.6345e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.4259e-02, 7.5313e-02, 1.5348e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.3075e-02, 4.5835e-02, 8.9939e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.1055e-02, 4.2427e-02, 7.8514e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.6705e-02, 3.4664e-02, 9.5060e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.5473e-02, 3.4141e-02, 9.2131e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.8647e-04, 1.7293e-01, 2.6586e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.0468e-03, 6.1113e-03, 6.7894e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.0268e-02, 7.9325e-01, 1.6007e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.6269e-02, 8.5378e-02, 6.0805e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0305e-02, 7.4746e-01, 1.7371e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[3.0270e-01, 1.0044e-01, 4.8681e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.8830e-02, 9.3728e-01, 1.3087e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.1525e-01, 1.9482e-01, 1.8899e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.5416e-01, 7.6911e-01, 4.9963e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.8324e-01, 3.5339e-01, 1.6017e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.4388e-01, 6.3758e-01, 6.1867e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[2.3744e-02, 3.8067e-01, 1.1357e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0134e-03, 1.2217e-02, 3.3686e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.0416e-03, 1.4093e-01, 2.2532e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.0232e-02, 3.3711e-02, 8.9543e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9166e-02, 2.1919e-01, 3.2628e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4586e-02, 5.1180e-02, 1.0537e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]], grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[-3.0984e-01, -3.0332e-01,  3.3577e-01,  ..., -4.3640e-01,\n",
      "           -2.2878e-01,  7.5183e-01],\n",
      "          [-2.1848e-01, -2.4806e-01,  1.4391e-01,  ..., -2.9668e-01,\n",
      "           -1.8779e-01,  5.5207e-01],\n",
      "          [-2.1467e-01, -2.7710e-01,  2.4229e-01,  ..., -2.7408e-01,\n",
      "           -1.7752e-01,  6.7301e-01],\n",
      "          ...,\n",
      "          [-2.2282e-01, -2.8567e-01,  1.7927e-01,  ..., -3.4268e-01,\n",
      "           -1.8352e-01,  5.8909e-01],\n",
      "          [-1.2011e-01, -1.2834e-01,  1.1358e-01,  ..., -1.1897e-01,\n",
      "           -1.1491e-01,  3.8611e-01],\n",
      "          [-1.4751e-01, -1.5036e-01,  6.7067e-02,  ..., -1.6087e-01,\n",
      "           -1.1552e-01,  4.2470e-01]],\n",
      "\n",
      "         [[ 2.0984e-01, -1.8102e-01,  6.9516e-03,  ...,  3.3494e-01,\n",
      "           -2.3503e-02, -1.5721e-01],\n",
      "          [ 7.0496e-02, -2.1538e-02,  5.1661e-02,  ...,  9.8281e-02,\n",
      "           -4.5214e-02, -1.3021e-01],\n",
      "          [ 1.1527e-01, -9.5915e-02,  1.2042e-01,  ...,  1.4999e-01,\n",
      "           -4.4689e-03, -2.0652e-01],\n",
      "          ...,\n",
      "          [ 3.1568e-02, -7.7307e-02,  1.1096e-01,  ...,  1.0076e-01,\n",
      "            1.3581e-02, -1.9956e-01],\n",
      "          [ 2.7645e-02, -3.9785e-02,  9.4766e-02,  ...,  1.7369e-01,\n",
      "           -3.5938e-02, -1.4119e-01],\n",
      "          [ 7.3022e-02, -2.0306e-02,  5.0006e-02,  ...,  9.5975e-02,\n",
      "           -4.5890e-02, -1.2850e-01]],\n",
      "\n",
      "         [[ 2.1842e-01, -1.5147e-01, -3.1128e-02,  ..., -5.5735e-02,\n",
      "           -2.1275e-01, -7.4343e-03],\n",
      "          [ 7.1719e-02, -2.7436e-01, -2.6859e-02,  ...,  3.3282e-03,\n",
      "           -1.5051e-01,  3.8859e-02],\n",
      "          [-2.7212e-01, -1.0858e-01,  1.4323e-02,  ...,  7.4397e-03,\n",
      "            1.2069e-02, -4.0406e-02],\n",
      "          ...,\n",
      "          [-6.3316e-02, -1.4098e-01, -1.6198e-02,  ...,  2.7371e-02,\n",
      "           -3.7011e-02,  3.0635e-03],\n",
      "          [-1.1854e-01, -3.6838e-01, -1.7018e-02,  ...,  1.0661e-01,\n",
      "           -1.4989e-02,  9.4108e-02],\n",
      "          [ 1.1370e-01, -8.2336e-02, -2.6908e-02,  ..., -7.3005e-02,\n",
      "           -1.5694e-01, -2.8125e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1702e-01,  3.0874e-02,  3.6243e-02,  ...,  4.5931e-03,\n",
      "            7.3434e-02, -7.9804e-02],\n",
      "          [ 1.5695e-01,  2.9076e-02,  8.8245e-02,  ...,  6.7027e-02,\n",
      "            1.2333e-01, -3.1697e-03],\n",
      "          [ 9.1508e-01,  1.4732e-01,  2.4316e-01,  ...,  2.4992e-01,\n",
      "           -8.1165e-02, -1.3869e-02],\n",
      "          ...,\n",
      "          [-4.1451e-02, -4.9690e-01,  2.5135e-01,  ...,  8.6011e-02,\n",
      "            4.3980e-01, -1.8315e-01],\n",
      "          [ 1.0200e-01, -9.2002e-02,  6.1243e-02,  ...,  1.0235e-01,\n",
      "            1.9467e-01, -4.7246e-02],\n",
      "          [ 7.9039e-02,  3.5048e-02,  1.7657e-02,  ..., -2.4767e-02,\n",
      "            1.2204e-02, -1.1634e-01]],\n",
      "\n",
      "         [[-1.0928e-01, -1.4618e-01, -5.5216e-02,  ..., -5.6346e-02,\n",
      "           -3.9578e-02,  3.4510e-02],\n",
      "          [-4.0297e-01, -2.6268e-01,  1.6830e-01,  ..., -2.7277e-01,\n",
      "           -2.0694e-01, -7.1126e-03],\n",
      "          [-3.6162e-01, -1.5728e-01,  9.2778e-02,  ..., -2.7483e-01,\n",
      "           -1.8990e-01,  6.4311e-02],\n",
      "          ...,\n",
      "          [-2.6809e-01, -2.5009e-01,  4.0129e-01,  ...,  2.7733e-01,\n",
      "           -2.5455e-01,  2.1148e-01],\n",
      "          [-6.7264e-01, -4.1049e-01,  2.1963e-01,  ..., -4.8956e-01,\n",
      "           -2.5176e-01, -1.0475e-01],\n",
      "          [-2.2732e-01, -1.4476e-01, -1.5158e-03,  ..., -9.8976e-02,\n",
      "           -1.1955e-01,  1.0158e-01]],\n",
      "\n",
      "         [[-6.8368e-02, -2.4836e-01, -4.3528e-01,  ..., -9.8354e-02,\n",
      "           -1.3931e-01,  2.5665e-02],\n",
      "          [ 1.0570e-01, -1.1778e-01, -2.4762e-01,  ..., -1.0453e-01,\n",
      "           -1.4105e-01,  1.9755e-01],\n",
      "          [ 1.2785e-01, -9.0128e-02, -2.6802e-01,  ..., -1.7053e-01,\n",
      "           -1.4838e-01,  2.6939e-01],\n",
      "          ...,\n",
      "          [ 4.3317e-02, -9.4228e-02, -1.5509e-01,  ..., -4.1526e-02,\n",
      "           -1.0106e-01,  1.0025e-01],\n",
      "          [-2.2017e-02, -2.1621e-01, -2.8493e-01,  ...,  3.6760e-02,\n",
      "           -8.3735e-02,  1.1523e-01],\n",
      "          [-2.6904e-02, -5.2397e-02, -9.1715e-02,  ..., -8.3178e-02,\n",
      "           -1.0309e-01, -9.4783e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.6704e-01, -8.9575e-01,  6.4860e-02,  ..., -3.4147e-02,\n",
      "           -7.8448e-01, -1.7381e-02],\n",
      "          [-2.7423e-01, -4.1360e-01, -1.2497e-02,  ...,  2.2360e-02,\n",
      "           -4.5054e-01,  9.7387e-02],\n",
      "          [-8.5241e-02, -1.6381e-01, -2.3754e-02,  ...,  1.4525e-01,\n",
      "           -1.8624e-01,  9.2867e-02],\n",
      "          ...,\n",
      "          [-3.4573e-02, -5.1349e-02, -4.1769e-02,  ...,  1.6410e-01,\n",
      "           -1.0394e-01,  1.1653e-01],\n",
      "          [-6.6744e-02, -1.3466e-01, -2.2409e-02,  ...,  1.5651e-01,\n",
      "           -1.5603e-01,  9.2823e-02],\n",
      "          [-3.3176e-02, -5.0760e-02, -4.1464e-02,  ...,  1.6539e-01,\n",
      "           -1.0233e-01,  1.1583e-01]],\n",
      "\n",
      "         [[-7.2306e-02, -1.7157e-01,  3.2327e-03,  ...,  1.5584e-01,\n",
      "           -8.9537e-02, -1.3843e-01],\n",
      "          [-2.0536e-02, -4.6850e-02,  1.0601e-02,  ...,  1.0801e-01,\n",
      "           -5.0300e-02, -8.2262e-02],\n",
      "          [ 2.4871e-02, -5.3914e-02,  7.8864e-04,  ...,  8.1501e-02,\n",
      "           -1.8690e-02, -1.2565e-01],\n",
      "          ...,\n",
      "          [-2.6321e-01, -4.0661e-01,  1.1656e-02,  ...,  3.2083e-01,\n",
      "           -2.3271e-01, -1.8920e-01],\n",
      "          [-4.1974e-02, -1.3539e-01,  2.4154e-03,  ...,  1.3280e-01,\n",
      "           -6.7456e-02, -1.3498e-01],\n",
      "          [-2.6451e-01, -4.0070e-01,  1.3313e-02,  ...,  3.2340e-01,\n",
      "           -2.3402e-01, -1.8656e-01]],\n",
      "\n",
      "         [[ 2.9046e-01,  1.2002e-02, -1.1950e-02,  ...,  8.6550e-02,\n",
      "           -7.8680e-02,  4.3318e-02],\n",
      "          [ 9.2784e-01,  2.8160e-02, -1.2127e-01,  ...,  3.4421e-01,\n",
      "            1.0745e-01,  1.0964e-01],\n",
      "          [ 4.1915e-01, -8.7959e-04, -2.1873e-02,  ...,  1.6126e-01,\n",
      "            2.9203e-03,  4.0646e-02],\n",
      "          ...,\n",
      "          [ 3.8682e-01,  2.4076e-02, -3.5916e-02,  ...,  1.0275e-01,\n",
      "           -9.1192e-02,  6.6865e-02],\n",
      "          [ 2.3554e-01,  3.8237e-02, -2.1396e-02,  ...,  1.1919e-01,\n",
      "           -2.3925e-02,  2.5101e-02],\n",
      "          [ 3.7330e-01,  1.8810e-02, -3.0122e-02,  ...,  9.3056e-02,\n",
      "           -9.9103e-02,  6.5319e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.3292e-02, -1.1403e-02, -1.2313e-01,  ...,  4.2508e-02,\n",
      "            1.5063e-02, -4.1315e-02],\n",
      "          [ 1.2395e-01, -1.0769e-01, -2.0218e-01,  ...,  9.4598e-02,\n",
      "            1.7623e-01,  3.4262e-02],\n",
      "          [ 1.2981e-01,  3.2022e-01, -6.4392e-01,  ...,  3.7423e-01,\n",
      "           -1.8440e-01, -5.1683e-02],\n",
      "          ...,\n",
      "          [ 3.1076e-01, -4.0777e-01, -8.7486e-01,  ...,  5.1303e-01,\n",
      "            6.8929e-01,  3.1061e-01],\n",
      "          [ 1.4205e-01,  2.3861e-01, -6.5887e-01,  ...,  3.8178e-01,\n",
      "           -1.0057e-01, -1.9296e-02],\n",
      "          [ 2.9683e-01, -3.8479e-01, -8.2709e-01,  ...,  4.8326e-01,\n",
      "            6.5031e-01,  2.8992e-01]],\n",
      "\n",
      "         [[-2.0002e-01,  2.1731e-01, -8.1130e-02,  ..., -1.1176e-02,\n",
      "           -8.8885e-02,  1.5920e-01],\n",
      "          [-3.1684e-01,  6.0335e-01,  3.0303e-01,  ...,  2.1259e-01,\n",
      "            5.6799e-02,  5.2759e-02],\n",
      "          [-1.7075e-01,  1.7834e-01,  4.6450e-02,  ..., -5.4167e-02,\n",
      "           -2.4402e-01,  5.7640e-02],\n",
      "          ...,\n",
      "          [-2.8093e-01,  5.0475e-01,  2.4140e-01,  ...,  1.5538e-01,\n",
      "           -3.4895e-04,  5.2560e-02],\n",
      "          [-2.0357e-01,  2.7212e-01,  9.8428e-02,  ...,  5.0743e-03,\n",
      "           -1.7420e-01,  5.9814e-02],\n",
      "          [-2.4852e-01,  4.2112e-01,  1.9633e-01,  ...,  1.0835e-01,\n",
      "           -4.9071e-02,  4.6067e-02]],\n",
      "\n",
      "         [[-2.2460e-02, -1.3086e-01, -1.5298e-01,  ...,  4.6075e-01,\n",
      "            3.8567e-02, -2.3599e-01],\n",
      "          [ 1.6117e-01, -3.0967e-02,  2.4684e-02,  ...,  3.8112e-02,\n",
      "            3.4344e-02, -3.6009e-02],\n",
      "          [ 8.6455e-02, -2.7090e-02, -1.7302e-01,  ...,  4.1432e-01,\n",
      "            1.5858e-02, -1.8279e-01],\n",
      "          ...,\n",
      "          [ 1.5128e-01, -2.3896e-02, -3.2792e-02,  ...,  1.3141e-01,\n",
      "            2.5578e-02, -8.1525e-02],\n",
      "          [ 4.6081e-02, -2.7655e-02, -2.8497e-01,  ...,  6.1858e-01,\n",
      "            3.7919e-03, -2.7435e-01],\n",
      "          [ 1.4370e-01, -2.5424e-02, -5.3357e-02,  ...,  1.6694e-01,\n",
      "            2.3031e-02, -1.0119e-01]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n",
      "hidden states going to mixed query layer: torch.Size([2, 7, 768])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "inside transpose for scores, shape before new shape:torch.Size([2, 7, 768])\n",
      "new x shape is: torch.Size([2, 7, 12, 64])\n",
      "key layer: tensor([[[[-3.5697e-01,  7.8581e-01, -1.2997e+00,  ..., -6.9165e-01,\n",
      "            1.6134e+00, -8.5742e-01],\n",
      "          [ 1.4218e-01,  6.7656e-01, -1.2913e+00,  ..., -6.6128e-01,\n",
      "            8.1954e-01, -2.0807e+00],\n",
      "          [-8.6089e-01,  1.8751e+00, -5.3985e-01,  ..., -1.2510e+00,\n",
      "            1.1288e+00, -2.0072e+00],\n",
      "          ...,\n",
      "          [ 5.6873e-01,  7.5253e-01, -6.0087e-01,  ..., -1.1652e+00,\n",
      "            7.4936e-01, -1.1482e+00],\n",
      "          [ 3.0592e-01,  4.9650e-01, -7.5602e-01,  ..., -3.4905e-01,\n",
      "            8.4118e-01, -1.3782e+00],\n",
      "          [ 2.7818e-01,  1.2198e-01,  9.3284e-02,  ...,  2.2286e-01,\n",
      "           -2.8032e-01,  3.7879e-01]],\n",
      "\n",
      "         [[-1.2647e+00,  1.4240e+00, -2.8100e-01,  ...,  1.2896e+00,\n",
      "            5.6929e-01, -7.8238e-01],\n",
      "          [-1.5678e+00,  2.2664e+00, -2.9138e-01,  ..., -1.9664e-02,\n",
      "           -5.5839e-01, -2.8956e-02],\n",
      "          [-1.3755e+00,  2.5126e+00, -3.0060e-01,  ...,  3.6794e-01,\n",
      "            3.7103e-01,  9.2341e-01],\n",
      "          ...,\n",
      "          [-6.0668e-01,  2.9054e+00, -4.3750e-01,  ...,  6.7214e-01,\n",
      "           -4.6779e-01,  7.0494e-02],\n",
      "          [-1.5706e+00,  2.2262e+00, -8.7323e-01,  ..., -1.2466e+00,\n",
      "           -8.4671e-01, -1.0422e-01],\n",
      "          [ 9.1418e-01, -1.3233e+00,  9.9547e-01,  ..., -2.3520e-01,\n",
      "           -1.1122e-01, -4.6875e-01]],\n",
      "\n",
      "         [[-2.4650e+00,  8.3428e-01,  8.1622e-02,  ...,  1.3306e+00,\n",
      "            4.0837e-01, -5.2434e-01],\n",
      "          [-9.6192e-02,  7.6310e-01,  8.4724e-01,  ...,  5.9963e-01,\n",
      "            1.5323e+00,  2.2965e-01],\n",
      "          [ 7.4469e-02,  7.7835e-01,  1.0639e+00,  ...,  1.2442e+00,\n",
      "            1.4610e+00,  1.1167e-01],\n",
      "          ...,\n",
      "          [-1.3779e+00,  2.9022e-01,  4.7884e-01,  ...,  1.6289e+00,\n",
      "            1.5867e+00,  1.4452e+00],\n",
      "          [-1.3780e-01,  1.8422e+00, -1.1983e-01,  ...,  1.4521e+00,\n",
      "            1.0575e+00,  2.6090e-01],\n",
      "          [ 6.6023e-01, -7.3980e-01, -3.0078e-02,  ...,  1.8685e-01,\n",
      "           -3.1423e-01,  2.2141e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.1395e-01,  7.7525e-02,  3.4662e-01,  ..., -9.9949e-01,\n",
      "            9.5862e-01, -1.3954e-01],\n",
      "          [ 1.7467e+00,  3.3870e-01,  4.9464e-01,  ...,  4.7180e-01,\n",
      "            6.0143e-01, -2.6469e-01],\n",
      "          [ 1.2636e+00,  2.0003e+00,  1.5169e-01,  ...,  4.9535e-01,\n",
      "            1.1836e+00, -4.2060e-01],\n",
      "          ...,\n",
      "          [ 1.9009e+00, -1.1152e+00,  1.9793e-01,  ...,  9.6120e-01,\n",
      "           -2.7430e-02, -3.3792e-01],\n",
      "          [ 2.1244e+00, -1.6487e+00,  4.7854e-01,  ...,  5.6050e-01,\n",
      "           -5.3269e-01,  3.1387e-01],\n",
      "          [ 3.4159e-02, -2.4909e-01, -5.0716e-02,  ...,  3.3236e-01,\n",
      "           -1.1572e-01, -1.7756e-01]],\n",
      "\n",
      "         [[-8.3159e-01, -4.6215e-01,  1.4069e+00,  ...,  1.3862e-01,\n",
      "            1.7039e+00, -7.2058e-02],\n",
      "          [-6.5903e-01,  9.1927e-01,  1.9446e-01,  ..., -8.5702e-02,\n",
      "            4.5186e-01, -8.7410e-01],\n",
      "          [-4.8308e-01,  7.2129e-01,  2.3816e-02,  ...,  4.9659e-01,\n",
      "            1.1602e+00,  1.8707e-01],\n",
      "          ...,\n",
      "          [ 3.7347e-01, -4.4330e-01, -1.9321e-01,  ...,  3.0710e-01,\n",
      "            8.8460e-01,  9.8387e-01],\n",
      "          [-9.3088e-01, -3.3592e-01,  6.5038e-01,  ..., -1.1964e-01,\n",
      "            1.2656e+00,  1.2073e-02],\n",
      "          [ 3.5497e-01,  4.7782e-01, -5.3967e-01,  ..., -8.3539e-02,\n",
      "           -1.9462e-02, -1.3329e-01]],\n",
      "\n",
      "         [[ 7.8875e-01,  4.7581e-02, -5.2171e-01,  ...,  2.3094e-01,\n",
      "           -8.2435e-01, -9.3185e-01],\n",
      "          [-3.0001e-01,  1.3615e-01, -6.6022e-01,  ...,  1.7973e-01,\n",
      "            6.9061e-01, -9.9517e-01],\n",
      "          [ 1.7823e-01,  2.6838e-01, -7.8361e-01,  ..., -1.9475e-02,\n",
      "            3.2902e-01, -1.9574e+00],\n",
      "          ...,\n",
      "          [ 7.7024e-01,  3.4798e-01, -7.4595e-01,  ...,  3.8775e-02,\n",
      "            1.3849e-01, -1.7251e+00],\n",
      "          [ 3.8653e-01,  5.8445e-01, -1.7706e-01,  ..., -2.9702e-02,\n",
      "            4.7158e-01, -1.2607e+00],\n",
      "          [ 2.0651e-01,  1.5192e-01,  6.4735e-01,  ...,  8.4137e-02,\n",
      "            2.7016e-01,  8.5233e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.6733e-01,  2.9916e-01, -7.4851e-01,  ..., -5.9570e-01,\n",
      "            5.7570e-01, -4.0870e-02],\n",
      "          [-7.3310e-01,  1.1313e+00, -1.1472e+00,  ..., -1.3377e+00,\n",
      "            3.1804e-01,  4.0694e-01],\n",
      "          [ 3.7058e-02,  1.7130e+00, -5.4772e-01,  ..., -1.5310e+00,\n",
      "            2.8066e-01, -9.0081e-01],\n",
      "          ...,\n",
      "          [-1.7630e-01,  4.0718e-01, -1.5901e-01,  ..., -1.3404e+00,\n",
      "           -2.1264e-01, -4.3140e-01],\n",
      "          [ 4.0430e-01,  1.1115e+00,  9.3910e-03,  ..., -9.5257e-01,\n",
      "            2.8524e-01, -4.8301e-01],\n",
      "          [-2.9011e-02,  3.9035e-01, -2.5505e-01,  ..., -1.2713e+00,\n",
      "           -7.7347e-03, -2.7288e-01]],\n",
      "\n",
      "         [[-1.1226e+00,  1.4329e+00,  7.0790e-01,  ...,  6.2939e-01,\n",
      "            3.0009e-01,  1.8153e-01],\n",
      "          [-6.9923e-01,  2.3876e+00, -2.9162e-01,  ..., -4.8213e-02,\n",
      "            3.6125e-01,  1.3938e+00],\n",
      "          [-1.6073e+00,  2.4047e+00, -1.6739e-01,  ..., -1.0039e+00,\n",
      "            4.9614e-01,  7.1812e-01],\n",
      "          ...,\n",
      "          [-1.0340e+00,  3.0948e+00, -1.4275e+00,  ...,  2.3396e-03,\n",
      "           -7.9264e-01,  1.1200e+00],\n",
      "          [-1.7002e+00,  2.4258e+00, -7.6804e-01,  ..., -5.4709e-01,\n",
      "            3.4109e-01,  4.3519e-01],\n",
      "          [-8.4173e-01,  2.8696e+00, -1.3081e+00,  ..., -7.4826e-03,\n",
      "           -6.4288e-01,  9.5776e-01]],\n",
      "\n",
      "         [[-3.6576e+00,  9.6024e-01, -4.9961e-01,  ...,  1.7968e+00,\n",
      "           -5.2033e-01,  7.8225e-01],\n",
      "          [-9.2333e-01,  1.9225e+00, -8.4259e-01,  ...,  1.0891e+00,\n",
      "            7.2686e-03,  8.9934e-01],\n",
      "          [-6.7553e-01,  2.4743e+00,  6.2355e-02,  ...,  1.3013e+00,\n",
      "           -1.0966e+00,  3.7831e-01],\n",
      "          ...,\n",
      "          [-1.1848e+00,  1.5653e+00, -7.6765e-01,  ...,  1.2712e+00,\n",
      "            1.7943e-01,  6.6225e-01],\n",
      "          [-4.5546e-01,  2.2748e+00, -2.3496e-01,  ...,  2.0598e+00,\n",
      "           -4.5760e-01,  5.6633e-01],\n",
      "          [-1.1137e+00,  1.4005e+00, -6.6253e-01,  ...,  1.4987e+00,\n",
      "            1.2498e-01,  7.3261e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0212e-01, -3.1272e-01, -3.9182e-02,  ..., -4.2385e-01,\n",
      "            1.1832e+00,  6.4378e-02],\n",
      "          [-2.8923e-01, -4.8891e-01,  8.9110e-02,  ..., -2.5264e-01,\n",
      "           -2.8621e-03, -9.8542e-02],\n",
      "          [-2.3210e-01, -1.3662e+00,  2.8391e-01,  ..., -3.1001e-01,\n",
      "            9.9854e-01, -1.6224e-01],\n",
      "          ...,\n",
      "          [-6.3922e-01, -6.9566e-01, -1.6040e-01,  ...,  5.5281e-01,\n",
      "            4.9363e-01,  3.5631e-02],\n",
      "          [-2.8598e-01, -1.2321e+00,  5.0157e-01,  ...,  5.4744e-01,\n",
      "            1.2583e+00, -4.3881e-02],\n",
      "          [-6.4178e-01, -6.8332e-01, -3.9140e-01,  ...,  7.3628e-01,\n",
      "            5.7712e-01, -3.7247e-02]],\n",
      "\n",
      "         [[-5.4290e-01,  8.2795e-01,  1.1491e+00,  ...,  8.0322e-01,\n",
      "            1.3148e+00, -7.3794e-01],\n",
      "          [ 4.6608e-01, -2.4951e-01, -3.7080e-01,  ...,  1.8503e+00,\n",
      "            6.1032e-01,  3.7981e-01],\n",
      "          [-1.5175e+00,  1.0753e+00,  3.7002e-01,  ...,  7.9610e-01,\n",
      "            1.2340e+00,  2.5039e-01],\n",
      "          ...,\n",
      "          [ 2.7269e-01,  3.4629e-01,  6.0992e-01,  ...,  2.3733e+00,\n",
      "            5.5438e-01,  9.6148e-01],\n",
      "          [-1.1533e+00,  1.2616e+00,  1.4696e+00,  ...,  1.3759e+00,\n",
      "            9.1815e-01,  1.1383e-01],\n",
      "          [ 1.9427e-01,  4.3895e-01,  9.5009e-01,  ...,  2.1979e+00,\n",
      "            4.9331e-01,  7.6814e-01]],\n",
      "\n",
      "         [[ 3.4496e-01, -4.9512e-01, -7.8193e-01,  ...,  3.6695e-02,\n",
      "           -9.8190e-01, -1.0349e+00],\n",
      "          [ 1.1209e-02,  5.3610e-01, -9.8778e-01,  ..., -7.3066e-01,\n",
      "           -1.3218e-01, -1.6825e-01],\n",
      "          [-4.8731e-01, -2.4899e-01, -9.7958e-01,  ..., -1.1159e+00,\n",
      "           -7.5108e-02, -1.3038e+00],\n",
      "          ...,\n",
      "          [-3.0211e-01, -3.5920e-01, -1.0734e+00,  ..., -8.2591e-01,\n",
      "           -1.1951e+00, -2.0835e+00],\n",
      "          [-3.1985e-01, -9.1769e-02, -1.4203e+00,  ..., -8.2003e-01,\n",
      "           -3.2627e-01, -1.8666e+00],\n",
      "          [-2.7296e-01, -3.2892e-01, -8.3229e-01,  ..., -6.7192e-01,\n",
      "           -1.1237e+00, -2.2078e+00]]]], grad_fn=<PermuteBackward0>), query layer: tensor([[[[-3.2502e-01,  9.0811e-02,  1.4317e+00,  ...,  6.1651e-01,\n",
      "           -2.3002e-01,  1.8661e-01],\n",
      "          [ 9.0665e-01, -7.7711e-01,  1.4250e+00,  ...,  1.1462e+00,\n",
      "           -6.1297e-01,  1.5278e+00],\n",
      "          [ 1.8160e-01, -4.7536e-01,  6.8908e-01,  ...,  1.7677e+00,\n",
      "           -5.1787e-01,  5.8183e-01],\n",
      "          ...,\n",
      "          [ 4.1760e-01, -8.4912e-01,  2.4800e+00,  ...,  1.0903e+00,\n",
      "            6.6832e-02, -1.1462e-01],\n",
      "          [ 3.8513e-01, -7.4463e-01,  1.5236e+00,  ...,  1.5476e+00,\n",
      "            7.0149e-01,  1.1281e+00],\n",
      "          [ 8.4029e-01,  1.0318e+00,  9.2518e-01,  ...,  1.3196e+00,\n",
      "           -6.6685e-01,  1.5953e+00]],\n",
      "\n",
      "         [[-4.2774e-01, -8.8642e-01,  2.5390e-01,  ..., -2.0752e-01,\n",
      "           -5.2453e-01,  3.5319e-01],\n",
      "          [ 1.0996e+00, -2.8758e+00,  1.3426e+00,  ..., -4.3431e-01,\n",
      "            8.4375e-01, -4.8611e-01],\n",
      "          [ 1.4392e+00, -2.8305e+00,  1.5886e+00,  ..., -1.2517e+00,\n",
      "            9.2468e-01, -5.4165e-01],\n",
      "          ...,\n",
      "          [ 1.5573e+00, -2.1768e+00,  1.8778e+00,  ..., -5.6921e-01,\n",
      "            1.6796e-01, -2.7549e-01],\n",
      "          [ 1.6508e+00, -1.6161e+00,  1.9984e+00,  ...,  2.3369e-01,\n",
      "           -1.4068e-01,  1.3834e-02],\n",
      "          [ 1.4325e+00, -2.1635e+00,  1.4262e+00,  ..., -5.7748e-01,\n",
      "           -4.0548e-01, -6.1846e-01]],\n",
      "\n",
      "         [[ 2.9693e+00, -2.6263e-01,  5.3581e-02,  ..., -1.5238e-01,\n",
      "           -3.3053e-01, -2.5695e+00],\n",
      "          [ 1.7126e+00, -1.3214e+00, -1.1983e-01,  ..., -5.2617e-01,\n",
      "            3.3351e-01, -6.0026e-01],\n",
      "          [ 1.4818e+00, -2.3037e+00, -7.8691e-01,  ...,  4.7131e-01,\n",
      "           -7.0157e-01, -7.8922e-01],\n",
      "          ...,\n",
      "          [ 1.1337e+00, -1.8982e+00,  6.7457e-01,  ..., -4.2819e-01,\n",
      "            7.7384e-01, -1.4693e+00],\n",
      "          [ 2.0963e+00, -1.7153e+00,  1.9441e-01,  ..., -6.3067e-01,\n",
      "           -8.8105e-01, -7.0252e-01],\n",
      "          [ 1.2985e+00, -1.5108e+00, -3.3813e-01,  ...,  5.4297e-01,\n",
      "           -4.1947e-01, -9.1731e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0390e-01,  4.0736e-01,  1.8180e-02,  ...,  2.5253e-03,\n",
      "           -9.3476e-01, -3.6676e-01],\n",
      "          [-7.3233e-01,  5.0197e-01,  3.7399e-01,  ..., -5.7988e-01,\n",
      "           -6.0307e-01,  7.8627e-01],\n",
      "          [ 1.8954e-01,  1.5723e+00, -5.3671e-01,  ...,  4.4913e-01,\n",
      "           -4.9897e-01,  2.0893e-01],\n",
      "          ...,\n",
      "          [-8.0686e-01,  1.4979e+00, -8.6293e-01,  ...,  7.4428e-01,\n",
      "           -4.7822e-01,  7.2112e-01],\n",
      "          [-1.4095e-01,  6.9975e-01,  9.1203e-01,  ..., -2.6367e-02,\n",
      "           -1.1290e+00,  4.3362e-01],\n",
      "          [-1.2520e-01,  5.4578e-02,  9.4669e-02,  ...,  6.6685e-01,\n",
      "           -4.1829e-01, -4.5440e-01]],\n",
      "\n",
      "         [[ 7.2612e-01, -4.2967e-01,  2.8324e-01,  ..., -1.1672e-01,\n",
      "            1.3933e-01,  7.2145e-01],\n",
      "          [ 1.3677e+00,  1.1154e+00, -1.8131e+00,  ...,  2.6832e-01,\n",
      "           -2.0488e-01, -2.9930e-01],\n",
      "          [ 1.5663e+00,  4.0057e-01, -1.3101e+00,  ...,  1.2970e+00,\n",
      "           -7.2437e-01, -8.4790e-01],\n",
      "          ...,\n",
      "          [-2.6476e-01,  6.2492e-01, -2.6271e+00,  ..., -1.8815e-01,\n",
      "            4.2124e-01,  6.7355e-01],\n",
      "          [ 6.5184e-01,  1.1675e+00, -1.7027e+00,  ..., -5.0583e-01,\n",
      "            1.4618e-01, -7.0388e-01],\n",
      "          [ 9.6472e-01,  1.4951e+00, -1.2521e+00,  ..., -1.6103e-01,\n",
      "           -1.0742e-01, -4.3000e-01]],\n",
      "\n",
      "         [[ 5.2773e-01,  3.6801e-01, -2.2068e-01,  ...,  2.0785e-01,\n",
      "            7.4279e-01,  1.5460e+00],\n",
      "          [-6.4291e-01,  7.1110e-01,  8.1627e-01,  ...,  1.1801e+00,\n",
      "            2.4778e-01,  1.4438e+00],\n",
      "          [ 1.6832e-01, -1.9261e-01,  6.5662e-01,  ...,  4.0717e-01,\n",
      "            5.8857e-01,  1.0076e-01],\n",
      "          ...,\n",
      "          [ 3.7968e-01,  3.7319e-01, -5.4577e-01,  ..., -1.1682e-01,\n",
      "           -4.8790e-01,  4.4752e-01],\n",
      "          [ 4.5768e-01,  2.0912e-01, -4.0089e-01,  ...,  2.9128e-01,\n",
      "           -1.3507e-01, -2.3044e-01],\n",
      "          [-9.1182e-02,  2.4452e-01,  1.5232e+00,  ...,  4.9287e-01,\n",
      "            8.5353e-01,  1.7829e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.2429e-01, -5.6675e-02,  6.6704e-01,  ...,  8.3152e-01,\n",
      "           -1.7520e-01,  2.1104e-01],\n",
      "          [ 3.7887e-01, -3.6863e-01,  9.5634e-01,  ...,  1.2721e+00,\n",
      "           -1.9937e-01,  6.2892e-01],\n",
      "          [-6.9238e-02, -2.5053e-01,  9.0689e-01,  ...,  1.7059e+00,\n",
      "           -3.2272e-01,  7.0323e-01],\n",
      "          ...,\n",
      "          [ 2.6296e-01, -1.3960e+00, -1.7598e-01,  ...,  1.4221e+00,\n",
      "           -1.0764e+00,  1.5049e+00],\n",
      "          [-2.8745e-01, -8.6069e-01,  2.4706e-01,  ...,  1.7713e+00,\n",
      "           -5.7682e-01,  1.4037e+00],\n",
      "          [ 9.9616e-02, -1.4331e+00, -1.9695e-01,  ...,  1.3126e+00,\n",
      "           -1.1746e+00,  1.7421e+00]],\n",
      "\n",
      "         [[ 1.6604e-01, -6.9924e-01, -1.7982e-01,  ...,  3.0278e-01,\n",
      "           -5.5868e-01, -5.8917e-02],\n",
      "          [ 5.6470e-01, -2.2756e+00,  1.7713e+00,  ..., -1.0837e+00,\n",
      "           -4.9486e-01, -1.3870e+00],\n",
      "          [ 1.4602e+00, -1.8126e+00,  2.1915e+00,  ...,  2.9398e-01,\n",
      "           -5.4009e-01,  5.9772e-01],\n",
      "          ...,\n",
      "          [ 7.0042e-01, -2.2212e+00,  1.8817e+00,  ..., -1.1331e+00,\n",
      "           -1.1415e+00, -4.8367e-01],\n",
      "          [ 1.6676e+00, -1.9181e+00,  2.5655e+00,  ...,  1.0370e+00,\n",
      "           -1.2251e+00,  1.1752e+00],\n",
      "          [ 7.5811e-01, -2.2156e+00,  1.8967e+00,  ..., -9.6103e-01,\n",
      "           -1.1367e+00, -1.5798e-01]],\n",
      "\n",
      "         [[ 2.8368e+00, -3.9202e-02, -1.2037e+00,  ..., -2.0509e-01,\n",
      "           -3.9237e-01, -3.9575e+00],\n",
      "          [ 1.7602e+00, -2.1043e+00, -1.3814e+00,  ..., -3.4425e-01,\n",
      "            4.0242e-02, -1.5890e+00],\n",
      "          [ 1.7814e+00, -1.2556e+00, -1.3569e+00,  ...,  2.7431e-01,\n",
      "           -1.7833e+00, -1.0270e+00],\n",
      "          ...,\n",
      "          [ 2.3494e+00, -2.8370e+00, -7.1511e-01,  ..., -2.7012e-01,\n",
      "           -7.2415e-01, -7.2606e-01],\n",
      "          [ 2.2824e+00, -1.5489e+00, -1.1108e+00,  ...,  3.0174e-01,\n",
      "           -1.8018e+00, -3.3590e-01],\n",
      "          [ 2.3505e+00, -2.7199e+00, -5.4482e-01,  ...,  2.3132e-02,\n",
      "           -7.5684e-01, -9.7011e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3708e-01,  2.3692e-01, -6.1232e-01,  ...,  8.8688e-01,\n",
      "           -7.6804e-01, -3.0591e-01],\n",
      "          [-6.0827e-01,  1.5528e+00,  2.0250e-01,  ..., -2.7418e-01,\n",
      "           -1.3622e+00, -4.1268e-02],\n",
      "          [ 5.1581e-01,  1.0927e+00, -3.2241e-01,  ...,  8.4932e-02,\n",
      "           -7.1221e-01, -5.8974e-01],\n",
      "          ...,\n",
      "          [-3.9173e-01,  1.7249e+00, -5.2930e-01,  ...,  7.8097e-02,\n",
      "           -8.3100e-01,  8.5542e-02],\n",
      "          [ 4.1729e-01,  1.3710e+00, -5.9640e-01,  ..., -2.6153e-01,\n",
      "           -1.2450e+00, -9.0136e-01],\n",
      "          [-5.8734e-01,  1.5257e+00, -6.7609e-01,  ..., -4.2001e-02,\n",
      "           -7.8755e-01, -1.5671e-02]],\n",
      "\n",
      "         [[ 6.1777e-01,  7.3267e-03, -5.9577e-02,  ...,  8.4292e-01,\n",
      "            5.3361e-01,  3.7327e-03],\n",
      "          [ 1.0529e+00,  1.3927e+00, -1.9463e+00,  ..., -2.0599e-01,\n",
      "            4.6223e-01, -5.6201e-02],\n",
      "          [ 1.2426e+00,  8.0200e-01, -2.1633e+00,  ...,  6.3162e-01,\n",
      "           -2.8640e-01, -1.0149e+00],\n",
      "          ...,\n",
      "          [ 1.0774e+00,  1.0711e+00, -1.7110e+00,  ...,  9.5071e-01,\n",
      "            6.3788e-01, -4.9920e-01],\n",
      "          [ 1.1615e+00,  1.1892e+00, -1.8102e+00,  ...,  7.7440e-01,\n",
      "            3.6738e-01, -1.3174e+00],\n",
      "          [ 1.2618e+00,  1.0086e+00, -1.4883e+00,  ...,  1.2245e+00,\n",
      "            4.6693e-01, -3.3176e-01]],\n",
      "\n",
      "         [[-8.8583e-02, -2.8722e-01,  1.4807e-01,  ..., -3.6068e-01,\n",
      "            6.1505e-01,  1.7552e+00],\n",
      "          [-3.6509e-01, -7.4513e-04,  7.5476e-01,  ..., -9.3147e-01,\n",
      "           -3.8101e-01,  1.1444e+00],\n",
      "          [ 1.8490e-01, -1.4016e+00,  5.7884e-01,  ..., -3.7062e-01,\n",
      "            5.4454e-02,  2.4992e-01],\n",
      "          ...,\n",
      "          [ 2.6249e-01, -9.4667e-01,  1.3082e+00,  ..., -9.8388e-01,\n",
      "           -2.8081e-01,  4.2240e+00],\n",
      "          [-7.0162e-02, -1.3467e+00,  8.4500e-01,  ..., -8.5827e-01,\n",
      "            2.4829e-01,  2.0116e+00],\n",
      "          [ 1.7229e-02, -1.0863e+00,  1.2945e+00,  ..., -9.1738e-01,\n",
      "           -1.3888e-01,  3.9234e+00]]]], grad_fn=<PermuteBackward0>)\n",
      "after transposing the new key layer shape is: torch.Size([2, 12, 7, 64]), new value layer is: torch.Size([2, 12, 7, 64]) and query layer is: torch.Size([2, 12, 7, 64])\n",
      "attention scores shape is: torch.Size([2, 12, 7, 7])\n",
      "Attention mask is: tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]])\n",
      "attention scores before mask is: tensor([[[[ 5.1802e-01, -2.2422e+00, -1.8733e+00,  ..., -2.2612e+00,\n",
      "           -2.1938e+00,  7.3675e-01],\n",
      "          [-2.5367e+00, -3.1794e+00, -4.6498e+00,  ..., -4.0561e+00,\n",
      "           -3.6223e+00,  2.0448e+00],\n",
      "          [-2.0933e+00, -2.5531e+00, -3.8380e+00,  ..., -3.9475e+00,\n",
      "           -3.1174e+00,  2.1336e+00],\n",
      "          ...,\n",
      "          [-2.6543e+00, -3.0456e+00, -4.2688e+00,  ..., -4.7494e+00,\n",
      "           -3.2667e+00,  2.0145e+00],\n",
      "          [-2.5690e+00, -3.0752e+00, -3.9229e+00,  ..., -3.7927e+00,\n",
      "           -2.8693e+00,  1.7792e+00],\n",
      "          [-2.0807e+00, -2.4943e+00, -2.2856e+00,  ..., -3.1252e+00,\n",
      "           -3.0142e+00,  2.5472e+00]],\n",
      "\n",
      "         [[ 6.4192e-02, -1.4947e+00, -1.5872e+00,  ..., -1.8007e+00,\n",
      "           -9.5180e-01, -1.1029e-01],\n",
      "          [-1.1059e+00, -1.5400e+00, -2.1152e+00,  ..., -1.5738e+00,\n",
      "           -5.7895e-01,  2.2599e+00],\n",
      "          [-1.9539e+00, -1.7955e+00, -3.3297e+00,  ..., -3.1010e+00,\n",
      "           -1.9380e+00,  2.8802e+00],\n",
      "          ...,\n",
      "          [-1.3050e+00, -1.5263e+00, -1.7932e+00,  ..., -1.9581e+00,\n",
      "           -1.4978e+00,  2.5925e+00],\n",
      "          [-3.1714e-01,  1.6806e-01, -4.6123e-01,  ..., -2.1730e-01,\n",
      "           -6.2126e-02,  2.3336e+00],\n",
      "          [-1.5616e+00, -1.1109e+00, -1.7488e+00,  ..., -1.3846e+00,\n",
      "           -5.3850e-01,  3.2423e+00]],\n",
      "\n",
      "         [[ 1.7226e+00,  2.8520e-01,  1.1045e-01,  ..., -5.8203e-01,\n",
      "            5.8848e-02,  1.3890e-01],\n",
      "          [-1.4173e+00, -3.1799e-01, -5.5886e-01,  ..., -1.0032e+00,\n",
      "           -4.4658e-01,  1.0919e+00],\n",
      "          [-3.1482e+00, -1.2244e+00, -1.7137e+00,  ..., -1.5610e+00,\n",
      "           -8.2114e-01,  1.5389e+00],\n",
      "          ...,\n",
      "          [-1.5294e+00, -7.6665e-01, -1.5154e+00,  ..., -1.1536e+00,\n",
      "           -1.2060e+00,  1.3200e+00],\n",
      "          [-1.7112e+00, -1.5810e+00, -2.4079e+00,  ..., -2.6057e+00,\n",
      "           -9.3475e-01,  2.0199e+00],\n",
      "          [-2.1328e+00, -2.0275e+00, -2.4653e+00,  ..., -2.5357e+00,\n",
      "           -1.6058e+00,  2.1847e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2796e+00,  1.1081e+00,  5.0488e-01,  ...,  1.6793e+00,\n",
      "            2.3129e+00, -2.6406e-01],\n",
      "          [ 2.1274e-03, -5.8946e-02, -9.4016e-01,  ..., -2.8134e-01,\n",
      "            2.8556e-01,  3.1358e-01],\n",
      "          [-3.4294e-01, -5.9664e-01, -1.5786e+00,  ..., -5.6153e-01,\n",
      "            1.3704e-01,  8.4528e-01],\n",
      "          ...,\n",
      "          [-7.4386e-01, -1.6915e+00, -2.2256e+00,  ..., -5.3148e-01,\n",
      "           -1.9123e-01,  1.1749e+00],\n",
      "          [-5.8961e-01, -1.2665e+00, -1.9876e+00,  ..., -1.2858e+00,\n",
      "            1.1769e+00,  1.5928e+00],\n",
      "          [-1.4913e+00, -2.3731e+00, -2.9804e+00,  ..., -2.5121e+00,\n",
      "           -1.5114e+00,  1.8834e+00]],\n",
      "\n",
      "         [[-3.0247e+00, -1.8236e+00, -1.3143e+00,  ..., -2.2714e+00,\n",
      "           -1.7241e+00,  5.4224e-01],\n",
      "          [-2.0937e+00, -5.5066e-02, -1.5477e+00,  ..., -9.1033e-01,\n",
      "           -1.0682e+00,  2.4265e+00],\n",
      "          [-2.4092e+00, -8.7713e-01, -1.4703e+00,  ..., -1.0755e+00,\n",
      "           -1.4530e+00,  2.3663e+00],\n",
      "          ...,\n",
      "          [-1.8657e+00, -8.3590e-01, -1.1503e+00,  ..., -3.7187e-01,\n",
      "           -4.9568e-01,  2.6225e+00],\n",
      "          [-1.5756e+00, -3.6176e-01, -1.4104e+00,  ..., -6.7604e-01,\n",
      "           -1.0789e+00,  2.2802e+00],\n",
      "          [-2.4343e+00, -1.5877e+00, -2.0954e+00,  ..., -2.4012e+00,\n",
      "           -1.6699e+00,  2.6977e+00]],\n",
      "\n",
      "         [[-3.9676e+00, -1.7626e+00, -1.8445e+00,  ..., -3.2624e+00,\n",
      "           -1.7336e+00,  6.5923e-01],\n",
      "          [-2.2957e+00, -2.0241e+00, -3.1116e+00,  ..., -3.2534e+00,\n",
      "           -2.6785e+00,  2.1498e+00],\n",
      "          [-2.8177e+00, -1.9140e+00, -2.6666e+00,  ..., -3.0562e+00,\n",
      "           -2.5293e+00,  2.3964e+00],\n",
      "          ...,\n",
      "          [-2.9049e+00, -2.9002e+00, -3.0990e+00,  ..., -3.1929e+00,\n",
      "           -2.6501e+00,  2.2567e+00],\n",
      "          [-1.3561e+00, -1.7643e+00, -2.0230e+00,  ..., -2.3930e+00,\n",
      "           -1.7240e+00,  1.7489e+00],\n",
      "          [-2.6193e+00, -2.6726e+00, -3.1513e+00,  ..., -2.8878e+00,\n",
      "           -2.2251e+00,  2.7970e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3529e-01, -1.7081e+00, -2.1075e+00,  ..., -5.0756e-01,\n",
      "           -8.1542e-01, -2.1826e-01],\n",
      "          [-1.1418e+00, -3.0022e+00, -2.5772e+00,  ..., -4.0170e+00,\n",
      "           -2.8101e+00, -3.8857e+00],\n",
      "          [-1.1609e+00, -2.4212e+00, -2.1763e+00,  ..., -3.5085e+00,\n",
      "           -2.2394e+00, -3.3690e+00],\n",
      "          ...,\n",
      "          [-1.1534e+00, -3.7864e+00, -3.1001e+00,  ..., -5.6264e+00,\n",
      "           -3.5870e+00, -5.3748e+00],\n",
      "          [-1.1364e+00, -3.0778e+00, -2.6333e+00,  ..., -4.4296e+00,\n",
      "           -2.5339e+00, -4.1599e+00],\n",
      "          [-1.1055e+00, -3.7541e+00, -3.0910e+00,  ..., -5.4461e+00,\n",
      "           -3.4295e+00, -5.1591e+00]],\n",
      "\n",
      "         [[-1.4330e+00, -2.0709e+00, -2.0918e+00,  ..., -9.8794e-01,\n",
      "           -1.5618e+00, -8.2931e-01],\n",
      "          [-1.1402e+00, -1.8539e+00, -1.7658e+00,  ..., -2.4948e+00,\n",
      "           -1.5021e+00, -2.2003e+00],\n",
      "          [-1.0915e+00, -6.4809e-01, -1.2041e+00,  ..., -9.2583e-01,\n",
      "           -1.0054e+00, -8.7267e-01],\n",
      "          ...,\n",
      "          [-5.6084e-01, -3.1309e-01, -4.7741e-01,  ..., -1.2703e+00,\n",
      "           -6.8820e-01, -1.2146e+00],\n",
      "          [ 5.7079e-02,  7.2548e-01, -2.8194e-01,  ..., -3.5988e-01,\n",
      "           -4.3751e-01, -3.5988e-01],\n",
      "          [-3.4216e-01,  9.1284e-02, -2.0205e-01,  ..., -1.0229e+00,\n",
      "           -4.9065e-01, -1.0084e+00]],\n",
      "\n",
      "         [[-5.7709e-02,  2.4200e-02, -5.4530e-01,  ..., -1.0734e+00,\n",
      "           -6.9968e-01, -9.2574e-01],\n",
      "          [-4.7676e-01, -6.2450e-01, -3.4558e-01,  ..., -7.6228e-01,\n",
      "           -4.7988e-02, -4.4638e-01],\n",
      "          [-1.5118e+00, -1.5990e+00, -1.3883e+00,  ..., -1.4739e+00,\n",
      "           -1.1020e+00, -1.1955e+00],\n",
      "          ...,\n",
      "          [-1.5786e+00, -2.9972e+00, -1.6598e+00,  ..., -3.7338e+00,\n",
      "           -2.4221e+00, -3.4194e+00],\n",
      "          [-1.8815e+00, -2.4673e+00, -2.2119e+00,  ..., -2.8924e+00,\n",
      "           -2.3389e+00, -2.5261e+00],\n",
      "          [-1.5759e+00, -2.8763e+00, -1.7993e+00,  ..., -3.6882e+00,\n",
      "           -2.5044e+00, -3.3238e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6646e+00,  9.8022e-01,  1.3255e+00,  ...,  1.2427e+00,\n",
      "            9.7294e-01,  1.4375e+00],\n",
      "          [-9.3344e-01, -1.1241e+00, -1.4960e+00,  ..., -1.9078e+00,\n",
      "           -1.6018e+00, -1.8918e+00],\n",
      "          [-1.1971e+00, -2.1940e+00, -1.5707e+00,  ..., -2.4183e+00,\n",
      "           -1.7234e+00, -2.1700e+00],\n",
      "          ...,\n",
      "          [-1.9772e+00, -2.8991e+00, -3.2247e+00,  ..., -3.5465e+00,\n",
      "           -3.2894e+00, -3.4984e+00],\n",
      "          [-1.5940e+00, -2.9399e+00, -2.4773e+00,  ..., -3.2950e+00,\n",
      "           -2.5766e+00, -3.0910e+00],\n",
      "          [-1.8966e+00, -2.7256e+00, -3.1020e+00,  ..., -3.2900e+00,\n",
      "           -3.1551e+00, -3.2111e+00]],\n",
      "\n",
      "         [[-2.4622e+00, -1.2677e+00, -9.6276e-01,  ...,  1.1807e-01,\n",
      "            2.9338e-01,  3.1267e-01],\n",
      "          [-1.3654e+00,  5.4752e-01, -9.3341e-01,  ..., -1.6647e+00,\n",
      "           -1.5560e+00, -1.8909e+00],\n",
      "          [-1.5004e+00, -2.8688e-01, -1.8129e+00,  ..., -2.2399e+00,\n",
      "           -2.5970e+00, -2.3190e+00],\n",
      "          ...,\n",
      "          [-1.1389e+00,  6.6374e-01, -1.2471e+00,  ..., -1.7779e+00,\n",
      "           -1.9864e+00, -1.9384e+00],\n",
      "          [-9.0545e-01,  4.6476e-01, -1.0376e+00,  ..., -1.5458e+00,\n",
      "           -1.6228e+00, -1.5351e+00],\n",
      "          [-1.0946e+00,  6.9031e-01, -1.1918e+00,  ..., -1.5544e+00,\n",
      "           -1.7838e+00, -1.6459e+00]],\n",
      "\n",
      "         [[-4.0283e+00, -1.2402e+00, -2.0336e+00,  ..., -5.9212e-01,\n",
      "           -1.0540e+00, -4.7797e-01],\n",
      "          [-1.9929e+00, -7.9440e-01, -1.8136e+00,  ..., -2.0081e+00,\n",
      "           -1.8642e+00, -2.0462e+00],\n",
      "          [-1.8134e+00, -1.3818e-01, -1.7641e+00,  ..., -1.5139e+00,\n",
      "           -1.6067e+00, -1.4567e+00],\n",
      "          ...,\n",
      "          [-8.5792e-01,  1.3758e-01, -1.7084e+00,  ..., -8.2450e-01,\n",
      "           -1.4112e+00, -8.8347e-01],\n",
      "          [-9.3102e-01,  3.8083e-01, -1.1433e+00,  ..., -9.0413e-01,\n",
      "           -9.8826e-01, -8.4386e-01],\n",
      "          [-1.0440e+00, -6.9929e-02, -1.8433e+00,  ..., -8.5624e-01,\n",
      "           -1.4629e+00, -8.6314e-01]]]], grad_fn=<DivBackward0>) of shape: torch.Size([2, 12, 7, 7])\n",
      "attention scores after mask is: tensor([[[[ 5.1802e-01, -2.2422e+00, -1.8733e+00,  ..., -2.2612e+00,\n",
      "           -2.1938e+00,  7.3675e-01],\n",
      "          [-2.5367e+00, -3.1794e+00, -4.6498e+00,  ..., -4.0561e+00,\n",
      "           -3.6223e+00,  2.0448e+00],\n",
      "          [-2.0933e+00, -2.5531e+00, -3.8380e+00,  ..., -3.9475e+00,\n",
      "           -3.1174e+00,  2.1336e+00],\n",
      "          ...,\n",
      "          [-2.6543e+00, -3.0456e+00, -4.2688e+00,  ..., -4.7494e+00,\n",
      "           -3.2667e+00,  2.0145e+00],\n",
      "          [-2.5690e+00, -3.0752e+00, -3.9229e+00,  ..., -3.7927e+00,\n",
      "           -2.8693e+00,  1.7792e+00],\n",
      "          [-2.0807e+00, -2.4943e+00, -2.2856e+00,  ..., -3.1252e+00,\n",
      "           -3.0142e+00,  2.5472e+00]],\n",
      "\n",
      "         [[ 6.4192e-02, -1.4947e+00, -1.5872e+00,  ..., -1.8007e+00,\n",
      "           -9.5180e-01, -1.1029e-01],\n",
      "          [-1.1059e+00, -1.5400e+00, -2.1152e+00,  ..., -1.5738e+00,\n",
      "           -5.7895e-01,  2.2599e+00],\n",
      "          [-1.9539e+00, -1.7955e+00, -3.3297e+00,  ..., -3.1010e+00,\n",
      "           -1.9380e+00,  2.8802e+00],\n",
      "          ...,\n",
      "          [-1.3050e+00, -1.5263e+00, -1.7932e+00,  ..., -1.9581e+00,\n",
      "           -1.4978e+00,  2.5925e+00],\n",
      "          [-3.1714e-01,  1.6806e-01, -4.6123e-01,  ..., -2.1730e-01,\n",
      "           -6.2126e-02,  2.3336e+00],\n",
      "          [-1.5616e+00, -1.1109e+00, -1.7488e+00,  ..., -1.3846e+00,\n",
      "           -5.3850e-01,  3.2423e+00]],\n",
      "\n",
      "         [[ 1.7226e+00,  2.8520e-01,  1.1045e-01,  ..., -5.8203e-01,\n",
      "            5.8848e-02,  1.3890e-01],\n",
      "          [-1.4173e+00, -3.1799e-01, -5.5886e-01,  ..., -1.0032e+00,\n",
      "           -4.4658e-01,  1.0919e+00],\n",
      "          [-3.1482e+00, -1.2244e+00, -1.7137e+00,  ..., -1.5610e+00,\n",
      "           -8.2114e-01,  1.5389e+00],\n",
      "          ...,\n",
      "          [-1.5294e+00, -7.6665e-01, -1.5154e+00,  ..., -1.1536e+00,\n",
      "           -1.2060e+00,  1.3200e+00],\n",
      "          [-1.7112e+00, -1.5810e+00, -2.4079e+00,  ..., -2.6057e+00,\n",
      "           -9.3475e-01,  2.0199e+00],\n",
      "          [-2.1328e+00, -2.0275e+00, -2.4653e+00,  ..., -2.5357e+00,\n",
      "           -1.6058e+00,  2.1847e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2796e+00,  1.1081e+00,  5.0488e-01,  ...,  1.6793e+00,\n",
      "            2.3129e+00, -2.6406e-01],\n",
      "          [ 2.1274e-03, -5.8946e-02, -9.4016e-01,  ..., -2.8134e-01,\n",
      "            2.8556e-01,  3.1358e-01],\n",
      "          [-3.4294e-01, -5.9664e-01, -1.5786e+00,  ..., -5.6153e-01,\n",
      "            1.3704e-01,  8.4528e-01],\n",
      "          ...,\n",
      "          [-7.4386e-01, -1.6915e+00, -2.2256e+00,  ..., -5.3148e-01,\n",
      "           -1.9123e-01,  1.1749e+00],\n",
      "          [-5.8961e-01, -1.2665e+00, -1.9876e+00,  ..., -1.2858e+00,\n",
      "            1.1769e+00,  1.5928e+00],\n",
      "          [-1.4913e+00, -2.3731e+00, -2.9804e+00,  ..., -2.5121e+00,\n",
      "           -1.5114e+00,  1.8834e+00]],\n",
      "\n",
      "         [[-3.0247e+00, -1.8236e+00, -1.3143e+00,  ..., -2.2714e+00,\n",
      "           -1.7241e+00,  5.4224e-01],\n",
      "          [-2.0937e+00, -5.5066e-02, -1.5477e+00,  ..., -9.1033e-01,\n",
      "           -1.0682e+00,  2.4265e+00],\n",
      "          [-2.4092e+00, -8.7713e-01, -1.4703e+00,  ..., -1.0755e+00,\n",
      "           -1.4530e+00,  2.3663e+00],\n",
      "          ...,\n",
      "          [-1.8657e+00, -8.3590e-01, -1.1503e+00,  ..., -3.7187e-01,\n",
      "           -4.9568e-01,  2.6225e+00],\n",
      "          [-1.5756e+00, -3.6176e-01, -1.4104e+00,  ..., -6.7604e-01,\n",
      "           -1.0789e+00,  2.2802e+00],\n",
      "          [-2.4343e+00, -1.5877e+00, -2.0954e+00,  ..., -2.4012e+00,\n",
      "           -1.6699e+00,  2.6977e+00]],\n",
      "\n",
      "         [[-3.9676e+00, -1.7626e+00, -1.8445e+00,  ..., -3.2624e+00,\n",
      "           -1.7336e+00,  6.5923e-01],\n",
      "          [-2.2957e+00, -2.0241e+00, -3.1116e+00,  ..., -3.2534e+00,\n",
      "           -2.6785e+00,  2.1498e+00],\n",
      "          [-2.8177e+00, -1.9140e+00, -2.6666e+00,  ..., -3.0562e+00,\n",
      "           -2.5293e+00,  2.3964e+00],\n",
      "          ...,\n",
      "          [-2.9049e+00, -2.9002e+00, -3.0990e+00,  ..., -3.1929e+00,\n",
      "           -2.6501e+00,  2.2567e+00],\n",
      "          [-1.3561e+00, -1.7643e+00, -2.0230e+00,  ..., -2.3930e+00,\n",
      "           -1.7240e+00,  1.7489e+00],\n",
      "          [-2.6193e+00, -2.6726e+00, -3.1513e+00,  ..., -2.8878e+00,\n",
      "           -2.2251e+00,  2.7970e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3529e-01, -1.7081e+00, -2.1075e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1418e+00, -3.0022e+00, -2.5772e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1609e+00, -2.4212e+00, -2.1763e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-1.1534e+00, -3.7864e+00, -3.1001e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1364e+00, -3.0778e+00, -2.6333e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1055e+00, -3.7541e+00, -3.0910e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-1.4330e+00, -2.0709e+00, -2.0918e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1402e+00, -1.8539e+00, -1.7658e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.0915e+00, -6.4809e-01, -1.2041e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-5.6084e-01, -3.1309e-01, -4.7741e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [ 5.7079e-02,  7.2548e-01, -2.8194e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-3.4216e-01,  9.1284e-02, -2.0205e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-5.7709e-02,  2.4200e-02, -5.4530e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-4.7676e-01, -6.2450e-01, -3.4558e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.5118e+00, -1.5990e+00, -1.3883e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-1.5786e+00, -2.9972e+00, -1.6598e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.8815e+00, -2.4673e+00, -2.2119e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.5759e+00, -2.8763e+00, -1.7993e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6646e+00,  9.8022e-01,  1.3255e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-9.3344e-01, -1.1241e+00, -1.4960e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.1971e+00, -2.1940e+00, -1.5707e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-1.9772e+00, -2.8991e+00, -3.2247e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.5940e+00, -2.9399e+00, -2.4773e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.8966e+00, -2.7256e+00, -3.1020e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-2.4622e+00, -1.2677e+00, -9.6276e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.3654e+00,  5.4752e-01, -9.3341e-01,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.5004e+00, -2.8688e-01, -1.8129e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-1.1389e+00,  6.6374e-01, -1.2471e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-9.0545e-01,  4.6476e-01, -1.0376e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.0946e+00,  6.9031e-01, -1.1918e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]],\n",
      "\n",
      "         [[-4.0283e+00, -1.2402e+00, -2.0336e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.9929e+00, -7.9440e-01, -1.8136e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.8134e+00, -1.3818e-01, -1.7641e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          ...,\n",
      "          [-8.5792e-01,  1.3758e-01, -1.7084e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-9.3102e-01,  3.8083e-01, -1.1433e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38],\n",
      "          [-1.0440e+00, -6.9929e-02, -1.8433e+00,  ..., -3.4028e+38,\n",
      "           -3.4028e+38, -3.4028e+38]]]], grad_fn=<AddBackward0>) of shape torch.Size([2, 12, 7, 7])\n",
      "attention probs shape is: tensor([[[[0.3929, 0.0249, 0.0360,  ..., 0.0244, 0.0261, 0.4889],\n",
      "          [0.0100, 0.0053, 0.0012,  ..., 0.0022, 0.0034, 0.9765],\n",
      "          [0.0141, 0.0089, 0.0025,  ..., 0.0022, 0.0051, 0.9662],\n",
      "          ...,\n",
      "          [0.0092, 0.0062, 0.0018,  ..., 0.0011, 0.0050, 0.9758],\n",
      "          [0.0124, 0.0075, 0.0032,  ..., 0.0037, 0.0092, 0.9625],\n",
      "          [0.0095, 0.0063, 0.0077,  ..., 0.0033, 0.0037, 0.9674]],\n",
      "\n",
      "         [[0.3350, 0.0705, 0.0643,  ..., 0.0519, 0.1213, 0.2814],\n",
      "          [0.0297, 0.0193, 0.0108,  ..., 0.0186, 0.0504, 0.8608],\n",
      "          [0.0077, 0.0090, 0.0019,  ..., 0.0024, 0.0078, 0.9697],\n",
      "          ...,\n",
      "          [0.0186, 0.0149, 0.0114,  ..., 0.0097, 0.0153, 0.9164],\n",
      "          [0.0482, 0.0783, 0.0417,  ..., 0.0533, 0.0622, 0.6828],\n",
      "          [0.0077, 0.0120, 0.0064,  ..., 0.0092, 0.0213, 0.9353]],\n",
      "\n",
      "         [[0.4752, 0.1129, 0.0948,  ..., 0.0474, 0.0900, 0.0975],\n",
      "          [0.0408, 0.1224, 0.0962,  ..., 0.0617, 0.1076, 0.5013],\n",
      "          [0.0072, 0.0494, 0.0303,  ..., 0.0353, 0.0739, 0.7831],\n",
      "          ...,\n",
      "          [0.0396, 0.0849, 0.0402,  ..., 0.0577, 0.0547, 0.6845],\n",
      "          [0.0210, 0.0239, 0.0105,  ..., 0.0086, 0.0456, 0.8755],\n",
      "          [0.0124, 0.0138, 0.0089,  ..., 0.0083, 0.0210, 0.9283]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1288, 0.1085, 0.0593,  ..., 0.1920, 0.3619, 0.0275],\n",
      "          [0.1435, 0.1350, 0.0559,  ..., 0.1081, 0.1906, 0.1960],\n",
      "          [0.1155, 0.0896, 0.0336,  ..., 0.0928, 0.1866, 0.3788],\n",
      "          ...,\n",
      "          [0.0847, 0.0328, 0.0192,  ..., 0.1047, 0.1472, 0.5769],\n",
      "          [0.0581, 0.0295, 0.0144,  ..., 0.0290, 0.3398, 0.5151],\n",
      "          [0.0309, 0.0128, 0.0070,  ..., 0.0111, 0.0303, 0.9039]],\n",
      "\n",
      "         [[0.0192, 0.0638, 0.1062,  ..., 0.0408, 0.0705, 0.6797],\n",
      "          [0.0091, 0.0699, 0.0157,  ..., 0.0297, 0.0254, 0.8358],\n",
      "          [0.0074, 0.0342, 0.0189,  ..., 0.0281, 0.0192, 0.8768],\n",
      "          ...,\n",
      "          [0.0093, 0.0260, 0.0190,  ..., 0.0414, 0.0366, 0.8274],\n",
      "          [0.0172, 0.0579, 0.0203,  ..., 0.0423, 0.0282, 0.8123],\n",
      "          [0.0056, 0.0131, 0.0079,  ..., 0.0058, 0.0121, 0.9505]],\n",
      "\n",
      "         [[0.0075, 0.0676, 0.0623,  ..., 0.0151, 0.0696, 0.7616],\n",
      "          [0.0112, 0.0147, 0.0050,  ..., 0.0043, 0.0076, 0.9543],\n",
      "          [0.0052, 0.0129, 0.0061,  ..., 0.0041, 0.0070, 0.9619],\n",
      "          ...,\n",
      "          [0.0056, 0.0056, 0.0046,  ..., 0.0042, 0.0072, 0.9708],\n",
      "          [0.0386, 0.0257, 0.0198,  ..., 0.0137, 0.0267, 0.8618],\n",
      "          [0.0043, 0.0041, 0.0026,  ..., 0.0033, 0.0064, 0.9776]]],\n",
      "\n",
      "\n",
      "        [[[0.4160, 0.0488, 0.0327,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0354, 0.0055, 0.0084,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0539, 0.0153, 0.0195,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0247, 0.0018, 0.0035,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0399, 0.0057, 0.0089,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0261, 0.0018, 0.0036,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.2158, 0.1141, 0.1117,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0248, 0.0122, 0.0133,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0190, 0.0296, 0.0170,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0240, 0.0308, 0.0261,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0613, 0.1196, 0.0437,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0331, 0.0511, 0.0381,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.2670, 0.2898, 0.1639,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0846, 0.0730, 0.0964,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0340, 0.0312, 0.0385,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0043, 0.0010, 0.0040,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0074, 0.0041, 0.0053,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0048, 0.0013, 0.0038,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.4238, 0.2138, 0.3019,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0958, 0.0792, 0.0546,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0659, 0.0243, 0.0453,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0100, 0.0040, 0.0029,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0212, 0.0055, 0.0087,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0118, 0.0051, 0.0035,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0434, 0.1435, 0.1946,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0216, 0.1463, 0.0333,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0150, 0.0504, 0.0110,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0179, 0.1084, 0.0160,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0300, 0.1180, 0.0263,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0219, 0.1304, 0.0199,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0061, 0.0992, 0.0449,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0139, 0.0460, 0.0166,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0131, 0.0700, 0.0138,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0583, 0.1577, 0.0249,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0581, 0.2156, 0.0470,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0533, 0.1412, 0.0240,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "before context layer calc, attention_probs shape is:\n",
      " torch.Size([2, 12, 7, 7]), and value_layer shape is: \n",
      "torch.Size([2, 12, 7, 64])\n",
      "context layer after matmul is:\n",
      " tensor([[[[ 7.7308e-01,  2.8582e-02,  3.3100e-01,  ..., -9.5733e-02,\n",
      "           -3.4260e-01,  3.2999e-01],\n",
      "          [-1.8622e-02, -2.4069e-03,  2.5267e-02,  ..., -4.1006e-02,\n",
      "           -3.6423e-02, -1.4777e-02],\n",
      "          [-6.3011e-03, -3.5099e-03,  3.0166e-02,  ..., -4.0600e-02,\n",
      "           -4.2932e-02, -9.6523e-03],\n",
      "          ...,\n",
      "          [-1.8038e-02, -1.9893e-03,  2.5423e-02,  ..., -4.0752e-02,\n",
      "           -3.6754e-02, -1.3900e-02],\n",
      "          [-7.7710e-03, -7.8795e-03,  3.1680e-02,  ..., -4.2103e-02,\n",
      "           -4.3855e-02, -9.1769e-03],\n",
      "          [-1.8378e-02, -5.6424e-03,  2.3077e-02,  ..., -3.9649e-02,\n",
      "           -4.1021e-02, -1.2120e-02]],\n",
      "\n",
      "         [[ 9.1443e-02, -2.4716e-01, -2.9414e-01,  ...,  9.0251e-02,\n",
      "            2.6067e-01,  2.5210e-01],\n",
      "          [ 2.5775e-02, -5.4660e-02, -3.6733e-02,  ...,  4.3654e-02,\n",
      "            3.8305e-02,  6.1670e-02],\n",
      "          [ 3.7192e-03, -1.2496e-02,  2.7322e-02,  ...,  3.0901e-02,\n",
      "            9.8642e-03,  3.0632e-02],\n",
      "          ...,\n",
      "          [ 6.1791e-03, -2.6237e-02, -2.7409e-03,  ...,  4.1292e-02,\n",
      "            3.2393e-02,  4.6131e-02],\n",
      "          [ 4.6622e-02, -1.2345e-01, -1.3712e-01,  ...,  5.3953e-02,\n",
      "            1.1389e-01,  7.7248e-02],\n",
      "          [ 8.3742e-03, -2.3278e-02,  4.7008e-03,  ...,  3.8593e-02,\n",
      "            1.9964e-02,  4.1410e-02]],\n",
      "\n",
      "         [[-4.6342e-02, -4.7713e-01, -2.8092e-01,  ...,  1.0253e-01,\n",
      "            1.4139e-01, -1.4371e-01],\n",
      "          [-1.9485e-02, -3.1576e-02, -6.3958e-02,  ..., -1.1826e-02,\n",
      "           -4.7676e-02, -8.2543e-02],\n",
      "          [-4.6656e-03, -4.9439e-03, -7.0963e-03,  ..., -4.1317e-02,\n",
      "           -2.9045e-02, -2.7653e-03],\n",
      "          ...,\n",
      "          [-1.6462e-02, -4.3574e-02, -2.4048e-02,  ..., -6.1583e-03,\n",
      "           -8.1303e-03, -4.0597e-02],\n",
      "          [ 3.1422e-03, -1.3274e-02,  5.0480e-05,  ..., -3.5001e-02,\n",
      "           -1.2002e-02,  2.4369e-03],\n",
      "          [ 2.1583e-03, -2.2252e-03,  1.4555e-02,  ..., -2.1554e-02,\n",
      "           -7.5468e-03, -2.3962e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.5578e-02,  2.5448e-01, -6.7382e-01,  ..., -1.0064e-01,\n",
      "            3.9223e-01, -4.0478e-01],\n",
      "          [ 2.3459e-04,  1.7470e-01, -7.0276e-01,  ...,  4.1686e-02,\n",
      "            2.4892e-01, -2.1342e-01],\n",
      "          [ 2.0021e-02,  1.2385e-01, -5.1660e-01,  ..., -8.6775e-03,\n",
      "            2.2103e-01, -2.1757e-01],\n",
      "          ...,\n",
      "          [ 3.1517e-02,  9.7587e-02, -2.8709e-01,  ..., -6.7484e-02,\n",
      "            1.6175e-01, -2.4026e-01],\n",
      "          [ 1.0339e-01,  1.8269e-02, -3.7871e-01,  ..., -7.4004e-02,\n",
      "            3.2649e-01, -2.3484e-01],\n",
      "          [-2.5740e-04, -3.0534e-02, -1.1316e-01,  ..., -1.4836e-03,\n",
      "            2.8937e-02, -7.9734e-02]],\n",
      "\n",
      "         [[ 3.5861e-02, -1.1910e-01,  4.1782e-02,  ...,  3.4592e-02,\n",
      "            4.4091e-02,  1.5682e-01],\n",
      "          [ 5.0537e-02, -2.7134e-02,  1.9303e-02,  ...,  2.8166e-02,\n",
      "           -2.7777e-02,  7.3573e-02],\n",
      "          [ 2.6914e-02, -1.4426e-02,  9.9436e-03,  ...,  1.3549e-02,\n",
      "           -2.2173e-02,  4.1485e-02],\n",
      "          ...,\n",
      "          [ 5.6681e-02, -1.8086e-02,  8.5330e-03,  ...,  3.6837e-02,\n",
      "           -4.9611e-03,  1.1741e-02],\n",
      "          [ 5.4737e-02, -2.5701e-02,  1.6783e-02,  ...,  3.2621e-02,\n",
      "           -1.7041e-02,  6.3762e-02],\n",
      "          [ 6.1666e-03, -6.6266e-03,  2.8479e-03,  ..., -1.0802e-02,\n",
      "           -2.9393e-02,  1.5489e-02]],\n",
      "\n",
      "         [[ 5.2724e-02,  4.5659e-02, -1.5909e-02,  ..., -6.8821e-02,\n",
      "           -1.3388e-01,  3.6875e-02],\n",
      "          [-4.9616e-02,  1.4816e-02, -5.4131e-03,  ...,  2.4208e-03,\n",
      "           -1.8084e-02,  2.5491e-02],\n",
      "          [-4.9264e-02,  1.1316e-02, -5.6365e-03,  ...,  3.7026e-03,\n",
      "           -1.4325e-02,  2.9785e-02],\n",
      "          ...,\n",
      "          [-5.6617e-02,  7.4651e-03, -5.0029e-03,  ...,  1.0819e-02,\n",
      "           -6.0247e-03,  2.8416e-02],\n",
      "          [-1.8766e-02,  3.8305e-02, -4.2079e-05,  ..., -1.9415e-02,\n",
      "           -6.1365e-02,  1.0217e-02],\n",
      "          [-6.0269e-02,  4.8972e-03, -5.7368e-03,  ...,  1.3749e-02,\n",
      "           -2.1646e-03,  2.8422e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9550e-01, -1.3134e-01,  1.7725e-01,  ..., -1.4502e-02,\n",
      "           -4.2336e-01,  9.7905e-02],\n",
      "          [ 3.9057e-03, -2.0125e-02,  1.8893e-02,  ..., -1.7222e-02,\n",
      "           -7.1711e-02,  1.3156e-02],\n",
      "          [ 4.1145e-02, -4.7730e-02,  2.4105e-02,  ..., -1.6533e-02,\n",
      "           -1.2195e-01,  2.5950e-02],\n",
      "          ...,\n",
      "          [-1.6395e-02, -8.6655e-03,  1.5883e-02,  ..., -1.7401e-02,\n",
      "           -4.8836e-02,  7.4267e-03],\n",
      "          [ 1.1027e-02, -2.1211e-02,  2.0454e-02,  ..., -1.7260e-02,\n",
      "           -7.5835e-02,  1.4119e-02],\n",
      "          [-1.4201e-02, -8.9179e-03,  1.6448e-02,  ..., -1.7404e-02,\n",
      "           -4.9956e-02,  7.6879e-03]],\n",
      "\n",
      "         [[ 6.6898e-02, -2.3802e-01,  2.6402e-02,  ...,  3.7321e-02,\n",
      "            1.9752e-02,  4.3471e-01],\n",
      "          [ 6.5319e-03, -2.9161e-02,  3.6472e-02,  ...,  5.1833e-02,\n",
      "            1.4021e-02,  9.1117e-02],\n",
      "          [ 1.6436e-02, -4.3245e-02,  3.4720e-02,  ...,  4.5925e-02,\n",
      "            3.4364e-03,  9.4035e-02],\n",
      "          ...,\n",
      "          [ 2.0340e-02, -5.2130e-02,  3.3761e-02,  ...,  4.7612e-02,\n",
      "            4.3522e-03,  1.0418e-01],\n",
      "          [ 6.0625e-02, -1.4468e-01,  2.7783e-02,  ...,  1.7989e-02,\n",
      "           -2.9463e-02,  2.0889e-01],\n",
      "          [ 3.3043e-02, -7.8961e-02,  3.1465e-02,  ...,  4.2666e-02,\n",
      "           -3.1973e-03,  1.3120e-01]],\n",
      "\n",
      "         [[-4.6383e-01, -4.0041e-01,  9.3264e-02,  ...,  1.2791e-01,\n",
      "            2.1421e-01, -1.7419e-01],\n",
      "          [-1.9764e-01, -1.2987e-01,  5.1012e-02,  ...,  1.5771e-02,\n",
      "            1.0079e-01, -3.7053e-02],\n",
      "          [-8.6760e-02, -6.9250e-02,  4.3172e-02,  ...,  4.7654e-03,\n",
      "            4.2912e-02, -3.3243e-03],\n",
      "          ...,\n",
      "          [-2.0079e-02, -3.2310e-02,  3.7065e-02,  ..., -4.1973e-03,\n",
      "            7.7893e-03,  1.9990e-02],\n",
      "          [-2.4672e-02, -3.6677e-02,  3.7625e-02,  ..., -2.6428e-03,\n",
      "            9.7718e-03,  1.8003e-02],\n",
      "          [-2.0435e-02, -3.3049e-02,  3.7086e-02,  ..., -3.9533e-03,\n",
      "            7.8301e-03,  1.9868e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6947e-01,  6.3888e-01, -4.2811e-01,  ..., -4.6501e-02,\n",
      "            6.1146e-01, -1.4098e-02],\n",
      "          [-2.1958e-02,  1.4790e-01, -1.1068e-01,  ..., -2.0259e-02,\n",
      "            1.2425e-01, -1.0544e-02],\n",
      "          [-2.6753e-02,  6.7203e-02, -1.0233e-01,  ...,  2.0433e-02,\n",
      "            7.6963e-02, -2.3387e-02],\n",
      "          ...,\n",
      "          [-4.9838e-04, -1.4008e-02, -4.7258e-02,  ...,  2.2559e-02,\n",
      "           -5.2498e-03, -2.2078e-02],\n",
      "          [-6.8276e-03, -1.8832e-03, -5.7533e-02,  ...,  2.4496e-02,\n",
      "            6.4982e-03, -2.2446e-02],\n",
      "          [-1.1174e-03, -1.1285e-02, -4.8461e-02,  ...,  2.2041e-02,\n",
      "           -3.2994e-03, -2.1853e-02]],\n",
      "\n",
      "         [[ 2.2127e-01,  2.9066e-02, -3.3800e-01,  ..., -3.2984e-01,\n",
      "            5.2788e-02, -2.0538e-01],\n",
      "          [ 5.3865e-02, -1.0127e-02, -1.8527e-01,  ..., -1.2601e-01,\n",
      "            1.3885e-03, -1.2604e-01],\n",
      "          [ 6.3186e-03,  2.3272e-03, -6.6448e-02,  ..., -6.5702e-02,\n",
      "           -1.8497e-02, -5.4415e-02],\n",
      "          ...,\n",
      "          [ 2.6336e-02, -7.2297e-03, -1.3024e-01,  ..., -9.1539e-02,\n",
      "           -9.1706e-03, -9.3540e-02],\n",
      "          [ 4.4634e-02, -7.3769e-03, -1.5131e-01,  ..., -1.1567e-01,\n",
      "           -6.2626e-03, -1.0899e-01],\n",
      "          [ 3.7239e-02, -1.0612e-02, -1.5664e-01,  ..., -1.0578e-01,\n",
      "           -5.4486e-03, -1.1043e-01]],\n",
      "\n",
      "         [[ 1.2310e-01,  2.4927e-01,  1.4876e-01,  ..., -3.9942e-02,\n",
      "            3.1554e-02,  1.2339e-01],\n",
      "          [ 2.2059e-02,  1.0746e-01,  6.4823e-02,  ..., -1.4648e-02,\n",
      "            1.3896e-02,  8.2343e-02],\n",
      "          [ 5.6675e-02,  1.6010e-01,  9.5141e-02,  ..., -2.7020e-02,\n",
      "            2.8690e-02,  9.9482e-02],\n",
      "          ...,\n",
      "          [ 2.3772e-01,  4.3013e-01,  2.4834e-01,  ..., -8.4737e-02,\n",
      "            4.7021e-02,  1.4729e-01],\n",
      "          [ 3.4651e-01,  5.8593e-01,  3.3948e-01,  ..., -1.1455e-01,\n",
      "            6.6614e-02,  1.8897e-01],\n",
      "          [ 2.0720e-01,  3.8447e-01,  2.2228e-01,  ..., -7.4765e-02,\n",
      "            4.1144e-02,  1.3716e-01]]]], grad_fn=<UnsafeViewBackward0>) of shape: torch.Size([2, 12, 7, 64]) \n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs, output_attentions = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0061, 0.0992, 0.0449, 0.8498, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0139, 0.0460, 0.0166, 0.9236, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0131, 0.0700, 0.0138, 0.9031, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0040, 0.0077, 0.0035, 0.9848, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0583, 0.1577, 0.0249, 0.7591, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0581, 0.2156, 0.0470, 0.6794, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0533, 0.1412, 0.0240, 0.7816, 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[11][1][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = BertConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config.num_hidden_layers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n",
      "Number of attention heads is: 12\n",
      "\n",
      "attention_head_size is: 64\n",
      "all_head size is: 768\n",
      "Query is: Linear(in_features=768, out_features=768, bias=True), key is: Linear(in_features=768, out_features=768, bias=True), value is: Linear(in_features=768, out_features=768, bias=True)\n",
      "got layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'cls.seq_relationship.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'cls.predictions.decoder.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.10.attention.self.query.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "new_mmodel = BertModel.from_pretrained(model_name, config = bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0783,  0.0866,  0.1033,  ...,  0.1033, -0.0544,  0.1943],\n",
       "         [-0.1187, -0.5730,  0.5325,  ..., -0.4623, -0.2475,  0.8137],\n",
       "         [-0.1058, -0.9067,  0.2418,  ..., -0.1606, -0.9152,  1.0719],\n",
       "         ...,\n",
       "         [-0.1620, -0.8657,  0.4911,  ..., -0.1683, -0.1217,  0.6050],\n",
       "         [ 0.5600, -0.3490,  0.1551,  ...,  0.4750, -0.0517,  0.0820],\n",
       "         [ 0.7919,  0.1759, -0.0070,  ...,  0.2596, -0.6880, -0.2924]],\n",
       "\n",
       "        [[-0.2745,  0.1772, -0.1122,  ..., -0.1597,  0.0635,  0.5667],\n",
       "         [-0.0968,  0.0795,  0.3907,  ..., -0.0089,  0.4327, -0.3006],\n",
       "         [-0.5905,  0.1020, -0.0052,  ..., -0.0424, -0.2373,  0.3690],\n",
       "         ...,\n",
       "         [-0.4491,  0.1657,  0.5893,  ..., -0.2171, -0.0297, -0.0493],\n",
       "         [-0.6241, -0.2416,  0.2437,  ...,  0.2038, -0.0893,  0.1127],\n",
       "         [-0.3921,  0.0510,  0.5750,  ..., -0.1938, -0.1002, -0.0422]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention explanation \n",
    "(Delete stuff above attention explanation this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_1</th>\n",
       "      <td>0.402937</td>\n",
       "      <td>-1.700308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_2</th>\n",
       "      <td>2.288591</td>\n",
       "      <td>-1.089179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_3</th>\n",
       "      <td>2.064445</td>\n",
       "      <td>0.369130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            emb_0     emb_1\n",
       "token_1  0.402937 -1.700308\n",
       "token_2  2.288591 -1.089179\n",
       "token_3  2.064445  0.369130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "v = np.random.randn(3, 2)\n",
    "v = pd.DataFrame(v, columns=[f'emb_{i}' for i in range(v.shape[1])])\n",
    "v.index = ['token_1', 'token_2', 'token_3']\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_1</th>\n",
       "      <th>token_2</th>\n",
       "      <th>token_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token_1  token_2  token_3\n",
       "token_1        1        0        0\n",
       "token_2        0        1        0\n",
       "token_3        0        0        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "att_prob = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "att_prob = pd.DataFrame(att_prob, columns=['token_1', 'token_2', 'token_3'])\n",
    "att_prob.index = ['token_1', 'token_2', 'token_3']\n",
    "att_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_1</th>\n",
       "      <td>0.402937</td>\n",
       "      <td>-1.700308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_2</th>\n",
       "      <td>2.288591</td>\n",
       "      <td>-1.089179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_3</th>\n",
       "      <td>2.064445</td>\n",
       "      <td>0.369130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            emb_0     emb_1\n",
       "token_1  0.402937 -1.700308\n",
       "token_2  2.288591 -1.089179\n",
       "token_3  2.064445  0.369130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "att_prob @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02261702407849185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "att_out = np.zeros_like(v)\n",
    "for r in range(att_prob.shape[0]):\n",
    "    for c in range(att_prob.shape[1]):\n",
    "        # attn_output[:, i, :] +=  attn_values[:, i, j] * inputs[:, j, :] \n",
    "        att_out[r, :] += att_prob.iloc[r, c] * v.iloc[r, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random matrix stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create torch.linear layer\n",
    "# set seed\n",
    "torch.manual_seed(42)\n",
    "linear = torch.nn.Linear(6, 7, bias = False)\n",
    "# create inputs and attn_mask of shape batch, seq_len, 'hidden_size\n",
    "\n",
    "inputs = torch.randn(1, 3, 2)\n",
    "attn_mask = torch.ones(1, 3)\n",
    "# create attn values of shape batch, seq_len, seq_len\n",
    "attn_values = torch.randn(1, 3, 3)\n",
    "# make last sequence attn_values 0\n",
    "attn_values[:, :, -1] = 0\n",
    "# now matmul inputs with attn_values\n",
    "attn_output = torch.matmul(attn_values, inputs)\n",
    "\n",
    "# do same with numpy @ \n",
    "import numpy as np\n",
    "inputs_np = inputs.detach().numpy()\n",
    "attn_values_np = attn_values.detach().numpy()\n",
    "attn_output_np = attn_values_np @ inputs_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3514, -0.7906],\n",
       "        [-0.0915,  0.2352],\n",
       "        [ 2.2440,  0.5817]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4528,  0.6410,  0.0000],\n",
       "        [ 0.5567,  0.0744,  0.0000],\n",
       "        [-0.5687,  1.2580,  0.0000]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2178, -0.2072],\n",
       "         [-0.2025, -0.4227],\n",
       "         [ 0.0847,  0.7455]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.21777847, -0.2072228 ],\n",
       "        [-0.20247006, -0.4226767 ],\n",
       "        [ 0.08472988,  0.7454629 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4528)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_values[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35144043, -0.7906431 ],\n",
       "       [-0.09150922,  0.23517996],\n",
       "       [ 2.2439866 ,  0.5816687 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45276532,  0.6410112 ,  0.        ],\n",
       "       [ 0.55673623,  0.07442352,  0.        ],\n",
       "       [-0.56865716,  1.2580069 ,  0.        ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_values_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.217737714912, -0.2071717130952)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(0.4527 * -0.3514 + 0.6410112 * -0.09151 + 0.0 * 2.2439866), (0.4527 * -0.790643 + 0.6410112 * 0.235179 + 0.0 * 0.5816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2178)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs[0, 0,:][0] * attn_values[0, 0, 0] + inputs[0, 1,:][0] * attn_values[0, 0, 1] + inputs[0, 2,:][0] * attn_values[0, 0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5736)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs[0, 0, :][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8235)\n",
      "tensor(-0.4613)\n",
      "tensor(0.2052)\n"
     ]
    }
   ],
   "source": [
    "# get first element of dot product\n",
    "print((inputs[0, 0, :][0] * attn_values[0, 0, :][0]) + (inputs[0, 1, :][0] * attn_values[0, 0, :][1]) + (inputs[0, 2, :][0] * attn_values[0, 0, :][2]))\n",
    "# same for next\n",
    "print((inputs[0, 0, :][1] * attn_values[0, 1, :][0]) + (inputs[0, 1, :][1] * attn_values[0, 1, :][1]) + (inputs[0, 2, :][1] * attn_values[0, 1, :][2]))\n",
    "# keep going\n",
    "print((inputs[0, 0, :][2] * attn_values[0, 2, :][0]) + (inputs[0, 1, :][2] * attn_values[0, 2, :][1]) + (inputs[0, 2, :][2] * attn_values[0, 2, :][2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, j: 0\n",
      "inputs[:, j, :]:\n",
      " tensor([[-0.3514, -0.7906]])\n",
      "\n",
      "attn_values[:, i, j]:\n",
      " tensor([0.4528])\n",
      "\n",
      " result of the multiplication about to enter is:\n",
      " tensor([[-0.1591, -0.3580]])\n",
      "\n",
      "attn_output[:, i, :] before plus:\n",
      "tensor([[0., 0.]])\n",
      "\n",
      "i: 0, j: 1\n",
      "inputs[:, j, :]:\n",
      " tensor([[-0.0915,  0.2352]])\n",
      "\n",
      "attn_values[:, i, j]:\n",
      " tensor([0.6410])\n",
      "\n",
      " result of the multiplication about to enter is:\n",
      " tensor([[-0.0587,  0.1508]])\n",
      "\n",
      "attn_output[:, i, :] before plus:\n",
      "tensor([[-0.1591, -0.3580]])\n",
      "\n",
      "i: 0, j: 2\n",
      "inputs[:, j, :]:\n",
      " tensor([[2.2440, 0.5817]])\n",
      "\n",
      "attn_values[:, i, j]:\n",
      " tensor([0.])\n",
      "\n",
      " result of the multiplication about to enter is:\n",
      " tensor([[0., 0.]])\n",
      "\n",
      "attn_output[:, i, :] before plus:\n",
      "tensor([[-0.2178, -0.2072]])\n",
      "\n",
      "attn_output currently:\n",
      " tensor([[[-0.2178, -0.2072],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]]])\n",
      "i: 1, j: 0\n",
      "inputs[:, j, :]:\n",
      " tensor([[-0.3514, -0.7906]])\n",
      "\n",
      "attn_values[:, i, j]:\n",
      " tensor([0.5567])\n",
      "\n",
      " result of the multiplication about to enter is:\n",
      " tensor([[-0.1957, -0.4402]])\n",
      "\n",
      "attn_output[:, i, :] before plus:\n",
      "tensor([[0., 0.]])\n",
      "\n",
      "i: 1, j: 1\n",
      "inputs[:, j, :]:\n",
      " tensor([[-0.0915,  0.2352]])\n",
      "\n",
      "attn_values[:, i, j]:\n",
      " tensor([0.0744])\n",
      "\n",
      " result of the multiplication about to enter is:\n",
      " tensor([[-0.0068,  0.0175]])\n",
      "\n",
      "attn_output[:, i, :] before plus:\n",
      "tensor([[-0.1957, -0.4402]])\n",
      "\n",
      "i: 1, j: 2\n",
      "inputs[:, j, :]:\n",
      " tensor([[2.2440, 0.5817]])\n",
      "\n",
      "attn_values[:, i, j]:\n",
      " tensor([0.])\n",
      "\n",
      " result of the multiplication about to enter is:\n",
      " tensor([[0., 0.]])\n",
      "\n",
      "attn_output[:, i, :] before plus:\n",
      "tensor([[-0.2025, -0.4227]])\n",
      "\n",
      "attn_output currently:\n",
      " tensor([[[-0.2178, -0.2072],\n",
      "         [-0.2025, -0.4227],\n",
      "         [ 0.0000,  0.0000]]])\n",
      "i: 2, j: 0\n",
      "inputs[:, j, :]:\n",
      " tensor([[-0.3514, -0.7906]])\n",
      "\n",
      "attn_values[:, i, j]:\n",
      " tensor([-0.5687])\n",
      "\n",
      " result of the multiplication about to enter is:\n",
      " tensor([[0.1998, 0.4496]])\n",
      "\n",
      "attn_output[:, i, :] before plus:\n",
      "tensor([[0., 0.]])\n",
      "\n",
      "i: 2, j: 1\n",
      "inputs[:, j, :]:\n",
      " tensor([[-0.0915,  0.2352]])\n",
      "\n",
      "attn_values[:, i, j]:\n",
      " tensor([1.2580])\n",
      "\n",
      " result of the multiplication about to enter is:\n",
      " tensor([[-0.1151,  0.2959]])\n",
      "\n",
      "attn_output[:, i, :] before plus:\n",
      "tensor([[0.1998, 0.4496]])\n",
      "\n",
      "i: 2, j: 2\n",
      "inputs[:, j, :]:\n",
      " tensor([[2.2440, 0.5817]])\n",
      "\n",
      "attn_values[:, i, j]:\n",
      " tensor([0.])\n",
      "\n",
      " result of the multiplication about to enter is:\n",
      " tensor([[0., 0.]])\n",
      "\n",
      "attn_output[:, i, :] before plus:\n",
      "tensor([[0.0847, 0.7455]])\n",
      "\n",
      "attn_output currently:\n",
      " tensor([[[-0.2178, -0.2072],\n",
      "         [-0.2025, -0.4227],\n",
      "         [ 0.0847,  0.7455]]])\n"
     ]
    }
   ],
   "source": [
    "# (inputs[0, 0, :][0] * attn_values[0, 0, :][0]) + (inputs[0, 1, :][0] * attn_values[0, 0, :][1]) + (inputs[0, 2, :][0] * attn_values[0, 0, :][2])\n",
    "(inputs[0, 0, :][0] * attn_values[0, 0, :][0]) + (inputs[0, 1, :][0] * attn_values[0, 0, :][1]) + (inputs[0, 2, :][0] * attn_values[0, 0, :][2])\n",
    "\n",
    "\n",
    "# do this for all\n",
    "attn_output = torch.zeros(1, 3, 2)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        print(f\"i: {i}, j: {j}\")\n",
    "        print(f\"inputs[:, j, :]:\\n {inputs[:, j, :]}\\n\")\n",
    "        print(f\"attn_values[:, i, j]:\\n {attn_values[:, i, j]}\\n\")\n",
    "        print(f\" result of the multiplication about to enter is:\\n {inputs[:, j, :] * attn_values[:, i, j]}\\n\")\n",
    "        print(f\"attn_output[:, i, :] before plus:\\n{attn_output[:, i, :]}\\n\")\n",
    "        attn_output[:, i, :] +=  attn_values[:, i, j] * inputs[:, j, :] \n",
    "    print(f\"attn_output currently:\\n {attn_output}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2178, -0.2072],\n",
       "         [-0.2025, -0.4227],\n",
       "         [ 0.0847,  0.7455]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0., -0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs[:,2,:] * attn_values[:, i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_values[:, i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 3x2 matrix  \n",
    "A = torch.tensor([[1, 2],  \n",
    "                  [3, 4],\n",
    "                  [5, 6]]) \n",
    "\n",
    "# 3x3 matrix\n",
    "B = torch.tensor([[1, 0, 1],\n",
    "                  [0, 1, 0],\n",
    "                  [1, 0, 1]])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 8],\n",
       "        [3, 4],\n",
       "        [6, 8]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "B @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21777847, -0.2072228 ],\n",
       "       [-0.20247006, -0.4226767 ],\n",
       "       [ 0.08472988,  0.7454629 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_values_np @ inputs_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_1</th>\n",
       "      <td>0.402937</td>\n",
       "      <td>-1.700308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_2</th>\n",
       "      <td>2.288591</td>\n",
       "      <td>-1.089179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_3</th>\n",
       "      <td>2.064445</td>\n",
       "      <td>0.369130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            emb_0     emb_1\n",
       "token_1  0.402937 -1.700308\n",
       "token_2  2.288591 -1.089179\n",
       "token_3  2.064445  0.369130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "v = np.random.randn(3, 2)\n",
    "v = pd.DataFrame(v, columns=[f'emb_{i}' for i in range(v.shape[1])])\n",
    "v.index = ['token_1', 'token_2', 'token_3']\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_1</th>\n",
       "      <th>token_2</th>\n",
       "      <th>token_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token_1  token_2  token_3\n",
       "token_1        1        0        0\n",
       "token_2        0        1        0\n",
       "token_3        0        0        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "att_prob = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "att_prob = pd.DataFrame(att_prob, columns=['token_1', 'token_2', 'token_3'])\n",
    "att_prob.index = ['token_1', 'token_2', 'token_3']\n",
    "att_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_1</th>\n",
       "      <td>0.402937</td>\n",
       "      <td>-1.700308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_2</th>\n",
       "      <td>2.288591</td>\n",
       "      <td>-1.089179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_3</th>\n",
       "      <td>2.064445</td>\n",
       "      <td>0.369130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            emb_0     emb_1\n",
       "token_1  0.402937 -1.700308\n",
       "token_2  2.288591 -1.089179\n",
       "token_3  2.064445  0.369130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "att_prob @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02261702407849185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "att_out = np.zeros_like(v)\n",
    "for r in range(att_prob.shape[0]):\n",
    "    for c in range(att_prob.shape[1]):\n",
    "        # attn_output[:, i, :] +=  attn_values[:, i, j] * inputs[:, j, :] \n",
    "        att_out[r, :] += att_prob.iloc[r, c] * v.iloc[r, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "39nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bf09d40e77d3786deb49768c5a0e6c92c433b20cf5c332bc185780ac9d11fb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
